Authors,Author full names,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID,Domain
Warren P.; Boers F.; Grimshaw G.; Siyanova-Chanturia A.,"Warren, Paul (56067713700); Boers, Frank (57064106600); Grimshaw, Gina (7004267866); Siyanova-Chanturia, Anna (37068026400)",56067713700; 57064106600; 7004267866; 37068026400,THE EFFECT of GLOSS TYPE on LEARNERS' INTAKE of NEW WORDS during READING: EVIDENCE from EYE-TRACKING,2018,Studies in Second Language Acquisition,40,4,,883,906,23.0,48,10.1017/S0272263118000177,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057792849&doi=10.1017%2fS0272263118000177&partnerID=40&md5=261804bbc6da0bbeadb236fbb90a4603,"A reading experiment combining online and offline data evaluates the effect on second language learners' reading behaviors and lexical uptake of three gloss types designed to clarify word meaning. These are (a) textual definition, (b) textual definition accompanied by picture, and (c) picture only. We recorded eye movements while intermediate learners of English read a story presented on-screen and containing six glossed pseudowords repeated three times each. Cumulative fixation counts and time spent on the pseudowords predicted posttest performance for form recall and meaning recognition, confirming findings of previous eye-tracking studies of vocabulary acquisition from reading. However, the total visual attention given to pseudowords and glosses was smallest in the condition with picture-only glosses, and yet this condition promoted best retention of word meaning. This suggests that gloss types differentially influence learners' processing of novel words in ways that may elude the quantitative measures of attention captured by eye-tracking. Copyright © Cambridge University Press 2018.",,,Article,Final,,Scopus,2-s2.0-85057792849,Movies / Media
Stolzenwald J.; Mayol-Cuevas W.W.,"Stolzenwald, Janis (57201691691); Mayol-Cuevas, Walterio W. (6507899137)",57201691691; 6507899137,I Can See Your Aim: Estimating User Attention from Gaze for Handheld Robot Collaboration,2018,IEEE International Conference on Intelligent Robots and Systems,,,8594184,3897,3904,7.0,4,10.1109/IROS.2018.8594184,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062938326&doi=10.1109%2fIROS.2018.8594184&partnerID=40&md5=2bac5b4f70ffb8c5d035ef7c2878363e,"This paper explores the estimation of user attention in the setting of a cooperative handheld robot - a robot designed to behave as a handheld tool but that has levels of task knowledge. We use a tool-mounted gaze tracking system, which, after modelling via a pilot study, we use as a proxy for estimating the attention of the user. This information is then used for cooperation with users in a task of selecting and engaging with objects on a dynamic screen. Via a video game setup, we test various degrees of robot autonomy from fully autonomous, where the robot knows what it has to do and acts, to no autonomy where the user is in full control of the task. Our results measure performance and subjective metrics and show how the attention model benefits the interaction and preference of users. © 2018 IEEE.",,Eye tracking; Interactive computer graphics; Attention model; Full control; Gaze tracking system; Hand-held tools; Pilot studies; Robot autonomy; Task knowledge; User attention; Intelligent robots,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85062938326,Movies / Media
Chan C.Y.H.; Chan A.B.; Lee T.M.C.; Hsiao J.H.,"Chan, Cynthia Y. H. (57196235612); Chan, Antoni B. (14015159100); Lee, Tatia M. C. (7501437381); Hsiao, Janet H. (7101605473)",57196235612; 14015159100; 7501437381; 7101605473,Eye-movement patterns in face recognition are associated with cognitive decline in older adults,2018,Psychonomic Bulletin and Review,25,6,,2200,2207,7.0,67,10.3758/s13423-017-1419-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057245591&doi=10.3758%2fs13423-017-1419-0&partnerID=40&md5=7dcc009166a8875a46f1cb5e1773028e,"The Hidden Markov Modeling approach for eye-movement data analysis is able to quantitatively assess differences and similarities among individual patterns. Here we applied this approach to examine the relationships between eye-movement patterns in face recognition and age-related cognitive decline. We found that significantly more older than young adults adopted “holistic” patterns, in which most eye fixations landed around the face center, as opposed to “analytic” patterns, in which eye movements switched among the two eyes and the face center. Participants showing analytic patterns had better performance than those with holistic patterns regardless of age. Interestingly, older adults with lower cognitive status (as assessed by the Montreal Cognitive Assessment), particularly in executive and visual attention functioning (as assessed by Tower of London and Trail Making Tests) were associated with a higher likelihood of holistic patterns. This result suggests the possibility of using eye movements as an easily deployable screening assessment for cognitive decline in older adults. © 2017, Psychonomic Society, Inc.",Aging; Cognitive ability; Eye movement; Face recognition; Hidden Markov Model (HMM),"Adolescent; Adult; Aged; Aged, 80 and over; Aging; Cognitive Dysfunction; Executive Function; Facial Recognition; Female; Fixation, Ocular; Humans; Male; Young Adult; adolescent; adult; aged; aging; cognitive defect; executive function; eye fixation; facial recognition; female; human; male; pathophysiology; physiology; very elderly; young adult",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85057245591,Movies / Media
Navarro O.; Gonzalez A.L.; Molina A.I.,"Navarro, Oscar (57214505169); Gonzalez, Angel Luis (57205673495); Molina, Ana Isabel (34467788400)",57214505169; 57205673495; 34467788400,Experience of use of eye tracking technology with children who have attention problems,2018,"SIIE 2018 - 2018 International Symposium on Computers in Education, Proceedings",,,8586721,,,,1,10.1109/SIIE.2018.8586721,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061023802&doi=10.1109%2fSIIE.2018.8586721&partnerID=40&md5=81f16c5d57ed788b2c46d5634be0f39f,"The presence and need to integrate educational technology into the teaching process is becoming increasingly common in the pedagogical field. The presence of students who show difficulty focusing their attention on daily activities is also very common and can be an influencing factor on their academic performance. The objective of this research is to analyse the visual behaviour of fifth year primary education students with attention problems, and to assess the effect of this attention problems when different formats are presented. For this purpose, an eye tracking technique was used to record the differences that took place when students with and without attention difficulties were looking at a screen that presented images, text and videos. After analysing the data collected, it is concluded that there are some differences in the observation process of these students. In some cases there are only different observations when some formats (text and video) appear for the first time, while the main differences between the participating groups occur when the displayed contents contain images. © 2018 IEEE.",ADHD; attention problems; eye tracking; Primary Education,Students; Academic performance; ADHD; attention problems; Daily activity; Eye tracking technologies; Primary education; Teaching process; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85061023802,Movies / Media
Oda R.; Mizumatsu Y.; Kajinami T.,"Oda, Ryohei (57205472626); Mizumatsu, Yuto (57205468489); Kajinami, Tomoki (8506936800)",57205472626; 57205468489; 8506936800,An interface for post-match play-by-play analysis of a fighting game based on the two players' eye movements,2018,"SIGGRAPH Asia 2018 Posters, SA 2018",,,3283312,,,,1,10.1145/3283289.3283312,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060129998&doi=10.1145%2f3283289.3283312&partnerID=40&md5=5237235524b4af961de4b06f56a055cb,"In this paper, we propose an interface to support post-match play-by-play analysis of a hand-to-hand fighting game based on the two players' eye movements. In the domain of e-Sports, the ""fighting game"" genre refers to hand-to-hand combat games in which two players fight each other by manipulating their respective martial artist characters within the same game screen. An e-Sports match, like a professional chess match, is followed by analysis and commentary about the performance of the players. In this study, we constructed an interface for visualizing information about the match based on the players' eye movements to facilitate post-match play-by-play analysis and commentary. Our interface highlights commonalities and differences in the areas on the screen where the players focus their attention, as well as commonalities and differences in the direction of their eye movements. Copyright is held by the owner/author(s).",E-Sports; Eye movements; Fighting game; Play analysis,Interactive computer graphics; Sports; E-sports; Fighting games; Play analysis; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85060129998,Movies / Media
Ibrahim F.N.; Zin Z.M.; Ibrahim N.,"Ibrahim, Farah Nadia (57204889647); Zin, Zalhan Mohd (36730188700); Ibrahim, Norazlin (55432531800)",57204889647; 36730188700; 55432531800,Eye Center Detection Using Combined Viola-Jones and Neural Network Algorithms,2018,"International Symposium on Agents, Multi-Agent Systems and Robotics 2018, ISAMSR 2018",,,8540543,,,,5,10.1109/ISAMSR.2018.8540543,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059759363&doi=10.1109%2fISAMSR.2018.8540543&partnerID=40&md5=fca138267154845b64015ea2fd206368,"In eye tracking, calibration plays as a first crucial process towards detecting the eye. This process required the user's information to learn and maximize the accuracy of the eye tracking. Such that, various techniques can be used to detect and train eye gaze parameters. Thus, as the first step, the calibration points have been set on the user's screen display for the eye tracking process. The process of calibration is done by tracking the user's attention at 5 and 9 points of calibration process using a webcam. The circle detection of iris is used to determine the eye center coordinates. In this paper, the eye center coordinates are being extracted by using the well-known face detection algorithm which is Viola-Jones algorithm. Then, the coordinates will be trained as a data set for gaze location by using neural network algorithm. Results have shown that eye center can be well detected by using combination of both algorithms. © 2018 IEEE.",calibration; circle detection; eye center; eye tracking; neural network,Calibration; Face recognition; Multi agent systems; Neural networks; Robotics; Calibration points; Calibration process; Center detection; Circle detection; eye center; Face detection algorithm; Neural network algorithm; Viola - Jones algorithms; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85059759363,Movies / Media
Melnik A.; Schüler F.; Rothkopf C.A.; König P.,"Melnik, Andrew (57194009339); Schüler, Felix (57205186915); Rothkopf, Constantin A. (15078701200); König, Peter (7102563952)",57194009339; 57205186915; 15078701200; 7102563952,The world as an external memory: The price of saccades in a sensorimotor task,2018,Frontiers in Behavioral Neuroscience,12,,253,,,,22,10.3389/fnbeh.2018.00253,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058978498&doi=10.3389%2ffnbeh.2018.00253&partnerID=40&md5=431663984b4efdd9b65d87884969d1d8,"Theories of embodied cognition postulate that the world can serve as an external memory. This implies that instead of storing visual information in working memory the information may be equally retrieved by appropriate eye movements. Given this assumption, the question arises, how we balance the effort of memorization with the effort of visual sampling our environment. We analyzed eye-tracking data in a sensorimotor task where participants had to produce a copy of a LEGO®-blocks-model displayed on a computer screen. In the unconstrained condition, the model appeared immediately after eye-fixation on the model. In the constrained condition, we introduced a 0.7 s delay before uncovering the model. The model disappeared as soon as participants made a saccade outside of the Model Area. To successfully copy a model of 8 blocks participants made saccades to the Model Area on average 7.9 times in the unconstrained condition and 5.2 times in the constrained condition. However, the mean duration of a trial was 2.9 s (14%) longer in the constrained condition even when taking into account the delayed visibility of the model. In this study, we found evidence for an adaptive shift in subjects’ behavior toward memorization by introducing a price for a certain type of saccades. However, the response is not adaptive; it is maladaptive, as memorization leads to longer overall performance time. © 2018 Melnik, Schüler, Rothkopf and König.",Adaptive behavior; Embodied cognition; Eye-tracking; saccadic eye movements; Sensorimotor task; Short-term memory; Visual sampling; Working memory,adaptive behavior; adult; article; clinical article; controlled study; eye fixation; eye tracking; female; human; human experiment; male; saccadic eye movement; sampling; sensorimotor function; short term memory; visibility; working memory,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85058978498,Movies / Media
Colliot T.; Jamet É.,"Colliot, Tiphaine (57198815847); Jamet, Éric (7004278417)",57198815847; 7004278417,Understanding the effects of a teacher video on learning from a multimedia document: an eye-tracking study,2018,Educational Technology Research and Development,66,6,,1415,1433,18.0,59,10.1007/s11423-018-9594-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046545767&doi=10.1007%2fs11423-018-9594-x&partnerID=40&md5=0ac0f8d9c087a7d79e8fd9fba5024164,"The present study investigated the effects on students’ learning experience of adding a video of a teacher to an e-learning module. A total of 43 undergraduates were asked to learn the content of a pedagogical document either with or without a teacher video on the screen. Although video captures of teachers are increasingly being integrated into online courses, few studies have investigated their impact and the best way of optimizing them. According to the social-cue hypothesis, the presence of a teacher (face and gestures) positively influences learners’ motivation and engagement in their learning. By contrast, the interference hypothesis holds that the teacher’s presence can lead to poor performances, as it acts as a source of visual interference that diverts students’ attention away from the relevant information. By assessing subjective ratings and learning outcomes, the present study tended to support the social-cue hypothesis, as it showed that adding a teacher video on screen significantly improved students’ retention of the spoken explanations, without disturbing either their performances on diagram and transfer problems or the time needed to process the document. Eye-tracking data showed that students spent 25% of their time watching the teacher video. Adding this video had no significant observable effects on the subjective ratings (i.e., social presence, evaluation of the teacher’s motivational skills, situational interest, cognitive load). These results suggest that videos of teachers can be used to improve social cues in multimedia learning without creating interference effects. © 2018, Association for Educational Communications and Technology.",Cognitive load; Eye-tracking; Interference hypothesis; Multimedia learning; Social-cue hypothesis; Teacher video,,Article,Final,,Scopus,2-s2.0-85046545767,Movies / Media
Tang M.; Auffrey C.,"Tang, Ming (52464583400); Auffrey, Christopher (6506865112)",52464583400; 6506865112,"Advanced Digital Tools for Updating Overcrowded Rail Stations: Using Eye Tracking, Virtual Reality, and Crowd Simulation to Support Design Decision-making",2018,Urban Rail Transit,4,4,,249,256,7.0,15,10.1007/s40864-018-0096-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058847825&doi=10.1007%2fs40864-018-0096-2&partnerID=40&md5=a5a2b23ef7ced0cf02f4bd63d138f12f,"This paper describes an innovative integration of eye tracking (ET) with virtual reality (VR) and details the application of these combined technologies for the adaptive reuse redesign of the Wudaokou rail station in Beijing. The objective of the research is to develop a hybrid approach, combining ET and VR technologies, as part of an experimental study of how to improve wayfinding and pedestrian movement in crowded environments such as those found in urban subway stations during peak hours. Using ET analysis, design features such as edges, and color contrast are used to evaluate several proposed rail station redesigns. Through VR and screen-based ET, visual attention and related spatial responses are tracked and analyzed for the selected redesign elements. This paper assesses the potential benefits of using ET and VR to assist identification of station design elements that will improve wayfinding and pedestrian movement, and describes how the combination of VR and ET can influence the design process. The research concludes that the combination of VR and ET offers unique advantages for modeling how the design of rail transit hub interiors can influence the visual attention and movement behavior of those using the redesigned station. This is especially true for crowded conditions in complex interior spaces. The use of integrated ET and VR technology is shown to inform innovative design approaches for facilitating improved wayfinding and pedestrian movement within redesigned rail stations. © 2018, The Author(s).",Agent-based crowd simulation; Eye tracking; Signage; Urban rail station redesign; Virtual reality; Wayfinding,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85058847825,Movies / Media
Abdrabou Y.; Ismael S.; Khamis M.; Elmougy A.; Eisa R.M.,"Abdrabou, Yasmeen (57200212716); Ismael, Sherif (57193345198); Khamis, Mohamed (35243028400); Elmougy, Amr (16318622700); Eisa, Rana Mohamed (57199644986)",57200212716; 57193345198; 35243028400; 16318622700; 57199644986,eNGAGE: Resisting Shoulder surfing using Novel Gaze Gestures Authentication,2018,ACM International Conference Proceeding Series,,,,469,473,4.0,2,10.1145/3282894.3289741,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059991466&doi=10.1145%2f3282894.3289741&partnerID=40&md5=fd4e5cca1dde27e60cb0ad392202d478,"Most of the already existing authentication schemes are subject to multiple types of side-channel attacks such as shoulder surfing, smudge attacks, and thermal attacks. Meanwhile, motion sensors and eye trackers are becoming more accurate. We propose a novel authentication technique that leverages a combination of mid-air gestures and gaze input for shoulder surfing resilient authentication. The aim is to complicate shoulder surfing attacks by dividing the attacker’s attention onto 1) the user’s eyes, 2) hand-gestures, and 3) the screen. We report on the concept and implementation of the approach using both random and fixed layouts. © 2018 Association for Computing Machinery. All Rights Reserved.",Gaze; Gestures; Multimodal Authentication,Side channel attack; Authentication scheme; Authentication techniques; Gaze; Gestures; Motion sensors; Multimodal authentication; Shoulder surfing; Shoulder-surfing attacks; Authentication,Conference paper,Final,,Scopus,2-s2.0-85059991466,Movies / Media
John B.; Banerjee A.; Raiturkar P.; Jain E.,"John, Brendan (57205639875); Banerjee, Arunava (58829249000); Raiturkar, Pallavi (57193240475); Jain, Eakta (36715118000)",57205639875; 58829249000; 57193240475; 36715118000,An evaluation of pupillary light response models for 2D screens and VR HMDs,2018,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,3281538,,,,23,10.1145/3281505.3281538,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060940034&doi=10.1145%2f3281505.3281538&partnerID=40&md5=0f13eb73d5d1bb2a7acafcb88eea3bb3,"Pupil diameter changes have been shown to be indicative of user engagement and cognitive load for various tasks and environments. However, it is still not the preferred physiological measure for applied settings. This reluctance to leverage the pupil as an index of user engagement stems from the problem that in scenarios where scene brightness cannot be controlled, the pupil light response confounds the cognitive-emotional response. What if we could predict the light response of an individual’s pupil, thus creating the opportunity to factor it out of the measurement? In this work, we lay the groundwork for this research by evaluating three models of pupillary light response in 2D, and in a virtual reality (VR) environment. Our results show that either a linear or an exponential model can be fit to an individual participant with an easy-to-use calibration procedure. This work opens several new research directions in VR relating to performance analysis and inspires the use of eye tracking beyond gaze as a pointer and foveated rendering. © 2018 Association for Computing Machinery.",Eyetracking; Light response; Pupil dilation; Videos; Virtual reality,Virtual reality; Calibration procedure; Emotional response; Exponential models; Light response; Performance analysis; Physiological measures; Pupil dilation; Videos; Eye tracking,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85060940034,Movies / Media
Drewes H.; Khamis M.; Alt F.,"Drewes, Heiko (23392062600); Khamis, Mohamed (35243028400); Alt, Florian (27267528900)",23392062600; 35243028400; 27267528900,Smooth pursuit target speeds and trajectories,2018,ACM International Conference Proceeding Series,,,,139,146,7.0,18,10.1145/3282894.3282913,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059976647&doi=10.1145%2f3282894.3282913&partnerID=40&md5=66b4ef192f25d96411e6b4c660747dd8,"In this paper we present an investigation of how the speed and trajectory of smooth pursuits targets impact on detection rates in gaze interfaces. Previous work optimized these values for the specific application for which smooth pursuit eye movements were employed. However, this may not always be possible. For example UI designers may want to minimize distraction caused by the stimulus, integrate it with a certain UI element (e.g., a button), or limit it to a certain area of the screen. In these cases an in-depth understanding of the interplay between speed, trajectory, and accuracy is required. To achieve this, we conducted a user study with 15 participants who had to follow targets with different speeds and on different trajectories using their gaze. We evaluated the data with respect to detectability. As a result, we obtained reasonable ranges for target speeds and demonstrate the effects of trajectory shapes. We show that slow moving targets are hard to detect by correlation and that introducing a delay improves the detection rate for fast moving targets. Our research is complemented by design rules which enable designers to implement better pursuit detectors and pursuit-based user interfaces. © 2018 Association for Computing Machinery. All Rights Reserved.",Eye tracking; Pursuit detection; Smooth pursuits; Trajectories,Eye movements; Eye tracking; Speed; User interfaces; Detection rates; Different speed; Gaze interfaces; In-depth understanding; Slow-moving targets; Smooth pursuit; Smooth pursuit eye movement; Trajectory shapes; Trajectories,Conference paper,Final,,Scopus,2-s2.0-85059976647,Movies / Media
Eisenberg M.L.; Zacks J.M.; Flores S.,"Eisenberg, Michelle L. (54400888500); Zacks, Jeffrey M. (7003373705); Flores, Shaney (55533424300)",54400888500; 7003373705; 55533424300,Dynamic prediction during perception of everyday events,2018,Cognitive Research: Principles and Implications,3,1,53,,,,31,10.1186/s41235-018-0146-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064093340&doi=10.1186%2fs41235-018-0146-z&partnerID=40&md5=3fa9e2b085a5c6a1422ad4f7cda4c83a,"The ability to predict what is going to happen in the near future is integral for daily functioning. Previous research suggests that predictability varies over time, with increases in prediction error at those moments that people perceive as boundaries between meaningful events. These moments also tend to be points of rapid change in the environment. Eye tracking provides a method for noninterruptive measurement of prediction as participants watch a movie of an actor performing a series of actions. In two studies, we used eye tracking to study the time course of prediction around event boundaries. In both studies, viewers looked at objects that were about to be touched by the actor shortly before the objects were contacted, demonstrating predictive looking. However, this behavior was modulated by event boundaries: looks to to-be-contacted objects near event boundaries were less likely to be early and more likely to be late compared to looks to objects contacted within events. This result is consistent with theories proposing that event segmentation results from transient increases in prediction error. © 2018, The Author(s).",Event cognition; Eye tracking; Prediction,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85064093340,Movies / Media
Sibanda W.; Zhang Z.,"Sibanda, Wilbert (6506746895); Zhang, Zhongheng (36761802400)",6506746895; 36761802400,Application of eye-tracking technology to predict concentration on HIV campaigns among students in South Africa,2018,"Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018",,,8508415,988,994,6.0,1,10.1109/ASONAM.2018.8508415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057340492&doi=10.1109%2fASONAM.2018.8508415&partnerID=40&md5=41b0cd0a8c96c636054f468945b8ff89,"The aim of the study was to use eye-tracking data to predict students' concentration on both combined 'photo and text' and 'text only' HIV campaign messages. Eye-tracking was used to measure attention allocation processes to HIV campaigns. Each study participant completed a post-eye-tracking questionnaire to determine the recall of HIV messages and the relationship between eye-tracking measures with cognitive processing of HIV messages. In total, 60 students were randomly selected from Westville and Howard campuses of the University of KwaZulu-Natal, Durban, South Africa. A multivariate analysis of variance (MANOVA) test used to determine relationship between participants' ages, sex and educational level with gaze parameters, indicated that age had a statistically significant effect on measures of search and processing. Using Tukey's pair-wise post-hoc test, age was found to significantly affect the average saccade length and fixation/saccade ratio. The higher fixation/saccade ratio for male students, meant that males had more processing and less search activity than females. Mean fixation attention heat-maps, showed that younger students at high school, paid attention to only combined 'photo and text' messages, while university students, in addition to fixating on combined 'photo and text' messages, also paid significant attention to 'text only' messages. © 2018 IEEE.",Eye-tracking; Fixations; HIV; Saccades,"Eye movements; Multivariant analysis; Students; Allocation process; Cognitive processing; Durban , South Africa; Educational levels; Eye tracking technologies; Fixations; Multivariate analysis of variances; University students; Eye tracking",Conference paper,Final,,Scopus,2-s2.0-85057340492,Movies / Media
Knöll J.; Pillow J.W.; Huk A.C.,"Knöll, Jonas (23466784900); Pillow, Jonathan W. (7003670493); Huk, Alexander C. (6603186426)",23466784900; 7003670493; 6603186426,"Lawful tracking of visual motion in humans, macaques, and marmosets in a naturalistic, continuous, and untrained behavioral context",2018,Proceedings of the National Academy of Sciences of the United States of America,115,44,,E10486,E10494,8.0,21,10.1073/pnas.1807192115,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055668009&doi=10.1073%2fpnas.1807192115&partnerID=40&md5=c842cd691e35efff4850804cc8fd21d4,"Much study of the visual system has focused on how humans and monkeys integrate moving stimuli over space and time. Such assessments of spatiotemporal integration provide fundamental grounding for the interpretation of neurophysiological data, as well as how the resulting neural signals support perceptual decisions and behavior. However, the insights supported by classical characterizations of integration performed in humans and rhesus monkeys are potentially limited with respect to both generality and detail: Standard tasks require extensive amounts of training, involve abstract stimulus-response mappings, and depend on combining data across many trials and/or sessions. It is thus of concern that the integration observed in classical tasks involves the recruitment of brain circuits that might not normally subsume natural behaviors, and that quantitative analyses have limited power for characterizing single-trial or single-session processes. Here we bridge these gaps by showing that three primate species (humans, macaques, and marmosets) track the focus of expansion of an optic flow field continuously and without substantial training. This flow-tracking behavior was volitional and reflected substantial temporal integration. Most strikingly, gaze patterns exhibited lawful and nuanced dependencies on random perturbations in the stimulus, such that repetitions of identical flow movies elicited remarkably similar eye movements over long and continuous time periods. These results demonstrate the generality of spatiotemporal integration in natural vision, and offer a means for studying integration outside of artificial tasks while maintaining lawful and highly reliable behavior. © 2018 National Academy of Sciences. All rights reserved.",Eye tracking; Motion; Optic flow,Animals; Callithrix; Eye Movements; Humans; Macaca mulatta; Male; Motion Perception; Photic Stimulation; Young Adult; adult; animal behavior; animal experiment; Article; behavior; Callitrichinae; cognition; evidence based medicine; eye movement; eye tracking; gaze; human; Macaca; male; nonhuman; normal human; optic flow; priority journal; quantitative analysis; spatiotemporal analysis; vision; visual stimulation; young adult; animal; Callithrix; eye movement; movement perception; photostimulation; physiology; procedures; rhesus monkey,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85055668009,Movies / Media
Al-Moteri M.O.; Symmons M.; Cooper S.; Plummer V.,"Al-Moteri, Modi Owied (57191263572); Symmons, Mark (6603473749); Cooper, Simon (35433320600); Plummer, Virginia (6602481484)",57191263572; 6603473749; 35433320600; 6602481484,Inattentional blindness and pattern-matching failure: The case of failure to recognize clinical cues,2018,Applied Ergonomics,73,,,174,182,8.0,19,10.1016/j.apergo.2018.07.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051387676&doi=10.1016%2fj.apergo.2018.07.001&partnerID=40&md5=84428b6a1e52cf0a06ba1ad58dae894f,"Eye-tracking methodology was used to investigate lapses in the appropriate treatment of ward patients due to not noticing critical cues of deterioration. Forty nursing participants with different levels of experience participated in an interactive screen-based simulation of hypovolemic shock. The results show that 65% of the participants exhibited at least one episode of non-fixation on clinically relevant, fully visible cues that were in plain sight. Thirty-five percent of participants dwelt for sufficient time (>200 ms) on important cues for perception to take place, but no action followed, indicating they had pattern-matching failure. When participants fail to notice what, they should notice in patient status until it is too late, this can have serious consequences. Much work needs to be done, since these human perceptual limitations can affect patient safety in general wards. © 2018 Elsevier Ltd",Attention; Eye tracking; Inattentional blindness; Notice; Nursing; Patient safety; Pattern matching,"Adult; Attention; Awareness; Comprehension; Computer Simulation; Cues; Eye Movements; Female; Humans; Male; Middle Aged; Nursing Staff, Hospital; Perception; Shock; Young Adult; Eye protection; Nursing; Patient treatment; Pattern matching; Attention; Hypovolemic shock; Inattentional blindness; Notice; Patient safety; adult; Article; controlled study; eye tracking; female; human; hypovolemic shock; inattentional blindness; male; nurse; patient safety; pattern matching; pilot study; simulation; vision; association; attention; awareness; comprehension; computer simulation; eye movement; middle aged; nursing staff; perception; psychology; shock; young adult; Eye tracking",Article,Final,,Scopus,2-s2.0-85051387676,Movies / Media
Szajerman D.; Napieralski P.; Lecointe J.-P.,"Szajerman, Dominik (23398275300); Napieralski, Piotr (24481496100); Lecointe, Jean-Philippe (6507300413)",23398275300; 24481496100; 6507300413,Joint analysis of simultaneous EEG and eye tracking data for video images,2018,COMPEL - The International Journal for Computation and Mathematics in Electrical and Electronic Engineering,37,5,,1870,1884,14.0,9,10.1108/COMPEL-07-2018-0281,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054374050&doi=10.1108%2fCOMPEL-07-2018-0281&partnerID=40&md5=348bde762bc1b2f8365ffbb3d86815b6,"Purpose: Technological innovation has made it possible to review how a film cues particular reactions on the part of the viewers. The purpose of this paper is to capture and interpret visual perception and attention by the simultaneous use of eye tracking and electroencephalography (EEG) technologies. Design/methodology/approach: The authors have developed a method for joint analysis of EEG and eye tracking. To achieve this goal, an algorithm was implemented to capture and interpret visual perception and attention by the simultaneous use of eye tracking and EEG technologies. All parameters have been measured as a function of the relationship between the tested signals, which, in turn, allowed for a more accurate validation of hypotheses by appropriately selected calculations. Findings: The results of this study revealed a coherence between EEG and eye tracking that are of particular relevance for human perception. Practical implications: This paper endeavors both to capture and interpret visual perception and attention by the simultaneous use of eye tracking and EEG technologies. Eye tracking provides a powerful real-time measure of viewer region of interest. EEG technologies provides data regarding the viewer’s emotional states while watching the movie. Originality/value: The approach in this paper is distinct from similar studies because it takes into account the integration of the eye tracking and EEG technologies. This paper provides a method for determining a fully functional video introspection system. © 2018, Emerald Publishing Limited.",Applied electromagnetism; Condition monitoring; Control systems; Numerical analysis; Optimal design; Sensors,Condition monitoring; Control system analysis; Control systems; Electroencephalography; Electrophysiology; Image segmentation; Man machine systems; Numerical analysis; Sensors; Vision; Design/methodology/approach; Human perception; Optimal design; Real time measure; Region of interest; Simultaneous use; Technological innovation; Visual perception; Eye tracking,Article,Final,,Scopus,2-s2.0-85054374050,Movies / Media
Celine G.; Cho V.; Kogan A.; Anthonappa R.; King N.,"Celine, Gregory (57199166556); Cho, Vanessa (57203388334); Kogan, Alexandr (57203400513); Anthonappa, Robert (16241017100); King, Nigel (55454268600)",57199166556; 57203388334; 57203400513; 16241017100; 55454268600,Eye-tracking in dentistry: What do children notice in the dentist?,2018,Journal of Dentistry,78,,,72,75,3.0,12,10.1016/j.jdent.2018.08.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051495596&doi=10.1016%2fj.jdent.2018.08.006&partnerID=40&md5=20ad779bf2517aad6d92411b1dd96fd5,"Objectives: To determine, using eye-tracking technology, what children notice the most when they look at the dentist. Methods: A total of 41 children viewed 10 images of dentists of different genders and ethnicities, and wearing different attires, on a computer screen. Due to calibration issues with the eye tracking equipment, data from one child was excluded thus resulting in a final sample of 40 children (21 females; 19 males). Participants were aged 4–12 years. A Tobii X2-60 eye-tracking camera was used, which follows the location of participants’ gaze as they look at images on a screen. Areas of interest (AOI's) were pre-defined on each image (e.g. eyes, mouth, shirt). Other images were displayed between dentist images with no consecutive dentist images displayed. Number of participants to fixate and mean length of fixation for each AOI were measured. Results: Visual assessment illustrated that the dentist's face had the highest concentration of fixations, followed by attire. The circum-oral area has significantly more fixations than the eyes. The number of fixations and the mean length of fixation were both longer for the face than for the attire, and for the circum-oral area compared to the eyes. Distractors such as pens and ties exhibited more and longer fixations compared to images without distractors. Conclusions: Children fixated most on the dentist's face particularly the circum-oral area, followed by attire. Distractors were able to draw the children's gaze. Importantly, eye-tracking was an effective tool in assessing where children look on dentists’ images. Clinical significance: This research will provide an understanding of where children focus when they look at a dentist. This has not previously been known and will allow dentists to modify how they present themselves and interact with child patients. © 2018 Elsevier Ltd",Attire; Children; Dentist; Eye-tracking,"Attention; Child; Child, Preschool; Dentists; Eye Movements; Face; Female; Fixation, Ocular; Humans; Male; Mouth; Visual Perception; article; calibration; child; clinical article; clinical assessment; dentist; dentistry; ethnicity; eye tracking; female; gaze; gender; human; human tissue; male; mouth; preschool child; attention; eye fixation; eye movement; face; physiology; vision",Article,Final,,Scopus,2-s2.0-85051495596,Movies / Media
Kirkorian H.L.; Anderson D.R.,"Kirkorian, Heather L. (6505817429); Anderson, Daniel R. (9742427200)",6505817429; 9742427200,Effect of sequential video shot comprehensibility on attentional synchrony: A comparison of children and adults,2018,Proceedings of the National Academy of Sciences of the United States of America,115,40,,9867,9874,7.0,18,10.1073/pnas.1611606114,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054406754&doi=10.1073%2fpnas.1611606114&partnerID=40&md5=a3b93c4786ffba387b3d2380b0937990,"To comprehend edited video, viewers must infer the meaning conveyed by successive video shots (i.e., continuous video segments separated by edit points, such as camera cuts). The central question here was whether comprehension-related top-down cognitive processes drive eye movements during sequential processing of video montage. Eye movements were recorded as 4 year olds and adults (n = 62) watched a video with the same constituent shots in either normal or random sequence. The key analyses compared eye movements to constituent shots when presented in normal order with those to the same shots presented in random order. The dependent variable was attentional synchrony or the extent to which viewers looked at the same location at the same time, indicating commonality of processing the video. This was calculated as the bivariate contour ellipse area within which points of gaze fell during each video frame. Results indicated that children were more scattered in their gaze locations than adults. Viewers became more similar to each other as normal vignettes unfolded over time; this was especially true in adults and possibly reflects a growing and shared understanding of the content. Conversely, adult attentional synchrony was reduced when watching random shot sequences. Thus, attentional synchrony during normal video viewing is driven not only by salient visual features, such as movement and areas of high contrast, but also, by the unfolding sequential comprehension of video montage, especially in adults. Differences between children and adults indicate that this top-down control of eye movements while watching video changes systematically over development. © 2018 National Academy of Sciences. All Rights Reserved.",Cognition; Development; Eye movements; Sequential comprehension; Television,"Adult; Attention; Child, Preschool; Comprehension; Female; Fixation, Ocular; Humans; Male; Multimedia; age; age difference; Article; attention; attentional synchrony; bivariate contour ellipse area; cognition; comprehension; eye movement; hierarchical linear model; human; mathematical analysis; priority journal; random sequence; randomization; sequential video shot; videorecording; vision; watching random; adult; attention; clinical trial; comparative study; comprehension; eye fixation; female; male; multimedia; physiology; preschool child",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85054406754,Movies / Media
Dogan K.M.; Suzuki H.; Gunpinar E.,"Dogan, Kemal Mert (57196346133); Suzuki, Hiromasa (59983213300); Gunpinar, Erkan (18433861100)",57196346133; 59983213300; 18433861100,Eye tracking for screening design parameters in adjective-based design of yacht hull,2018,Ocean Engineering,166,,,262,277,15.0,19,10.1016/j.oceaneng.2018.08.026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051802736&doi=10.1016%2fj.oceaneng.2018.08.026&partnerID=40&md5=801dc2ef72725cba03c08e2bc22c7a2d,"Adjective-based design is a method that translates human perception into design parameters quantitatively in order to achieve better understanding between designers and clients. In this approach, adjectives are used to describe product designs, which are generated via design parameters in terms of geometry. As a requirement of the concept, relations between hull adjectives (e.g., comfortable and aesthetic) and design parameters (e.g., length and width) are learned via a machine-learning algorithm. Nevertheless, the relations cannot be represented by some of the design parameters, although they are in the learning process. This issue shows that the parameters do not impact the adjective choices but add noises to the learning process. Therefore, in this study, visual evaluations are made using eye tracking technology for screening the parameters based on their attractiveness and establishing relations between the attractive ones and the adjectives to enhance quality of the relation representations. Eye tracking is used in perceptual research, which proves the existence of correlations between gaze data and human preferences. The main advantage of eye tracking is that reliable human perception data can more likely be collected compared to the user tests, since the evaluation is based on subjects’ attention rather than applying solely questionnaires that are limited by the question content. In light of the benefits and finding, an eye tracking device is used to collect gaze data, and then, eye tracking tools such as Area of Interest (AOI), scan path, and heat map are used to evaluate attractiveness of the design parameters. Finally, regression analysis is used to represent relations between gaze data of design parameters and the adjectives. © 2018 Elsevier Ltd",Adjective-based design; Eye tracking; Generalized linear model (GLM); Human factor in design; Industrial design; Parametric design,Eye tracking; Learning algorithms; Machine learning; Parameter estimation; Quality control; Regression analysis; Surveys; Adjective-based design; Design parameters; Eye-tracking; Generalized linear model; Human factor in design; Human perception; Learning process; Parametric design; Screening design; algorithm; design; hull; machine learning; regression analysis; Product design,Article,Final,,Scopus,2-s2.0-85051802736,Movies / Media
Kaakinen J.K.; Ballenghein U.; Tissier G.; Baccino T.,"Kaakinen, Johanna K. (55917360500); Ballenghein, Ugo (57200412292); Tissier, Geoffrey (56027572700); Baccino, Thierry (6506451570)",55917360500; 57200412292; 56027572700; 6506451570,Fluctuation in cognitive engagement during reading: Evidence From Concurrent Recordings of Postural and Eye Movements,2018,Journal of Experimental Psychology: Learning Memory and Cognition,44,10,,1671,1677,6.0,25,10.1037/xlm0000539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041193759&doi=10.1037%2fxlm0000539&partnerID=40&md5=03d3228f674ea079c8750cd45ccf3c7a,"The present study utilized a novel methodological combination of eye tracking and postural movement recordings to study task-induced changes in cognitive engagement during expository text reading. Thirty-three participants read an expository text with a specific task in mind while their eye and postural movements were concurrently recorded, and after reading recalled the text from memory. The results showed that readers spent longer total fixation time and had better memory for task-relevant than irrelevant text information. During the course of reading, head-to-screen distance and the speed of head motion decreased more for relevant than irrelevant text segments. The results support the dynamic engagement hypothesis: there is task-induced fluctuation in cognitive engagement during reading. Moreover, the results suggest two types of engagement processes: transient and sustained engagement. The former refers to fast, momentary changes, whereas the latter refers to slower changes in the level of engagement observed across the reading task. The novel combination of eye and postural movement recordings proved to be useful in studying how readers embody the cognitive task demands during reading. © 2018 American Psychological Association.",Cognitive engagement; Eye movements; Postural movements; Reading,"Adult; Attention; Cognition; Eye Movements; Female; Head Movements; Humans; Male; Memory; Pattern Recognition, Visual; Posture; Reading; adult; attention; body position; cognition; eye movement; female; head movement; human; male; memory; pattern recognition; reading",Article,Final,,Scopus,2-s2.0-85041193759,Movies / Media
Rothe S.; Höllerer T.; Hußmann H.,"Rothe, Sylvia (57199996760); Höllerer, Tobias (8358959700); Hußmann, Heinrich (23389275800)",57199996760; 8358959700; 23389275800,CVR-Analyzer: A tool for analyzing cinematic virtual reality viewing patterns,2018,SUI 2018 - Proceedings of the Symposium on Spatial User Interaction,,,,171,,,0,10.1145/3267782.3274688,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058469856&doi=10.1145%2f3267782.3274688&partnerID=40&md5=157bfab215fb91e192d419080e952653,"Cinematic Virtual Reality (CVR) has been increasing in popularity over the last years. During our research on user attention in CVR, we encountered many analytic demands and documented potentially useful features. This led us to develop an analyzing tool for omnidirectional movies: the CVR-Analyzer. © 2018 Copyright is held by the owner/author(s).",360° movie; Cinematic Virtual Reality; Eye tracking; Head pose; Heatmaps; Omnidirectional movie,Eye tracking; Motion pictures; Head pose; Heatmaps; Omnidirectional movie; User attention; Virtual reality,Conference paper,Final,,Scopus,2-s2.0-85058469856,Movies / Media
Strickland J.C.; Marks K.R.; Beckmann J.S.; Lile J.A.; Rush C.R.; Stoops W.W.,"Strickland, Justin C. (55585838700); Marks, Katherine R. (35810581900); Beckmann, Joshua S. (8659707600); Lile, Joshua A. (7003286497); Rush, Craig R. (7101969531); Stoops, William W. (6603049193)",55585838700; 35810581900; 8659707600; 7003286497; 7101969531; 6603049193,Contribution of cocaine-related cues to concurrent monetary choice in humans,2018,Psychopharmacology,235,10,,2871,2881,10.0,13,10.1007/s00213-018-4978-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050653587&doi=10.1007%2fs00213-018-4978-5&partnerID=40&md5=1837933b8c113082ed292e94e8ef3939,"Rationale: Theoretical accounts highlight the importance of drug-related cues for the development and persistence of drug-taking behavior. Few studies have evaluated the ability of spatially contiguous drug cues to bias decisions between two concurrently presented non-drug reinforcers. Objective: Evaluate the contribution of spatially contiguous cocaine cues to choice between two concurrently presented monetary reinforcers Methods: Participants with cocaine use disorder completed a cued concurrent choice task. Two cues (one cocaine and one control image) were presented side-by-side followed by concurrent monetary offers below each image. Concurrent choice was measured for cocaine-side advantageous, equal, and disadvantageous concurrent monetary offers. The primary dependent measure was bias for selecting cocaine-cued monetary reinforcers. Three experiments tested selectivity of cocaine-cued bias in individuals with a cocaine use history (Experiment 1), replication when including additional control trials (Experiment 2), and a potential attentional mechanism evaluated using eye-tracking technology (Experiment 3). Results: Significant and robust cocaine-cued bias at equal monetary value was observed in three experiments (mean percent choice = 65–77%) and higher Drug Abuse Screening Test (DAST) scores were associated with greater cocaine-choice bias. These experiments demonstrated that cocaine-cued bias was (1) selective to individuals with a cocaine use history, (2) specific to trials involving a cocaine cue, and (3) partially associated with attentional bias. Conclusions: These experiments provide evidence that drug-related cues can influence choice and potentially promote maladaptive decision making during concurrent choice events. Future research evaluating prospective associations of drug-cued bias with drug-associated behaviors will help reveal the clinical relevance for substance use disorder. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.",Addiction; Conditioning; Cue; Drug; Salience,Adult; Attention; Choice Behavior; Cocaine; Cocaine-Related Disorders; Cues; Female; Humans; Male; Middle Aged; Photic Stimulation; Prospective Studies; Reward; cocaine; adult; Article; attention; clinical article; cocaine dependence; controlled study; decision making; Drug Abuse Screening Test; eye tracking; female; human; maladjustment; male; medical history; middle aged; money; priority journal; screening test; association; cocaine dependence; decision making; photostimulation; physiology; procedures; prospective study; psychology; reward,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85050653587,Movies / Media
Grainger S.A.; Henry J.D.; Naughtin C.K.; Comino M.S.; Dux P.E.,"Grainger, Sarah A. (57194713728); Henry, Julie D. (7403672085); Naughtin, Claire K. (39861952900); Comino, Marita S. (57204418172); Dux, Paul E. (7004246809)",57194713728; 7403672085; 39861952900; 57204418172; 7004246809,Implicit false belief tracking is preserved in late adulthood,2018,Quarterly Journal of Experimental Psychology,71,9,,1980,1987,7.0,15,10.1177/1747021817734690,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055466706&doi=10.1177%2f1747021817734690&partnerID=40&md5=74381973869a89f4cbbc73352beec9a4,"It is now well established that relative to their younger counterparts, older adults experience difficulties on tasks that require the conscious and explicit processing of others’ mental states (e.g., beliefs, intentions; theory of mind [ToM]). Despite the importance of relatively automatic and unconscious mental state attribution processes in everyday life, no study to date has tested whether tasks that require the implicit processing of others’ belief states also show age-related changes. In this study, younger and older adults completed an implicit false belief task, in which their eye movement patterns were monitored while they passively viewed true and false belief movies. In addition, they were assessed on measures of explicit ToM processing. While older adults showed impairments in explicit ToM processing relative to younger adults, both age groups demonstrated a similar capacity for implicit false belief processing. These findings suggest that implicit components of ToM are preserved in late adulthood and are consistent with dual process models of ageing that emphasise age-related stability in automatic processing and declines in more controlled and effortful cognitive operations. We discuss the potential implications of these findings for social interactions in old age. © Experimental Psychology Society 2017.",Eye-tracking; Implicit false belief tracking; Social cognition; ToM,"Adolescent; Adult; Age Factors; Aged; Aged, 80 and over; Aging; Eye Movement Measurements; Eye Movements; Female; Humans; Male; Photic Stimulation; Reading; Social Perception; Surveys and Questionnaires; Theory of Mind; Young Adult; adolescent; adult; age; aged; aging; eye movement; female; human; male; oculography; perception; photostimulation; physiology; questionnaire; reading; theory of mind; very elderly; young adult",Article,Final,,Scopus,2-s2.0-85055466706,Movies / Media
Murauer M.; Haslgrubler M.; Ferscha A.,"Murauer, Michaela (57200218858); Haslgrubler, Michael (35274999300); Ferscha, Alois (6701318941)",57200218858; 35274999300; 6701318941,Natural pursuits for eye tracker calibration,2018,ACM International Conference Proceeding Series,,,a3,,,,3,10.1145/3266157.3266207,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055620172&doi=10.1145%2f3266157.3266207&partnerID=40&md5=be6eaff108e56912e06614d0d18fe6a8,"Although, gaze-based interaction has been investigated since the 1980s and provides promising concepts to realize cognitive systems and support universal interaction within distributed environments, the main challenges, such as the Midas touch problem [16] or calibration are still frequent topics of research. In this work, Natural Pursuit Calibration is presented, which is a comfortable, unobtrusive technique enabling ongoing attention detection and eye tracker calibration within an off-screen context. The user is able to perform calibration, without a digital user interface, artificial annotation of the environment nor further assistance, by simply following any arbitrary moving target. Due to the characteristics of the calibration process, it can be executed simultaneously to any primary task, without active user participation. A two-stage evaluation process is conducted to (i) optimize parameter settings in a first setup and (ii) compare the accuracy as well as the user acceptance of the proposed procedure to prevailing calibration techniques. © 2018 Association for Computing Machinery.",Eye-Tracking; Gaze-based Interaction; Wearable Computing,Calibration; Cognitive systems; Pattern recognition; Petroleum reservoir evaluation; Stereo vision; User interfaces; Attention detection; Calibration process; Calibration techniques; Distributed environments; Gaze-based interaction; Midas touch problems; User participation; Wearable computing; Eye tracking,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85055620172,Movies / Media
Mann A.; Naveh I.; Zohary E.,"Mann, Alon (57202988934); Naveh, Ilana (57202990449); Zohary, Ehud (6701638657)",57202988934; 57202990449; 6701638657,On the superiority of visual processing in spatiotopic coordinates,2018,Vision Research,150,,,15,23,8.0,1,10.1016/j.visres.2018.06.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050073393&doi=10.1016%2fj.visres.2018.06.010&partnerID=40&md5=fa49f3ed0ba55b692bb728e09ccf07c4,"Organisms exploit spatiotemporal regularities in the environment to optimize goal attainment. For example, in experimental conditions, repetition of a stimulus at the same position speeds up response time. A recent study reported that this spatial priming occurs even when the eyes move between trials, indicating that the target is encoded in spatiotopic coordinates (Attention, Perception & Psychophysics 78, (2016) 114–132). However, in that study, the relevant position of the repeated stimulus eliciting spatiotopic priming, was always at the screen center. Using a similar paradigm, we find that reaction times for screen-centered targets are markedly shorter than for retinally-equidistant target positions. When this center preference is taken into account, the alleged spatiotopic priming effects are dramatically reduced, though not totally eliminated. In a second experiment, we show that the preferred central stimulus position is encoded in allocentric coordinates (e.g. screen position) rather than in an egocentric frame of reference (e.g. straight ahead). The better performance at the screen center, irrespective of gaze direction or seating position, is likely to reflect an optimal choice for the allocation of spatial attention. © 2018",Priming; Retinotopic; Screen center; Spatial attention; Spatiotopic; Straight ahead,Adult; Attention; Female; Humans; Male; Psychophysics; Reaction Time; Retina; Spatial Processing; Visual Fields; Young Adult; adult; Article; attention; controlled study; female; gaze; human; male; priority journal; reaction time; repetition priming; retina; spatiotemporal analysis; stimulus response; vision; visual field; visual system; young adult; physiology; psychophysics; spatial behavior,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85050073393,Movies / Media
Poletti B.; Carelli L.; Faini A.; Solca F.; Meriggi P.; Lafronza A.; Ciringione L.; Pedroli E.; Ticozzi N.; Ciammola A.; Cipresso P.; Riva G.; Silani V.,"Poletti, Barbara (16646951300); Carelli, Laura (25926814500); Faini, Andrea (23979799200); Solca, Federica (54385936000); Meriggi, Paolo (16175827600); Lafronza, Annalisa (56716478300); Ciringione, Luciana (57203572792); Pedroli, Elisa (55225670600); Ticozzi, Nicola (23062054500); Ciammola, Andrea (6505767145); Cipresso, Pietro (36717478000); Riva, Giuseppe (56962750600); Silani, Vincenzo (7006146949)",16646951300; 25926814500; 23979799200; 54385936000; 16175827600; 56716478300; 57203572792; 55225670600; 23062054500; 6505767145; 36717478000; 56962750600; 7006146949,The Arrows and Colors Cognitive Test (ACCT): A new verbal-motor free cognitive measure for executive functions in ALS,2018,PLoS ONE,13,8,e0200953,,,,20,10.1371/journal.pone.0200953,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052280341&doi=10.1371%2fjournal.pone.0200953&partnerID=40&md5=76734db6fae12d97866e55eed1276513,"Background and objective The presence of executive deficits in patients with Amyotrophic Lateral Sclerosis is well established, even if standardized measures are difficult to obtain due to progressive physical disability of the patients. We present clinical data concerning a newly developed measure of cognitive flexibility, administered by means of Eye-Tracking (ET) technology in order to bypass verbal-motor limitations. Methods 21 ALS patients and 21 age-and education-matched healthy subjects participated in an ET-based cognitive assessment, including a newly developed test of cognitive flexibility (Arrows and Colors Cognitive Test–ACCT) and other oculomotor-driven measures of cognitive functions. A standard screening of frontal and working memory abilities and global cognitive efficiency was administered to all subjects, in addition to a psychological self-rated assessment. For ALS patients, a clinical examination was also performed. Results ACCT successfully discriminated between patients and healthy controls, mainly concerning execution times obtained at different subtests. A qualitative analysis performed on error distributions in patients highlighted a lower prevalence of perseverative errors, with respect to other type of errors. Correlations between ACCT and other ET-based frontal-executive measures were significant and involved different frontal sub-domains. Limited correlations were observed between ACCT and standard ‘paper and pencil’ cognitive tests.; Conclusions The newly developed ET-based measure of cognitive flexibility could be a useful tool to detect slight frontal impairments in non-demented ALS patients by bypassing verbal-motor limitations through the oculomotor-driven administration. The findings reported in the present study represent the first contribution towards the development of a full verbal-motor free executive test for ALS patients. © 2018 Poletti et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Aged; Amyotrophic Lateral Sclerosis; Case-Control Studies; Cognition; Cognition Disorders; Color; Executive Function; Eye Movements; Female; Humans; Male; Memory, Short-Term; Middle Aged; Neuropsychological Tests; adult; article; clinical article; clinical assessment; clinical examination; controlled study; education; error; executive function; eye tracking; female; human; male; prevalence; qualitative analysis; working memory; aged; amyotrophic lateral sclerosis; case control study; cognition; cognitive defect; color; eye movement; middle aged; neuropsychological test; pathophysiology; physiology; psychology; short term memory",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85052280341,Movies / Media
Ishikawa M.; Itakura S.,"Ishikawa, Mitsuhiko (57193431831); Itakura, Shoji (7006345646)",57193431831; 7006345646,Observing others' gaze direction affects infants' preference for looking at gazing- or gazed-at faces,2018,Frontiers in Psychology,9,AUG,1503,,,,7,10.3389/fpsyg.2018.01503,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051601068&doi=10.3389%2ffpsyg.2018.01503&partnerID=40&md5=db43bcd824fd7fc16d2e6a0735553b6a,"Eye gaze is an important signal in social interactions, and it plays an important role to understand what others looking in joint attention (JA) situations. JA has been examined in situations involving two people gazing at objects; however, ecologically, infants observe not only faces that gaze at objects but also those that gaze at other people. Here, we examined how eye gaze directed toward another face affect face preferences in infants. A total of 19 children were observed during a JA situation and a no-JA situation. In the JA situation, an adult face in the central position of the screen shifted her gaze to look at another adult face at a lateral position on the screen. However, during the no JA situation, the central face shifted her eye gaze away from the adult face presented on the screen. At test, for the centrally presented faces, infant looking times were longer at faces in the no JA condition. At test, for the laterally presented faces, looking times were longer at the faces in the JA condition. Thus, the adult's eye gaze biased the duration of the gaze of the infants at either the central faces or the lateral-cued faces in the preferential looking tests. These results suggest that 10-month-old infants may interpret adult gazing behavior and that this can affect the gazing behavior of infants. © 2018 Ishikawa and Itakura.",Eye gaze; Eye tracking; Face preference; Joint attention; Preferential looking,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85051601068,Movies / Media
Anstis S.,"Anstis, Stuart (7006802779)",7006802779,Amodal Presence and the Bounce/Stream Illusion,2018,i-Perception,9,4,,,,,4,10.1177/2041669518791833,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052560495&doi=10.1177%2f2041669518791833&partnerID=40&md5=8912e4f689c361e4e5e3c5be34c1fc25,"Ambiguous bounce/stream collision points were hidden behind an occluder so that observers had to complete them amodally. In Movie 1, straight or curved static lines were painted on the occluder. In Movie 2, dotted textures flowed in straight or curved lines across the front of the occluder. In Movie 3, moving eyes, painted on the occluder, either moved in straight lines, as if tracking streaming spots, or else followed curved paths, as if tracking bouncing spots. The straight (or curved) lines, texture flow or eye movements led to judgments of streaming (or bouncing). These effects demonstrate the role of attention and expectations in disambiguating bounce/stream stimuli. © The Author(s) 2018.",amodal completion; attention; bounce/stream; motion,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85052560495,Movies / Media
Iskander J.; Jia D.; Hettiarachchi I.; Hossny M.; Saleh K.; Nahavandi S.; Best C.; Hosking S.; Rice B.; Bhatti A.; Hanoun S.,"Iskander, Julie (57193686489); Jia, Dawei (35483935100); Hettiarachchi, Imali (36717585800); Hossny, Mohammed (23667683300); Saleh, Khaled (57193135096); Nahavandi, Saeid (55992860000); Best, Christopher (30367594700); Hosking, Simon (26632187300); Rice, Benjamin (57207104616); Bhatti, Asim (12345621500); Hanoun, Samer (24780376000)",57193686489; 35483935100; 36717585800; 23667683300; 57193135096; 55992860000; 30367594700; 26632187300; 57207104616; 12345621500; 24780376000,Age-Related Effects of Multi-screen Setup on Task Performance and Eye Movement Characteristics,2018,"Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018",,,8616586,3480,3485,5.0,11,10.1109/SMC.2018.00589,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062243062&doi=10.1109%2fSMC.2018.00589&partnerID=40&md5=b9308b07712f591606a7bae18bc091d0,"Multi-screens or wide screen setup is becoming increasingly popular in many work places and training environments. However, there has been limited studies of their effect on human health and performance. In this study, we investigate individuals performance and eye movement characteristics while performing a visual task on multi-screen setup consisting of three monitors. During the task, subjects had to share their attention among three screens to identify the location of the visual stimulus and respond accordingly. Subjects' score was calculated based on validity of input to stimulus and response time, while fixation characteristics were investigated with respect to eye movements. The results show that the use of 3-screens added extra demand on the individual causing a decrease on the score and decrease in reaction time. In a further investigation, we found statistically significant negative correlation between the task score and the participant's age while a statistically significant positive correlation between the response time and the participant's age. In addition, the use of multi-screens to perform the tasks caused both fixation occurrences and duration to decrease, denoting an increased alertness since respond was given with less fixation duration and occurrences and less response time. © 2018 IEEE.",age; eye fixation behaviour; Eye movement; multi-screen; performance; response time; visual task,Age; Age-related; Eye fixation behavior; Eye fixations; Movement characteristics; Multi screens; Performance; Response time; Task performance; Visual tasks; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85062243062,Movies / Media
Shishkin S.L.; Velichkovsky B.M.; Melnichuk E.V.; Dubynin I.A.; Zhao D.G.; Isachenko A.V.,"Shishkin, Sergei L. (56624132800); Velichkovsky, Boris M. (57216017177); Melnichuk, Eugeny V. (57207104790); Dubynin, Ignat A. (55571045600); Zhao, Darisy G. (57207115216); Isachenko, Andrey V. (57196151192)",56624132800; 57216017177; 57207104790; 55571045600; 57207115216; 57196151192,The Pursuing Gaze Beats Mouse in Non-Pop-Out Target Selection,2018,"Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018",,,8616592,3518,3523,5.0,6,10.1109/SMC.2018.00595,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062244208&doi=10.1109%2fSMC.2018.00595&partnerID=40&md5=df0117b0c37f1145f78d8367aab63c36,"Demonstration of faster target selection by gaze compared to computer mouse so far was limited to targets attracting attention due to their visual saliency. This task, however, can be performed much faster with modern computer vision systems. Can gaze be faster than mouse in a more 'intentional' selection task: when targets and non-targets do not significantly differ by their visual features We propose that this may be the case when targets are moving at speeds beneficial for smooth pursuit eye movements. 16 healthy participants were asked to select 20 balls numbered 1 to 20 in numerical order. Balls were moving linearly at a screen in different directions at 12°/s speed. We compared selection made using a consumer grade eye tracker and a simple smooth pursuit detection algorithm with selection made using a computer mouse, either with clicks or pursuit. Compared to both mouse selection techniques, gaze selection was significantly faster and was experienced as more convenient by all participants. © 2018 IEEE.",computer mouse; eye tracking; gaze interaction; intention; selection; smooth pursuit,Eye movements; Mammals; Computer mouse; Computer vision system; Eye-tracking; Fast target; Gaze interaction; Intention; Selection; Smooth pursuit; Targets selection; Visual saliency; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85062244208,Movies / Media
Wang K.; Ji Q.,"Wang, Kang (56637259500); Ji, Qiang (18935108400)",56637259500; 18935108400,3D gaze estimation without explicit personal calibration,2018,Pattern Recognition,79,,,216,227,11.0,50,10.1016/j.patcog.2018.01.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044650376&doi=10.1016%2fj.patcog.2018.01.031&partnerID=40&md5=398ebfcd4005aa8dd4cd7e59246830a5,"Model-based 3D gaze estimation represents a dominant technique for eye gaze estimation. It allows free head movement and gives good estimation accuracy. But it requires a personal calibration, which may significantly limit its practical utility. Various techniques have been proposed to replace intrusive and subject-unfriendly calibration methods. In this paper, we introduce a new implicit calibration method that takes advantage of four natural constraints during eye gaze tracking. The first constraint is based on two complementary gaze estimation methods. The underlying assumption is that different gaze estimation methods, though based on different principles and mechanisms, ideally predict exactly the same gaze point at the same time. The second constraint is inspired by the well-known center prior principle, it is assumed that most fixations are concentrated on the center of the screen with natural viewing scenarios. The third constraint arises from the fact that for console based eye tracking, human's attention/gaze are always within the screen region. The final constraint comes from eye anatomy, where the value of eye parameters must be within certain regions. The four constraints are integrated jointly and help formulate the implicit calibration as a constrained unsupervised regression problem, which can be effectively solved through the proposed iterative hard EM algorithm. Experiments on two everyday interactions Web-browsing and Video-watching demonstrate the effectiveness of the proposed implicit calibration method. © 2018 Elsevier Ltd",Gaze estimation; Human computer interaction; Implicit calibration; Natural constraints,Calibration; Eye movements; Human computer interaction; Iterative methods; Calibration method; EM algorithms; Eye gaze tracking; Eye parameters; Gaze estimation; Model-based OPC; Natural constraints; Regression problem; Eye tracking,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85044650376,Movies / Media
Rothe S.; Hollerer T.; Hubmann H.,"Rothe, Sylvia (57199996760); Hollerer, Tobias (8358959700); Hubmann, Heinrich (57208693420)",57199996760; 8358959700; 57208693420,CVR-Analyzer: A Tool for Analyzing Cinematic Virtual Reality Viewing Patterns,2018,"Adjunct Proceedings - 2018 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2018",,,8699221,403,404,1.0,2,10.1109/ISMAR-Adjunct.2018.00117,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065550889&doi=10.1109%2fISMAR-Adjunct.2018.00117&partnerID=40&md5=514c83a33e08bf62add4aaab639d8fe1,"Cinematic Virtual Reality (CVR) has been increasing in popularity over the last years. In Cinematic Virtual Reality (CVR) the viewer watches omnidirectional movies using a head-mounted display or other VR devices. Thus, the viewer is positioned inside the scene, and can freely choose the direction of view. Accordingly, the viewer determines the visible section of the movie, and so it may happen that details, important for the story, are missed. During our research on user attention in CVR, we encountered many analytic demands and documented potentially useful features. This led us to developing an analyzing tool for omnidirectional movies: the CVR-Analyzer. © 2018 IEEE.",360° movie; Cinematic Virtual Reality; eye tracking; head pose; heatmaps; omnidirectional movie,Augmented reality; Eye tracking; Helmet mounted displays; Virtual reality; Head mounted displays; Head pose; Heatmaps; omnidirectional movie; User attention; Motion pictures,Conference paper,Final,,Scopus,2-s2.0-85065550889,Movies / Media
Chang C.-S.; Chen C.-M.; Lin Y.-C.,"Chang, Chin-Sheng (57212663963); Chen, Chih-Ming (56534408400); Lin, Yu-Chieh (57188964504)",57212663963; 56534408400; 57188964504,A Visual Interactive Reading System Based on Eye Tracking Technology to Improve Digital Reading Performance,2018,"Proceedings - 2018 7th International Congress on Advanced Applied Informatics, IIAI-AAI 2018",,,8693104,182,187,5.0,4,10.1109/IIAI-AAI.2018.00043,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065193468&doi=10.1109%2fIIAI-AAI.2018.00043&partnerID=40&md5=627fc233f15be44ea18a470b4f41e15a,"Developing attention-aware systems and interfaces based on eye tracking technology could revolutionize mainstream human-computer interaction to make that interaction between human beings and computers more effective and immersive than can be achieved traditionally using a computer mouse. This study proposes an eye-controlled interactive reading system (ECIRS) that uses human eyes instead of the traditional mouse to control digital text to support screen-based digital reading. This study uses a quasi-experimental design to examine the effects of an experimental group and a control group of learners who respectively used the ECIRS and a mouse-controlled interactive reading system (MCIRS) to support their reading of two types of English-language text online - pure text and Q & A type articles. Analytical results reveal that the reading comprehension of learners in the experimental group significantly exceeded that of those in the control group for the Q & A article, but the difference was insignificant for the pure text article. Moreover, the ECIRS improved the reading comprehension of field-independent learners more than it did that of field-dependent learners. Clearly, the proposed ECIRS supports deeper digital reading than does the MCIRS. © 2018 IEEE.",Digital reading; Eye tracking technology; Human computer interaction; Reading behavior analysis,Human computer interaction; Mammals; Analytical results; Behavior analysis; Digital reading; English languages; Experimental groups; Eye tracking technologies; Field independents; Reading comprehension; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85065193468,Movies / Media
Maruta J.; Spielman L.A.; Rajashekar U.; Ghajar J.,"Maruta, Jun (10439234200); Spielman, Lisa A. (7004206470); Rajashekar, Umesh (57198522057); Ghajar, Jamshid (7003903051)",10439234200; 7004206470; 57198522057; 7003903051,Association of visual tracking metrics with Post-Concussion Symptomatology,2018,Frontiers in Neurology,9,JUL,611,,,,25,10.3389/fneur.2018.00611,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050633207&doi=10.3389%2ffneur.2018.00611&partnerID=40&md5=0bff6e15b929050d748dbb9a200b4d86,"Attention impairment may provide a cohesive neurobiological explanation for clusters of clinical symptoms that occur after a concussion; therefore, objective quantification of attention is needed. Visually tracking a moving target is an attention-dependent sensorimotor function, and eye movement can be recorded easily and objectively to quantify performance. Our previous work suggested the utility of gaze-target synchronization metrics of a predictive visual tracking task in concussion screening and recovery monitoring. Another objectively quantifiable performance measure frequently suggested for concussion screening is simple visuo-manual reaction time (simple reaction time, SRT). Here, we used visual tracking and SRT tasks to assess changes between pre- and within-2-week post-concussion performances and explore their relationships to post-concussion symptomatology. Athletes participating in organized competitive sports were recruited. Visual tracking and SRT records were collected from the recruited athlete pool as baseline measures over a 4-year period. When athletes experienced a concussion, they were re-assessed within 2 weeks of their injury. We present the data from a total of 29 concussed athletes. Post-concussion symptom burden was assessed with the Rivermead Post-Concussion Symptoms Questionnaire and subscales of the Brain Injury Screening Questionnaire. Post-concussion changes in visual tracking and SRT performance were examined using a paired t-test. Correlations of changes in visual tracking and SRT performance to symptom burden were examined using Pearson's coefficients. Post-concussion changes in visual tracking performance were not consistent among the athletes. However, changes in several visual tracking metrics had moderate to strong correlations to symptom scales (r up to 0.68). On the other hand, while post-concussion SRT performance was reduced (p < 0.01), the changes in the performance metrics were not meaningfully correlated to symptomatology (r = 0.33). Results suggest that visual tracking performance metrics reflect clinical symptoms when assessed within 2 weeks of concussion. Evaluation of concussion requires assessments in multiple domains because the clinical profiles are heterogeneous. While most individuals show recovery within a week of injury, others experience prolonged recovery periods. Visual tracking performance metrics may serve as a biomarker of debilitating symptoms of concussion implicating attention as a root cause of such pathologies. © 2018 Maruta, Spielman, Rajashekar and Ghajar.",Closed head injury; Mild traumatic brain injury; Ocular pursuit; Predictive timing; Smooth pursuit,adolescent; adult; Article; athlete; clinical article; eye tracking; female; human; male; postconcussion syndrome; prediction; response time; sport injury; task performance,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85050633207,Movies / Media
Leveque L.; Bosmans H.; Cockmartin L.; Liu H.,"Leveque, Lucie (57195552369); Bosmans, Hilde (7005849463); Cockmartin, Lesley (36239682900); Liu, Hantao (55581726800)",57195552369; 7005849463; 36239682900; 55581726800,State of the art: Eye-Tracking studies in medical imaging,2018,IEEE Access,6,,,37023,37034,11.0,51,10.1109/ACCESS.2018.2851451,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049312400&doi=10.1109%2fACCESS.2018.2851451&partnerID=40&md5=ce8c3c6c0baf62edc9ade001a61ebdfd,"Eye-tracking - the process of measuring where people look in a visual field - has been widely used to study how humans process visual information. In medical imaging, eye-tracking has become a popular technique in many applications to reveal how visual search and recognition tasks are performed, providing information that can improve human performance. In this paper, we present a comprehensive review of eye-tracking studies conducted with medical images and videos for diverse research purposes, including the identification of the degree of expertise, development of training, and understanding and modeling of visual search patterns. In addition, we present our recent eye-tracking study that involves a large number of screening mammograms viewed by experienced breast radiologists. Based on the eye-tracking data, we evaluate the plausibility of predicting visual attention by computational models. © 2013 IEEE.",eye-tracking; image quality; Medical imaging; saliency; visual attention,Behavioral research; Computerized tomography; Diagnostic radiography; Flow visualization; Image quality; Job analysis; Mammography; Medical imaging; Quality control; Radiology; Computational model; Eye-tracking studies; Medical diagnostic imaging; saliency; Screening mammogram; Task analysis; Visual Attention; Visual information; Eye tracking,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85049312400,Movies / Media
Menges R.; Tamimi H.; Kumar C.; Walber T.; Schaefer C.; Staab S.,"Menges, Raphael (57192103839); Tamimi, Hanadi (57188846490); Kumar, Chandan (57192105487); Walber, Tina (54894287600); Schaefer, Christoph (57202892948); Staab, Steffen (7004053291)",57192103839; 57188846490; 57192105487; 54894287600; 57202892948; 7004053291,Enhanced representation of web pages for usability analysis with eye tracking,2018,Eye Tracking Research and Applications Symposium (ETRA),,,a18,,,,13,10.1145/3204493.3204535,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049686173&doi=10.1145%2f3204493.3204535&partnerID=40&md5=db8eaa447f424876feda1cbb25905a3f,"Eye tracking as a tool to quantify user attention plays a major role in research and application design. For Web page usability, it has become a prominent measure to assess which sections of a Web page are read, glanced or skipped. Such assessments primarily depend on the mapping of gaze data to a Web page representation. However, current representation methods, a virtual screenshot of the Web page or a video recording of the complete interaction session, suffer either from accuracy or scalability issues. We present a method that identifies fixed elements on Web pages and combines user viewport screenshots in relation to fixed elements for an enhanced representation of the page. We conducted an experiment with 10 participants and the results signify that analysis with our method is more efficient than a video recording, which is an essential criterion for large scale Web studies. © 2018 Copyright held by the owner/author(s).",Eye tracking; Viewport-relative elements; Web page usability,Video recording; Web Design; Websites; Representation method; Research and application; Scalability issue; Screenshots; Usability analysis; User attention; Eye tracking,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85049686173,Movies / Media
Wang H.; Pi J.; Qin T.; Shen S.; Shi B.E.,"Wang, Haofei (56809110800); Pi, Jimin (57195220788); Qin, Tong (57194712639); Shen, Shaojie (55325638900); Shi, Bertram E. (7402547071)",56809110800; 57195220788; 57194712639; 55325638900; 7402547071,SLAM-based localization of 3D gaze using a mobile eye tracker,2018,Eye Tracking Research and Applications Symposium (ETRA),,,a65,,,,41,10.1145/3204493.3204584,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049673814&doi=10.1145%2f3204493.3204584&partnerID=40&md5=d577a55a59834f1957c2cd0ded9a18f7,"Past work in eye tracking has focused on estimating gaze targets in two dimensions (2D), e.g. on a computer screen or scene camera image. Three-dimensional (3D) gaze estimates would be extremely useful when humans are mobile and interacting with the real 3D environment. We describe a system for estimating the 3D locations of gaze using a mobile eye tracker. The system integrates estimates of the user’s gaze vector from a mobile eye tracker, estimates of the eye tracker pose from a visual-inertial simultaneous localization and mapping (SLAM) algorithm, a 3D point cloud map of the environment from a RGB-D sensor. Experimental results indicate that our system produces accurate estimates of 3D gaze over a much larger range than remote eye trackers. Our system will enable applications, such as the analysis of 3D human attention and more anticipative human robot interfaces. © 2018 Copyright held by the owner/author(s).",3D Gaze Estimation; Eye Tracker; Human-Robot Interaction; Point Cloud; RGB-D camera; SLAM,Cameras; Eye movements; Human robot interaction; Robotics; Eye trackers; Gaze estimation; Point cloud; Rgb-d cameras; SLAM; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85049673814,Movies / Media
Dehghani C.; Frost S.; Jayasena R.; Masters C.L.; Kanagasingam Y.,"Dehghani, Cirous (24480737600); Frost, Shaun (49963364600); Jayasena, Rajiv (56040709500); Masters, Colin L. (35373080600); Kanagasingam, Yogesan (6506620581)",24480737600; 49963364600; 56040709500; 35373080600; 6506620581,Ocular biomarkers of Alzheimer’s disease: The role of anterior eye and potential future directions,2018,Investigative Ophthalmology and Visual Science,59,8,,3554,3563,9.0,28,10.1167/iovs.18-24694,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050333884&doi=10.1167%2fiovs.18-24694&partnerID=40&md5=93f3244fd9922a55cd3b876aacd2f6d2,"Globally, Alzheimer’s disease (AD) is a growing health and economic challenge that has no effective cure. Recent clinical trials indicate that preclinical treatment may be required but a routine screening tool for AD has been elusive. Hence, a simple, yet sensitive biomarker for preclinical AD, when the disease is most likely to be amenable to treatment, is lacking. Due to several features, the eye has been explored for this purpose and, among the ocular tissues, the retina has received the most attention. Currently, major works investigating the potential AD diagnosis by detecting amyloid-β (Aβ) signatures in the retinal tissue are underway, while the anterior eye is more accessible for in vivo imaging and examination. This report provides a concise review of current literature on the anterior eye components, including the crystalline lens, cornea, and aqueous humor, in AD. We also discuss the potential for assessment of the corneal nerve structure and regeneration as well as conjunctival tissue for AD-related alterations. The crystalline lens has received considerable attention, but further research is required to confirm whether Aβ accumulates in the lens and whether it mirrors brain neuropathologic changes, particularly in preclinical AD. The rich corneal neural network and conjunctival vasculature also merit exploration in future studies to shed light on their potential association with AD pathologic changes. © 2018 The Authors.",Alzheimer’s disease; Amyloid-β; Amyloid-β protein precursor; Anterior eye; Biomarker; Cornea; Crystalline lens; Dementia,"Alzheimer Disease; Amyloid beta-Peptides; Animals; Anterior Eye Segment; Aqueous Humor; Biomarkers; Cornea; Humans; Lens, Crystalline; amyloid beta protein; amyloid precursor protein; biological marker; messenger RNA; presenilin; amyloid beta protein; biological marker; age related macular degeneration; aging; Alzheimer disease; anterior eye chamber; aqueous humor; cerebrospinal fluid; chromosome 21; cornea; diabetes mellitus; diabetic retinopathy; Down syndrome; enzyme linked immunosorbent assay; epithelium basal cell; eye movement control; human; immunoblotting; immunohistochemistry; immunoreactivity; intraocular pressure; lens; nerve degeneration; nerve fiber degeneration; neuroectoderm; neuropathology; nonhuman; positron emission tomography; priority journal; protein expression; pseudoexfoliation; retina blood flow; Review; senile cataract; Alzheimer disease; animal; anterior eye segment; metabolism",Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85050333884,Movies / Media
Pilzer J.; Mahmud S.; Putnam V.; Liu X.; Munzner T.,"Pilzer, Jan (57208018602); Mahmud, Shareen (57190983623); Putnam, Vanessa (57207916120); Liu, Xinhong (57208017901); Munzner, Tamara (6603594088)",57208018602; 57190983623; 57207916120; 57208017901; 6603594088,GaRSIVis: Improving the predicting of self-interruption during reading using gaze data,2018,Proceedings - ETVIS 2018: Eye Tracking and Visualization,,,3205933,,,,0,10.1145/3205929.3205933,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063574748&doi=10.1145%2f3205929.3205933&partnerID=40&md5=d8844fda671d361b934d7ab64d101799,"Gaze pattern data provides a promising opportunity to create a predictive model of self-interruption during reading that could support active interventions to keep a reader's attention at times when self-interruptions are predicted to occur. We present two systems designed to help analysts create and improve such a model. We present GaRSIVis, (Gaze Reading Self-Interruption Visualizer), that integrates a visualization front-end suitable for data cleansing and a prediction back-end that can be run repeatedly as the input data is iteratively improved. It allows analysts refining the predictive model to filter out unwanted parts of the gaze data that should not be used in the prediction. It relies on data gathered by GaRSILogger, which logs gaze data and activity associated with interruptions during on-screen reading. By integrating data cleansing and our prediction results in our visualization, we enable analysts using GaRSIVis to come up with a comprehensible way of understanding self-interruption from gaze related features. © 2018 ACM.",Eye tracking; Log visualization; Reading tasks; Self-interruption,Data visualization; Forecasting; Visualization; Data cleansing; Input datas; Pattern datum; Predictive modeling; Reading tasks; Self-interruption; Visualization front end; Visualizers; Eye tracking,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85063574748,Movies / Media
Toreini P.; Langner M.; Maedche A.,"Toreini, Peyman (57202336455); Langner, Moritz (57202891667); Maedche, Alexander (6603610788)",57202336455; 57202891667; 6603610788,Use of attentive information dashboards to support task resumption in working environments,2018,Eye Tracking Research and Applications Symposium (ETRA),,,a92,,,,9,10.1145/3204493.3208348,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049673648&doi=10.1145%2f3204493.3208348&partnerID=40&md5=5e6248b23ea432cfd0b40b556ebec820,"Interruptions are known as one of the big challenges in working environments. Due to improper resuming the primary task, such interruptions may result in task resumption failures and negatively influence the task performance. This phenomenon also occurs when users are working with information dashboards in working environments. To address this problem, an attentive dashboard issuing visual feedback is developed. This feedback supports the user in resuming the primary task after the interruption by guiding the visual attention. The attentive dashboard captures visual attention allocation of the user with a low-cost screen-based eye-tracker while they are monitoring the graphs. This dashboard is sensitive to the occurrence of external interruption by tracking the eye-movement data in real-time. Moreover, based on the collected eye-movement data, two types of visual feedback are designed which highlight the last fixated graph and unnoticed ones. © 2018 Copyright held by the owner/author(s).",Attentive user interface; Interruption; Low-cost Eye-tracker; Task-resumption,Behavioral research; Eye tracking; User interfaces; Visual communication; Attentive user interfaces; Eye movement datum; Eye trackers; Interruption; Task performance; Task-resumption; Visual Attention; Working environment; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85049673648,Movies / Media
Dawson S.J.; Chivers M.L.,"Dawson, Samantha J. (55064612600); Chivers, Meredith L. (57207548217)",55064612600; 57207548217,The effect of static versus dynamic stimuli on visual processing of sexual cues in androphilic women and gynephilic men,2018,Royal Society Open Science,5,6,172286,,,,30,10.1098/rsos.172286,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048592983&doi=10.1098%2frsos.172286&partnerID=40&md5=fdbb424086de6f01723e77a00bf49eee,"Models of sexual response posit that attentional processing of sexual cues is requisite for sexual responding. Despite hypothesized similarities in the underlying processes resulting in sexual response, gender differences in sexual arousal patterns are abundant. One such gender difference relates to the stimulus features (e.g. gender cues, sexual activity cues) that elicit a response in men and women. In this study, we examined how stimulus modality (static visual images versus dynamic audiovisual films) and stimulus features (gender, sexual activity and nonsexual contextual cues) influences attentional (i.e. gaze) and elaborative (i.e. self-reported attraction (SRA), self-reported arousal) processing of sexual stimuli. Men’s initial and controlled attention was consistently gender-specific (i.e. greater attention towards female targets), and this was not influenced by stimulus modality or the presence of sexual activity cues. By contrast, gender-specificity of women’s attention patterns differed as a function of attentional stage, stimulus modality and the features within the stimulus. Degree of specificity was positively predictive of SRA in both genders; however, it was not significantly predictive of self-reported arousal. These findings are discussed in the context of gendered processing of visual sexual information, including a discussion of implications for research designs. © 2018 The Authors.",Attention; Eye tracking; Gender difference; Gender-specificity; Sexual arousal; Sexual interest,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85048592983,Movies / Media
Mohamed A.A.,"Mohamed, Ayman A. (57194398502)",57194398502,EXPOSURE FREQUENCY in L2 READING: AN EYE-MOVEMENT PERSPECTIVE of INCIDENTAL VOCABULARY LEARNING,2018,Studies in Second Language Acquisition,40,2,,269,293,24.0,79,10.1017/S0272263117000092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019932673&doi=10.1017%2fS0272263117000092&partnerID=40&md5=2163fbc9e88cbacd10cbe3fa888dded5,"The present study brings together methods of extensive reading studies and eye-movement research to track the cognitive effects of exposure frequency on vocabulary processing and learning. Forty-two advanced second language learners of English read a stage 1 graded reader, Goodbye Mr. Hollywood, on a computer screen while their eye movements were recorded. The eye-tracking task was followed by comprehension questions and vocabulary posttests. Target vocabulary consisted of 20 pseudo words and 20 known words with a range of repetition from 1 to 30. Eye-movement data showed that readers spent more time on pseudo words than on familiar words and that fixation times decreased across encounters with more attention given to target words on early encounters. Repeated exposure supported form recognition but was not as significant for meaning recall and recognition. Total times spent on each encounter was positively associated with learning success in all vocabulary measures. The amount of attention, as reflected in total reading times on each pseudo word, positively predicted learning outcomes above and beyond the number of encounters. Results of the study add a cognitive dimension to the concept of engagement in lexical learning in the process of incidental learning from second language reading. © 2017 Cambridge University Press.",,,Article,Final,,Scopus,2-s2.0-85019932673,Movies / Media
Kumar A.; Burch M.; Mueller K.,"Kumar, Ayush (57202315472); Burch, Michael (36927991800); Mueller, Klaus (55366200700)",57202315472; 36927991800; 55366200700,Visual analysis of eye gazes to assist strategic planning in computer games,2018,Proceedings - ETVIS 2018: Eye Tracking and Visualization,,,3205935,,,,6,10.1145/3205929.3205935,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063572332&doi=10.1145%2f3205929.3205935&partnerID=40&md5=f54c80efb59b2712208a643bcef8064d,"This work studies the use of a conventional eye tracking system for analysis of an online game player's thinking processes. For this purpose, the eye gaze data of several users playing a simple online turn-based checkers game were recorded and made available in real-time to gaze-informed players. The motivation behind this work is to determine if making the eye-gaze data available can help these players to predict the gaze-tracked opponent player's further moves, and also how this can be most effectively done. We also tested different orientations of the screen on which the gaze data were displayed. By our visual and algorithmic analysis we validated (1) that prediction is possible and (2) that accuracy highly depends on the moves of players throughout the game as well as on the screen orientation. We believe that our study has implications on visual problem solving in general, especially in collaborative scenarios. © 2018 ACM.",Cognition; Eye gazes; Eye-tracking; Heat map; Visual analytics; Visualization,Computer games; Flow visualization; Interactive computer graphics; Problem solving; Visualization; Algorithmic analysis; Cognition; Eye tracking systems; Eye-gaze; Heat maps; Thinking process; Visual analysis; Visual analytics; Eye tracking,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85063572332,Movies / Media
Pauchet S.; Letondal C.; Vinot J.-L.; Causse M.; Cousy M.; Becquet V.; Crouzet G.,"Pauchet, Sylvain (57193317412); Letondal, Catherine (9132416200); Vinot, Jean-Luc (8425613100); Causse, Mickaël (35084804500); Cousy, Mathieu (57190617327); Becquet, Valentin (57202023580); Crouzet, Guillaume (57204000771)",57193317412; 9132416200; 8425613100; 35084804500; 57190617327; 57202023580; 57204000771,GazeForm: Dynamic gaze-adaptive touch surface for eyes-free interaction in airliner cockpits,2018,DIS 2018 - Proceedings of the 2018 Designing Interactive Systems Conference,,,,1193,1206,13.0,25,10.1145/3196709.3196712,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054036305&doi=10.1145%2f3196709.3196712&partnerID=40&md5=c5eafdd1cdb740215b427c7cf8902f13,"An increasing number of domains, including aeronautics, are adopting touchscreens. However, several drawbacks limit their operational use, in particular, eyes-free interaction is almost impossible making it difficult to perform other tasks simultaneously. We introduce GazeForm, an adaptive touch interface with shape-changing capacity that offers an adapted interaction modality according to gaze direction. When the user's eyes are focused on interaction, the surface is flat and the system acts as a touchscreen. When eyes are directed towards another area, physical knobs emerge from the surface. Compared to a touch only mode, experimental results showed that GazeForm generated a lower subjective mental workload and a higher efficiency of execution (20% faster). Furthermore, GazeForm required less visual attention and participants were able to concentrate more on a secondary monitoring task. Complementary interviews with pilots led us to explore timings and levels of control for using gaze to adapt modality. © 2018 Association for Computing Machinery.",Adaptive interfaces; Critical contexts; Eye-tracking; Eyes-free interaction; Shape-changing interfaces; TEI; Touchscreens,Behavioral research; Fighter aircraft; Touch screens; Adaptive interface; Critical contexts; Eyes-free interaction; Higher efficiency; Operational use; Secondary monitoring; Touch interfaces; Visual Attention; Eye tracking,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85054036305,Movies / Media
Koo B.-Y.; Jang M.-H.; Kim Y.-C.; Mah K.-C.,"Koo, Bon-Yeop (57201393212); Jang, Man-Ho (57201399049); Kim, Young-Chul (57219206370); Mah, Ki-Choong (24076496600)",57201393212; 57201399049; 57219206370; 24076496600,Changes in the subjective fatigue and pupil diameters induced by watching LED TVs,2018,Optik,164,,,701,710,9.0,16,10.1016/j.ijleo.2018.03.077,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044591886&doi=10.1016%2fj.ijleo.2018.03.077&partnerID=40&md5=a8210f354993d4c8530a0b2a7cec4237,"To assess the changes in subjective fatigue and pupil diameters while watching two different videos in different viewing conditions such as the screen luminosity and the display forms. A total of 108 subjects were participated in this study. The pupil diameter of the participants was measured by an eye tracker while the subjects watched one of the two different videos in different viewing conditions. The subjective fatigue of each subject was measured by a questionnaire conducted before and after watching the videos. The relative effects of the viewing conditions on the pupil diameters showed significant correlations in both screen luminosity and display forms (p < 0.05). The levels of subjective fatigue increased after watching the videos, compared to those before watching them, and the young subjects significantly felt more tired (p < 0.05). Changes in the subjective fatigue and pupil diameters during watching videos on LED TVs were different according to the display forms, the screen luminosity and videos. However, the pupil diameters decreased with a pattern of regression in the linear and third-order polynomial expressions in process of viewing time. The present study suggests a further study with a detailed analysis is needed to prove these findings. © 2018 Elsevier GmbH",Curved display; Eye tracking device; LED TV; Pupil diameter,Display devices; Eye tracking; Luminance; Eye trackers; Eye tracking devices; In-process; Pupil diameter; Relative effects; Third order; Viewing conditions; Light emitting diodes,Article,Final,,Scopus,2-s2.0-85044591886,Movies / Media
Menges R.; Walber T.; Tamimi H.; Schaefer C.; Kumar C.; Staab S.,"Menges, Raphael (57192103839); Walber, Tina (54894287600); Tamimi, Hanadi (57188846490); Schaefer, Christoph (57202892948); Kumar, Chandan (57192105487); Staab, Steffen (7004053291)",57192103839; 54894287600; 57188846490; 57202892948; 57192105487; 7004053291,Enhanced representation of web pages for usability analysis with eye tracking,2018,Eye Tracking Research and Applications Symposium (ETRA),,,a96,,,,3,10.1145/3204493.3214308,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049670036&doi=10.1145%2f3204493.3214308&partnerID=40&md5=e0fa1097e9beaa8bc8a137a227a32e7f,"Eye tracking as a tool to quantify user attention plays a major role in research and application design. For Web page usability, it has become a prominent measure to assess which sections of a Web page are read, glanced or skipped. Such assessments primarily depend on the mapping of gaze data to a Web page representation. However, current representation methods, a virtual screenshot of the Web page or a video recording of the complete interaction session, suffer either from accuracy or scalability issues. We present a method that identifies fixed elements on Web pages and combines user viewport screenshots in relation to fixed elements for an enhanced representation of the page. We conducted an experiment with 10 participants and the results signify that analysis with our method is more efficient than a video recording, which is an essential criterion for large scale Web studies. © 2018 Copyright held by the owner/author(s).",Eye tracking; Viewport-relative elements; Web page usability,Video recording; Web Design; Websites; Representation method; Research and application; Scalability issue; Screenshots; Usability analysis; User attention; Eye tracking,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85049670036,Movies / Media
Chen C.-C.; Lin Y.-S.,"Chen, Chun-Ching (36536757100); Lin, Yi-Sin (57203017440)",36536757100; 57203017440,Study on the interactive interface design of gaze input smart TV,2018,"Proceedings of 4th IEEE International Conference on Applied System Innovation 2018, ICASI 2018",,,,196,199,3.0,5,10.1109/ICASI.2018.8394566,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050283080&doi=10.1109%2fICASI.2018.8394566&partnerID=40&md5=1041b7ef4ff0306c27d939d25fd3a7fb,"In recent years, using eye movements as an input method to control smart TVs remotely has been gaining attention. In the past, eye control was mostly applied to assistive devices for specific ethnic groups due to the high cost. However, it is gradually being applied to computer games as well. This study summarizes the principles of interface design by analyzing the existing eye-controlled interfaces and attempts to apply it to the operation and interface design of smart TVs. Finally, based on heuristic evaluation by experts, the study explored the feasibility of applying eye control to smart TV operation and proposed a design of the eye control interface suitable for smart TVs. © 2018 IEEE.",Eye Tracking; Gaze Input; User Interface and Smart TV,Computer games; Eye movements; User interfaces; Assistive devices; Ethnic groups; Gaze Input; Heuristic evaluation; Input methods; Interactive interfaces; Interface designs; Smart-TV; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85050283080,Movies / Media
Iskander J.; Hettiarachchi I.; Hanoun S.; Hossny M.; Nahavandi S.; Bhatti A.,"Iskander, J. (57193686489); Hettiarachchi, I. (36717585800); Hanoun, S. (24780376000); Hossny, M. (23667683300); Nahavandi, S. (55992860000); Bhatti, A. (12345621500)",57193686489; 36717585800; 24780376000; 23667683300; 55992860000; 12345621500,A classifier approach to multi-screen switching based on low cost eye-trackers,2018,"12th Annual IEEE International Systems Conference, SysCon 2018 - Proceedings",,,,1,6,5.0,6,10.1109/SYSCON.2018.8369597,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048863536&doi=10.1109%2fSYSCON.2018.8369597&partnerID=40&md5=1fe1db0fbaeb2a796a4c290927b93fee,"During the past few years, research using eye movements has moved from controlled laboratory setup to the more complex natural task environments. In natural environments, the subjects will adopt to the dynamic environments, and this will involve head movements and various other pose interactions. Thus, in studies such as in visual perception, vigilance and fatigue the assessment paradigms should account for complex environments. The study presented in this paper addresses one such complex problem of using multiple low cost eye-trackers in a task using multiple computer screens. When using multiple screens in order to accurately record the eye tracking data the eye-trackers need to switch between eye-trackers depending on the head orientation with respect to the eye-trackers' field of view. Here, we present a classification-based switching mechanism for three eye-trackers. The proposed approach has given a higher accuracy of screen detection compared to the built-in switching mechanism of the eye-trackers under a natural task condition. © 2018 IEEE.",Classification; Eye tracking; Gazepoint; Head movement; Multiscreen; Multitracker,,Conference paper,Final,,Scopus,2-s2.0-85048863536,Movies / Media
Raikes A.C.; Schaefer S.Y.; Studenka B.E.,"Raikes, Adam C. (56741048000); Schaefer, Sydney Y. (7103168856); Studenka, Breanna E. (23104013100)",56741048000; 7103168856; 23104013100,Concussion history is negatively associated with visual-motor force complexity: evidence for persistent effects on visual-motor integration,2018,Brain Injury,32,6,,747,754,7.0,2,10.1080/02699052.2018.1444204,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042944873&doi=10.1080%2f02699052.2018.1444204&partnerID=40&md5=ec3ae348c26faedf161ad7180c137648,"Objectives: Long-term monitoring of concussion recovery requires time- and cost-effective methods. Physiologic complexity may be useful in evaluating visual-motor integration following concussion. The purpose of this study was to quantify the extent to which prior number of concussions influenced visual-motor tracking force complexity. Methods: Thirty-five individuals with a self-reported concussion history (age: 20.92 ± 1.98) and 15 without (age: 20.92 ± 2.21) performed an isometric visual-motor tracking task, using index finger force to trace a straight line across a computer screen. Finger force root mean square error (RMSE), multi-scale complexity, and average power from 0 to 12 Hertz (Hz) were calculated. Individual multiple regressions were fit to these outcomes. Results: Force complexity decreased linearly with an increasing number of concussions (R2 = 0.101). Males had more complex force overall (R2 = 0.219) and greater 4–8 Hz average power (R2 = 0.193). The 8–12 Hz average power decreased significantly for individuals with prior loss of consciousness (LOC) and increasing numbers of concussions (R2 = 0.143). Conclusion: Individuals exhibited linear decreases in visual-motor tracking force complexity with increasing numbers of concussions, influenced by both gender and a history of LOC. These findings indicate cumulative changes in the ways in which previously concussed individuals process and integrate visual information to guide behaviour. © 2018 Taylor & Francis Group, LLC.",Concussion; mild traumatic brain injury; multi-scale complexity; visual-motor tracking,"Adolescent; Adult; Brain Concussion; Cognition Disorders; Feedback, Sensory; Female; Humans; Male; Neurologic Examination; Neuropsychological Tests; Psychomotor Disorders; Psychomotor Performance; Self Report; Young Adult; adult; Article; brain concussion; clinical article; clinical assessment; disease association; evidence based practice; eye tracking; female; force; human; index finger; male; medical history; outcome assessment; self report; sensorimotor function; unconsciousness; visual information; visual motor force complexity; visual motor integration; visual motor tracking task; visuomotor coordination; adolescent; brain concussion; cognitive defect; complication; neurologic examination; neuropsychological test; physiology; psychomotor disorder; psychomotor performance; sensory feedback; young adult",Article,Final,,Scopus,2-s2.0-85042944873,Movies / Media
Otoom M.; Alzubaidi M.A.,"Otoom, Mwaffaq (26424765100); Alzubaidi, Mohammad A. (35174245000)",26424765100; 35174245000,Ambient intelligence framework for real-time speech-to-sign translation,2018,Assistive Technology,30,3,,119,132,13.0,15,10.1080/10400435.2016.1268218,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011568212&doi=10.1080%2f10400435.2016.1268218&partnerID=40&md5=4c63edd9009b115b07f3c9a4a4091e5a,"Sign language can be used to facilitate communication with and between deaf or hard of hearing (Deaf/HH). With the advent of video streaming applications in smart TVs and mobile devices, it is now possible to use sign language to communicate over worldwide networks. In this article, we develop a prototype assistive device for real-time speech-to-sign translation. The proposed device aims at enabling Deaf/HH people to access and understand materials delivered in mobile streaming videos through the applications of pipelined and parallel processing for real-time translation, and the application of eye-tracking based user-satisfaction detection to support dynamic learning to improve speech-to-signing translation. We conduct two experiments to evaluate the performance and usability of the proposed assistive device. Nine deaf people participated in these experiments. Our real-time performance evaluation shows the addition of viewer’s attention-based feedback reduced translation error rates by 16% (per the sign error rate [SER] metric) and increased translation accuracy by 5.4% (per the bilingual evaluation understudy [BLEU] metric) when compared to a non-real-time baseline system without these features. The usability study results indicate that our assistive device was also pleasant and satisfying to deaf users, and it may contribute to greater engagement of deaf people in day-to-day activities. © 2018 RESNA.",assistive devices; deaf; hard of hearing persons; machine learning; satisfaction; sign language; smartphones; streaming videos,Adolescent; Adult; Algorithms; Artificial Intelligence; Communication Aids for Disabled; Female; Humans; Internet; Male; Natural Language Processing; Patient Satisfaction; Persons With Hearing Impairments; Sign Language; Smartphone; Video Recording; Young Adult; Ambient intelligence; Artificial intelligence; Audition; Eye tracking; Learning systems; Smartphones; Video streaming; Assistive devices; deaf; Hard of hearings; satisfaction; Sign language; Streaming videos; attention; eye tracking; hearing impaired person; human; intelligence; machine learning; satisfaction; sign language; smartphone; speech; videorecording; adolescent; adult; algorithm; artificial intelligence; communication aid; female; hearing impaired person; Internet; male; natural language processing; patient satisfaction; rehabilitation; videorecording; young adult; Translation (languages),Article,Final,,Scopus,2-s2.0-85011568212,Movies / Media
Szarkowska A.; Gerber-Morón O.,"Szarkowska, Agnieszka (54416458200); Gerber-Morón, Olivia (57202588774)",54416458200; 57202588774,Viewers can keep up with fast subtitles: Evidence from eye movements,2018,PLoS ONE,13,6,e0199331,,,,88,10.1371/journal.pone.0199331,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048801213&doi=10.1371%2fjournal.pone.0199331&partnerID=40&md5=19c971471c88cb857d1a16fa27e190d7,"People watch subtitled audiovisual materials more than ever before. With the proliferation of subtitled content, we are also witnessing an increase in subtitle speeds. However, there is an ongoing controversy about what optimum subtitle speeds should be. This study looks into whether viewers can keep up with increasingly fast subtitles and whether the way people cope with subtitled content depends on their familiarity with subtitling and on their knowledge of the language of the film soundtrack. We tested 74 English, Polish and Spanish viewers watching films subtitled at different speeds (12, 16 and 20 characters per second). The films were either in Hungarian, a language unknown to the participants (Experiment 1), or in English (Experiment 2). We measured viewers’ comprehension, self-reported cognitive load, scene and subtitle recognition, preferences and enjoyment. By analyzing people’s eye gaze, we were able to discover that most viewers could read the subtitles as well as follow the images, coping well even with fast subtitle speeds. Slow subtitles triggered more rereading, particularly in English clips, causing more frustration and less enjoyment. Faster subtitles with unreduced text were preferred in the case of English videos, and slower subtitles with text edited down in Hungarian videos. The results provide empirical grounds for revisiting current subtitling practices to enable more efficient processing of subtitled videos for viewers. © 2018 Szarkowska, Gerber-Morón. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Cognition; Eye Movements; Humans; Language; Videotape Recording; Visual Perception; adult; article; comprehension; eye movement; female; frustration; gaze; human; human experiment; language; male; velocity; videorecording; cognition; eye movement; language; physiology; vision,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85048801213,Movies / Media
Caruana N.; Stieglitz Ham H.; Brock J.; Woolgar A.; Kloth N.; Palermo R.; McArthur G.,"Caruana, Nathan (56251828400); Stieglitz Ham, Heidi (23767378500); Brock, Jon (8656371700); Woolgar, Alexandra (25636632200); Kloth, Nadine (15725791200); Palermo, Romina (7003869492); McArthur, Genevieve (7005268526)",56251828400; 23767378500; 8656371700; 25636632200; 15725791200; 7003869492; 7005268526,Joint attention difficulties in autistic adults: An interactive eye-tracking study,2018,Autism,22,4,,502,512,10.0,61,10.1177/1362361316676204,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029704918&doi=10.1177%2f1362361316676204&partnerID=40&md5=0e1cda4879c43195b9382b7b31317ebf,"Joint attention – the ability to coordinate attention with a social partner – is critical for social communication, learning and the regulation of interpersonal relationships. Infants and young children with autism demonstrate impairments in both initiating and responding to joint attention bids in naturalistic settings. However, little is known about joint attention abilities in adults with autism. Here, we tested 17 autistic adults and 17 age- and nonverbal intelligence quotient–matched controls using an interactive eye-tracking paradigm in which participants initiated and responded to joint attention bids with an on-screen avatar. Compared to control participants, autistic adults completed fewer trials successfully. They were also slower to respond to joint attention bids in the first block of testing but performed as well as controls in the second block. There were no group differences in responding to spatial cues on a non-social task with similar attention and oculomotor demands. These experimental results were mirrored in the subjective reports given by participants, with some commenting that they initially found it challenging to communicate using eye gaze, but were able to develop strategies that allowed them to achieve joint attention. Our study indicates that for many autistic individuals, subtle difficulties using eye-gaze information persist well into adulthood. © 2017, © The Author(s) 2017.",autism; eye gaze; eye tracking; joint attention; social interaction,Adult; Attention; Autistic Disorder; Case-Control Studies; Cues; Eye Movement Measurements; Eye Movements; Female; Humans; Interpersonal Relations; Male; accuracy; adolescent; algorithm; Article; attention deficit disorder; autism; clinical article; communication skill; controlled study; DSM-5; DSM-IV; eye movement; eye tracking; female; human; intelligence quotient; joint attention difficulty; male; negative feedback; priority journal; questionnaire; adult; association; attention; autism; case control study; eye movement; human relation; oculography; psychology,Article,Final,,Scopus,2-s2.0-85029704918,Movies / Media
Cheng S.; Fan J.; Dey A.K.,"Cheng, Shiwei (25630245300); Fan, Jing (35317355100); Dey, Anind K. (7101701731)",25630245300; 35317355100; 7101701731,Smooth Gaze: a framework for recovering tasks across devices using eye tracking,2018,Personal and Ubiquitous Computing,22,3,,489,501,12.0,18,10.1007/s00779-018-1115-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041903794&doi=10.1007%2fs00779-018-1115-8&partnerID=40&md5=c86e49fb425bcd09e55d8a8101b094d4,"A user task is often distributed across devices, e.g., a student listening to a lecture in a classroom while watching slides on a projected screen and making notes on her laptop, and sometimes checking Twitter for comments on her smartphone. In scenarios like this, users move between heterogeneous devices and have to deal with task resumption overhead from both physical and mental perspectives. To address this problem, we created Smooth Gaze, a framework for recording the user’s work state and resuming it seamlessly across devices by leveraging implicit gaze input. In particular, we propose two novel and intuitive techniques, smart watching and smart posting, for detecting which display and target region the user is looking at, and transferring and integrating content across devices respectively. In addition, we designed and implemented a cross-device reading system SmoothReading that captures content from secondary devices and generates annotations based on eye tracking, to be displayed on the primary device. We conducted a study that showed that the system supported information seeking and task resumption, and improved users’ overall reading experience. © 2018, Springer-Verlag London Ltd., part of Springer Nature.",Active reading; Interaction design; User interface; Visual attention,Behavioral research; Display devices; Students; User interfaces; Active reading; Heterogeneous devices; Information seeking; Interaction design; Target regions; Visual Attention; Eye tracking,Article,Final,,Scopus,2-s2.0-85041903794,Movies / Media
Kiat J.E.; Dodd M.D.; Belli R.F.; Cheadle J.E.,"Kiat, John E. (37021513600); Dodd, Michael D. (7103061070); Belli, Robert F. (7003836374); Cheadle, Jacob E. (14008828100)",37021513600; 7103061070; 7003836374; 14008828100,The signature of undetected change: An exploratory electrotomographic investigation of gradual change blindness,2018,Journal of Neurophysiology,119,5,,1629,1635,6.0,3,10.1152/jn.00722.2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046857969&doi=10.1152%2fjn.00722.2017&partnerID=40&md5=30f4f13161137bfcf7ae4d34e5d0dd5c,"Neuroimaging- based investigations of change blindness, a phenomenon in which seemingly obvious changes in visual scenes fail to be detected, have significantly advanced our understanding of visual awareness. The vast majority of prior investigations, however, utilize paradigms involving visual disruptions (e.g., intervening blank screens, saccadic movements, “mudsplashes”), making it difficult to isolate neural responses toward visual changes cleanly. To address this issue in this present study, high-density EEG data (256 channel) were collected from 25 participants using a paradigm in which visual changes were progressively introduced into detailed real-world scenes without the use of visual disruption. Oscillatory activity associated with undetected changes was contrasted with activity linked to their absence using standardized low-resolution brain electromagnetic tomography (sLORETA). Although an insufficient number of detections were present to allow for analysis of actual change detection, increased beta-2 activity in the right inferior parietal lobule (rIPL), a region repeatedly associated with change blindness in disruption paradigms, followed by increased theta activity in the right superior temporal gyrus (rSTG) was noted in undetected visual change responses relative to the absence of change. We propose the rIPL beta-2 activity to be associated with orienting attention toward visual changes, with the subsequent rise in rSTG theta activity being potentially linked with updating preconscious perceptual memory representations. NEW & NOTEWORTHY This study represents the first neuroimaging- based investigation of gradual change blindness, a visual phenomenon that has significant potential to shed light on the processes underlying visual detection and conscious perception. The use of gradual change materials is reflective of real-world visual phenomena and allows for cleaner isolation of signals associated with the neural registration of change relative to the use of abrupt change transients. © 2018 American Physiological Society. All rights reserved.",Change blindness; EEG; Electrotomography; Time-frequency; Visual perception,"Adolescent; Adult; Attention; Awareness; Brain Waves; Electroencephalography; Female; Humans; Male; Neuroimaging; Parietal Lobe; Pattern Recognition, Visual; Temporal Lobe; Tomography; Vision Disorders; Young Adult; adult; alpha rhythm; Article; beta rhythm; blindness; clinical article; electroencephalogram; female; human; inferior parietal lobule; low resolution brain electromagnetic tomography; male; middle temporal gyrus; nerve potential; priority journal; saccadic eye movement; signal detection; superior temporal gyrus; theta rhythm; visual attention; visual information; young adult; adolescent; attention; awareness; diagnostic imaging; electroencephalogram; electroencephalography; neuroimaging; parietal lobe; pathophysiology; pattern recognition; physiology; procedures; temporal lobe; tomography; visual disorder",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85046857969,Movies / Media
Yaneva V.; An Ha L.; Eraslan S.; Yesilada Y.; Mitkov R.,"Yaneva, Victoria (57003253500); An Ha, Le (13612155200); Eraslan, Sukru (55785840000); Yesilada, Yeliz (8454176800); Mitkov, Ruslan (6602533142)",57003253500; 13612155200; 55785840000; 8454176800; 6602533142,Etecting autism based on eye-tracking data from web searching tasks,2018,"Proceedings of the 15th Web for All Conference : Internet of Accessible Things, W4A 2018",,,a16,,,,49,10.1145/3192714.3192819,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051796947&doi=10.1145%2f3192714.3192819&partnerID=40&md5=293a9aa591c8d27e996876ba9cfa7b93,"The ASD diagnosis requires a long, elaborate, and expensive prnnocedure, which is subjective and is currently restricted to behavioural, historical, and parent-report information. In this paper, we present an alternative way for detecting the condition based on the atypical visual-attention patterns of people with autism. We collect gaze data from two different kinds of tasks related to processing of information from web pages: Browsing and Searching. The gaze data is then used to train a machine learning classifier whose aim is to distinguish between participants with autism and a control group of participants without autism. In addition, we explore the effects of the type of the task performed, different approaches to defining the areas of interest, gender, visual complexity of the web pages and whether or not an area of interest contained the correct answer to a searching task. Our best-performing classifier achieved 0.75 classification accuracy for a combination of selected web pages using all gaze features. These preliminary results show that the differences in the way people with autism process web content could be used for the future development of serious games for autism screening. The gaze data, R code, visual stimuli and task descriptionare made freely available for replication purposes. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Autism; Diagnostic Classification; Eye Tracking; Screening; Web,Behavioral research; Diseases; Eye movements; Learning systems; Screening; Serious games; Websites; Area of interest; Autism; Classification accuracy; Control groups; Searching task; Visual Attention; Visual complexity; Visual stimulus; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85051796947,Movies / Media
Shen W.; Qu Q.; Tong X.,"Shen, Wei (55599630700); Qu, Qingqing (56921462200); Tong, Xiuhong (36453383300)",55599630700; 56921462200; 36453383300,Visual attention shift to printed words during spoken word recognition in Chinese: The role of phonological information,2018,Memory and Cognition,46,4,,642,654,12.0,9,10.3758/s13421-018-0790-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040904540&doi=10.3758%2fs13421-018-0790-z&partnerID=40&md5=57dc3afbe5cabc3955a54d73a8c0c184,"The aim of this study was to investigate the extent to which phonological information mediates the visual attention shift to printed Chinese words in spoken word recognition by using an eye-movement technique with a printed-word paradigm. In this paradigm, participants are visually presented with four printed words on a computer screen, which include a target word, a phonological competitor, and two distractors. Participants are then required to select the target word using a computer mouse, and the eye movements are recorded. In Experiment 1, phonological information was manipulated at the full-phonological overlap; in Experiment 2, phonological information at the partial-phonological overlap was manipulated; and in Experiment 3, the phonological competitors were manipulated to share either fulloverlap or partial-overlap with targets directly. Results of the three experiments showed that the phonological competitor effects were observed at both the full-phonological overlap and partial-phonological overlap conditions. That is, phonological competitors attracted more fixations than distractors, which suggested that phonological information mediates the visual attention shift during spoken word recognition. More importantly, we found that the mediating role of phonological information varies as a function of the phonological similarity between target words and phonological competitors. © 2018, Psychonomic Society, Inc.",Chinese; Phonology; Printed-word paradigm; Spoken word recognition,"Adult; Attention; China; Female; Humans; Male; Pattern Recognition, Visual; Phonetics; Psycholinguistics; Speech Perception; Young Adult; adult; attention; China; female; human; male; pattern recognition; phonetics; physiology; psycholinguistics; speech perception; young adult",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85040904540,Movies / Media
Pentus K.; Ploom K.; Kuusik A.; Mehine T.,"Pentus, Kristian (57201258159); Ploom, Kerli (16402824500); Kuusik, Andres (25960966100); Mehine, Tanel (57201261808)",57201258159; 16402824500; 25960966100; 57201261808,How to optimize sales flyers – novel experiment design,2018,Baltic Journal of Management,13,2,,191,208,17.0,7,10.1108/BJM-05-2017-0132,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044042957&doi=10.1108%2fBJM-05-2017-0132&partnerID=40&md5=43831f4a31ba98682fe0b5af7345f99d,"Purpose: The purpose of this paper is to show how analysing sales flyers with a combination of eye tracking, measurement of emotions, interview and content analysis can give an in-depth understanding on how different design aspects influence sales flyers’ effectiveness as a communication tool. The paper shows the relationship between different sales flyer design principles and a person’s preference towards it, as well as the intent to read it. Design/methodology/approach: The paper chose for pilot study using eye tracking and emotions measurement to analyse retail sales flyers. In addition, interviews and content analysis were conducted to fully understand which aspects of sales flyer design influenced consumers. Findings: The paper’s main findings are that sales flyers that evoke more positive emotions are prone to be chosen, and the attention and the view time of content pages is related to the number of elements on the page, page coherence and the location of the offers. Research limitations/implications: This research uses eye tracking were sales flyers are shown on screen, which is not a natural way to read sales flyers. Future research should aim to test this methodology and prepositions in the natural environment. Practical implications: The paper includes implications for designing better sales flyers. Originality/value: To the authors’ knowledge, sales flyers have never been studied with a research design combining eye tracking, measurement of emotions, interview, content analysis and preferences. © 2018, Emerald Publishing Limited.",Direct mail design principles; Eye tracking; Measurement of emotions; Sales flyers,,Article,Final,,Scopus,2-s2.0-85044042957,Movies / Media
Zhou Y.; Zhang L.; Zhang C.; Li P.; Li X.,"Zhou, Yinzuo (35207925000); Zhang, Luming (35231925400); Zhang, Chao (56192792200); Li, Ping (57210250079); Li, Xuelong (55936260100)",35207925000; 35231925400; 56192792200; 57210250079; 55936260100,Perceptually aware image retargeting for mobile devices,2018,IEEE Transactions on Image Processing,27,5,,2301,2313,12.0,25,10.1109/TIP.2017.2779272,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037589719&doi=10.1109%2fTIP.2017.2779272&partnerID=40&md5=9c5f4e25a470da10e7584bce1cbe4da2,"Retargeting aims at adapting an original high-resolution photograph/video to a low-resolution screen with an arbitrary aspect ratio. Conventional approaches are generally based on desktop PCs, since the computation might be intolerable for mobile platforms (especially when retargeting videos). Typically, only low-level visual features are exploited, and human visual perception is not well encoded. In this paper, we propose a novel retargeting framework that rapidly shrinks a photograph/video by leveraging human gaze behavior. Specifically, we first derive a geometry-preserving graph ranking algorithm, which efficiently selects a few salient object patches to mimic the human gaze shifting path (GSP) when viewing a scene. Afterward, an aggregation-based CNN is developed to hierarchically learn the deep representation for each GSP. Based on this, a probabilistic model is developed to learn the priors of the training photographs that are marked as aesthetically pleasing by professional photographers. We utilize the learned priors to efficiently shrink the corresponding GSP of a retargeted photograph/video to maximize its similarity to those from the training photographs. Extensive experiments have demonstrated that: 1) our method requires less than 35 ms to retarget a 1024× 768 photograph (or a 1280× 720 video frame) on popular iOS/Android devices, which is orders of magnitude faster than the conventional retargeting algorithms; 2) the retargeted photographs/videos produced by our method significantly outperform those of its competitors based on a paired-comparison-based user study; and 3) the learned GSPs are highly indicative of human visual attention according to the human eye tracking experiments. © 1992-2012 IEEE.",deep feature; gaze behavior; Mobile platform; perceptual; probabilistic model; retarget,Aspect ratio; Computation theory; Flow visualization; Mobile phones; Mobile telecommunication systems; Personnel training; Probabilistic logics; Semantics; Adaptation models; Deep feature; Gaze behavior; Mobile communications; Mobile platform; Perceptual; Probabilistic modeling; Retarget; Videos; article; controlled study; eye tracking; gaze; geometry; human; human experiment; photography; videorecording; visual attention; Behavioral research,Article,Final,,Scopus,2-s2.0-85037589719,Movies / Media
Huang Y.-T.,"Huang, Yi-Ting (57221274536)",57221274536,"The female gaze: Content composition and slot position in personalized banner ads, and how they influence visual attention in online shoppers",2018,Computers in Human Behavior,82,,,1,15,14.0,39,10.1016/j.chb.2017.12.038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039947294&doi=10.1016%2fj.chb.2017.12.038&partnerID=40&md5=784ee7a28d2801cc83983485b3a60a92,"With the overload of information on the internet today, consumer attention is becoming increasingly precious. Online retailers often use banner advertising for products that consumers have previously viewed so as to achieve retargeting. This study examined the attention that female consumers paid to product-based personalized banner ads for online apparel retailers, and how this attention was influenced by visual content composition and slot position. Using a screen eye tracker, we analyzed the interaction effects of ad slot position (content relevance, top-center or right sidebar slot on portal site) and the content composition (image-text ratio, discount information, use of models) of personalized banner ads on relevant eye movement data. This data allowed for increased understanding of the combinations of ad content/layout composition and slot position that gain the most attention. The results revealed that placing apparel banner ads next to articles associated with apparel and fashion increases the overall amount of attention that consumers give the ad. Furthermore, ads in the top-center slot on portal sites receive greater total contact time and number of fixations than those in the right sidebar. We further found that adding discount information and using models to display the garment in banner ads can effectively increase the total contact time and number of fixations. © 2017 Elsevier Ltd",Ad content; Ad slot position; Eye tracking; Online apparel retailer; Personalized banners; Visual attention,Behavioral research; Electronic commerce; Sales; Ad content; Eye-tracking; Online apparel retailer; Personalized banners; Slot position; Visual Attention; adult; consumer; eye tracking; female; gaze; human; human experiment; visual attention; Eye movements,Article,Final,,Scopus,2-s2.0-85039947294,Movies / Media
Höfler C.; Gremsl A.; Schienle A.,"Höfler, Carina (57193337817); Gremsl, Andreas (57056445900); Schienle, Anne (7003820877)",57193337817; 57056445900; 7003820877,Nocebo and pseudo-neglect: Paradoxical effects detected with eye-tracking,2018,International Journal of Psychophysiology,125,,,29,34,5.0,7,10.1016/j.ijpsycho.2018.01.014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042179400&doi=10.1016%2fj.ijpsycho.2018.01.014&partnerID=40&md5=ba8766f7787743aba8e676891e9d0680,"The knowledge about effects of placebos and nocebos on specific visual attention processes is still very limited. In the present eye-tracking study, it was analyzed if a nocebo (sham transcranial magnetic stimulation) is able to elicit left-sided attentional deficits (pseudo-neglect). Fifty-two healthy participants performed a search task on the computer, once with and once without the nocebo. Indicators of left-biased search behavior (e.g. fixation count, reaction times for left vs. right-sided target detection) and affective state (e.g., valence, arousal) were assessed. The sample was divided into two groups (nocebo responder, non-responder) based on the experienced effectiveness of the nocebo. The nocebo treatment was associated with a positive and calm affective state. Contrary to the verbal suggestion, the nocebo increased the number of fixations and the dwell time on the left side of the computer screen. Moreover, the nocebo decreased the detection time for targets on the left side. These paradoxical nocebo effects were restricted to nocebo responders. Possible implications of nocebo-related compensatory behaviors for neuropsychological therapy are discussed. © 2018",Compensatory behavior; Eye movements; Nocebo; Nocebo responsivity; Pseudo-neglect,Adolescent; Analysis of Variance; Attention; Attention Deficit Disorder with Hyperactivity; Emotions; Eye Movements; Female; Functional Laterality; Humans; Male; Nocebo Effect; Photic Stimulation; Reaction Time; Space Perception; Transcranial Magnetic Stimulation; Young Adult; adult; arousal; Article; blurred vision; controlled study; dizziness; eye tracking; female; gaze; human; nocebo effect; normal human; oculography; placebo effect; reaction time; right handedness; transcranial magnetic stimulation; adolescent; analysis of variance; attention; attention deficit disorder; depth perception; emotion; eye movement; hemispheric dominance; male; pathophysiology; photostimulation; physiology; young adult,Article,Final,,Scopus,2-s2.0-85042179400,Movies / Media
Król M.E.,"Król, Magdalena Ewa (57208580432)",57208580432,"Auditory noise increases the allocation of attention to the mouth, and the eyes pay the price: An eye-tracking study",2018,PLoS ONE,13,3,e0194491,,,,18,10.1371/journal.pone.0194491,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044212974&doi=10.1371%2fjournal.pone.0194491&partnerID=40&md5=e78b5fa8b9e043b8d239d71f0a76edaa,"We investigated the effect of auditory noise added to speech on patterns of looking at faces in 40 toddlers. We hypothesised that noise would increase the difficulty of processing speech, making children allocate more attention to the mouth of the speaker to gain visual speech cues from mouth movements. We also hypothesised that this shift would cause a decrease in fixation time to the eyes, potentially decreasing the ability to monitor gaze. We found that adding noise increased the number of fixations to the mouth area, at the price of a decreased number of fixations to the eyes. Thus, to our knowledge, this is the first study demonstrating a mouth-eyes trade-off between attention allocated to social cues coming from the eyes and linguistic cues coming from the mouth. We also found that children with higher word recognition proficiency and higher average pupil response had an increased likelihood of fixating the mouth, compared to the eyes and the rest of the screen, indicating stronger motivation to decode the speech. © 2018 Magdalena Ewa Król. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Acoustic Stimulation; Attention; Child, Preschool; Eye Movements; Face; Female; Fixation, Ocular; Humans; Infant; Male; Mouth; Noise; Speech; Visual Perception; article; attention; child; eye tracking; female; gaze; human; human experiment; male; motivation; mouth; noise; rest; speech; toddler; word recognition; attention; auditory stimulation; eye fixation; eye movement; face; infant; mouth; physiology; preschool child; vision",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85044212974,Movies / Media
Stephenson L.J.; Edwards S.G.; Howard E.E.; Bayliss A.P.,"Stephenson, Lisa J. (56727722000); Edwards, S. Gareth (57191038661); Howard, Emma E. (57191043548); Bayliss, Andrew P. (7005185834)",56727722000; 57191038661; 57191043548; 7005185834,Eyes that bind us: Gaze leading induces an implicit sense of agency,2018,Cognition,172,,,124,133,9.0,35,10.1016/j.cognition.2017.12.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038834318&doi=10.1016%2fj.cognition.2017.12.011&partnerID=40&md5=b395ee7ce20dc182e90a560ad8db456f,"Humans feel a sense of agency over the effects their motor system causes. This is the case for manual actions such as pushing buttons, kicking footballs, and all acts that affect the physical environment. We ask whether initiating joint attention – causing another person to follow our eye movement – can elicit an implicit sense of agency over this congruent gaze response. Eye movements themselves cannot directly affect the physical environment, but joint attention is an example of how eye movements can indirectly cause social outcomes. Here we show that leading the gaze of an on-screen face induces an underestimation of the temporal gap between action and consequence (Experiments 1 and 2). This underestimation effect, named ‘temporal binding,’ is thought to be a measure of an implicit sense of agency. Experiment 3 asked whether merely making an eye movement in a non-agentic, non-social context might also affect temporal estimation, and no reliable effects were detected, implying that inconsequential oculomotor acts do not reliably affect temporal estimations under these conditions. Together, these findings suggest that an implicit sense of agency is generated when initiating joint attention interactions. This is important for understanding how humans can efficiently detect and understand the social consequences of their actions. © 2017 Elsevier B.V.",Gaze leading; Joint attention; Sense of agency; Social cognition; Temporal binding,Adult; Attention; Eye Movements; Female; Humans; Male; Social Perception; Time Perception; Young Adult; adult; Article; compression; controlled study; effect size; eye; eye tracking; face; female; gaze; human; human experiment; male; normal human; oculomotor system; priority journal; saccadic eye movement; social cognition; social environment; temporal cortex; temporal summation; vision; young adult; attention; eye movement; perception; physiology; time perception,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85038834318,Movies / Media
Allard E.S.; Kensinger E.A.,"Allard, Eric S. (25921839800); Kensinger, Elizabeth A. (6701709422)",25921839800; 6701709422,Cognitive emotion regulation in adulthood and old age: positive gaze preferences across two strategies,2018,"Aging, Neuropsychology, and Cognition",25,2,,213,230,17.0,22,10.1080/13825585.2017.1279265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009752481&doi=10.1080%2f13825585.2017.1279265&partnerID=40&md5=904ef376e53154bf4bfd4e695046b10d,"While positive emotional functioning may be enhanced across adulthood and old age, research is mixed as to the types of regulatory strategies that are more or less beneficial for facilitating well-being. The goal of the present study was to examine how specific cognitive emotion regulation strategies assumed to rely on varying levels of effortful processing (selective attention vs. reappraisal) would impact regulatory behaviors (via eye gaze deployment) and resultant affective outcomes. Participants viewed a series of positive, negative, and neutral film clips while their eyes were tracked across three conditions: passive viewing, selective attention, and reappraisal. Results revealed that (a) both younger and older adults displayed positive fixation preferences and showed mood improvement across both regulatory conditions and (b) there was a marginal association between positive fixation and post-regulation mood. Implications for linking positivity to emotion regulation and well-being across adulthood are discussed. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",Aging; emotion regulation; fixation; positivity,"Adolescent; Adult; Affect; Aged; Aged, 80 and over; Aging; Attention; Cognition; Emotional Intelligence; Female; Fixation, Ocular; Humans; Male; Middle Aged; Motion Perception; Young Adult; adult; adulthood; aging; emotionality; eye; gaze; human; human experiment; mood; selective attention; wellbeing; adolescent; affect; aged; aging; attention; cognition; emotional intelligence; eye fixation; female; male; middle aged; movement perception; physiology; psychology; very elderly; young adult",Article,Final,,Scopus,2-s2.0-85009752481,Movies / Media
Barber T.R.; Muhammed K.; Drew D.; Lawton M.; Crabbe M.; Rolinski M.; Quinnell T.; Zaiwalla Z.; Ben-Shlomo Y.; Husain M.; Hu M.T.M.,"Barber, T.R. (57192254924); Muhammed, K. (55817660300); Drew, D. (57194872214); Lawton, M. (57202798417); Crabbe, M. (57199391550); Rolinski, M. (37028938400); Quinnell, T. (8740905200); Zaiwalla, Z. (57216324843); Ben-Shlomo, Y. (7006649063); Husain, M. (7201522757); Hu, M.T.M. (57189494530)",57192254924; 55817660300; 57194872214; 57202798417; 57199391550; 37028938400; 8740905200; 57216324843; 7006649063; 7201522757; 57189494530,Apathy in rapid eye movement sleep behaviour disorder is common and under-recognized,2018,European Journal of Neurology,25,3,,469,e32,-437.0,27,10.1111/ene.13515,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038017693&doi=10.1111%2fene.13515&partnerID=40&md5=59f007b17be2db5f4a5a364d37dfdcc9,"Background and purpose: Apathy is an important neuropsychiatric feature of Parkinson's disease (PD), which often emerges before the onset of motor symptoms. Patients with rapid eye movement sleep behaviour disorder (RBD) have a high probability of developing PD in future. Neuropsychiatric problems are common in RBD, but apathy has not previously been detailed in this key prodromal population. Methods: Eighty-eight patients with polysomnographically proven RBD, 65 patients with PD and 33 controls were assessed for apathy using the Lille Apathy Rating Scale. Cognition and depression were also quantified. The sensitivity of the Unified Parkinson's Disease Rating Scale screening questions for apathy and depression was calculated. Results: A total of 46% of patients with RBD were apathetic, compared with 31% of patients with PD in our sample. Most patients with RBD with depression were apathetic but more than half of apathetic patients were not depressed. The sensitivity of the single Unified Parkinson's Disease Rating Scale screening question was only 33% for mild apathy and 50% for severe apathy. Conclusions: Apathy is common in RBD and is underestimated by a single self-report question. Recognition of apathy as a distinct neuropsychiatric feature in RBD could aid targeted treatment interventions and might contribute to the understanding of prodromal PD. © 2017 The Authors. European Journal of Neurology published by John Wiley & Sons Ltd on behalf of European Academy of Neurology.",apathy; Parkinson's disease; prodromal; rapid eye movement sleep behaviour disorder,"Aged; Aged, 80 and over; Apathy; Cognition; Cohort Studies; Depression; Dopamine Agonists; Emotions; Female; Humans; Levodopa; Male; Mass Screening; Middle Aged; Neuropsychological Tests; Parkinson Disease; Polysomnography; REM Sleep Behavior Disorder; dopamine receptor stimulating agent; levodopa; aged; apathy; Article; Beck Depression Inventory; clinical assessment; cognition; cohort analysis; controlled study; depression; disease severity; emotional disorder; female; high risk patient; human; Lille Apathy Rating Scale; major clinical study; male; Montreal cognitive assessment; Parkinson disease; phenotype; polysomnography; priority journal; quantitative analysis; rapid eye movement sleep behavior disorder; rating scale; REM sleep; sensitivity analysis; sleep disorder; Unified Parkinson Disease Rating Scale; complication; emotion; mass screening; middle aged; neuropsychological test; parasomnia; Parkinson disease; psychology; very elderly",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85038017693,Movies / Media
Mesrobian S.K.; Villa A.E.P.; Bader M.; Götte L.; Lintas A.,"Mesrobian, Sarah K. (56016864000); Villa, Alessandro E. P. (7201597625); Bader, Michel (7202377829); Götte, Lorenz (8622257000); Lintas, Alessandra (23470040700)",56016864000; 7201597625; 7202377829; 8622257000; 23470040700,Event-related potentials during a gambling task in young adults with attention-deficit/hyperactivity disorder,2018,Frontiers in Human Neuroscience,12,,79,,,,7,10.3389/fnhum.2018.00079,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043594067&doi=10.3389%2ffnhum.2018.00079&partnerID=40&md5=bd077f12837d74e05ae59f7e16b58472,"Attention-deficit hyperactivity disorder (ADHD) is characterized by deficits in executive functions and decision making during childhood and adolescence. Contradictory results exist whether altered event-related potentials (ERPs) in adults are associated with the tendency of ADHD patients toward risky behavior. Clinically diagnosed ADHD patients (n = 18) and healthy controls (n = 18), aged between 18 and 29 (median 22 Yo), were screened with the Conners’ Adult ADHD Rating Scales and assessed by the Mini-International Neuropsychiatric Interview, adult ADHD Self-Report Scale, and by the 60-item HEXACO Personality Inventory. The characteristic personality traits of ADHD patients were the high level of impulsiveness associated with lower values of agreeableness. All participants performed a probability gambling task (PGT) with two frequencies of the feedback information of the outcome. For each trial, ERPs were triggered by the self-paced trial onset and by the gamble selection. After trial onset, N2-P3a ERP component associated with the attentional load peaked earlier in the ADHD group than in controls. An N500 component related to the feedback frequency condition after trial onset and an N400-like component after gamble selection suggest a large affective stake of the decision making and an emphasized post-decisional evaluation of the choice made by the ADHD participants. By combining ERPs, related to the emotions associated with the feedback frequency condition, and behavioral analyses during completion of PGT, this study provides new findings on the neural dynamics that differentiate controls and young ADHD adults. In the patients’ group, we raise the hypothesis that the activity of frontocentral and centroparietal neural circuits drive the decision-making processes dictated by an impaired cognitive workload followed by the build-up of large emotional feelings generated by the conflict toward the outcome of the gambling choice. Our results can be used for new investigations aimed at studying the fine spatiotemporal distribution of cortical activity, and the neural circuits that underly the generation of that activity, associated with the behavioral deficits characteristic of ADHD. © 2018 Mesrobian, Villa, Bader, Götte and Lintas.",ADHD; Decision-making; Evoked potentials; N2-P3; N400-like; Personality,adrenal cortex; adult; Article; attention deficit disorder; behavior; clinical article; cognitive defect; connectome; controlled study; decision making; disease association; DSM-IV; electroencephalogram; emotion; event related potential; executive function; feedback system; female; frontal lobe; human; impulsiveness; male; pathological gambling; personality; probability; rating scale; self report; spatiotemporal analysis; workload,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85043594067,Movies / Media
Foerster R.M.,"Foerster, Rebecca M. (52163407300)",52163407300,“Looking-at-nothing” during sequential sensorimotor actions: Long-term memory-based eye scanning of remembered target locations,2018,Vision Research,144,,,29,37,8.0,9,10.1016/j.visres.2018.01.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042383346&doi=10.1016%2fj.visres.2018.01.005&partnerID=40&md5=2625687fc8b695e3b6b27a76dc49e5f1,"Before acting humans saccade to a target object to extract relevant visual information. Even when acting on remembered objects, locations previously occupied by relevant objects are fixated during imagery and memory tasks – a phenomenon called “looking-at-nothing”. While looking-at-nothing was robustly found in tasks encouraging declarative memory built-up, results are mixed in the case of procedural sensorimotor tasks. Eye-guidance to manual targets in complete darkness was observed in a task practiced for days beforehand, while investigations using only a single session did not find fixations to remembered action targets. Here, it is asked whether looking-at-nothing can be found in a single sensorimotor session and thus independent from sleep consolidation, and how it progresses when visual information is repeatedly unavailable. Eye movements were investigated in a computerized version of the trail making test. Participants clicked on numbered circles in ascending sequence. Fifty trials were performed with the same spatial arrangement of 9 visual targets to enable long-term memory consolidation. During 50 consecutive trials, participants had to click the remembered target sequence on an empty screen. Participants scanned the visual targets and also the empty target locations sequentially with their eyes, however, the latter less precise than the former. Over the course of the memory trials, manual and oculomotor sequential target scanning became more similar to the visual trials. Results argue for robust looking-at-nothing during procedural sensorimotor tasks provided that long-term memory information is sufficient. © 2018 Elsevier Ltd",Action control; Eye movements; Long-term memory; Looking-at-nothing; Trail making test; Visual attention,"Adult; Attention; Female; Fixation, Ocular; Humans; Male; Memory, Long-Term; Mental Recall; Psychomotor Performance; Saccades; Visual Perception; adult; Article; auditory feedback; eye movement; female; gaze; human; human experiment; long term memory; male; memory; normal human; priority journal; sensorimotor function; sleep parameters; task performance; visual information; visual stimulation; visual system function; attention; eye fixation; physiology; psychomotor performance; recall; saccadic eye movement; vision",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85042383346,Movies / Media
Kontos A.P.; Collins M.W.; Holland C.L.; Reeves V.L.; Edelman K.; Benso S.; Schneider W.; Okonkwo D.,"Kontos, Anthony P (7004528698); Collins, Michael W (35557667100); Holland, Cyndi L (57212662091); Reeves, Valerie L (55188804100); Edelman, Kathryn (57189513938); Benso, Steven (56638377400); Schneider, Walter (7403514850); Okonkwo, David (6602896494)",7004528698; 35557667100; 57212662091; 55188804100; 57189513938; 56638377400; 7403514850; 6602896494,"Preliminary Evidence for Improvement in Symptoms, Cognitive, Vestibular, and Oculomotor Outcomes Following Targeted Intervention with Chronic mTBI Patients",2018,Military Medicine,183,,,333,338,5.0,61,10.1093/milmed/usx172,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045445502&doi=10.1093%2fmilmed%2fusx172&partnerID=40&md5=3636adada1586c0913552d1f4dd9a7df,"Introduction To determine if targeted, active interventions would improve symptoms and impairment in previously intractable patients with chronic mild traumatic brain injury (mTBI). Materials and Methods Twenty-six (20 males; 6 females) out of 51 (51%) former military and civilian patients with chronic (1-3 yr) mTBI enrolled in the TEAM traumatic brain injury (TBI) study completed both an initial and 6-mo post-intervention comprehensive mTBI assessment including symptoms (Post-concussion Symptom Scale [PCSS], Dizziness Handicap Inventory [DHI]), cognitive (Immediate Post-concussion Assessment and Cognitive Testing [ImPACT]), vestibular/oculomotor (Vestibular/Ocular Motor Screening [VOMS]), balance (Activities-specific Balance Confidence [ABC] scale, Balance Error Scoring System [BESS]), and cervical (Neck Disability Index [NDI]). Patients were prescribed progressive, targeted interventions and therapies (e.g., behavioral, vestibular, vision, and exertion) that matched their mTBI clinical profile. A series of paired t-tests adjusted for multiple corrections were used to compare pre- and post-intervention assessment scores. Results Patients demonstrated significant improvement from pre- to post-intervention on total symptoms (t = 2.69, p = 0.01), verbal memory (t = -1.96, p = 0.05), ABC balance score (t = -2.05, p = 0.05), smooth pursuits (t = 2.32, p = 0.04), near-point convergence distance (t = -3.58, p = 0.01), vestibular ocular reflex (t = 2.31, p = 0.03), and visual motion sensitivity (t = 2.43, p = 0.03). Conclusions Previously recalcitrant patients with chronic complex mTBI demonstrated significant improvement in symptoms, cognitive, vestibular, oculomotor, and balance function following targeted interventions. © Association of Military Surgeons of the United States 2018. All rights reserved.",Chronic; intervention; military; mTBI,"Adult; Brain Injuries, Traumatic; Eye Movements; Female; Humans; Male; Memory and Learning Tests; Middle Aged; Neuropsychological Tests; Postural Balance; Severity of Illness Index; Treatment Outcome; adult; body equilibrium; cognition assessment; eye movement; female; human; male; middle aged; neuropsychological test; pathophysiology; physiology; severity of illness index; traumatic brain injury; treatment outcome",Conference paper,Final,,Scopus,2-s2.0-85045445502,Movies / Media
Hu J.; Li S.; Chang Y.; Zhu Z.; Hou C.,"Hu, Jiajie (57201407362); Li, Sumei (55741035700); Chang, Yongli (57201403555); Zhu, Zhaoqi (57201679897); Hou, Chunping (7202210195)",57201407362; 55741035700; 57201403555; 57201679897; 7202210195,Measurement of Comfortable Contrast Range of Stereo Image Based on Salient Region,2018,Guangxue Xuebao/Acta Optica Sinica,38,2,215001,,,,9,10.3788/AOS201838.0215001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045719008&doi=10.3788%2fAOS201838.0215001&partnerID=40&md5=66de0fc62e1b7d191eb77bfa2a54ae77,"Combined with the visual attention mechanism, the influence of contrast factor on visual comfort of stereo image is studied quantitatively through a large number of subjective experiments. First, a stereo salient degree map is derived from stereo disparity map and planar salient map. It is optimized through fuzzy membership degree and mask, and the salient stereoscopic images can be obtained. An eye tracker is used to verify its rationality. Then, a series of subjective experiments are conducted after contrast conversion of left and right views. Finally, the comfortable contrast matching map and difference map are obtained after data screening. The experimental results show that the contrast difference thresholds of left and right view change with different left view contrasts, and the contrast difference should not be too large. The maximum and minimum difference values are 1.97 and -2.40, respectively. The obtained comfortable contrast ranges reflect the comfort of stereo image better, and the correct rate reaches 95%, which provides more reasonable and feasible quantitative standards for the making of stereo contents. © 2018, Chinese Lasers Press. All right reserved.",Contrast; Machine vision; Quantitative research; Subjective evaluation; Visual comfort; Visual salient region,Behavioral research; Computer vision; Eye tracking; Contrast; Quantitative research; Salient regions; Subjective evaluations; Visual comfort; Stereo image processing,Article,Final,,Scopus,2-s2.0-85045719008,Movies / Media
Schmidt K.; Gamer M.; Forkmann K.; Bingel U.,"Schmidt, Katharina (57833729000); Gamer, Matthias (8979946100); Forkmann, Katarina (55578377700); Bingel, Ulrike (11240417300)",57833729000; 8979946100; 55578377700; 11240417300,Pain Affects Visual Orientation: an Eye-Tracking Study,2018,Journal of Pain,19,2,,135,145,10.0,20,10.1016/j.jpain.2017.09.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034974476&doi=10.1016%2fj.jpain.2017.09.005&partnerID=40&md5=783d0155a72c73c6a56956cec4fe89a3,"Because of its unique evolutionary relevance, it is understood that pain automatically attracts attention. So far, such attentional bias has mainly been shown for pain-related stimuli whereas little is known about shifts in attentional focus after actual painful stimulation. This study investigated attentional shifts by assessing eye movements into the direction of painful stimulation. Healthy participants were presented either a blank screen or a picture showing a natural scene while painful electrical stimuli were applied to the left or right hand. In general, painful stimulation reduced exploratory behavior as reflected by less and slower saccades as well as fewer and longer fixations. Painful stimulation on the right hand induced a rightward bias (ie, increased initial saccades, total number and duration of fixations to the right hemifield of the screen). Pain applied to the left hand as well as no pain induced a leftward bias that was largest for the direction of first saccades. These findings are in line with previous observations of attentional biases toward pain-related information and highlight eye tracking as a valuable tool to assess involuntary attentional consequences of pain. Future studies are needed to investigate how the observed changes in eye movements relate to pain-induced changes in perception and cognition. Perspective The study investigated pain-induced attentional shifts in terms of reflexive eye movements. This attention-capturing quality of pain should be examined in chronic pain conditions because it might contribute to the cognitive impairments often observed in chronic pain patients. © 2017 The American Pain Society",attentional focus; electrical pain; Experimental pain; eye-tracking; reflexive eye movements,Adult; Analysis of Variance; Anxiety; Attention; Catastrophization; Electric Stimulation; Exploratory Behavior; Eye Movements; Female; Functional Laterality; Hand; Humans; Male; Orientation; Pain; Pain Threshold; Photic Stimulation; Surveys and Questionnaires; Visual Analog Scale; Young Adult; adult; Article; attentional bias; catastrophizing; exploratory behavior; eye movement; eye tracking; female; human; human experiment; male; normal human; pain; pain intensity; pain threshold; saccadic eye movement; visual attention; visual orientation; visual stimulation; adverse event; analysis of variance; anxiety; attention; electrostimulation; hand; hemispheric dominance; innervation; orientation; pain; pathophysiology; photostimulation; physiology; psychology; questionnaire; visual analog scale; young adult,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85034974476,Movies / Media
Rider A.T.; Coutrot A.; Pellicano E.; Dakin S.C.; Mareschal I.,"Rider, Andrew T. (57191329031); Coutrot, Antoine (55553538900); Pellicano, Elizabeth (6507658484); Dakin, Steven C. (7004755048); Mareschal, Isabelle (6602146747)",57191329031; 55553538900; 6507658484; 7004755048; 6602146747,Semantic content outweighs low-level saliency in determining children's and adults’ fixation of movies,2018,Journal of Experimental Child Psychology,166,,,293,309,16.0,26,10.1016/j.jecp.2017.09.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034093253&doi=10.1016%2fj.jecp.2017.09.002&partnerID=40&md5=530653ac887391f023eb95affe788833,"To make sense of the visual world, we need to move our eyes to focus regions of interest on the high-resolution fovea. Eye movements, therefore, give us a way to infer mechanisms of visual processing and attention allocation. Here, we examined age-related differences in visual processing by recording eye movements from 37 children (aged 6–14 years) and 10 adults while viewing three 5-min dynamic video clips taken from child-friendly movies. The data were analyzed in two complementary ways: (a) gaze based and (b) content based. First, similarity of scanpaths within and across age groups was examined using three different measures of variance (dispersion, clusters, and distance from center). Second, content-based models of fixation were compared to determine which of these provided the best account of our dynamic data. We found that the variance in eye movements decreased as a function of age, suggesting common attentional orienting. Comparison of the different models revealed that a model that relies on faces generally performed better than the other models tested, even for the youngest age group (<10 years). However, the best predictor of a given participant's eye movements was the average of all other participants’ eye movements both within the same age group and in different age groups. These findings have implications for understanding how children attend to visual information and highlight similarities in viewing strategies across development. © 2017 The Author(s)",Development; Dynamic; Eye movements; Faces; Gaze; Saliency; Visual attention,"Adolescent; Adult; Aging; Attention; Child; Female; Fixation, Ocular; Humans; Male; Motion Pictures; Orientation; Semantics; Visual Perception; Young Adult; adolescent; adult; aging; attention; child; eye fixation; female; human; male; movie; orientation; physiology; semantics; vision; young adult",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85034093253,Movies / Media
Kano F.; Shepherd S.V.; Hirata S.; Call J.,"Kano, Fumihiro (23489132100); Shepherd, Stephen V. (12446187300); Hirata, Satoshi (35726539100); Call, Josep (35578594200)",23489132100; 12446187300; 35726539100; 35578594200,"Primate social attention: Species differences and effects of individual experience in humans, great apes, and macaques",2018,PLoS ONE,13,2,e0193283,,,,27,10.1371/journal.pone.0193283,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042500997&doi=10.1371%2fjournal.pone.0193283&partnerID=40&md5=3f2c52a725cbbc49d6c482df25624751,"When viewing social scenes, humans and nonhuman primates focus on particular features, such as the models’ eyes, mouth, and action targets. Previous studies reported that such viewing patterns vary significantly across individuals in humans, and also across closely-related primate species. However, the nature of these individual and species differences remains unclear, particularly among nonhuman primates. In large samples of human and nonhuman primates, we examined species differences and the effects of experience on patterns of gaze toward social movies. Experiment 1 examined the species differences across rhesus macaques, nonhuman apes (bonobos, chimpanzees, and orangutans), and humans while they viewed movies of various animals’ species-typical behaviors. We found that each species had distinct viewing patterns of the models’ faces, eyes, mouths, and action targets. Experiment 2 tested the effect of individuals’ experience on chimpanzee and human viewing patterns. We presented movies depicting natural behaviors of chimpanzees to three groups of chimpanzees (individuals from a zoo, a sanctuary, and a research institute) differing in their early social and physical experiences. We also presented the same movies to human adults and children differing in their expertise with chimpanzees (experts vs. novices) or movie-viewing generally (adults vs. preschoolers). Individuals varied within each species in their patterns of gaze toward models’ faces, eyes, mouths, and action targets depending on their unique individual experiences. We thus found that the viewing patterns for social stimuli are both individual- and species-specific in these closely-related primates. Such individual/ species-specificities are likely related to both individual experience and species-typical temperament, suggesting that primate individuals acquire their unique attentional biases through both ontogeny and evolution. Such unique attentional biases may help them learn efficiently about their particular social environments. © 2018 Kano et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Adult; Animals; Attention; Female; Hominidae; Humans; Macaca mulatta; Male; Social Behavior; Species Specificity; Visual Perception; animal behavior; animal experiment; ape; Article; attentional bias; body movement; chimpanzee; controlled study; evolution; eye movement; facial expression; gaze; human; Macaca; nonhuman; ontogeny; orangutan; personal experience; primate; rhesus monkey; social behavior; social environment; species difference; stimulus response; visual discrimination; adult; animal; attention; female; hominid; male; physiology; species difference; vision,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85042500997,Movies / Media
Zhang Y.; Yang H.; Xu Y.; Feng L.,"Zhang, Yunhong (56964064500); Yang, Haibo (36618479600); Xu, Yufeng (57194727939); Feng, Lei (57191069964)",56964064500; 36618479600; 57194727939; 57191069964,Comparison of visual comfort and fatigue between watching different types of 3D TVS as measured by eye tracking,2018,Advances in Intelligent Systems and Computing,586,,,175,186,11.0,4,10.1007/978-3-319-60642-2_16,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021836298&doi=10.1007%2f978-3-319-60642-2_16&partnerID=40&md5=a7089c3a3a78c3e658296aeba4cb7d6f,"An eye movement study was conducted to make clear whether different types of 3D TVs would help to relieve visual fatigue after watching films for a long time. 64 undergraduates and ordinary researchers were measured to compare the difference of watching different 3D TVs by Eye-tracking. 64 participants were divided into four groups after being matched, and the four matched groups were separately arranged to watch Switched 3D TV, polarized 3D TV, naked 3D TV and 2D TV. They watched the same video contents which were scenery video and a film, while eye movement data were recorded. The results showed that: (1) with the increase of watching time, participants’ fatigue also increased. The blink frequency, blink counts, blink total duration, saccade angle and saccade velocity of the four group participants who watched different types of 3D TVs remarkably increased in the overall trend with time; (2) There was a remarkable difference between the participants watching polarized 3D TV and others watching 3D TV and 2D TV in average saccade duration, saccade duration peak, average saccade angle and saccade total angle, which might indicate that the principle of polarized 3D TV would affect users’ saccade duration and saccade distance during watching videos. (3) The saccade amplitude of switched 3D TV was significantly higher than that of other three conditions, which might indicate a greater influence of saccade amplitude in switched 3D TV. © Springer International Publishing AG 2018.",3D TV; Eye-tracking; Visual comfort; Visual fatigue,Computer programming; Computer science; Blink frequencies; Eye movement datum; Eye-tracking; Polarized 3D; Saccade distances; Video contents; Visual comfort; Visual fatigue; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85021836298,Movies / Media
Zhang C.; Zhou J.; Zhu S.,"Zhang, Chi (57202085584); Zhou, Jun (56203158200); Zhu, Shoucheng (57200655465)",57202085584; 56203158200; 57200655465,The statistic modeling of eye movement viewing S3D images,2018,Communications in Computer and Information Science,815,,,203,214,11.0,0,10.1007/978-981-10-8108-8_19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042128191&doi=10.1007%2f978-981-10-8108-8_19&partnerID=40&md5=ac2a7b567d466b0feb335f686067050c,"Nowadays, more and more families are willing to buy 3D TV to improve their watching experience. Stereo perception produced by watching 3D images or videos brings strong immersive watching experience to users. However, accumulated vision fatigue confuses users a lot after watching 3D TV for a long time. When watching 3D images, controlled by past recognition experience and visual attention mechanism, gaze point of two eyes is changing among different objects which have different depth of field. The eye movement in this changing process is called vergence. Vergence can be defined as movement of our eyes in opposite directions to locate the area of interest on the fovea and accommodation as alteration of the lens to obtain and maintain the area of interest focused on the fovea. So the more frequently the vergence process occurs, the more uncomfortable we feel. We expect to obtain several eye movement patterns, which can be considered as some typical visual attention patterns, by building a top-down recognition and visual attention model and then applying some clustering methods to find them. So we use an eye tracker to record eye movement data and then model it as a bayesian network model. The generative model is based on beta process and we build an Autoregression-HMM model to describe the relationship between latent eye movement patterns and eye movement data. To uncover parameters which represent different eye movement patterns in this model, we use MCMC method to calculate them with iterative computations. In this work, some different latent patterns existed in the sequential eye movement data can be revealed. After analyzing these patterns, we are able to find out some similarities and differences of visual attention models between different people watching the same image or between different images viewed by the same one. These conclusions can help to improve quality of 3D image thus lessening the users’ vision fatigue when watching 3D TV. This work also will contribute to understanding the relationship between visual attention, visual model and visual discomfort. A regression method can be applied to discover more specific conclusions in further research. © 2018, Springer Nature Singapore Pte Ltd.",Bayes network; Beta process; Clustering; Hidden Markov chain,Bayesian networks; Behavioral research; Bioinformatics; Digital television; Image enhancement; Iterative methods; Markov processes; Multimedia systems; Regression analysis; Bayes networks; Bayesian network models; Beta process; Clustering; Hidden Markov chains; Iterative computation; Visual attention mechanisms; Visual attention model; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85042128191,Movies / Media
Noiret N.; Carvalho N.; Laurent É.; Chopard G.; Binetruy M.; Nicolier M.; Monnin J.; Magnin E.; Vandel P.,"Noiret, Nicolas (56222724100); Carvalho, Nicolas (56222392400); Laurent, Éric (55362209600); Chopard, Gilles (20435560700); Binetruy, Mickaël (26429194500); Nicolier, Magali (25629884100); Monnin, Julie (6602314217); Magnin, Eloi (27467599800); Vandel, Pierre (7003744211)",56222724100; 56222392400; 55362209600; 20435560700; 26429194500; 25629884100; 6602314217; 27467599800; 7003744211,Saccadic eye movements and attentional control in Alzheimer's disease,2018,Archives of Clinical Neuropsychology,33,1,,1,13,12.0,54,10.1093/arclin/acx044,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041651666&doi=10.1093%2farclin%2facx044&partnerID=40&md5=ebfb1bdc6ecc5acb7d4a3e7b7bc8f81e,"Objective: Several studies have demonstrated saccadic eye movement (SEM) abnormalities in Alzheimer's disease (AD) when patients performed prosaccade (PS) and antisaccade (AS) tasks. Some studies have also showed that SEM abnormalities were correlated with dementia rating tests such as the Mini Mental State Evaluation (MMSE). Therefore, it has been suggested that SEMs could provide useful information for diagnosis. However, little is known about predictive saccades (PreS)-saccades triggered before or very quickly after stimuli appearance-and their relationships with cognition in AD. Here, we aimed to examine the relationships between our usual dementia screening tests and SEM parameters in PS, AS, and also PreS task. Method: We compared SEMs in 20 patients suffering from AD and in 35 healthy older adults (OA) in PS, AS, and PreS task. All participants also completed a neuropsychological evaluation. Results: We showed that AD patients had higher latency and latency variability regardless the tasks, and also higher AS cost, in comparison with OA. Moreover, AD patients made more uncorrected AS and took more time-To-correct incorrect AS. In PreS task, AD patients showed higher gain and gain variability than OA when they made anticipated saccades. Close relationships were found between the majority of SEM variables in PS, AS, and PreS tasks and dementia screening tests, especially the MMSE and episodic memory measures. Conclusion: Our findings, in agreement with previous studies, demonstrated that AD affects several SEM parameters. SEM abnormalities may reflect selective and executive-Attention impairments in AD.",Attention; Dementia; Executive functions,"Aged; Aged, 80 and over; Alzheimer Disease; Case-Control Studies; Female; Humans; Male; Neuropsychological Tests; Psychomotor Performance; Saccades; aged; Alzheimer disease; case control study; female; human; male; neuropsychological test; pathophysiology; physiology; psychology; psychomotor performance; saccadic eye movement; very elderly",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85041651666,Movies / Media
Doebel S.; Dickerson J.P.; Hoover J.D.; Munakata Y.,"Doebel, Sabine (25635565400); Dickerson, John P. (55363539800); Hoover, Jerome D. (57193315031); Munakata, Yuko (57206398848)",25635565400; 55363539800; 57193315031; 57206398848,Using language to get ready: Familiar labels help children engage proactive control,2018,Journal of Experimental Child Psychology,166,,,147,159,12.0,24,10.1016/j.jecp.2017.08.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034052023&doi=10.1016%2fj.jecp.2017.08.006&partnerID=40&md5=44968d738d5b0718ef3da7f3cd683971,"A key developmental transition is the ability to engage executive functions proactively in advance of needing them. We tested the potential role of linguistic processes in proactive control. Children completed a task in which they could proactively track a novel (target) shape on a screen as it moved unpredictably amid novel distractors and needed to identify where it disappeared. Children almost always remembered which shape to track, but those who learned familiar labels for the target shapes before the task had nearly twice the odds of tracking the target compared with those who received experience with the targets but no labels. Children who learned labels were also more likely to spontaneously vocalize labels when the target appeared. These findings provide the first evidence of a causal role for linguistic processes in proactive control and suggest new ideas about how proactive control develops, why language supports a variety of executive functions, and how interventions might best be targeted. © 2017 Elsevier Inc.",Cognitive control; Executive functions; Labeling; Language and thought; Proactive control; Visual tracking,"Child Development; Child, Preschool; Executive Function; Female; Humans; Language; Learning; Male; Pattern Recognition, Visual; Psychomotor Performance; Space Perception; child; executive function; eye tracking; female; human; human experiment; language; male; thinking; child development; depth perception; executive function; learning; pattern recognition; physiology; preschool child; psychomotor performance",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85034052023,Movies / Media
Erridge S.; Ashraf H.; Purkayastha S.; Darzi A.; Sodergren M.H.,"Erridge, S. (56989487600); Ashraf, H. (57197830758); Purkayastha, S. (36151052000); Darzi, A. (14633357600); Sodergren, M.H. (25929707800)",56989487600; 57197830758; 36151052000; 14633357600; 25929707800,Comparison of gaze behaviour of trainee and experienced surgeons during laparoscopic gastric bypass,2018,British Journal of Surgery,105,3,,287,294,7.0,35,10.1002/bjs.10672,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036553856&doi=10.1002%2fbjs.10672&partnerID=40&md5=d8f4f95609be9015b80cb3502aa2d3ea,"Background: Eye tracking presents a novel tool that could be used to profile skill levels in surgery objectively. The primary aim of this study was to identify differences in gaze behaviour between expert and junior surgeons performing a laparoscopic Roux-en-Y gastric bypass (LRYGB) for obesity. Methods: This prospective observational study used a lightweight eye-tracking apparatus to determine the difference in gaze behaviours between expert (more than 75 procedures) and junior (75 or fewer procedures) surgeons at defined stages of LRYGB. Primary endpoints were normalized dwell time and fixation frequency. Secondary endpoints were blink rate, maximum pupil size and rate of pupil change. Results: A total of 20 procedures (12 junior, 8 expert) were analysed. Compared with juniors, experts showed a prolonged dwell time on the screen during angle of His dissection (median (range) 91·20 (83·40–94·40) versus 68·95 (59·80–87·60) per cent; P = 0·001), formation of the retrogastric tunnel (91·50 (85·80–95·50) versus 73·60 (34·60–90·50) per cent; P = 0·001) and gastric pouch formation (86·95 (83·60–90·20) versus 67·60 (37·10–80·00) per cent P < 0·001). Juniors had a greater blink frequency throughout all recorded segments (P < 0·010) and had a larger maximum pupil size during all recorded operative segments (P < 0·010). Rate of pupil change was greater in juniors in all analysed segments (P < 0·010). Conclusion: These results suggest that experts display more focused attention on significant stimuli, alongside experiencing a reduced mental workload and having increased concentration. This has the potential for future use in validation of surgical skill in high-stakes assessment. © 2017 BJS Society Ltd Published by John Wiley & Sons Ltd",,"Clinical Competence; Female; Fixation, Ocular; Gastric Bypass; Humans; Laparoscopy; London; Male; Obesity, Morbid; Prospective Studies; Surgeons; Article; comparative study; dwell time; eye tracking; eyelid reflex; female; gastric bypass surgery; gaze; human; laparoscopic surgery; male; medical expert; mini gastric bypass; obesity; observational study; prospective study; pupil diameter; Roux-en-Y gastric bypass; stomach pouch; surgeon; clinical competence; education; England; eye fixation; laparoscopy; morbid obesity; procedures; psychology; surgeon",Article,Final,All Open Access,Scopus,2-s2.0-85036553856,Movies / Media
"Rodriguez J.D.; Lane K.J.; Ousler G.W., III; Angjeli E.; Smith L.M.; Abelson M.B.","Rodriguez, John D. (55619203100); Lane, Keith J. (36463861200); Ousler, George W. (6507403042); Angjeli, Endri (54388521500); Smith, Lisa M. (55571996700); Abelson, Mark B. (7005842739)",55619203100; 36463861200; 6507403042; 54388521500; 55571996700; 7005842739,"Blink: Characteristics, Controls, and Relation to Dry Eyes",2018,Current Eye Research,43,1,,52,66,14.0,63,10.1080/02713683.2017.1381270,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039160403&doi=10.1080%2f02713683.2017.1381270&partnerID=40&md5=86b17160dae533954a6bd4b813bbe0b3,"Blink is a complex phenomenon that is profoundly affected by diverse endogenous and exogenous stimuli. It has been studied in the context of cognition, emotional, and psychological states, as an indicator of fatigue and sleepiness, particularly in the automobile and transportation industry, in visual tasking, and finally, as it relates to tear film stability and ocular surface health. The fact that it is highly variable and has input from so many sources makes it very difficult to study. In the present review, the behavior of blink in many of these systems is discussed, ultimately returning in each instance to a discussion of how these factors affect blink in the context of dry eyes. Blink is important to ocular surface health and to an individual’s optimal functioning and quality of life. Disturbances in blink, as cause or effect, result in a breakdown of tear film stability, optical clarity, and visual function. © 2017 Taylor & Francis.",Blink; clinical trialsmicrosleeps; dry eye; interblink interval; ocular surface; quality of life; tear film breakup; tear film stability; visual function; visual tasking,Blinking; Cornea; Dry Eye Syndromes; Humans; Quality of Life; Tears; blinking; clinical assessment; cognition; disease association; dry eye; early intervention; eye discomfort; eyelid reflex; fatigue; human; priority journal; quality of life; Review; saccadic eye movement; tear film; visual acuity; chemistry; cornea; dry eye; lacrimal fluid; metabolism; pathophysiology; physiology; quality of life,Review,Final,,Scopus,2-s2.0-85039160403,Movies / Media
Hammerschmidt D.; Wollner C.,"Hammerschmidt, David (57202651071); Wollner, Clemens (25621588600)",57202651071; 25621588600,The impact of music and stretched time on pupillary responses and eye movements in slow-motion film scenes,2018,Journal of Eye Movement Research,11,2,,1,17,16.0,12,10.16910/jemr.11.2.10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048947642&doi=10.16910%2fjemr.11.2.10&partnerID=40&md5=7e93c31444c623362fcb2f67b5066872,"This study investigated the effects of music and playback speed on arousal and visual perception in slow-motion scenes taken from commercial films. Slow-motion scenes are a ubiquitous film technique and highly popular. Yet the psychological effects of mediated time-stretching compared to real-time motion have not been empirically investigated. We hypothesised that music affects arousal and attentional processes. Furthermore, we assumed that playback speed influences viewers’ visual perception, resulting in a higher number of eye movements and larger gaze dispersion. Thirty-nine participants watched three film excerpts in a repeated-measures design in conditions with or without music and in slow motion vs. adapted real-time motion (both visual-only). Results show that music in slow-motion film scenes leads to higher arousal compared to no music as indicated by larger pupil diameters in the former. There was no systematic effect of music on visual perception in terms of eye movements. Playback speed influenced visual perception in eye movement parameters such that slow motion resulted in more and shorter fixations as well as more saccades compared to adapted real-time motion. Furthermore, in slow motion there was a higher gaze dispersion and a smaller centre bias, indicating that individuals attended to more detail in slow motion scenes. ©This article is licensed under a Creative Commons Attribution 4.0 International license",attention; blinks; emotion; eye tracking; film music; fixations; gaze; perception; pupil diameter; pupillometry; saccades,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85048947642,Movies / Media
Miller N.; Wyatt J.; Casey L.B.; Smith J.B.,"Miller, Neal (57190852376); Wyatt, Jennifer (57196417471); Casey, Laura Baylot (24074042400); Smith, J. Brian (56420651400)",57190852376; 57196417471; 24074042400; 56420651400,Using computer-assisted instruction to increase the eye gaze of children with autism,2018,Behavioral Interventions,33,1,,3,12,9.0,12,10.1002/bin.1507,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032954262&doi=10.1002%2fbin.1507&partnerID=40&md5=c621bd16339ad6c9636d97dd36b7714b,"Many children diagnosed with autism spectrum disorders have difficulty making appropriate eye contact and engaging in joint attention. The current study evaluated a computer-assisted instruction package (pairing visual stimuli with vocal stimuli) as a novel treatment to improve the eye gaze accuracy in 3 elementary school children with autism. The researchers measured the latency from a recorded verbal stimulus to the students making eye contact with pictures of familiar individuals displayed on a computer screen, and the duration for which eye gaze on the stimulus was maintained. An automated infrared camera system for measuring eye gaze was utilized that eliminated the need for an instructor to make subjective judgments regarding participants' eye gaze. For all three participants, duration of eye contact increased, and latency to responding decreased following exposure to the computer-assisted instruction. The implications of these findings for the treatment of individuals with autism are discussed, along with suggestions for future research on the topic. Copyright © 2017 John Wiley & Sons, Ltd.",,,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85032954262,Movies / Media
Wearne A.; Wray R.E.,"Wearne, Adam (55869466900); Wray, Robert E. (7006550568)",55869466900; 7006550568,Exploration of behavioral markers to support adaptive learning,2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10903 LNCS,,,355,365,10.0,2,10.1007/978-3-319-91250-9_28,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061551144&doi=10.1007%2f978-3-319-91250-9_28&partnerID=40&md5=64bc27e4c06ae3fe60bc4652e35d66a4,"In designing and developing adaptive learning systems, it is desirable to incorporate as much information about the learner as possible to better tailor in instructional experience. Behavioral markers exhibited by the learner offer a source of information with the potential to shape instructional content. In the case of computer-based training environments, this source of information may include behaviors ranging from mouse cursor movement, key stroke dynamics, or eye tracking. We present methods for analyzing the mouse behavior of a learner using kinematic data in situations where knowledge of areas of interest on the screen are not known by the system a priori, as well as in multiple-choice scenarios to analyze the amount of attention spent by the user on various response items. The outcome of this work is to help inform and to influence future studies in adaptive learning which may seek to incorporate such sources of learner information. © Springer International Publishing AG, part of Springer Nature 2018.",Adaptive training; Mouse tracking,Eye movements; Eye tracking; Learning systems; Mammals; Adaptive learning; Adaptive learning systems; Adaptive training; Computer - based trainings; Instructional experience; Learner information; Mouse behaviors; Multiple choice; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85061551144,Movies / Media
Wan Q.; Wang G.G.; Zhang Y.C.; Song S.S.; Fei B.H.; Li X.H.,"Wan, Qian (57203072372); Wang, Ge Ge (57191573956); Zhang, Ya Chi (57189380677); Song, Sha Sha (42962601700); Fei, Ben Hua (55141440600); Li, Xiao He (57201025907)",57203072372; 57191573956; 57189380677; 42962601700; 55141440600; 57201025907,Cognitve processing torword traditional and new Chinese style furniture: Evidence from eye-tracking technology,2018,Wood Research,63,4,,727,740,13.0,16,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052926786&partnerID=40&md5=047c5ee6ecf76694c7b67c07e3bcd117,"Eye-tracking technology was shown to have the ability to indicate human’s cognitive preferences toward objects. Using eye-tracking technology to study the cognitive preferences on different Chinese furniture style may have the potential to promote the furniture design from a novel perspective. Experiment was designed to test the differences of eye movement index (total fixation time, average fixation counts and average pupil diameter) within variables of gender, major and furniture styles. Participants were asked to observe two sets of different styles of Chinese furniture pictures on computer screen. Significant differences of total fixation time and average fixation counts were found between different furniture styles (p<0.01), gender (p<0.001), but not in major (p>0.05). Significant difference was also found in average pupil diameter in different furniture styles (p<0.01) and gender (p<0.01).Subjects’ fixation time stayed longer on new Chinese style furniture pictures than traditional furniture pictures. The results indicated that compared to traditional Chinese style furniture, people tend to take more interest in the new Chinese style furniture. Gender as a factor had a significant influence on the cognitive processing towards the viewing of pictures of the Chinese style furniture. Meanwhile, subjects paid more attention to the decorative details on the furniture, implying appropriate design and decoration may improve people’s interest to the furniture. © 2018 Statny Drevarsky Vyskumny Ustav. All Rights Reserved.",Cognitive processing; Eye-tracking technology; Furniture design; Traditional furniture. new Chinese style furniture,Chinese; Design; Furniture; Interest; Photographs; Processing; Ridges; Technology; Design; Eye movements; Appropriate designs; Cognitive processing; Computer screens; Eye tracking technologies; Fixation time; Furniture design; Pupil diameter; Traditional furniture. new Chinese style furniture; Eye tracking,Article,Final,,Scopus,2-s2.0-85052926786,Movies / Media
Puntiroli M.; Kerzel D.; Born S.,"Puntiroli, Michael (56674762700); Kerzel, Dirk (7004356164); Born, Sabine (25321131300)",56674762700; 7004356164; 25321131300,Placeholder objects shape spatial attention effects before eye movements,2018,Journal of Vision,18,6,1,1,20,19.0,6,10.1167/18.6.1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049755949&doi=10.1167%2f18.6.1&partnerID=40&md5=38d48857fc71bd4d1730e5c233f68b13,"In the time leading up to a saccade, the saccade target is perceptually enhanced compared to other objects in the visual field. This enhancement is attributed to a shift of spatial attention toward the target. We examined whether the presence of visual objects is critical for the perceptual enhancement at the saccade target to occur. We hypothesized that attention may need an object to focus on in order to be effective. We conducted four experiments using a dual-task design, where participants performed eye movements either to a location demarked by a placeholder or to an empty screen location where no object was displayed. At the same time, they discriminated a probe flashed at the location targeted by the eye movement or at one of two control locations. A strong perceptual advantage at the saccade target location was observed only when placeholders were displayed at the time of probe presentation. The complete absence of placeholders (Experiment 1), the presence of placeholders before but not during probe presentation (Experiment 3), and the presence of objects only around the saccade target (Experiments 3 and 4) led to a strong reduction in the saccade-target benefit. We conclude that placeholders may indeed be necessary to observe presaccadic enhancement at the saccade target. However, this is not because placeholders provide an object to focus attention on, but rather because they produce a masking (or crowding) effect. This detrimental effect is overcome by the presaccadic shift of attention, resulting in heightened perception only at the saccade target object. © 2018 The Authors.",Masking; Object selection; Perceptual enhancement; Placeholders; Saccades; Spatial attention,Adult; Attention; Female; Form Perception; Humans; Male; Saccades; Spatial Processing; Visual Fields; Young Adult; adult; attention; female; human; male; pattern recognition; physiology; saccadic eye movement; spatial behavior; visual field; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85049755949,Movies / Media
Imabuchi T.; Prima O.D.A.; Ito H.; Kameda M.,"Imabuchi, Takashi (56568206100); Prima, Oky Dicky Ardiansyah (14060899300); Ito, Hisayoshi (56200735700); Kameda, Masashi (7005058483)",56568206100; 14060899300; 56200735700; 7005058483,Head-Movement Compensation for Visible-Spectrum Remote Eye Tracker; [頭部姿勢の変動を考慮した可視光線非接触型の視線計測システムの開発],2018,Journal of the Institute of Image Electronics Engineers of Japan,47,1,,31,40,9.0,1,10.11371/iieej.47.31,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115940126&doi=10.11371%2fiieej.47.31&partnerID=40&md5=4c3d19d934daf453849bb649c7ba54f5,"Eye trackers have been used in various fields such as eye movement-related brain activity analyses, visual attention analyses and gaze input interfaces. Recently, these trackers have been improved in both terms of accuracy and portability. In this study, we propose a new eye tracking method which enables to estimate gaze direction from faces in images or movies without using the conventional eye trackers, and evaluate the proposed method based on accuracies of point-of-regards (POR) to measure its capability as gaze input interfaces. The proposed method contains four steps: fitting a 3D model to the targeted facial image, extracting and geometrically correcting the regions of eyes using head-pose information, fitting a circle to each iris to localize its center, and compensating the POR corresponding to the head-pose changes. Our experiment’s result on 11 subjects shows that the average error between each fixation target and the POR is about 2 and 3.5 degrees for ±5 and ±5~±20 degrees head movement, respectively. © 2018 Institute of Image Electronics Engineers of Japan. All rights reserved.",eye tracking; facial landmark detection; head movement compensation; iris center localization; visible-spectrum camera,3D modeling; Behavioral research; Brain; Eye tracking; Face recognition; Motion analysis; Eye trackers; Eye-tracking; Facial landmark detection; Head movement compensations; Input interface; Iris center localization; Localisation; Point of regards; Visible spectrums; Visible-spectrum camera; Eye movements,Article,Final,,Scopus,2-s2.0-85115940126,Movies / Media
Hara M.; Hida O.; Nakajima M.; Osaki M.; Kinoshita S.; Mitsumura K.; Omura T.; Tokunaga E.,"Hara, Mutsuko (56281995500); Hida, Osamu (24068705200); Nakajima, Masami (57191439632); Osaki, Masami (15045409200); Kinoshita, Shingo (36542836300); Mitsumura, Kazuhiro (24491896500); Omura, Takayo (57191440029); Tokunaga, Eikichi (15045943900)",56281995500; 24068705200; 57191439632; 15045409200; 36542836300; 24491896500; 57191440029; 15045943900,Two cases of paraneoplastic neurological syndrome with dizziness,2018,"Practica Otologica, Supplement",152,,,10,11,1.0,0,10.5631/jibirinsuppl.152.10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057111309&doi=10.5631%2fjibirinsuppl.152.10&partnerID=40&md5=de45e675ae63b5f51418bf4a30ca4985,"Patients with abnormal eye movements and dizziness are often encountered at the department of otolaryngology. We report on 2 patients with dizziness who were referred to our otolaryngology department for examination, and were finally diagnosed as having paraneoplastic neurological syndrome (PNS). In cases with abnormal eye movements, attention should be paid to the neurologic symptoms. PNS should be considered in the differential diagnosis, as it represents an important clue to the presence of an underlying malignant tumor. It is necessary to perform whole-body CT or PET-CT, and tests for tumor markers and anti-neuronal autoantibodies. Since the neurologic symptoms often precede the discovery of the tumor and the initial tests for anti-neuronal autoantibodies could be negative, it is important to repeat these screening tests. © 2018 Society of Practical Otolaryngology.All Rights Reserved.",Dizziness; Eye movement; Neurologic symptoms; Paraneoplastic neurological syndrome,,Article,Final,,Scopus,2-s2.0-85057111309,Movies / Media
Harvey H.; Walker R.,"Harvey, Hannah (55486476700); Walker, Robin (8130743500)",55486476700; 8130743500,Reading comprehension and its relationship with working memory capacity when reading horizontally scrolling text,2018,Quarterly Journal of Experimental Psychology,71,9,,1887,1897,10.0,7,10.1080/17470218.2017.1363258,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055586048&doi=10.1080%2f17470218.2017.1363258&partnerID=40&md5=1e01b64cdc42fe802440782d154a6515,"The horizontally scrolling format, where text is presented in a single line drifting right to left, is relatively commonly used to display text on digital screens. This format presents a potentially challenging reading situation as the text must be followed smoothly to the left (to track individual words) while rightward eye movements are made as usual to progress through the text. This conflict may reduce attention allocated to upcoming text. Returning to previously encountered text is also more difficult with this format. Here, a sustained reading comprehension task was used to compare performance with horizontally scrolling and multi-line static text formats. Results showed that literal comprehension can be reasonably well maintained with scrolling text, although small decrements are seen at faster scrolling rates. However, they indicated that this format makes it more difficult to answer questions requiring an inference to be made. The contribution of working memory capacity and the impact of display speed on these effects were considered. These findings have implications for the application of this format in digital media and also more widely for the conditions required for successful in-depth reading comprehension with any text format. © Experimental Psychology Society 2017.",Comprehension; Digital media; Dynamic text; Reading; Working memory,"Adolescent; Attention; Comprehension; Eye Movements; Female; Functional Laterality; Humans; Male; Memory, Short-Term; Online Systems; Photic Stimulation; Reading; Verbal Learning; Visual Perception; Young Adult; adolescent; attention; comprehension; eye movement; female; hemispheric dominance; human; male; online system; photostimulation; physiology; reading; short term memory; verbal learning; vision; young adult",Article,Final,,Scopus,2-s2.0-85055586048,Movies / Media
Carette R.; Cilia F.; Dequen G.; Bosche J.; Guerin J.-L.; Vandromme L.,"Carette, Romuald (57200860085); Cilia, Federica (57200855464); Dequen, Gilles (23396657900); Bosche, Jerome (6701595130); Guerin, Jean-Luc (57200857001); Vandromme, Luc (57019167100)",57200860085; 57200855464; 23396657900; 6701595130; 57200857001; 57019167100,Automatic Autism Spectrum Disorder Detection Thanks to Eye-Tracking and Neural Network-Based Approach,2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",225,,,75,81,6.0,24,10.1007/978-3-319-76213-5_11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042554864&doi=10.1007%2f978-3-319-76213-5_11&partnerID=40&md5=19c4eadd5c1c22b26f3010f8ea583c8d,"Autism spectrum disorder (ASD) is a neurodevelopmental disorder quite wide and its numerous variations render diagnosis hard. Some works have proven that children suffering from autism have trouble keeping their attention and tend to have a less focused sight. On top of that, eye-tracking systems enable the recording of precise eye focus on a screen. This paper deals with automatic detection of autism spectrum disorder thanks to eye-tracked data and an original Machine Learning approach. Focusing on data that describes the saccades of the patient’s sight, we distinguish, out of our six test patients, young autistic individuals from those with no problems in 83% (five) of tested patients, with a results confidence up to 95%. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",Autism spectrum disorder; Data processing; eHealth; Eye-tracking; Long Short-Term Memory (LSTM); Neural network,Data handling; Data processing; Diagnosis; Diseases; eHealth; Eye movements; Health care; Internet of things; Learning systems; Long short-term memory; Neural networks; Autism spectrum disorders; Automatic Detection; Eye tracking systems; Machine learning approaches; Network-based approach; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85042554864,Movies / Media
Betti V.; Corbetta M.; de Pasquale F.; Wens V.; Penna S.D.,"Betti, Viviana (23501031500); Corbetta, Maurizio (7003824365); de Pasquale, Francesco (55796810200); Wens, Vincent (22954733400); Penna, Stefania Della (6602677707)",23501031500; 7003824365; 55796810200; 22954733400; 6602677707,Topology of functional connectivity and hub dynamics in the beta band as temporal prior for natural vision in the human brain,2018,Journal of Neuroscience,38,15,,3858,3871,13.0,28,10.1523/JNEUROSCI.1089-17.2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050473264&doi=10.1523%2fJNEUROSCI.1089-17.2018&partnerID=40&md5=5e94103d5e7ca323095e94b6c81d7e39,"Networks hubs represent points of convergence for the integration of information across many different nodes and systems. Although a great deal is known on the topology of hub regions in the human brain, little is known about their temporal dynamics. Here, we examine the static and dynamic centrality of hub regions when measured in the absence of a task (rest) or during the observation of natural or synthetic visual stimuli. We used Magnetoencephalography (MEG) in humans (both sexes) to measure static and transient regional and network-level interaction in α- and β-band limited power (BLP) in three conditions: visual fixation (rest), viewing of movie clips (natural vision), and time-scrambled versions of the same clips (scrambled vision). Compared with rest, we observed in both movie conditions a robust decrement of α-BLP connectivity. Moreover, both movie conditions caused a significant reorganization of connections in the α band, especially between networks. In contrast, β-BLP connectivity was remarkably similar between rest and natural vision. Not only the topology did not change, but the joint dynamics of hubs in a core network during natural vision was predicted by similar fluctuations in the resting state. We interpret these findings by suggesting that slow-varying fluctuations of integration occurring in higher-order regions in the β band may be a mechanism to anticipate and predict slow-varying temporal patterns of the visual environment. © 2018 the authors.",Brain rhythms; Centrality; Functional connectivity; Magnetoencephalography; Natural stimulation; Resting-state networks,"Adult; Alpha Rhythm; Beta Rhythm; Brain; Eye Movements; Female; Humans; Magnetoencephalography; Male; Vision, Ocular; Visual Perception; adult; Article; audiovisual stimulation; auditory network; beta band limited power; beta rhythm; controlled study; default mode network; dorsal attention network; female; functional connectivity; functional magnetic resonance imaging; human; human experiment; language network; magnetoencephalography; male; natural vision; normal human; priority journal; rest vision; resting state network; scrambled vision; somatomotor network; task performance; ventral attention network; vision; visual network; visual stimulation; alpha rhythm; brain; eye movement; physiology; vision",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85050473264,Movies / Media
Wong S.F.; Cong Y.F.,"Wong, S.F. (14020711100); Cong, Y.F. (57192999633)",14020711100; 57192999633,Comparison of Visual Performance with Operational Fatigue Level based on Eye Tracking Model,2018,Procedia Manufacturing,17,,,302,308,6.0,1,10.1016/j.promfg.2018.10.050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060441889&doi=10.1016%2fj.promfg.2018.10.050&partnerID=40&md5=daa1b9ef1dd912ce67e68807a1c74575,"Fatigue is factor which can cause health problems and decrease work efficiency. State of the art fatigue studies are mainly committed to investigating impacts of the Visual Display Terminal (VDT) screen luminance, resolution, and the distance between the VDT and operators. Fewer studies commit to understanding visual performance experienced by the operator when facing different conditions. This paper aims to find out whether the degree of fatigue and color combination of the interface that can influence visual performance when interacting with a text-based and eye tracking under exercise and no-exercise consideration. The viewing performance of 30 subjects was estimated by comparing eye tracker measurements before and after moderate exercise. Visual reaction time is significantly affected by color backgrounds. Color background transfer results in a long reaction time, while the white background transfer leads to a short time reaction time. The testers who exercise before the experiment have more positive performance than those who do not in an attention test. For the subjects who exercised, the longer they were able to rest, the better their performance. Therefore, engaging in appropriate exercise may have a good effect on the performance of operators. Additionally, the change in interface motivates eye movements and improves eye performance. © 2018 The Authors.",Exercise Consideration; Eye Tracking; Fatigue Level; Visual Performance,,Conference paper,Final,,Scopus,2-s2.0-85060441889,Movies / Media
Gerber-Morón O.; Szarkowska A.; Woll B.,"Gerber-Morón, Olivia (57202588774); Szarkowska, Agnieszka (54416458200); Woll, Bencie (7004344871)",57202588774; 54416458200; 7004344871,The impact of text segmentation on subtitle reading,2018,Journal of Eye Movement Research,11,4,2,,,,14,10.16910/jemr.11.4.2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052838309&doi=10.16910%2fjemr.11.4.2&partnerID=40&md5=a7c755fa6c31cb05e327966ae3e86c1c,"Understanding the way people watch subtitled films has become a central concern for subtitling researchers in recent years. Both subtitling scholars and professionals generally believe that in order to reduce cognitive load and enhance readability, line breaks in twoline subtitles should follow syntactic units. However, previous research has been inconclusive as to whether syntactic-based segmentation facilitates comprehension and reduces cognitive load. In this study, we assessed the impact of text segmentation on subtitle processing among different groups of viewers: hearing people with different mother tongues (English, Polish, and Spanish) and deaf, hard of hearing, and hearing people with English as a first language. We measured three indicators of cognitive load (difficulty, effort, and frustration) as well as comprehension and eye tracking variables. Participants watched two video excerpts with syntactically and non-syntactically segmented subtitles. The aim was to determine whether syntactic-based text segmentation as well as the viewers' linguistic background influence subtitle processing. Our findings show that non-syntactically segmented subtitles induced higher cognitive load, but they did not adversely affect comprehension. The results are discussed in the context of cognitive load, audiovisual translation, and deafness. © 2018, International Group for Eye Movement Research.",Audiovisual translation; Cognitive load; eye movement; Line breaks; Media accessibility; Reading; Region of interest; Revisits; Segmentation; Subtitling,,Article,Final,,Scopus,2-s2.0-85052838309,Movies / Media
Egner S.; Reimann S.; Hoeger R.; Zangemeister W.H.,"Egner, Steffen (59823085200); Reimann, Stefanie (57204830348); Hoeger, Rainer (56162458600); Zangemeister, Wolfgang H. (7006368690)",59823085200; 57204830348; 56162458600; 7006368690,Attention and information acquisition: Comparison of mouse-click with eye-movement attention tracking,2018,Journal of Eye Movement Research,11,6,4,,,,20,10.16910/jemr.11.6.4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057419865&doi=10.16910%2fjemr.11.6.4&partnerID=40&md5=60ac41d0119e91d62d244c49657485c9,"Attention is crucial as a fundamental prerequisite for perception. The measurement of attention in viewing and recognizing the images that surround us constitutes an important part of eye movement research, particularly in advertising-effectiveness research. Record-ing eye and gaze (i.e. eye and head) movements is considered the standard procedure for measuring attention. However, alternative measurement methods have been developed in recent years, one of which is mouse-click attention tracking (mcAT) by means of an on-line based procedure that measures gaze motion via a mouse-click (i.e. a hand and finger positioning maneuver) on a computer screen. Here we compared the validity of mcAT with eye movement attention tracking (emAT). We recorded data in a between subject design via emAT and mcAT and analyzed and compared 20 subjects for correlations. The test stimuli consisted of 64 images that were assigned to eight categories. Our main results demonstrated a highly significant correlation (p < 0.001) between mcAT and emAT data. We also found significant differences in corre-lations between different image categories. For simply structured pictures of humans or animals in particular, mcAT provided highly valid and more consistent results compared to emAT. We concluded that mcAT is a suitable method for measuring the attention we give to the images that surround us, such as photographs, graphics, art or digital and print advertisements. © 2018 Journal of Eye Movement Research.",Comparison of attention tracking; Eye-movement attention tracking; Information acquisition; Mouse-click attention tracking; Scanpath; Visual attention; Visual search,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85057419865,Movies / Media
Gerber-Morón O.; Szarkowska A.; Woll B.,"Gerber-Morón, Olivia (57202588774); Szarkowska, Agnieszka (54416458200); Woll, Bencie (7004344871)",57202588774; 54416458200; 7004344871,The impact of text segmentation on subtitle reading,2018,Journal of Eye Movement Research,11,4,,1,18,17.0,15,10.16910/11.4.2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102822383&doi=10.16910%2f11.4.2&partnerID=40&md5=b547926800a03d07226b82444d07d34d,"Understanding the way people watch subtitled films has become a central concern for subtitling researchers in recent years. Both subtitling scholars and professionals generally believe that in order to reduce cognitive load and enhance readability, line breaks in two-line subtitles should follow syntactic units. However, previous research has been inconclusive as to whether syntactic-based segmentation facilitates comprehension and reduces cognitive load. In this study, we assessed the impact of text segmentation on subtitle processing among different groups of viewers: hearing people with different mother tongues (English, Polish, and Spanish) and deaf hard of hearing, and hearing people with English as a first language. We measured three indicators of cognitive load (difficulty, effort, and frustration) as well as comprehension and eye tracking variables. Participants watched two video excerpts with syntactically and non-syntactically segmented subtitles. The aim was to determine whether syntactic-based text segmentation as well as the viewers’ linguistic background influence subtitle processing. Our findings show that non-syntactically segmented subtitles induced higher cognitive load, but they did not adversely affect comprehension. The results are discussed in the context of cognitive load, audiovisual translation, and deafness. © 2018. This article is licensed under a Creative Commons Attribution 4.0 International license.",audiovisual translation; cognitive load; eye movement; line breaks; media accessibility; reading; region of interest; revisits; segmentation; subtitling,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85102822383,Movies / Media
Mishra A.; Tamilselvam S.; Dasgupta R.; Nagar S.; Dey K.,"Mishra, Abhijit (56349872900); Tamilselvam, Srikanth (50462419200); Dasgupta, Riddhiman (57190278878); Nagar, Seema (25825414900); Dey, Kuntal (56350361100)",56349872900; 50462419200; 57190278878; 25825414900; 56350361100,Cognition-cognizant sentiment analysis with multitask subjectivity summarization based on annotators' gaze behavior,2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,,,5884,5891,7.0,27,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060457246&partnerID=40&md5=95c1b557192d855508ab4deb57a4ff0f,"For document level sentiment analysis (SA), Subjectivity Extraction, ie., extracting the relevant subjective portions of the text that cover the overall sentiment expressed in the document, is an important step. Subjectivity Extraction, however, is a hard problem for systems, as it demands a great deal of world knowledge and reasoning. Humans, on the other hand, are good at extracting relevant subjective summaries from an opinionated document (say, a movie review), while inferring the sentiment expressed in it. This capability is manifested in their eye-movement behavior while reading: words pertaining to the subjective summary of the text attract a lot more attention in the form of gaze-fixations and/or saccadic patterns. We propose a multi-task deep neural framework for document level sentiment analysis that learns to predict the overall sentiment expressed in the given input document, by simultaneously learning to predict human gaze behavior and auxiliary linguistic tasks like part-of-speech and syntactic properties of words in the document. For this, a multi-task learning algorithm based on multi-layer shared LSTM augmented with task specific classifiers is proposed. With this composite multi-task network, we obtain performance competitive with or better than state-of-the-art approaches in SA. Moreover, the availability of gaze predictions as an auxiliary output helps interpret the system better; for instance, gaze predictions reveal that the system indeed performs subjectivity extraction better, which accounts for improvement in document level sentiment analysis performance. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Behavioral research; Data mining; Extraction; Eye movements; Forecasting; Learning algorithms; Long short-term memory; Sentiment analysis; Syntactics; Auxiliary output; Movement behavior; Multitask learning; Part Of Speech; Saccadic patterns; State-of-the-art approach; Syntactic properties; World knowledge; Natural language processing systems,Conference paper,Final,,Scopus,2-s2.0-85060457246,Movies / Media
Matthews G.; Wohleber R.; Lin J.; Reinerman-Jones L.; Yerdon V.; Pope N.,"Matthews, Gerald (7201422023); Wohleber, Ryan (55582589700); Lin, Jinchao (56962942600); Reinerman-Jones, Lauren (36139029200); Yerdon, Valarie (57191057623); Pope, Nathanael (58379060500)",7201422023; 55582589700; 56962942600; 36139029200; 57191057623; 58379060500,Cognitive and affective eye tracking metrics for detecting insider threat: A study of simulated espionage,2018,Proceedings of the Human Factors and Ergonomics Society,1,,,242,246,4.0,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072725666&partnerID=40&md5=9a18d5737f37822047d2240f1631dae3,"Insider Threat (IT) is a growing cybersecurity issue. Countermeasures based on cognitive engineering may utilize diagnostic eye fixation responses indicative of insider intent, elicited by Active Indicator Probes (AIPs). The current study embedded AIPs into an immersive simulation of espionage activities. Participants allocated to an insider role were required to monitor building images for cues to a terrorist person-of-interest, and communicate information to an external handler. Control participants performed matched normal work. Findings confirmed a previous finding that ITs show fixation responses suggestive of strategic concealment of interest They also showed heightened attention to communications from their local controller. These results may contribute to identification of possible ITs for further screening. © 2018 Human Factors an Ergonomics Society Inc.. All rights reserved.",,Ergonomics; Cognitive engineering; Cyber security; Eye fixations; Immersive; Insider Threat; Local controllers; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85072725666,Movies / Media
Nagamune K.; Takata K.,"Nagamune, Kouki (9334125600); Takata, Keisuke (57203131618)",9334125600; 57203131618,Analysis of human motion and cognition ability with virtual reality system: Basic mechanism of human response,2018,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10908 LNCS,,,78,86,8.0,0,10.1007/978-3-319-92052-8_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050613808&doi=10.1007%2f978-3-319-92052-8_7&partnerID=40&md5=ba0718a110a6a2cd3969f2eda617b7fd,"When grasping an object, a human needs to recognize the object. In general, after the center of gravity of the object is recognized from the object shape, the human grasps a position close to the center of gravity. This research analyzes the relationship between the object shape and the sight trajectory until grasping. The proposed method traces finger motions when grasping the virtual 3D objects displayed on a screen by using finger motion capture device. In the motion, the sight trajectory is also measured and analyzed by using the eye tracking device. We conducted experiments with five subjects and analyzed the relationship between the variation of the line of sight trajectory and the size of the grasped object. © Springer International Publishing AG, part of Springer Nature 2018.",Motion; Rehabilitation; Virtual reality,Eye tracking; Motion analysis; Patient rehabilitation; Trajectories; Virtual reality; Basic mechanism; Center of gravity; Eye tracking devices; Grasped object; Human response; Motion; Virtual 3D objects; Virtual reality system; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85050613808,Movies / Media
Meier M.E.; Smeekens B.A.; Silvia P.J.; Kwapil T.R.; Kane M.J.,"Meier, Matt E. (36627241500); Smeekens, Bridget A. (57113696000); Silvia, Paul J. (7004194432); Kwapil, Thomas R. (6603921291); Kane, Michael J. (7202167989)",36627241500; 57113696000; 7004194432; 6603921291; 7202167989,Working Memory Capacity and the Antisaccade Task: A Microanalytic–Macroanalytic Investigation of Individual Differences in Goal Activation and Maintenance,2018,Journal of Experimental Psychology: Learning Memory and Cognition,44,1,,68,84,16.0,34,10.1037/xlm0000431,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053488629&doi=10.1037%2fxlm0000431&partnerID=40&md5=fb788bb6435e859d917f65aee2919fec,"The association between working memory capacity (WMC) and the antisaccade task, which requires subjects to move their eyes and attention away from a strong visual cue, supports the claim that WMCis partially an attentional construct (Kane, Bleckley, Conway, & Engle, 2001; Unsworth, Schrock, &Engle, 2004). Specifically, the WMC-antisaccade relation suggests that WMC helps maintain andexecute task goals despite interference from habitual actions. Related work has recently shown that mindwandering (McVay & Kane, 2009, 2012a, 2012b) and reaction time (RT) variability (Unsworth, 2015)are also related to WMC and they partially explain WMC’s prediction of cognitive abilities. Here, wetested whether mind-wandering propensity and intraindividual RT variation account for WMC’s associations with 2 antisaccade-cued choice RT tasks. In addition, we asked whether any influences of WMC,mind wandering, or intraindividual RT variation on antisaccade are moderated by (a) the temporal gapbetween fixation and the flashing location cue, and (b) whether targets switch sides on consecutive trials.Our quasi-experimental study reexamined a published dataset (Kane et al., 2016) comprising 472 subjectswho completed 6 WMC tasks, 5 attentional tasks with mind-wandering probes, 5 tasks from which wemeasured intraindividual RT variation, and 2 antisaccade tasks with varying fixation-cue gap durations.The WMC-antisaccade association was not accounted for by mind wandering or intraindividual RTvariation. WMC’s effects on antisaccade performance were greater with longer fixation-to-cue intervals,suggesting that goal activation processes—beyond the ability to control mind wandering and RTvariability—are partially responsible for the WMC-antisaccade relation. © 2017. American Psychological Association",Antisaccade; Attention control; Individual difference; Mind wandering; Working memory capacity,"Adolescent; Adult; Attention; Executive Function; Fixation, Ocular; Goals; Humans; Individuality; Memory, Short-Term; Reaction Time; Saccades; Young Adult; adolescent; adult; attention; executive function; eye fixation; human; individuality; motivation; physiology; reaction time; saccadic eye movement; short term memory; young adult",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85053488629,Movies / Media
Hermund A.; Klint L.S.; Bundgaard T.S.,"Hermund, Anders (57203429395); Klint, Lars Simon (56650934800); Bundgaard, Ture Slot (57203432574)",57203429395; 56650934800; 57203432574,BIM with VR for architectural simulations building information models in virtual reality as an architectural and urban designtool,2018,Proceedings of the Annual International Conference on Architecture and Civil Engineering,0,,,,,,9,10.5176/2301-394X_ACE18.152,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051695962&doi=10.5176%2f2301-394X_ACE18.152&partnerID=40&md5=088bf4f2f185158d242eb9e975985455,"This paper discusses the possibilities of architectural representation models in new media such as virtual reality, seen in the context of perception, and neurology. The discussion takes it starting point in the findings of a study of the similarities between the perception of architectural space experienced in physical space conditions and in virtual reality. The research intents to clarify to what extend subjective and objective attributes of architectural space can be conveyed through a direct use of BIM (Building Information Models) in Virtual Reality. Sixty test subjects experienced the same architectural space, as either a physical environment or a virtual environment, while data from their experiences was collected through a quantitative/qualitative questionnaire and through collecting the eye tracking data from their experience. This paper deals with an extended analysis of the eye tracking data from the research. Neurology studies indicate that virtual reality three-dimensional representation models are less demanding on the cognitive load of the brain than three-dimensional models seen on flat two-dimensional computer screens. This research suggests that the correct use of virtual reality architectural BIM models can meaningfully improve architectural representation. Copyright © GSTF 2018.",Architectural perception; Architectural representation; Building Information Modelling; Neurology; Virtual reality,,Conference paper,Final,,Scopus,2-s2.0-85051695962,Movies / Media
Hazuchová N.; Nagyová L.; Stávková J.; Chytil O.; Košičiarová I.,"Hazuchová, Nada (57204585843); Nagyová, Ludmila (25625208700); Stávková, Jana (24473825300); Chytil, Ondřej (57205320320); Košičiarová, Ingrida (57190073978)",57204585843; 25625208700; 24473825300; 57205320320; 57190073978,Attention analysis of honey jar labels using eye-tracking techniques,2018,Potravinarstvo Slovak Journal of Food Sciences,12,1,,815,823,8.0,3,10.5219/1005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059515424&doi=10.5219%2f1005&partnerID=40&md5=f1c2e0ec75e226eef190fadafe8eecc5,"Honey represents not just a specific product of animal origin, which's major part are plant products, but also the oldest sweetener of human kind. It is actually a sweet substance produced by beetles from nectar plants or from insects excreted on plants. Because of many different reasons (e.g. for trading, handling, storage), in the history of mankind, there have been introduced different forms of packaging and protective means through which this precious product could be protected. The present paper addresses consumer behaviour, focusing on the influence of packaging and labelling on young consumers aged from 20 to 35 years, especially when choosing honey. The realization of the main aim is conditional on meeting the following partial objectives - to identify the basic elements appearing on two samples of honey packaging and their impact on consumer perception, respectively to identify the differences in the perception of individual elements of the packaging, based on the respondents' gender. In the present paper, there are used different marketing research techniques, specifically the eye-tracking observation. The experiment involved exactly 12 samples of honey and finally 35 participants (18 women and 17 men). Based on the results of the authors' own work, it can be stated that the most eye-catching aspects of honey packaging are the producer's brand, as well as the variety description and name given to the honey. The least noticed aspects are the weight details of the packaging and the graphic design. © 2018 Potravinarstvo Slovak Journal of Food Sciences.",Consumer behaviour; Eye-tracking; Honey; Labelling; Packaging,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85059515424,Movies / Media
Alicia T.J.; Taylor G.S.; Turpin T.S.; Surana A.,"Alicia, Thomas J. (54580521200); Taylor, Grant S. (59800340100); Turpin, Terry S. (7003775507); Surana, Amit (6602087409)",54580521200; 59800340100; 7003775507; 6602087409,Removing the bottleneck: Utilizing autonomy to manage multiple UAS sensors from inside a cockpit,2018,Proceedings of SPIE - The International Society for Optical Engineering,10640,,106400L,,,,5,10.1117/12.2303915,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050800132&doi=10.1117%2f12.2303915&partnerID=40&md5=af572a8ba3b72a799a184308f09fa00f,"The U.S. Army Aviation Development Directorate, in collaboration with United Technologies Research Center and University of California: Santa Barbara, has developed a system for controlling multiple unmanned aerial systems (UAS) from a manned helicopter cockpit. Similar manned-unmanned teaming (MUM-T) capabilities have been successfully fielded in the AH-64E attack helicopter, with the Copilot/Gunner (CPG) managing one UAS; however, managing multiple UAS in the same manner would result in a cognitive processing bottleneck within the CPG. Removing this bottleneck requires implementation of autonomous behaviors and human-centered design principles to avoid detracting from the CPG's primary mission. This research evaluates these concepts with respect to multi-UAS MUM-T performance. Sixteen U.S. Army aviators with MUM-T experience participated in the experiment. The first phase assessed the performance of a CPG managing multiple UAS simultaneously in a fixed-base MUM-T simulator featuring touchscreen displays, simulated aided target recognition, and task-level delegation of control (DelCon). The second phase iteratively improved the DelCon capability and added an Attention Allocation Aid (AAA) in the form of real-time gaze tracking feedback. The research demonstrated that a single crewmember can manage at least three UAS assets while executing complex multi- UAS MUM-T tactical missions. The DelCon capability allowed participants to more efficiently perform a subset of mission tasks. Furthermore, subjective ratings from the participants indicated a willingness to accept the AAA and DelCon systems. Overall, this research demonstrates the potential of utilizing automation and human-centered design principles to overcome cognitive bottlenecks and achieve greater system efficiency. © 2018 SPIE.",Advanced teaming; Automation; MUM-T; Sensor management; UAS; Unmanned systems,Antennas; Automation; Behavioral research; Cockpits (aircraft); Eye tracking; Human resource management; Military helicopters; Advanced teaming; Human-centered designs; MUM-T; Sensor management; University of California; Unmanned aerial systems; Unmanned system; Willingness to accept; Unmanned aerial vehicles (UAV),Conference paper,Final,,Scopus,2-s2.0-85050800132,Movies / Media
Gaspar P.; Kompan M.; Simko J.; Bielikova M.,"Gaspar, Peter (57192556745); Kompan, Michal (36502601300); Simko, Jakub (36631117900); Bielikova, Maria (6603891237)",57192556745; 36502601300; 36631117900; 6603891237,Analysis of user behavior in interfaces with recommended items: An eye-tracking study,2018,CEUR Workshop Proceedings,2225,,,32,36,4.0,6,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055494261&partnerID=40&md5=8a2c57cdc945477ace24bf32c8aa4427,"When analyzing user implicit feedback in recommender systems, several biases need to be taken into account. A user is influenced by the position (i.e., position bias) or by the appeal of the items (i.e., visual bias). Since images have become an essential part of the Web, the study of their impact on user behavior during the decision-making tasks is fundamental. This work contributes to the understanding of attention bias in item lists interfaces of recommenders. We present an eye-tracking user study that strives to analyze users' behavior in the task of choosing a movie to watch. Items are shown to users using two alternative representations: textual and image. We found changes in the user's behavior when the image type of interface is present. Based on our findings, the visual appeal of the images made users to change their gaze sequences more frequently. Copyright © 2018 for the individual papers by the papers' authors. Copying permitted for private and academic purposes.",Eye-tracking; Recommendation; User feedback; Visual bias,Behavioral research; Decision making; Recommender systems; Eye-tracking studies; Implicit feedback; Recommendation; User behaviors; User feedback; User study; Visual appeals; Visual bias; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85055494261,Movies / Media
Xiaoyu M.; Jiang Z.J.,"Xiaoyu, Miao (57200579836); Jiang, Zhenhui Jack (8979809300)",57200579836; 8979809300,The magic of cinemagraphs: Investigation of different image formats in online product presentation,2018,"International Conference on Information Systems 2018, ICIS 2018",,,,,,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062550373&partnerID=40&md5=fec0b2cf853eeeaf91e3e6ba53be15b0,"A cinemagraph is a special type of animation characterized by the contrast and coexistence of motion and stillness due to artificial manipulation. Cinemagraphs have attracted visual artists and marketers and have been widely used in online marketing campaigns. However, the effects of cinemagraphs in online product presentations require further examination. This study plans to examine the potential effects of cinemagraphs in online product presentations by comparing them with photographs and short animations. In addition, we aimed to examine the visual processing of cinemagraphs using eye-tracking technology. Drawing on the competition for attention theory, the attention-guiding principle, and incongruity theories of curiosity, we hypothesize that these different image formats have different effects on human visual attention and product interest. We then propose a laboratory experiment to test our hypotheses. Finally, potential theoretical contributions and practical implications are discussed. © International Conference on Information Systems 2018, ICIS 2018.All rights reserved.",Cinemagraph; Online product presentation; Product interest; Visual processing,Behavioral research; Eye tracking; Information systems; Information use; Cinemagraph; Competition for attention theory; Eye tracking technologies; Human visual attention; Laboratory experiments; Online products; Product interest; Visual-processing; Marketing,Conference paper,Final,,Scopus,2-s2.0-85062550373,Movies / Media
Kruger J.-L.; Doherty S.; Fox W.; De Lissa P.,"Kruger, Jan-Louis (9277428700); Doherty, Stephen (56137159600); Fox, Wendy (57202038756); De Lissa, Peter (55675817000)",9277428700; 56137159600; 57202038756; 55675817000,Multimodal measurement of cognitive load during subtitle processing: Same-language subtitles for foreign-language viewers,2018,American Translators Association Scholarly Monograph Series,18,,,267,294,27.0,38,10.1075/ata.18.12kru,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064047474&doi=10.1075%2fata.18.12kru&partnerID=40&md5=99b714483c323bdcc611b59ee4c4460c,"This chapter presents the findings of a multimodal study that combines a suite of methods, namely, eye tracking, electroencephalography, and self-reported psychometrics, to investigate the impact of language and layout on cognitive load in the absence and presence of conventional same-language subtitles and integrated titles (a transcript of the spoken language presented dynamically in line with the film presentation) in an English fiction film viewed by L2 speakers of English. Findings show similar levels of immersion for conventional same-language subtitles and integrated titles, whereas the latter appears to facilitate deeper processing of subtitle contents resulting in reductions in perceived complexity. © 2018 John Benjamins Publishing Company.",Cognitive load; Dynamic text; Electroencephalography; Eye tracking; Integrated titles; Multimodal; Reading index; Split attention; Subtitles; Transportation; Working memory,,Book chapter,Final,,Scopus,2-s2.0-85064047474,Movies / Media
Fernandes A.; Danielsen B.-E.; Nguyen H.T.; Langstrand J.-P.,"Fernandes, Alexandra (56941339200); Danielsen, Brit-Eli (55810629600); Nguyen, Hoa Thi (57209108684); Langstrand, Jens-Patrick (57209102920)",56941339200; 55810629600; 57209108684; 57209102920,Assessing human performance and fatigue in a control room during ISS operations,2018,"15th International Conference on Space Operations, 2018",,,AIAA 2018-2543,,,11.0,1,10.2514/6.2018-2543,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066470228&doi=10.2514%2f6.2018-2543&partnerID=40&md5=474fca9ea4b2c5a74d050ec73ccba60b,"This study aimed at exploring how human centered sensing can be used to assess performance and fatigue in a control room setting. The study was performed at CIRiS’ (Centre for Interdisciplinary Research in Space) control center while the staff was monitoring an experiment onboard the International Space Station (ISS). We had two parallel objectives: 1) to explore the participants’ use of the display screens in the new control center set-up; and 2) to identify eye-tracker markers that can signal fatigue during shift work. Six participants took part in the study, wearing eye-tracking glasses with a positioning tracking device for selected 30 minutes periods at the beginning and end of the shifts; as well as answering to fatigue and cognitive performance tasks at the beginning and end of each shift. A digit memory span task did not seem to be sensitive to the beginning/end of shift variable. Self-reported fatigue scales showed a tendency for lower scores in the beginning of the shift when compared to its end. The data from the eye-tracking analysis revealed a differential use of the control interfaces in the station at the beginning and end of shift. Regarding the fatigue levels, the eye-tracking indicators were not sensitive to any differences in the beginning/end of shift. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.",,Fatigue of materials; Space stations; Cognitive performance; Control interfaces; Display screen; Eye-tracking analysis; Human performance; Interdisciplinary research; International Space stations; Tracking devices; Eye tracking,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85066470228,Movies / Media
Tong Q.; Xiao H.; Qiu J.; Luo K.; Peng L.; Han P.,"Tong, Qinqin (57200368816); Xiao, Hua (15754768500); Qiu, Jian (38661707600); Luo, Kaiqing (35109480500); Peng, Li (57200375469); Han, Peng (35336999400)",57200368816; 15754768500; 38661707600; 35109480500; 57200375469; 35336999400,A new mapping function in table-mounted eye tracker,2018,Proceedings of SPIE - The International Society for Optical Engineering,10620,,106200B,,,,1,10.1117/12.2295594,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040993115&doi=10.1117%2f12.2295594&partnerID=40&md5=df4bf981146ee61f40c9826b26cde0c3,"Eye tracker is a new apparatus of human-computer interaction, which has caught much attention in recent years. Eye tracking technology is to obtain the current subject's ""visual attention (gaze)"" direction by using mechanical, electronic, optical, image processing and other means of detection. While the mapping function is one of the key technology of the image processing, and is also the determination of the accuracy of the whole eye tracker system. In this paper, we present a new mapping model based on the relationship among the eyes, the camera and the screen that the eye gazed. Firstly, according to the geometrical relationship among the eyes, the camera and the screen, the framework of mapping function between the pupil center and the screen coordinate is constructed. Secondly, in order to simplify the vectors inversion of the mapping function, the coordinate of the eyes, the camera and screen was modeled by the coaxial model systems. In order to verify the mapping function, corresponding experiment was implemented. It is also compared with the traditional quadratic polynomial function. And the results show that our approach can improve the accuracy of the determination of the gazing point. Comparing with other methods, this mapping function is simple and valid. © 2018 SPIE.",Eye tracker; Mapping function; Visual attention,Behavioral research; Cameras; Human computer interaction; Mapping; Optical data processing; Optical instruments; Optical signal processing; Signal processing; Eye trackers; Eye tracking technologies; Geometrical relationship; Key technologies; Mapping functions; Mapping model; Quadratic polynomial functions; Visual Attention; Image processing,Conference paper,Final,,Scopus,2-s2.0-85040993115,Movies / Media
Howard C.J.; Uttley J.; Andrews S.,"Howard, Christina J. (23978102100); Uttley, Jonathan (57204096101); Andrews, Sally (56727577300)",23978102100; 57204096101; 56727577300,Team ball sport participation is associated with performance in two sustained visual attention tasks: Position monitoring and target identification in rapid serial visual presentation streams,2018,Progress in Brain Research,240,,,53,69,16.0,13,10.1016/bs.pbr.2018.09.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054442213&doi=10.1016%2fbs.pbr.2018.09.001&partnerID=40&md5=7f9a0c4c1a04ea8594e0a40b2e39cff7,"We investigated the relationship between participation in team ball sports and performance in two sustained spatiotemporal attention tasks—a position monitoring variant of the multiple object tracking (MOT) task and target identification in the rapid serial visual presentation (RSVP) task. Thirty participants were asked about the frequency of their participation in team ball sports and undertook both the MOT task and RSVP task. In the MOT task, participants viewed an array of eight discs as they moved unpredictably for 3–8 s before disappearing. On each trial, a subset of these were marked as targets for tracking, meaning that participants attempted to keep track of their positions on the screen with as much precision as possible. At the end of each trial, participants reported the final perceived position of a queried target. In the RSVP task, a stream of letters was presented at the center of the screen and participants attempted to report either one or both of two target letters embedded in the stream. Participation in team ball sports was associated with superior performance in both tasks: in the MOT task, individuals reporting more time spent playing team ball sports on a weekly basis were able to report the positions of targets with greater precision, and in the RSVP task they reported targets more accurately. The current findings add to the literature of somewhat mixed findings regarding the extent to which participation in sports may be associated with superior visual attention abilities. © 2018 Elsevier B.V.",Multiple object tracking; Rapid serial visual presentation; Spatial cognition; Team ball sport; Visual attention,Adult; Attention; Female; Humans; Male; Reaction Time; Sports; Visual Perception; Young Adult; adult; article; clinical article; eye tracking; female; human; human experiment; male; monitoring; sport; visual attention; attention; physiology; reaction time; vision; young adult,Book chapter,Final,,Scopus,2-s2.0-85054442213,Movies / Media
Thériault J.-D.; Roberge-Vallières B.; Lafond D.; Tremblay S.; Vachon F.,"Thériault, Jean-Denis (57194723917); Roberge-Vallières, Benoit (57194109222); Lafond, Daniel (24178697000); Tremblay, Sébastien (35238788400); Vachon, François (8696710100)",57194723917; 57194109222; 24178697000; 35238788400; 8696710100,The impact of visual scan strategies on active surveillance performance: An eye-tracking study,2018,Neuroergonomics: The Brain at Work and in Everyday Life,,,,283,284,1.0,1,10.1016/B978-0-12-811926-6.00076-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081368802&doi=10.1016%2fB978-0-12-811926-6.00076-2&partnerID=40&md5=2a00e7fce71a38ba503a489b152fb440,"There has been substantial investment in the field of closed-circuit television (CCTV) technology to increase the level of surveillance efficiency and system performance for the security of citizens and the protection of public infrastructures. In control rooms, operators have to actively monitor a number of camera feeds that generally surpass the number of displays available. Operators tend to prioritize some visual scenes to cope with the sheer amount of visual content to monitor. The objective of the present study is to assess the impact on surveillance performance of different monitoring strategies adopted by (nonexpert) operators using a highly realistic CCTV operation simulation. © 2018 Elsevier Inc. All rights reserved.",Attention allocation; CCTV; Content prioritization; Detection; Monitoring strategy; Performance; Security; Surveillance; Visual attention; Visual scan strategy,,Book chapter,Final,,Scopus,2-s2.0-85081368802,Movies / Media
"Roverud E.; Best V.; Mason C.R.; Streeter T.; Kidd G., Jr.","Roverud, Elin (36465654400); Best, Virginia (57204836886); Mason, Christine R. (7202125775); Streeter, Timothy (24473763500); Kidd, Gerald (7102011314)",36465654400; 57204836886; 7202125775; 24473763500; 7102011314,Evaluating the performance of a visually guided hearing aid using a dynamic auditory-visual word congruence task,2018,Ear and Hearing,39,4,,756,769,13.0,10,10.1097/AUD.0000000000000532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056349041&doi=10.1097%2fAUD.0000000000000532&partnerID=40&md5=8517febcef5a185a96acc73f85472dad,"Objectives: The ""visually guided hearing aid"" (VGHA), consisting of a beamforming microphone array steered by eye gaze, is an experimental device being tested for effectiveness in laboratory settings. Previous studies have found that beamforming without visual steering can provide significant benefits (relative to natural binaural listening) for speech identification in spatialized speech or noise maskers when sound sources are fixed in location. The aim of the present study was to evaluate the performance of the VGHA in listening conditions in which target speech could switch locations unpredictably, requiring visual steering of the beamforming. To address this aim, the present study tested an experimental simulation of the VGHA in a newly designed dynamic auditory-visual word congruence task. Design: Ten young normal-hearing (NH) and 11 young hearing-impaired (HI) adults participated. On each trial, three simultaneous spoken words were presented from three source positions (-30, 0, and 30° azimuth). An auditory-visual word congruence task was used in which participants indicated whether there was a match between the word printed on a screen at a location corresponding to the target source and the spoken target word presented acoustically from that location. Performance was compared for a natural binaural condition (stimuli presented using impulse responses measured on KEMAR), a simulated VGHA condition (BEAM), and a hybrid condition that combined lowpass-filtered KEMAR and highpass-filtered BEAM information (BEAMAR). In some blocks, the target remained fixed at one location across trials, and in other blocks, the target could transition in location between one trial and the next with a fixed but low probability. Results: Large individual variability in performance was observed. There were significant benefits for the hybrid BEAMAR condition relative to the KEMAR condition on average for both NH and HI groups when the targets were fixed. Although not apparent in the averaged data, some individuals showed BEAM benefits relative to KEMAR. Under dynamic conditions, BEAM and BEAMAR performance dropped significantly immediately following a target location transition. However, performance recovered by the second word in the sequence and was sustained until the next transition. Conclusions: When performance was assessed using an auditory-visual word congruence task, the benefits of beamforming reported previously were generally preserved under dynamic conditions in which the target source could move unpredictably from one location to another (i.e., performance recovered rapidly following source transitions) while the observer steered the beamforming via eye gaze, for both young NH and young HI groups. Copyright © 2017 Wolters Kluwer Health, Inc. All rights reserved.",,"Adolescent; Adult; Attention; Case-Control Studies; Equipment Design; Female; Fixation, Ocular; Hearing Aids; Hearing Loss; Humans; Male; Spatial Processing; Speech Perception; Young Adult; adolescent; adult; attention; case control study; equipment design; eye fixation; female; hearing aid; hearing impairment; human; male; spatial behavior; speech perception; young adult",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85056349041,Movies / Media
Rogalska A.; Napieralski P.,"Rogalska, Anna (57200442787); Napieralski, Piotr (24481496100)",57200442787; 24481496100,The visual attention saliency map for movie retrospection,2018,Open Physics,16,1,,188,192,4.0,5,10.1515/phys-2018-0027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046093725&doi=10.1515%2fphys-2018-0027&partnerID=40&md5=2e42c995501d80f26907c1d9d3a35ae7,"The visual saliency map is becoming important and challenging for many scientific disciplines (robotic systems, psychophysics, cognitive neuroscience and computer science). Map created by the model indicates possible salient regions by taking into consideration face presence and motion which is essential in motion pictures. By combiningwe can obtain credible saliency map with a low computational cost. © 2018 Madeeha Tahir et al.",computer graphics; gaze tracking; saliency prediction; visual attention,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85046093725,Movies / Media
Siebenaler S.; Szymkowiak A.; Robertson P.; Johnson G.I.; Law J.; Fee K.,"Siebenaler, Susan (57195069820); Szymkowiak, Andrea (7004699671); Robertson, Paul (57210736415); Johnson, Graham I. (8219706600); Law, Jan (56963427900); Fee, Kenneth (37101295600)",57195069820; 7004699671; 57210736415; 8219706600; 56963427900; 37101295600,Social presence and dishonesty in retail,2018,"Proceedings of the 32nd International BCS Human Computer Interaction Conference, HCI 2018",,,,,,,0,10.14236/ewic/HCI2018.34,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058314913&doi=10.14236%2fewic%2fHCI2018.34&partnerID=40&md5=0b6f2d203324e9985002c6ea34727cd0,"Self-service checkouts (SCOs) in retail can benefit consumers and retailers, providing control and autonomy to shoppers independent from staff, together with reduced queuing times. Recent research indicates that the absence of staff may provide the opportunity for consumers to behave dishonestly, consistent with a perceived lack of social presence. This study examined whether a social presence in the form of various instantiations of embodied, visual, humanlike SCO interface agents had an effect on opportunistic user behaviour, i.e. an individual taking unwarranted advantages. Using a simulated SCO scenario, participants experienced various dilemmas in which they could financially benefit themselves undeservedly. We hypothesised that a humanlike social presence integrated within the checkout screen would receive more attention and result in fewer instances of dishonesty compared to a less humanlike agent. This was partially supported by the results. The findings contribute to the theoretical framework in social presence research. We concluded that companies adopting self-service technology may consider the implementation of social presence in technology applications to support ethical consumer behaviour, but that more research is required to explore the mixed findings in the current study. © Dupré et al. Published by BCS Learning and Development Ltd. Proceedings of British HCI 2018. Belfast, UK",Anthropomorphism; Embodied agents; Eye tracking; Retail shrinkage; Self-service; Social presence,Behavioral research; Eye tracking; Sales; Anthropomorphism; Embodied agent; Human-like agents; Recent researches; Self-service; Social presence; Technology application; Theoretical framework; Human computer interaction,Conference paper,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85058314913,Movies / Media
Turner D.; Briken P.,"Turner, Daniel (55416734500); Briken, Peer (6602126301)",55416734500; 6602126301,Treatment of Paraphilic Disorders in Sexual Offenders or Men With a Risk of Sexual Offending With Luteinizing Hormone-Releasing Hormone Agonists: An Updated Systematic Review,2018,Journal of Sexual Medicine,15,1,,77,93,16.0,53,10.1016/j.jsxm.2017.11.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039843703&doi=10.1016%2fj.jsxm.2017.11.013&partnerID=40&md5=5aecd63761f04b4fb291a9cace6439b8,"Background Different pharmacologic agents are used in the treatment of paraphilic disorders in sexual offenders or men with a risk of sexual offending, with luteinizing hormone-releasing hormone (LHRH) agonists being the agents introduced more recently to treatment regimens. Aim To summarize the relevant literature concerning LHRH agonist treatment of paraphilic disorders in sexual offenders and update the previously published systematic review by Briken et al (J Clin Psychiatry 2003;64:890–897). Methods The PubMed and Google Scholar databases were searched for literature published from January 2003 through October 2017 using the following key words: LHRH agonists, GnRH agonists, antiandrogens AND paraphilia, pedophilia, sex offenders. Outcomes Evaluation of the effectiveness and side effects of LHRH agonist treatment of paraphilic disorders in sexual offenders. Results After screening for duplicates and applying specific selection criteria, the search yielded 24 eligible studies reporting on a sample of 256 patients. There is increasing evidence that LHRH agonists are more effective than steroidal antiandrogens in lowering paraphilic sexual thoughts and behaviors. Current research also is based on methods that might be less susceptible to faking (eg, eye-tracking, brain imaging, and viewing-time measures). Side effects occurring most frequently are fatigue, hot flashes, depressive mood, weight gain, high blood pressure, diabetes, gynecomastia, loss of erectile function, and loss of bone mineral density. Clinical Implications Although LHRH agonists seem to be the most effective drugs in the treatment of paraphilic fantasies and behaviors, they should be reserved for patients with a paraphilic disorder and the highest risk of sexual offending because of their extensive side effects. Strengths and Limitations This systematic review considers all types of research on LHRH agonist treatment in patients with paraphilic disorders, thereby providing a complete overview of the current state of research. However, most studies are case reports or observational studies and randomized controlled clinical trials have not been conducted or published. Conclusions LHRH agonists are a useful treatment when combined with psychotherapy in patients with a paraphilic disorder and the highest risk of sexual offending. However, throughout treatment, close monitoring of side effects is needed and ethical concerns must always be kept in mind. Turner D, Briken P. Treatment of Paraphilic Disorders in Sexual Offenders or Men With a Risk of Sexual Offending With Luteinizing Hormone-Releasing Hormone Agonists: An Updated Systematic Review. J Sex Med 2018;15:77–93. © 2017 International Society for Sexual Medicine",Antiandrogens; Gonadotropin-Releasing Hormone Agonists; Luteinizing Hormone-Releasing Hormone Agonists; Paraphilia; Paraphilic Disorder; Pedophilia; Pedophilic Disorder; Sexual Offender; Treatment,Androgen Antagonists; Criminals; Gonadotropin-Releasing Hormone; Humans; Male; Paraphilic Disorders; Pedophilia; Psychotherapy; Sex Offenses; Sexual Behavior; gonadorelin agonist; goserelin; leuprorelin; triptorelin; antiandrogen; gonadorelin; depression; diabetes mellitus; drug efficacy; drug mechanism; erectile dysfunction; fatigue; gynecomastia; hot flush; human; hypertension; male; paraphilic disorder; priority journal; psychotherapy; Review; risk assessment; sexual behavior; sexual crime; systematic review; drug effect; offender; paraphilic disorder; pedophilia; prevention and control; procedures; sexual crime,Review,Final,,Scopus,2-s2.0-85039843703,Movies / Media
Fabio R.A.; Caprì T.; Nucita A.; Iannizzotto G.; Mohammadhasani N.,"Fabio, Rosa Angela (23977515400); Caprì, Tindara (56442731200); Nucita, Andrea (8420118800); Iannizzotto, Ginacarlo (6603452512); Mohammadhasani, Nasrin (57204031832)",23977515400; 56442731200; 8420118800; 6603452512; 57204031832,Eye-gaze digital games improve motivational and attentional abilities in RETT syndrome,2018,Journal of Special Education and Rehabilitation,19,4-Mar,,105,126,21.0,35,10.19057/jser.2019.43,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065594961&doi=10.19057%2fjser.2019.43&partnerID=40&md5=7fdd19dc75b4f1a0720e67701655fa7f,"Introduction: Recently, there has been an increase in the use of eye-gaze digital games in the field of education. Many studies have underlined that eye-gaze digital game use plays an important role in supporting students with intellectual disability. Digital game-based learning (DGBL) or educational games have the potential to provide effective, powerful learning environments in which disabled learners need to develop or improve cognitive skills. Method: The main focus of this study is to investigate the role of eye-gaze digital games in improving motivational and attentional abilities in subjects with Rett Syndrome (RTT). Fifty two Italian female patients with RTT (mean=12.10 years, SD=8.70) participated in the study, 30 in the treatment group and 22 in the awaiting treatment group. We employed a pre-test-post-test comparison design to evaluate the benefits of digital game-based learning on attention and motivation measures. In both pre-test and post-test phases, neuropsychological and behavioural parameters were measured using eye tracker technology. In addition, attentional and motivational measures were both evaluated in these two phases. In the learning phase, participants were presented with eye-gaze digital games, pre-installed in the Tobii Series-I eye-tracker. Eye-gaze games were divided into 5 levels: Blank Screen Engagement, Object Displacement, Zoned Focusing, Active Exploration and Controlled Targeting. Finding: The findings indicated a performance enhancement in attention and motivation. Suggestions and Conclusion: The results are discussed in terms of their implications for supporting eye-gaze digital game use in education and learning in subjects with RTT. © 2018 Institute of Special Education and Rehablitation. All rights reserved.",Cognitive functioning; Digital game-based learning; Rett Syndrome,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85065594961,Movies / Media
Da Silva M.R.D.; Postma-Nilsenová M.; Hermens F.,"Da Silva, Mariana Rachel Dias (57204687746); Postma-Nilsenová, Marie (55939937300); Hermens, Frouke (6603194458)",57204687746; 55939937300; 6603194458,"Wandering mice, wandering minds: Using computer mouse tracking to predict mind wandering",2018,CEUR Workshop Proceedings,2265,,,,,,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058641551&partnerID=40&md5=072843787c8ae517f876a36cae53ac3a,"Mind wandering is a state in which an individual’s attention is not fully focused on the task at hand. Mind wandering affects performance in many tasks requiring focused attention, including (online) learning. Previous studies have examined eye tracking and self-report as a method to assess whether a person is mind wandering. Because the first method requires specialized technology and the second method may be susceptible to reporting biases, we here examine whether mouse tracking can be used to predict mind wandering in tasks involving classical computer interfaces. Assuming that mouse trajectories towards a particular response on the screen are continuously updated by time-dependent and temporally-dynamic cognitive processes, as a behavioral methodology, mouse tracking could provide unique insight into a person’s thoughts. In our experiment, a total of 183 students completed a mouse-based operation span task, during which their thoughts were probed and their mouse movements recorded. Mixed model analysis of the recordings indicated that speed errors, time to press start, initiation time, total distance, and average speed can be used as predictors of task-unrelated thoughts. The results show that mouse movements may be able to provide an objective measure of mind wandering in online tasks. © 2018 CEUR-WS. All Rights Reserved.",Arousal; Mind wandering; Mouse tracking; Working memory,Eye tracking; Arousal; Cognitive process; Mind wandering; Mixed-model analysis; Objective measure; Specialized technologies; Total distances; Working memory; Mammals,Conference paper,Final,,Scopus,2-s2.0-85058641551,Movies / Media
Lewis D.E.; Smith N.A.; Spalding J.L.; Valente D.L.,"Lewis, Dawna E. (35565634000); Smith, Nicholas A. (55456213900); Spalding, Jody L. (56336854500); Valente, Daniel L. (36881602100)",35565634000; 55456213900; 56336854500; 36881602100,Looking behavior and audiovisual speech understanding in children with normal hearing and children with mild bilateral or unilateral hearing loss,2018,Ear and Hearing,39,4,,783,794,11.0,11,10.1097/AUD.0000000000000534,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056360018&doi=10.1097%2fAUD.0000000000000534&partnerID=40&md5=951603c9f60d4610e01c83ac6390b5bf,"Objectives: Visual information from talkers facilitates speech intelligibility for listeners when audibility is challenged by environmental noise and hearing loss. Less is known about how listeners actively process and attend to visual information from different talkers in complex multi-talker environments. This study tracked looking behavior in children with normal hearing (NH), mild bilateral hearing loss (MBHL), and unilateral hearing loss (UHL) in a complex multi-talker environment to examine the extent to which children look at talkers and whether looking patterns relate to performance on a speech-understanding task. It was hypothesized that performance would decrease as perceptual complexity increased and that children with hearing loss would perform more poorly than their peers with NH. Children with MBHL or UHL were expected to demonstrate greater attention to individual talkers during multi-talker exchanges, indicating that they were more likely to attempt to use visual information from talkers to assist in speech understanding in adverse acoustics. It also was of interest to examine whether MBHL, versus UHL, would differentially affect performance and looking behavior. Design: Eighteen children with NH, eight children with MBHL, and 10 children with UHL participated (8-12 years). They followed audiovisual instructions for placing objects on a mat under three conditions: a single talker providing instructions via a video monitor, four possible talkers alternately providing instructions on separate monitors in front of the listener, and the same four talkers providing both target and nontarget information. Multi-talker background noise was presented at a 5 dB signal-to-noise ratio during testing. An eye tracker monitored looking behavior while children performed the experimental task. Results: Behavioral task performance was higher for children with NH than for either group of children with hearing loss. There were no differences in performance between children with UHL and children with MBHL. Eye-tracker analysis revealed that children with NH looked more at the screens overall than did children with MBHL or UHL, though individual differences were greater in the groups with hearing loss. Listeners in all groups spent a small proportion of time looking at relevant screens as talkers spoke. Although looking was distributed across all screens, there was a bias toward the right side of the display. There was no relationship between overall looking behavior and performance on the task. Conclusions: The present study examined the processing of audiovisual speech in the context of a naturalistic task. Results demonstrated that children distributed their looking to a variety of sources during the task, but that children with NH were more likely to look at screens than were those with MBHL/UHL. However, all groups looked at the relevant talkers as they were speaking only a small proportion of the time. Despite variability in looking behavior, listeners were able to follow the audiovisual instructions and children with NH demonstrated better performance than children with MBHL/UHL. These results suggest that performance on some challenging multi-talker audiovisual tasks is not dependent on visual fixation to relevant talkers for children with NH or with MBHL/UHL. Copyright © 2017 Wolters Kluwer Health, Inc.",,"Case-Control Studies; Child; Child Behavior; Female; Fixation, Ocular; Hearing Loss, Bilateral; Hearing Loss, Unilateral; Humans; Male; Severity of Illness Index; Speech Perception; Task Performance and Analysis; Visual Perception; case control study; child; child behavior; eye fixation; female; hearing impairment; human; male; pathophysiology; severity of illness index; speech perception; task performance; unilateral hearing loss; vision",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85056360018,Movies / Media
Liu W.; Yu M.; Fan Z.; Xu J.; Tian Y.,"Liu, Wei (59447759500); Yu, Mengling (57201061607); Fan, Zijian (57191852187); Xu, Jing (57193018007); Tian, Yuan (55267852600)",59447759500; 57201061607; 57191852187; 57193018007; 55267852600,Visual attention based evaluation for multiple-choice tests in e-learning applications,2017,"Proceedings - Frontiers in Education Conference, FIE",2017-October,,,1,6,5.0,3,10.1109/FIE.2017.8190633,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043234234&doi=10.1109%2fFIE.2017.8190633&partnerID=40&md5=ae5fec37f1013c3ef3b020dcd55b281c,"Multiple-choice (MC) question is an important form of test to assess the students' academic achievement, especially in the e-learning applications. However, the classical evaluation metrics on MC questions (such as the correctness ratio) only consider the correctness of the final selection but ignore the solving progress of the testee. In the existing literature, the eye-tracking based visual attention was studied to infer the testee's cognitive progress towards a specific MC question. However, there is little work on the visual attention based evaluation of one complete MC test. In this paper, we measure the eye movement data of a group of students in an online test, which consists of forty more MC questions. We divide the screen area into five AOIs (area of interests), including one for the question and four for the candidate options. The fixation duration as well as the gaze sequence on these AOIs are recorded and studied. In the case study on the most difficult question, we observe the great differences among the eye movement of the testees in different academic levels. A new metric, namely Visual-Attention-assisted Score (VAS), is proposed to assess the student's performance with the bias of his fixations on the correct options. Experiment results show that, this metric can reflect the difference of gaze movement of testees, and thus it is helpful for the teachers to infer the real level of the students' academic achievement. © 2017 IEEE.",,Behavioral research; E-learning; Eye tracking; Students; Teaching; Academic achievements; Area of interest; e-Learning application; Evaluation metrics; Eye movement datum; Fixation duration; Student's performance; Visual Attention; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85043234234,Movies / Media
Hutson J.P.; Smith T.J.; Magliano J.P.; Loschky L.C.,"Hutson, John P. (57191540984); Smith, Tim J. (55568512084); Magliano, Joseph P. (6701369755); Loschky, Lester C. (6602946442)",57191540984; 55568512084; 6701369755; 6602946442,What is the role of the film viewer? The effects of narrative comprehension and viewing task on gaze control in film,2017,Cognitive Research: Principles and Implications,2,1,46,,,,40,10.1186/s41235-017-0080-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056659057&doi=10.1186%2fs41235-017-0080-5&partnerID=40&md5=7f4ef9d2cf16a100a074f4d821e85abe,"Film is ubiquitous, but the processes that guide viewers’ attention while viewing film narratives are poorly understood. In fact, many film theorists and practitioners disagree on whether the film stimulus (bottom-up) or the viewer (top-down) is more important in determining how we watch movies. Reading research has shown a strong connection between eye movements and comprehension, and scene perception studies have shown strong effects of viewing tasks on eye movements, but such idiosyncratic top-down control of gaze in film would be anathema to the universal control mainstream filmmakers typically aim for. Thus, in two experiments we tested whether the eye movements and comprehension relationship similarly held in a classic film example, the famous opening scene of Orson Welles’ Touch of Evil (Welles & Zugsmith, Touch of Evil, 1958). Comprehension differences were compared with more volitionally controlled task-based effects on eye movements. To investigate the effects of comprehension on eye movements during film viewing, we manipulated viewers’ comprehension by starting participants at different points in a film, and then tracked their eyes. Overall, the manipulation created large differences in comprehension, but only produced modest differences in eye movements. To amplify top-down effects on eye movements, a task manipulation was designed to prioritize peripheral scene features: a map task. This task manipulation created large differences in eye movements when compared to participants freely viewing the clip for comprehension. Thus, to allow for strong, volitional top-down control of eye movements in film, task manipulations need to make features that are important to narrative comprehension irrelevant to the viewing task. The evidence provided by this experimental case study suggests that filmmakers’ belief in their ability to create systematic gaze behavior across viewers is confirmed, but that this does not indicate universally similar comprehension of the film narrative. © 2017, The Author(s).",Eye movements; Eye tracking; Film comprehension; Film perception; Inferences; Narrative comprehension; Scene perception; Visual attention,,Article,Final,,Scopus,2-s2.0-85056659057,Movies / Media
Drew T.; Williams L.H.,"Drew, Trafton (15043986300); Williams, Lauren H. (57201011772)",15043986300; 57201011772,Simple eye-movement feedback during visual search is not helpful,2017,Cognitive Research: Principles and Implications,2,1,44,,,,19,10.1186/s41235-017-0082-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048229996&doi=10.1186%2fs41235-017-0082-3&partnerID=40&md5=3562f52f13a752c71055d2d484e17c4e,"Searching for targets in the visual world, or visual search, is something we all do every day. We frequently make ‘false-negative’ errors, wherein we erroneously conclude a target was absent when one was, in fact, present. These sorts of errors can have tremendous costs, as when signs of cancers are missed in diagnostic radiology. Prior research has characterized the cause of many of these errors as being due to failure to completely search the area where targets may be present; indeed, roughly one-third of chest nodules missed in lung cancer screening are never fixated (Drew, Võ, Olwal, Jacobson, Seltzer and Wolfe, Journal of Vision 13:3, 2013). This suggests that observers do not have a good representation of what areas have and have not been searched prior to declaring an area target free. Therefore, in six experiments, we sought to examine the utility of reducing the uncertainty with respect to what areas had been examined via online eye-tracking feedback. We hypothesized that providing information about what areas had or had not been examined would lead to lower rates of false negatives or more efficient search, namely faster response times with no cost on target detection accuracy. Neither of these predictions held true. Over six experiments, online eye-tracking feedback did not yield any reliable performance benefits. © 2017, The Author(s).",Eye-tracking; Feedback; Visual attention; Visual search,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85048229996,Movies / Media
Binda P.; Straßer T.; Stingl K.; Richter P.; Peters T.; Wilhelm H.; Wilhelm B.; Kelbsch C.,"Binda, Paola (18633542700); Straßer, Torsten (26221967000); Stingl, Krunoslav (25958406700); Richter, Paul (57191675384); Peters, Tobias (27567987000); Wilhelm, Helmut (7102047868); Wilhelm, Barbara (7006155973); Kelbsch, Carina (55326185900)",18633542700; 26221967000; 25958406700; 57191675384; 27567987000; 7102047868; 7006155973; 55326185900,Pupil response components: Attention-light interaction in patients with Parinaud's syndrome,2017,Scientific Reports,7,1,10283,,,,11,10.1038/s41598-017-10816-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028638991&doi=10.1038%2fs41598-017-10816-x&partnerID=40&md5=b734fd7cf4d0447a6989cbc6c9893ec3,"Covertly shifting attention to a brighter or darker image (without moving one's eyes) is sufficient to evoke pupillary constriction or dilation, respectively. One possibility is that this attentional modulation involves the pupillary light response pathway, which pivots around the olivary pretectal nucleus. We investigate this possibility by studying patients with Parinaud's syndrome, where the normal pupillary light response is strongly impaired due to lesions in the pretectal area. Four patients and nine control participants covertly attended (while maintaining fixation at the center of a monitor screen) to one of two disks located in the left and right periphery: one brighter, the other darker than the background. Patients and control subjects behaved alike, showing smaller pupils when attending to the brighter stimulus (despite no eye movements); consistent results were obtained with a dynamic version of the stimulus. We interpret this as proof of principle that attention to bright or dark stimuli can dynamically modulate pupil size in patients with Parinaud's syndrome, suggesting that attention acts independently of the pretectal circuit for the pupillary light response and indicating that several components of the pupillary response can be isolated - including one related to the focus of covert attention. © 2017 The Author(s).",,"Adult; Attention; Female; Fixation, Ocular; Humans; Light; Male; Middle Aged; Ocular Motility Disorders; Pupil; Reflex, Pupillary; adult; attention; eye fixation; eye movement disorder; female; human; light; male; middle aged; pathophysiology; physiology; pupil; pupil reflex; radiation response",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85028638991,Movies / Media
Peltier C.; Becker M.W.,"Peltier, Chad (56740831500); Becker, Mark W. (36933635200)",56740831500; 36933635200,Eye movement feedback fails to improve visual search performance,2017,Cognitive Research: Principles and Implications,2,1,47,,,,15,10.1186/s41235-017-0083-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048243196&doi=10.1186%2fs41235-017-0083-2&partnerID=40&md5=bf004c044beec5bea65cf0e6a38ab02e,"Many real-world searches (e.g., radiology and baggage screening) have rare targets. When targets are rare, observers perform rapid, incomplete searches, leading to higher miss rates. To improve search for rare (10% prevalence) targets, we provided eye movement feedback (EMF) to observers during their searches. Although the nature of the EMF varied across experiments, each method informed observers about the regions of the display that had not yet been inspected. We hypothesized that feedback would help guide attention to unsearched areas and increase the proportion of the display searched before making a target-absent response, thereby increasing accuracy. An eye tracker was used to mark fixated areas by either removing a semiopaque gray overlay (Experiments 1 and 4) as portions of the display were fixated or by adding the overlay once the eye left a segment of the image (Experiments 2 and 4). Experiment 3 provided automated EMF, such that a new region was uncovered every 540 milliseconds. Across experiments, we varied whether people searched for “Waldo” in images from “Where’s Waldo?” search books or searched for a T among offset Ls. We found weak evidence that EMF improves accuracy in Experiment 1. However, in the remaining experiments, EMF had no effect (Experiment 4), or even reduced accuracy (Experiments 2 and 3). We conclude that the one positive result we found is likely a Type I error and that the EMF method that we used is unlikely to improve visual search performance. © 2017, The Author(s).",Feedback; Target prevalence; Visual attention; Visual search,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85048243196,Movies / Media
Primativo S.; Clark C.; Yong K.X.X.; Firth N.C.; Nicholas J.; Alexander D.; Warren J.D.; Rohrer J.D.; Crutch S.J.,"Primativo, Silvia (55831755300); Clark, Camilla (57213539180); Yong, Keir X.X. (55650633000); Firth, Nicholas.C. (56179656700); Nicholas, Jennifer (25630004900); Alexander, Daniel (7402830766); Warren, Jason D. (35557252600); Rohrer, Jonathan D. (14020386900); Crutch, Sebastian J. (6602191607)",55831755300; 57213539180; 55650633000; 56179656700; 25630004900; 7402830766; 35557252600; 14020386900; 6602191607,Eyetracking metrics reveal impaired spatial anticipation in behavioural variant frontotemporal dementia,2017,Neuropsychologia,106,,,328,340,12.0,16,10.1016/j.neuropsychologia.2017.10.014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031797102&doi=10.1016%2fj.neuropsychologia.2017.10.014&partnerID=40&md5=65be312fbc53582ba393ccbeb5f3486f,"Eyetracking technology has had limited application in the dementia field to date, with most studies attempting to discriminate syndrome subgroups on the basis of basic oculomotor functions rather than higher-order cognitive abilities. Eyetracking-based tasks may also offer opportunities to reduce or ameliorate problems associated with standard paper-and-pencil cognitive tests such as the complexity and linguistic demands of verbal test instructions, and the problems of tiredness and attention associated with lengthy tasks that generate few data points at a slow rate. In the present paper we adapted the Brixton spatial anticipation test to a computerized instruction-less version where oculomotor metrics, rather than overt verbal responses, were taken into account as indicators of high level cognitive functions. Twelve bvFTD (in whom spatial anticipation deficits were expected), six SD patients (in whom deficits were predicted to be less frequent) and 38 healthy controls were presented with a 10 × 7 matrix of white circles. During each trial (N = 24) a black dot moved across seven positions on the screen, following 12 different patterns. Participants’ eye movements were recorded. Frequentist statistical analysis of standard eye movement metrics were complemented by a Bayesian machine learning (ML) approach in which raw eyetracking time series datasets were examined to explore the ability to discriminate diagnostic group performance not only on the overall performance but also on individual trials. The original pen and paper Brixton test identified a spatial anticipation deficit in 7/12 (58%) of bvFTD and in 2/6 (33%) of SD patients. The eyetracking frequentist approach reported the deficit in 11/12 (92%) of bvFTD and in none (0%) of the SD patients. The machine learning approach had the main advantage of identifying significant differences from controls in 24/24 individual trials for bvFTD patients and in only 12/24 for SD patients. Results indicate that the fine grained rich datasets obtained from eyetracking metrics can inform us about high level cognitive functions in dementia, such as spatial anticipation. The ML approach can help identify conditions where subtle deficits are present and, potentially, contribute to test optimisation and the reduction of testing times. The absence of instructions also favoured a better distinction between different clinical groups of patients and can help provide valuable disease-specific markers. © 2017 The Authors",Anticipatory saccades; Behavioural variant frontotemporal dementia; Eye movements; Machine learning; Spatial anticipation,"Aged; Anticipation, Psychological; Bayes Theorem; Eye Movement Measurements; Female; Frontotemporal Dementia; Humans; Machine Learning; Male; Middle Aged; Saccades; Space Perception; Spatial Processing; adult; aged; Article; Bayesian learning; Brixton spatial anticipation test; clinical article; clinical assessment; cognition; cognitive defect; controlled study; disease marker; executive function test; eye fixation; eye tracking; female; frontal variant frontotemporal dementia; human; male; neuroimaging; saccadic velocity; semantic dementia; spatial anticipation deficit; anticipation; Bayes theorem; depth perception; diagnostic imaging; frontotemporal dementia; machine learning; middle aged; oculography; pathology; pathophysiology; psychology; saccadic eye movement; spatial behavior",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85031797102,Movies / Media
Keenan K.G.; Huddleston W.E.; Ernest B.E.,"Keenan, Kevin G. (7006549493); Huddleston, Wendy E. (6602287410); Ernest, Bradley E. (56027771500)",7006549493; 6602287410; 56027771500,Altered visual strategies and attention are related to increased force fluctuations during a pinch grip task in older adults,2017,Journal of Neurophysiology,118,5,,2537,2548,11.0,8,10.1152/jn.00928.2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032931268&doi=10.1152%2fjn.00928.2016&partnerID=40&md5=fce345f548dcd6224023a13a8509d43d,"The purpose of the study was to determine the visual strategies used by older adults during a pinch grip task and to assess the relations between visual strategy, deficits in attention, and increased force fluctuations in older adults. Eye movements of 23 older adults (>65 yr) were monitored during a low-force pinch grip task while subjects viewed three common visual feedback displays. Performance on the Grooved Pegboard test and an attention task (which required no concurrent hand movements) was also measured. Visual strategies varied across subjects and depended on the type of visual feedback provided to the subjects. First, while viewing a high-gain compensatory feedback display (horizontal bar moving up and down with force), 9 of 23 older subjects adopted a strategy of performing saccades during the task, which resulted in 2.5 times greater force fluctuations in those that exhibited saccades compared with those who maintained fixation near the target line. Second, during pursuit feedback displays (force trace moving left to right across screen and up and down with force), all subjects exhibited multiple saccades, and increased force fluctuations were associated (rs = 0.6; P = 0.002) with fewer saccades during the pursuit task. Also, decreased low-frequency (<4 Hz) force fluctuations and Grooved Pegboard times were significantly related (P = 0.033 and P = 0.005, respectively) with higher (i.e., better) attention z scores. Comparison of these results with our previously published results in young subjects indicates that saccadic eye movements and attention are related to force control in older adults. NEW & NOTEWORTHY The significant contributions of the study are the addition of eye movement data and an attention task to explain differences in hand motor control across different visual displays in older adults. Older participants used different visual strategies across varying feedback displays, and saccadic eye movements were related with motor performance. In addition, those older individuals with deficits in attention had impaired motor performance on two different hand motor control tasks, including the Grooved Pegboard test. © 2017 the American Physiological Society.",Aging; Attention; Force steadiness; Hand; Visual strategies,"Adult; Aged; Aged, 80 and over; Aging; Attention; Feedback, Physiological; Female; Humans; Male; Pinch Strength; Saccades; Visual Perception; aged; Article; attention test; eye tracking; female; grip strength; grooved pegboard test; groups by age; human; human experiment; male; motor performance; normal human; precision grip; priority journal; saccadic eye movement; task performance; vision; visual attention; visual feedback; adult; aging; attention; physiological feedback; physiology; pinch strength; saccadic eye movement; very elderly; vision",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85032931268,Movies / Media
Zhou Q.; Velloso E.,"Zhou, Qiushi (57201290518); Velloso, Eduardo (53364337000)",57201290518; 53364337000,GazeGrip: Improving mobile device accessibility with gaze & grip interaction,2017,ACM International Conference Proceeding Series,,,,467,471,4.0,4,10.1145/3152771.3156159,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044219833&doi=10.1145%2f3152771.3156159&partnerID=40&md5=dfd59c826c1ffec1fb0a759b14613ac9,"Though modern tablet devices offer users high processing power in a compact form factor, interaction while holding them still presents problems, forcing the user to alternate the dominant hand between holding and touching the screen. In this paper, we explore how eye tracking can minimize this problem through GazeGrip---a prototype interactive system for a tablet that integrates eye tracking and back-of-device touch sensing. We propose a design space for potential interaction techniques that leverage the power of this combination, as well as prototype applications that instantiate it. Our preliminary results highlight as opportunities enabled by the system reduced fatigue while holding the device, minimal occlusion of the screen, and improved accuracy and precision in the interaction. © 2017 Association for Computing Machinery. All rights reserved.",Back-of-device Interaction; Gaze input; Multimodal UI; Tablet,Eye tracking; Interactive computer systems; Mobile devices; Touch screens; Accuracy and precision; Back of devices; Gaze input; High processing power; Interaction techniques; Interactive system; Multi-modal; Tablet; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85044219833,Movies / Media
Darling A.; Tello C.; Martí M.J.; Garrido C.; Aguilera-Albesa S.; Tomás Vila M.; Gastón I.; Madruga M.; González Gutiérrez L.; Ramos Lizana J.; Pujol M.; Gavilán Iglesias T.; Tustin K.; Lin J.P.; Zorzi G.; Nardocci N.; Martorell L.; Lorenzo Sanz G.; Gutiérrez F.; García P.J.; Vela L.; Hernández Lahoz C.; Ortigoza Escobar J.D.; Martí Sánchez L.; Moreira F.; Coelho M.; Correia Guedes L.; Castro Caldas A.; Ferreira J.; Pires P.; Costa C.; Rego P.; Magalhães M.; Stamelou M.; Cuadras Pallejà D.; Rodríguez-Blazquez C.; Martínez-Martín P.; Lupo V.; Stefanis L.; Pons R.; Espinós C.; Temudo T.; Pérez Dueñas B.,"Darling, Alejandra (55587386900); Tello, Cristina (57170042600); Martí, María Josep (35445809200); Garrido, Cristina (7005285843); Aguilera-Albesa, Sergio (11739427700); Tomás Vila, Miguel (6603848589); Gastón, Itziar (24461646700); Madruga, Marcos (23095136600); González Gutiérrez, Luis (57197722129); Ramos Lizana, Julio (7003297503); Pujol, Montserrat (57193854372); Gavilán Iglesias, Tania (37007468600); Tustin, Kylee (54893058300); Lin, Jean Pierre (50461740800); Zorzi, Giovanna (6603821807); Nardocci, Nardo (7003319824); Martorell, Loreto (6603864053); Lorenzo Sanz, Gustavo (6701726647); Gutiérrez, Fuencisla (57197695270); García, Pedro J. (57197716087); Vela, Lidia (58816792300); Hernández Lahoz, Carlos (6603427213); Ortigoza Escobar, Juan Darío (55585094600); Martí Sánchez, Laura (57190000248); Moreira, Fradique (57191420391); Coelho, Miguel (36888639000); Correia Guedes, Leonor (23766988600); Castro Caldas, Ana (55929976900); Ferreira, Joaquim (59971768900); Pires, Paula (55574154800); Costa, Cristina (56681707800); Rego, Paulo (57192382467); Magalhães, Marina (7102771258); Stamelou, María (57208560010); Cuadras Pallejà, Daniel (13004327700); Rodríguez-Blazquez, Carmen (56010307300); Martínez-Martín, Pablo (7005097519); Lupo, Vincenzo (25639913900); Stefanis, Leonidas (57202963715); Pons, Roser (7006478182); Espinós, Carmen (6601959468); Temudo, Teresa (6602098088); Pérez Dueñas, Belén (6602545967)",55587386900; 57170042600; 35445809200; 7005285843; 11739427700; 6603848589; 24461646700; 23095136600; 57197722129; 7003297503; 57193854372; 37007468600; 54893058300; 50461740800; 6603821807; 7003319824; 6603864053; 6701726647; 57197695270; 57197716087; 58816792300; 6603427213; 55585094600; 57190000248; 57191420391; 36888639000; 23766988600; 55929976900; 59971768900; 55574154800; 56681707800; 57192382467; 7102771258; 57208560010; 13004327700; 56010307300; 7005097519; 25639913900; 57202963715; 7006478182; 6601959468; 6602098088; 6602545967,Clinical rating scale for pantothenate kinase-associated neurodegeneration: A pilot study,2017,Movement Disorders,32,11,,1620,1630,10.0,20,10.1002/mds.27129,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034068284&doi=10.1002%2fmds.27129&partnerID=40&md5=0c3f9d26913d815744a52f42cab9c183,"Background: Pantothenate kinase-associated neurodegeneration is a progressive neurological disorder occurring in both childhood and adulthood. The objective of this study was to design and pilot-test a disease-specific clinical rating scale for the assessment of patients with pantothenate kinase-associated neurodegeneration. Methods: In this international cross-sectional study, patients were examined at the referral centers following a standardized protocol. The motor examination was filmed, allowing 3 independent specialists in movement disorders to analyze 28 patients for interrater reliability assessment. The scale included 34 items (maximal score, 135) encompassing 6 subscales for cognition, behavior, disability, parkinsonism, dystonia, and other neurological signs. Results: Forty-seven genetically confirmed patients (30 ± 17 years; range, 6-77 years) were examined with the scale (mean score, 62 ± 21; range, 20-106). Dystonia with prominent cranial involvement and atypical parkinsonian features were present in all patients. Other common signs were cognitive impairment, psychiatric features, and slow and hypometric saccades. Dystonia, parkinsonism, and other neurological features had a moderate to strong correlation with disability. The scale showed good internal consistency for the total scale (Cronbach's α = 0.87). On interrater analysis, weighted kappa values (0.30-0.93) showed substantial or excellent agreement in 85% of the items. The scale also discriminated a subgroup of homozygous c.1583C>T patients with lower scores, supporting construct validity for the scale. Conclusions: The proposed scale seems to be a reliable and valid instrument for the assessment of pediatric and adult patients with pantothenate kinase-associated neurodegeneration. Additional validation studies with a larger sample size will be required to confirm the present results and to complete the scale validation testing. © 2017 International Parkinson and Movement Disorder Society. © 2017 International Parkinson and Movement Disorder Society",clinical rating scale; dystonia parkinsonism; neurodegeneration with brain iron accumulation; pantothenate kinase-associated neurodegeneration; PKAN,Adolescent; Adult; Aged; Child; Cognitive Dysfunction; Cross-Sectional Studies; Disabled Persons; Dystonia; Humans; Mental Disorders; Middle Aged; Ocular Motility Disorders; Pantothenate Kinase-Associated Neurodegeneration; Parkinsonian Disorders; Pilot Projects; Reproducibility of Results; Severity of Illness Index; Young Adult; pantothenate kinase; adolescent; adult; aged; Article; behavior; child; clinical article; clinical assessment; clinical protocol; cognition; cognitive defect; construct validity; convergent validity; Cronbach alpha coefficient; cross-sectional study; disability; dystonia; female; genetic analysis; human; internal consistency; interrater reliability; male; medical specialist; mental disease; middle aged; motor dysfunction; neurodegeneration with brain iron accumulation; neurologic disease; Pantothenate Kinase Associated Neurodegeneration Rating Scale; parkinsonism; pilot study; point mutation; preschool child; priority journal; questionnaire; rating scale; saccadic eye movement; school child; young adult; clinical trial; cognitive defect; complication; disabled person; dystonia; eye movement disorder; genetics; mental disease; multicenter study; neurodegeneration with brain iron accumulation; parkinsonism; reproducibility; severity of illness index,Article,Final,,Scopus,2-s2.0-85034068284,Movies / Media
Carvalho J.; Pereira R.; Barreto D.; Nobre P.J.,"Carvalho, Joana (35361620100); Pereira, Raquel (57200135830); Barreto, Diana (56099758700); Nobre, Pedro J. (6603728349)",35361620100; 57200135830; 56099758700; 6603728349,The Effects of Positive Versus Negative Mood States on Attentional Processes During Exposure to Erotica,2017,Archives of Sexual Behavior,46,8,,2495,2504,9.0,15,10.1007/s10508-016-0875-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991055958&doi=10.1007%2fs10508-016-0875-3&partnerID=40&md5=d4d00d8d98a529dc89a90d3707138e27,"The relationship between emotions and sexual functioning has been documented since early sex research. Among other effects, emotions are expected to impact sexual response by shaping individuals’ attention to sexual cues; yet, this assumption has not been tested. This study aimed to investigate whether attentional processes to sexual cues are impacted by state emotions, and whether the processes impacted by emotions relate to subjective sexual arousal to a sex film clip. A total of 52 men and 73 women were randomly assigned to one of three experimental conditions: (1) a negative mood induction condition (sadness as dominant emotion), (2) a positive mood induction condition (amusement as dominant emotion), and a (3) neutral/control condition. After mood induction, participants were exposed to a sex film clip while their focus of visual attention was measured using an eye tracker. Three areas of interest (AOI) were considered within the sex clip: background (non-sexual cues), body interaction, and genital interaction. Self-reported attention, thoughts during the sex clip, percent dwell time, and pupil size to AOI were considered as attentional markers. Findings revealed that the attentional processes were not impacted by the mood conditions. Instead, gender effects were found. While men increased their visual attention to the background area of the film clip, women increased attention to the genital area. Also, sexual arousal thoughts during exposure to the sex clip were consistently related to subjective sexual arousal regardless of the momentary emotional state. Findings add to the literature by showing that men and women process the sexual components of a stimulus differently and by challenging the assumption that emotions shape attention to sexual cues. © 2016, Springer Science+Business Media New York.",Attention; Emotions; Mood induction; Sexual arousal,Affect; Attention; Erotica; Eye Movements; Female; Humans; Male; Random Allocation; controlled clinical trial; controlled study; erotica; experimental model; exposure; female; gender; genital system; human; major clinical study; male; mood; pupil; randomized controlled trial; sadness; sexual arousal; stimulus; visual attention; affect; attention; erotica; eye movement; physiology; psychology; randomization,Article,Final,,Scopus,2-s2.0-84991055958,Movies / Media
Watamaniuk S.N.J.; Bal J.; Heinen S.J.,"Watamaniuk, Scott N. J. (6603674849); Bal, Japjot (57224603087); Heinen, Stephen J. (7003536110)",6603674849; 57224603087; 7003536110,A subconscious interaction between fixation and anticipatory pursuit,2017,Journal of Neuroscience,37,47,,11424,11430,6.0,6,10.1523/JNEUROSCI.2186-17.2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035148710&doi=10.1523%2fJNEUROSCI.2186-17.2017&partnerID=40&md5=66517d111c5e53c9b91ee32e659e0e74,"Ocular smooth pursuit and fixation are typically viewed as separate systems, yet there is evidence that the brainstem fixation system inhibits pursuit. Here we present behavioral evidence that the fixation system modulates pursuit behavior outside of conscious awareness. Human observers (male and female) either pursued a small spot that translated across a screen, or fixated it as it remained stationary. As shown previously, pursuit trials potentiated the oculomotor system, producing anticipatory eye velocity on the next trial before the target moved that mimicked the stimulus-driven velocity. Randomly interleaving fixation trials reduced anticipatory pursuit, suggesting that a potentiated fixation system interacted with pursuit to suppress eye velocity in upcoming pursuit trials. The reduction was not due to passive decay of the potentiated pursuit signal because interleaving “blank” trials in which no target appeared did not reduce anticipatory pursuit. Interspersed short fixation trials reduced anticipation on long pursuit trials, suggesting that fixation potentiation was stronger than pursuit potentiation. Furthermore, adding more pursuit trials to a block did not restore anticipatory pursuit, suggesting that fixation potentiation was not overridden by certainty of an imminent pursuit trial but rather was immune to conscious intervention. To directly test whether cognition can override fixation suppression, we alternated pursuit and fixation trials to perfectly specify trial identity. Still, anticipatory pursuit did not rise above that observed with an equal number of random fixation trials. The results suggest that potentiated fixation circuitry interacts with pursuit circuitry at a subconscious level to inhibit pursuit. © 2017 the authors.",Eye movements; Human; Potentiation; Priming; Smooth pursuit,"Adult; Anticipation, Psychological; Brain; Female; Humans; Male; Pursuit, Smooth; Unconscious (Psychology); adult; anticipatory guidance; Article; connectome; eye fixation; eye movement; female; human; human experiment; information processing; male; normal human; oculomotor system; priority journal; stimulus response; task performance; visual acuity; visual stimulation; anticipation; brain; ego development; physiology; smooth pursuit eye movement",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85035148710,Movies / Media
Rothkegel L.O.M.; Trukenbrod H.A.; Schütt H.H.; Wichmann F.A.; Engbert R.,"Rothkegel, Lars O.M. (57191856407); Trukenbrod, Hans A. (18438977000); Schütt, Heiko H. (57188997782); Wichmann, Felix A. (6603676955); Engbert, Ralf (6701500744)",57191856407; 18438977000; 57188997782; 6603676955; 6701500744,Temporal evolution of the central fixation bias in scene viewing,2017,Journal of Vision,17,13,3,,,,31,10.1167/17.13.3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033791974&doi=10.1167%2f17.13.3&partnerID=40&md5=c52246681bbe0c4d90ff83ba0a53f5d3,"When watching the image of a natural scene on a computer screen, observers initially move their eyes toward the center of the image-a reliable experimental finding termed central fixation bias. This systematic tendency in eye guidance likely masks attentional selection driven by image properties and top-down cognitive processes. Here, we show that the central fixation bias can be reduced by delaying the initial saccade relative to image onset. In four scene-viewing experiments we manipulated observers' initial gaze position and delayed their first saccade by a specific time interval relative to the onset of an image. We analyzed the distance to image center over time and show that the central fixation bias of initial fixations was significantly reduced after delayed saccade onsets. We additionally show that selection of the initial saccade target strongly depended on the first saccade latency. A previously published model of saccade generation was extended with a central activation map on the initial fixation whose influence declined with increasing saccade latency. This extension was sufficient to replicate the central fixation bias from our experiments. Our results suggest that the central fixation bias is generated by default activation as a response to the sudden image onset and that this default activation pattern decreases over time. Thus, it may often be preferable to use a modified version of the scene viewing paradigm that decouples image onset from the start signal for scene exploration to explicitly reduce the central fixation bias. © 2017 The Authors.",Dynamic models; Eye movements; Visual attention; Visual scanpath,"Adolescent; Adult; Attention; Eye Movements; Female; Fixation, Ocular; Humans; Male; Photic Stimulation; Saccades; Young Adult; adolescent; adult; attention; eye fixation; eye movement; female; human; male; photostimulation; physiology; procedures; saccadic eye movement; young adult",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85033791974,Movies / Media
Al Raisi S.F.; Edirisinghe E.,"Al Raisi, Seema F. (57202440820); Edirisinghe, Eran (6701576984)",57202440820; 6701576984,A machine learning based approach to human observer behaviour analysis in CCTV video analytics & forensics,2017,ACM International Conference Proceeding Series,,,a58,,,,1,10.1145/3109761.3158376,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048366697&doi=10.1145%2f3109761.3158376&partnerID=40&md5=dcc102a68b61731bd67afb553bdb9884,"Human observer behaviour analysis in image and video inspection in many areas of practical application is conducted based on using data captured by eye tracking devices. Such data is analysed using statistical approaches leading to the creation of useful information and the ability to make decisions about the content. CCTV observer behaviour analysis is one example of a most widely used application. Unfortunately, the information and knowledge that such statistical approaches to data analysis can create is rather limited, especially the trends and patterns of data cannot be easily analysed. Thus, important information and knowledge that the data can provide may not be identifiable. In this paper, we proposed a novel approach to human observer eye tracking data analysis based on machine learning algorithms. Further, in order to conduct a more detailed and practically useful data analysis, we specifically analyse the attention human observers given instructions to search for specified content. We provide experimental results to demonstrate the significance and novelty of the information and knowledge that this novel approach to data analysis can provide. To the authors' knowledge, there is no work in literature that has proposed the use of machine learning in eye tracking data analysis. © 2017 Association for Computing Machinery.",CCTV surveillance; Eye-tracking system; Machine learning,Artificial intelligence; Behavioral research; Digital forensics; Eye tracking; Information analysis; Internet of things; Learning systems; Network security; Behaviour analysis; CCTV surveillance; Eye tracking devices; Eye tracking systems; Human observers; Statistical approach; Video analytics; Video inspection; Learning algorithms,Conference paper,Final,,Scopus,2-s2.0-85048366697,Movies / Media
Brunyé T.T.; Gardony A.L.,"Brunyé, Tad T. (35232274200); Gardony, Aaron L. (36570266900)",35232274200; 36570266900,Eye tracking measures of uncertainty during perceptual decision making,2017,International Journal of Psychophysiology,120,,,60,68,8.0,53,10.1016/j.ijpsycho.2017.07.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025083859&doi=10.1016%2fj.ijpsycho.2017.07.008&partnerID=40&md5=3fb8c4bb013bac3db221663d5681e46f,"Perceptual decision making involves gathering and interpreting sensory information to effectively categorize the world and inform behavior. For instance, a radiologist distinguishing the presence versus absence of a tumor, or a luggage screener categorizing objects as threatening or non-threatening. In many cases, sensory information is not sufficient to reliably disambiguate the nature of a stimulus, and resulting decisions are done under conditions of uncertainty. The present study asked whether several oculomotor metrics might prove sensitive to transient states of uncertainty during perceptual decision making. Participants viewed images with varying visual clarity and were asked to categorize them as faces or houses, and rate the certainty of their decisions, while we used eye tracking to monitor fixations, saccades, blinks, and pupil diameter. Results demonstrated that decision certainty influenced several oculomotor variables, including fixation frequency and duration, the frequency, peak velocity, and amplitude of saccades, and phasic pupil diameter. Whereas most measures tended to change linearly along with decision certainty, pupil diameter revealed more nuanced and dynamic information about the time course of perceptual decision making. Together, results demonstrate robust alterations in eye movement behavior as a function of decision certainty and attention demands, and suggest that monitoring oculomotor variables during applied task performance may prove valuable for identifying and remediating transient states of uncertainty. © 2017",Eye tracking; Perceptual decision making; Pupil diameter; Uncertainty,Adolescent; Adult; Analysis of Variance; Attention; Blinking; Decision Making; Eye Movements; Female; Humans; Imagination; Male; Photic Stimulation; Pupil; Uncertainty; Visual Perception; Young Adult; attention; decision making; eye tracking; female; human; human experiment; male; monitoring; pupil; saccadic eye movement; task performance; uncertainty; velocity; adolescent; adult; analysis of variance; blinking; decision making; eye movement; imagination; photostimulation; physiology; pupil; vision; young adult,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85025083859,Movies / Media
Szajerman D.; Napieralski P.,"Szajerman, Dominik (23398275300); Napieralski, Piotr (24481496100)",23398275300; 24481496100,Joint analysis of simultaneous EEG and eye tracking data for video picture,2017,"2017 18th International Symposium on Electromagnetic Fields in Mechatronics, Electrical and Electronic Engineering, ISEF 2017",,,8090693,,,,2,10.1109/ISEF.2017.8090693,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041288759&doi=10.1109%2fISEF.2017.8090693&partnerID=40&md5=ab014cfe0e026ff5e4a7c5dad7a5697c,The potential of BCI technology is used in scientific study of human perception and vision in medical and non-medical domains. In this paper we try to capture and interpret visual perception and attention in video movies by eye tracking and EEG technology simultaneously. Joint analysis of EEG and eye tracking offer new potentials for video analysis. The results of this research shown coherence between this both important for human perception information sources. Joint analysis of EEG and eye tracking data could find correlated features for video retrospection. © 2017 IEEE.,BCI; EEG; Eye tracking; Human perception; Video picture evaluation,Electroencephalography; Engineering; Industrial engineering; Mechanical engineering; Mechatronics; Eye-tracking; Human perception; Information sources; Medical domains; Scientific studies; Video analysis; Video picture evaluation; Visual perception; Electromagnetic fields,Conference paper,Final,,Scopus,2-s2.0-85041288759,Movies / Media
Glaser M.; Lengyel D.; Toulouse C.; Schwan S.,"Glaser, Manuela (35483880200); Lengyel, Dominik (57191753862); Toulouse, Catherine (57191752116); Schwan, Stephan (6603854115)",35483880200; 57191753862; 57191752116; 6603854115,Designing computer-based learning contents: influence of digital zoom on attention,2017,Educational Technology Research and Development,65,5,,1135,1151,16.0,13,10.1007/s11423-016-9495-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992694389&doi=10.1007%2fs11423-016-9495-9&partnerID=40&md5=3e098ca349da88fc41aaea2c013ec7e6,"In the present study, we investigated the role of digital zoom as a tool for directing attention while looking at visual learning material. In particular, we analyzed whether minimal digital zoom functions similarly to a rhetorical device by cueing mental zooming of attention accordingly. Participants were presented either static film clips, film clips with minimal zoom-ins, or film clips with minimal zoom-outs while eye movements were recorded. We hypothesized that minimal zoom-ins should lead to more gaze coherence, to longer dwell times as an indicator of more elaborative processing, and to fewer transitions as an indicator of less mental integration. Zoom-outs, on the other hand, were expected to have opposite effects. Results showed that zoom-ins increase gaze coherence and dwell times on the center parts of the depictions while decreasing transitions of pictorial elements from the center and the context areas. In contrast, patterns of results from zoom-outs and static presentations were similar to a large degree, indicating that zoom-ins and zoom-outs do not operate in a complementary fashion. Theoretical and practical implications of the present results are discussed. © 2016, Association for Educational Communications and Technology.",Attention; Camera; Cueing; Eye-tracking; Gaze coherence; Zoom,,Article,Final,,Scopus,2-s2.0-84992694389,Movies / Media
Rogalska A.; Napieralski P.,"Rogalska, Anna (57200442787); Napieralski, Piotr (24481496100)",57200442787; 24481496100,A model of saliency-based visual attention for movie retrospection,2017,"2017 18th International Symposium on Electromagnetic Fields in Mechatronics, Electrical and Electronic Engineering, ISEF 2017",,,8090692,,,,3,10.1109/ISEF.2017.8090692,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041311867&doi=10.1109%2fISEF.2017.8090692&partnerID=40&md5=b8489f4f10230bffff5fcbd323f70467,"Visual saliency modeling is becoming important and challenging for many scientific disciplines (robotic systems, psychophysics, cognitive neuroscience and computer science). Proposed model indicates possible salient regions by taking into consideration face presence and motion which is essential in motion pictures. By combining face presence and motion we can obtain credible saliency map with low computational costs. © 2017 IEEE.",Gaze tracking; Saliency map; Visual attention,Cognitive systems; Electromagnetic fields; Cognitive neurosciences; Computational costs; Gaze tracking; Saliency map; Salient regions; Scientific discipline; Visual Attention; Visual saliency model; Behavioral research,Conference paper,Final,,Scopus,2-s2.0-85041311867,Movies / Media
Okano M.; Asakawa M.,"Okano, Masao (57224714286); Asakawa, Masami (57206288656)",57224714286; 57206288656,Eye tracking analysis of consumer's attention to the product message of web advertisements and TV commercials,2017,"2017 5th International Conference on Cyber and IT Service Management, CITSM 2017",,,8089270,,,,6,10.1109/CITSM.2017.8089270,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040243191&doi=10.1109%2fCITSM.2017.8089270&partnerID=40&md5=39c98f0955e5147bd13357b1a6e41d12,"To examine the hypothesis that subjects who assign importance to the product selection criteria included in a commercial's message pay more attention to the message than do subjects who do not assign importance, an eye-tracking experiment was conducted. Commercials and websites with 'reducing body fat,' 'low in calories,' and 'beneficial for dieting' messages were shown to 81 college students and eye-tracking data were collected. The results of the statistical analysis supported the research hypothesis. The tendency to pay attention to the messages that matched subjects' product selection criteria was more prominent in the case of websites. © 2017 IEEE.",commercial; consumer; eye tracking; selection criterion; web advertisement,Students; commercial; consumer; Eye-tracking; Selection criteria; web advertisement; Websites,Conference paper,Final,,Scopus,2-s2.0-85040243191,Movies / Media
Liu Z.; Wang Z.; Zhang L.; Shah R.R.; Xia Y.; Yang Y.; Li X.,"Liu, Zhenguang (56177043100); Wang, Zepeng (57195973746); Zhang, Luming (35231925400); Shah, Rajiv Ratn (56121902800); Xia, Yingjie (35788434700); Yang, Yi (56159216600); Li, Xuelong (55936260100)",56177043100; 57195973746; 35231925400; 56121902800; 35788434700; 56159216600; 55936260100,FastShrinkage: Perceptually-aware retargeting toward mobile platforms,2017,MM 2017 - Proceedings of the 2017 ACM Multimedia Conference,,,,501,509,8.0,21,10.1145/3123266.3123377,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035231600&doi=10.1145%2f3123266.3123377&partnerID=40&md5=9c0f50fd71e5d8cf0437654516bf3253,"Retargeting aims at adapting an original high-resolution photo/video to a low-resolution screen with an arbitrary aspect ratio. Conventional approaches are generally based on desktop PCs, since the computation might be intolerable for mobile platforms (especially when retargeting videos). Besides, only low-level visual features are exploited typically, whereas human visual perception is not well encoded. In this paper, we propose a novel retargeting framework which fast shrinks photo/video by leveraging human gaze behavior. Specifically, we first derive a geometry-preserved graph ranking algorithm, which efficiently selects a few salient object patches to mimic human gaze shifting path (GSP) when viewing each scenery. Afterward, an aggregation-based CNN is developed to hierarchically learn the deep representation for each GSP. Based on this, a probabilistic model is developed to learn the priors of the training photos which are marked as aesthetically-pleasing by professional photographers. We utilize the learned priors to efficiently shrink the corresponding GSP of a retargeted photo/video to be maximally similar to those from the training photos. Extensive experiments have demonstrated that: 1) our method consumes less than 35ms to retarget a 1024 × 768 photo (or a 1280 × 720 video frame) on popular iOS/Android devices, which is orders of magnitude faster than the conventional retargeting algorithms; 2) the retargeted photos/videos produced by our method outperform its competitors significantly based on the paired-comparison-based user study; and 3) the learned GSPs are highly indicative of human visual attention according to the human eye tracking experiments. © 2017 ACM.",Deep feature; Mobile platform; Perceptual; Probabilistic model; Retarget,Aspect ratio; Mobile phones; Deep feature; Mobile platform; Perceptual; Probabilistic modeling; Retarget; Behavioral research,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85035231600,Movies / Media
Matar E.; Lewis S.J.G.,"Matar, Elie (55606952600); Lewis, Simon J. G. (7404041158)",55606952600; 7404041158,Rem sleep behaviour disorder: Not just a bad dream,2017,Medical Journal of Australia,207,6,,262,268,6.0,10,10.5694/mja17.00321,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029667929&doi=10.5694%2fmja17.00321&partnerID=40&md5=a8f8a4e5359510a9ea85644b24907b6f,"Rapid eye movement (REM) sleep behaviour disorder (RBD) is a parasomnia characterised by the loss of the normal atonia during the REM stage of sleep, resulting in overt motor behaviours that usually represent the enactment of dreams. Patients will seek medical attention due to sleep-related injuries or unpleasant dream content. Idiopathic RBD which occurs independently of any other disease occurs in up to 2% of the older population. Meanwhile, secondary RBD is very common in association with certain neurodegenerative conditions. RBD can also occur in the context of antidepressant use, obstructive sleep apnoea and narcolepsy. RBD can be diagnosed with a simple screening question followed by confirmation with polysomnography to exclude potential mimics. Treatment for RBD is effective and involves treatment of underlying causes, modification of the sleep environment, and pharmacotherapy with either clonazepam or melatonin. An important finding in the past decade is the recognition that almost all patients with idiopathic RBD will ultimately go on to develop Parkinson disease or dementia with Lewy bodies. This suggests that idiopathic RBD represents a prodromal phase of these conditions. Physicians should be aware of the risk of phenoconversion. They should educate idiopathic RBD patients to recognise the symptoms of these conditions and refer as appropriate for further testing and enrolment into research trials focused on neuroprotective measures. © 2017 AMPCo Pty Ltd. Produced with Elsevier B.V. All rights reserved.",,Clonazepam; Humans; Hypnotics and Sedatives; Melatonin; Polysomnography; REM Sleep Behavior Disorder; clonazepam; melatonin; clonazepam; hypnotic sedative agent; melatonin; Alzheimer disease; clinical feature; confusion; daytime somnolence; degenerative disease; differential diagnosis; diffuse Lewy body disease; disease association; dizziness; drug safety; epidemiological data; headache; human; latent period; narcolepsy; nerve degeneration; parasomnia; Parkinson disease; pathogenesis; patient care; polysomnography; prognosis; REM sleep; Review; risk factor; Shy Drager syndrome; sleep time; somnolence; synucleinopathy; unpleasant dream; REM Sleep Behavior Disorder,Article,Final,,Scopus,2-s2.0-85029667929,Movies / Media
Rossi D.; Maglione A.G.; Modica E.; Di Flumeri G.; Venuti I.; Brizi A.; Colosimo A.; Babiloni F.; Cartocci G.,"Rossi, Dario (57201867718); Maglione, Anton Giulio (35318192300); Modica, Enrica (57189727712); Di Flumeri, Gianluca (56647980200); Venuti, Isotta (57192917473); Brizi, Ambra (55875327500); Colosimo, Alfredo (26642958200); Babiloni, Fabio (7006787992); Cartocci, Giulia (52263349900)",57201867718; 35318192300; 57189727712; 56647980200; 57192917473; 55875327500; 26642958200; 7006787992; 52263349900,An eye tracking index for the salience estimation in visual stimuli,2017,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",,,8037852,4483,4486,3.0,4,10.1109/EMBC.2017.8037852,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032171826&doi=10.1109%2fEMBC.2017.8037852&partnerID=40&md5=cb700cce0fe4624a6db969f41108a8e8,"Every day we face visual stimuli able to catch our attention, but this aspect becomes crucial if the visual material has the purpose to spread a message aimed at engaging the observer. In this framework, a worthy aspect is how to measure the 'visual engagement' produced by visual stimuli exposure. To this purpose, in the present study, employing the eye tracking technique, an index of visual attention (VA) has been proposed, and applied to pictures belonging to antismoking public service announcements, so to investigate the saliency of health-promoting messages in a young sample. The VA index is a non-dimensional index, defined as the ratio between the percentage of the total time spent fixating an area of interest (AOI) weighted on the total time the picture is showed on the screen, and the percentage of the area occupied by the AOI weighted on the total dimension of the picture. It could be predicted that AOI reporting higher VA values will be the ones having more saliency. Three antismoking Public Service Announcements (PSAs) images have been selected for the study and for each of them were identified: i) 'picture' (such as a young man with a sarcastic expression depicted while smoking a cigarette, or the image of a lady who underwent a tracheotomy) and ii) 'writing' (text of the antismoking message) AOIs. Main results of the analysis revealed that writing AOIs obtained statistically significant higher VA values than visual AOIs (p=0.03), but these held true only for an ineffective PSA, probably because the text was not perceived as pertinent with the surrounding image. On the other hand, an effective PSA obtained higher VA values in response to visual than writing AOIs observation (p=0.02). The VA index appears therefore to represent a useful tool to measure the saliency of visual stimuli elements. © 2017 IEEE.",,Attention; Eye; Humans; Male; Photic Stimulation; Smoking; Smoking Cessation; Smoking Prevention; attention; eye; human; male; photostimulation; smoking; smoking cessation; smoking prevention,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85032171826,Movies / Media
Meža M.; Košir J.; Strle G.; Košir A.,"Meža, Marko (56230393100); Košir, Janja (57191505877); Strle, Gregor (35175418100); Košir, Andrej (6603413691)",56230393100; 57191505877; 35175418100; 6603413691,Towards Automatic Real-Time Estimation of Observed Learner's Attention Using Psychophysiological and Affective Signals: The Touch-Typing Study Case,2017,IEEE Access,5,,8046018,27043,27060,17.0,3,10.1109/ACCESS.2017.2750758,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030653958&doi=10.1109%2fACCESS.2017.2750758&partnerID=40&md5=e740728719065393d44e5963e8a45435,"This paper presents an experimental study on the real-time estimation of observed learners' attention given the task of touch-typing. The aim is to examine whether the observed attention estimates gathered from human raters can be computationally modeled in real time, based on the learner's psychophysiological and affective signals. A key observation from this paper is that the observed attention varies continuously and throughout the task. The findings show that a relatively high sampling interval is required for the modeling of observed learners' attention, which is impossible to achieve with traditional assessment methods (e.g., between-session self-reports). The results show that multiple linear regression models were relatively successful at discriminating low and high levels of the observed attention. In the best case, the within-learner model performed with the goodness-of-fit adjusted Radj2 = 0.888 and RMSE = 0.103 (range of the attention scores 1-5). However, the multiple linear model underperformed in the estimation of the observed attention between learners, indicating that the differences among the learners are often significant and cannot be overcome by a general linear model of attention. The between-learner model achieved an adjusted Radj2 = 0.227 and RMSE = 0.708), explaining only 22.7% of the variability. The influence of individual psychophysiological and affective signals (eye gaze, pupil dilation, and valence and arousal) on the estimation of the observed attention was also examined. The results show that both affective dimensions (valence and arousal), as well as the EyePos2D offset (the distance of an eye from the average position in the xy plane parallel to the screen), and the EyePos-Z (the distance of an eye from the screen) significantly and most frequently influence the performance of the within-learner model. © 2017 IEEE.",Attention estimation; psychophysiological and behavioral signals; rater agreement,E-learning; Estimation; Feature extraction; Interactive computer systems; Linear regression; Process control; Regression analysis; X-Y model; Attention estimations; Computational model; Electronic learning; General linear modeling; Multiple linear models; Multiple linear regression models; Real-time estimation; Traditional assessment; Real time systems,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85030653958,Movies / Media
Cheng S.; Shen X.; Lu Y.; Sun Z.,"Cheng, Shiwei (25630245300); Shen, Xiaoquan (57196219924); Lu, Yuhua (57189698241); Sun, Zhiqiang (56102869200)",25630245300; 57196219924; 57189698241; 56102869200,Distributed Attentive User Interface for Cross-device Interaction Based on Eye Tracking,2017,Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics,29,9,,1713,1724,11.0,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032280682&partnerID=40&md5=97e5e25c4a7847c1a90e0a5cdcf45e94,"In order to improve input efficiency in the cross-device interaction environment, and reduce cognitive workload during the process of switching visual attention among different devices, the eye tracking based attentive user interface for cross-device was proposed. First, extracted the edges of devices' screens, and then combined the geometry characters and the color histograms of the screens to detect different devices. The pupil center cornea reflection algorithm was used to calculate the gaze fixations' coordinates with supporting head movement. Detected areas of interest based on the gaze dwell time and collaborative recognition schemes across devices. Furthermore, proposed the task management model for distributed attentive user interface, and utilized this model to control task allocating, pausing, continuing and evaluating. Besides, applied production rules to change user interfaces, and then defined related design guidelines. Finally, built a cross-device English reading prototype system, including the functions such as notification of the last reading positions and adaptive annotations of word explanation. The user study results showed that the participants' visual attention detection accuracy was 94%, and the participants' reading comprehension, reading efficiency and subjective satisfaction were also improved. © 2017, Beijing China Science Journal Publishing Co. Ltd. All right reserved.",Attentive user interface; Cross-device interaction; Distributed user interface; Fixation,Behavioral research; Efficiency; Eye movements; Nitrogen fixation; Attentive user interfaces; Cognitive workloads; Cross-device interactions; Distributed user interfaces; Geometry character; Input efficiencies; Reading comprehension; Reading efficiencies; User interfaces,Article,Final,,Scopus,2-s2.0-85032280682,Movies / Media
Favre-Felix A.; Graversen C.; Dau T.; Lunner T.,"Favre-Felix, A. (57196191146); Graversen, C. (14024251600); Dau, T. (56368948300); Lunner, T. (6602520682)",57196191146; 14024251600; 56368948300; 6602520682,Real-time estimation of eye gaze by in-ear electrodes,2017,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",,,8037754,4086,4089,3.0,17,10.1109/EMBC.2017.8037754,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032188217&doi=10.1109%2fEMBC.2017.8037754&partnerID=40&md5=d7f90c40a76f8d94de12034405fd9b6f,"Cognitive control of a hearing aid is the topic for several ongoing studies. The relevance of these studies should be seen in the light of inadequate steering of current hearing aids. While most studies are concerned with auditory attention tracking from the electroencephalogram (EEG), a complimentary approach may be to use visual attention tracking to steer the devices. Visual attention may be characterized by gaze direction, which can be obtained by electrooculography (EOG). EOG may be recorded from electrodes placed in the ear canal, termed EarEOG. To test the comparison of conventional EOG and EarEOG recordings, we conducted two experiments with six subjects. In the first experiment, the subjects were instructed to follow a moving dot on the screen moving in large saccades. In the second experiment, there were five large targets, and within each target, the dot had minor movements. When comparing conventional EOG and EarEOG, correlations of 0.9 and 0.91 with standard deviations of 0.02 were obtained for the two experiments respectively. To assess the feasibility of using EarEOG in real-time, correlation between EarEOG and the timecourse of the dot position was performed. When both signals were filtered with the same real-time applicable filter, correlations of 0.83 and 0.85 with standard deviations of 0.09 and 0.05 were found respectively to the two experiments. In conclusion, this study provides motivational aspects of using EarEOG to estimate eye gaze, as well as it identifies important future challenges in real-time applications to steer external devices such as a hearing aid. © 2017 IEEE.",,"Electrodes; Electroencephalography; Electrooculography; Fixation, Ocular; Saccades; electrode; electroencephalography; electrooculography; eye fixation; saccadic eye movement",Conference paper,Final,,Scopus,2-s2.0-85032188217,Movies / Media
Chan L.; Minamizawa K.,"Chan, Liwei (8849949400); Minamizawa, Kouta (24587799600)",8849949400; 24587799600,FrontFace: Facilitating communication between HMD users and outsiders using front-facing-screen HMDs,2017,"Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2017",,,22,,,,59,10.1145/3098279.3098548,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030323844&doi=10.1145%2f3098279.3098548&partnerID=40&md5=89b3484dd2ab96ada9abebe3d2d8ad40,"A head-mounted display (HMD) immerses users in a virtual world, but separates them from outsiders in the real world. We present FrontFace, which is a novel HMD that combines an eye-tracker with a front-facing screen, to lower the communication barrier between HMD users and outsiders. The front-facing screen reveals user attention (e.g., the users eye motions) and user presence in the virtual or real world by displaying the scene in the virtual world or a skin background respectively, enabling eye-contact interactions between the HMD user and the outsiders. FrontFace has the following benefits. Firstly, it communicates the presence of the HMD user to outsiders; secondly, it reveals the player's visual attention by introducing the HMD users originally occluded eye motions, enabling outsiders to make sense of the HMD user's reaction in the virtual world or the real world. Three interactive techniques for the outsiders to initiate communication to HMD users are proposed: they are tap-trigger, hand-gesture trigger, and voice-trigger interactions. A small focus group provided feedback. © 2017 Association for Computing Machinery.",Spectator experience; Virtual reality,Behavioral research; Facings; Helmet mounted displays; Virtual reality; Visual communication; Communication barriers; Hand gesture; Head mounted displays; Interactive techniques; Spectator experience; User attention; Virtual worlds; Visual Attention; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85030323844,Movies / Media
O'Hanlon C.G.; Read J.C.A.,"O'Hanlon, Catherine G. (8879558400); Read, Jenny C.A. (15136816000)",8879558400; 15136816000,Blindness to background: an inbuilt bias for visual objects,2017,Developmental Science,20,5,e12478,,,,2,10.1111/desc.12478,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005976158&doi=10.1111%2fdesc.12478&partnerID=40&md5=15f833f0049f307dad70c43b99791d6f,"Sixty-eight 2- to 12-year-olds and 30 adults were shown colorful displays on a touchscreen monitor and trained to point to the location of a named color. Participants located targets near-perfectly when presented with four abutting colored patches. When presented with three colored patches on a colored background, toddlers failed to locate targets in the background. Eye tracking demonstrated that the effect was partially mediated by a tendency not to fixate the background. However, the effect was abolished when the targets were named as nouns, whilst the change to nouns had little impact on eye movement patterns. Our results imply a powerful, inbuilt tendency to attend to objects, which may slow the development of color concepts and acquisition of color words. A video abstract of this article can be viewed at: https://youtu.be/TKO1BPeAiOI. [Correction added on 27 January 2017, after first online publication: The video abstract link was added.]. © 2016 John Wiley & Sons Ltd",,"Age Factors; Analysis of Variance; Attention; Bias; Child; Child, Preschool; Color Perception; Cues; Eye Movements; Female; Form Perception; Humans; Male; Names; Photic Stimulation; Psychomotor Performance; Psychophysics; Reaction Time; Young Adult; age; analysis of variance; association; attention; child; color vision; eye movement; female; human; male; nomenclature; pattern recognition; photostimulation; physiology; preschool child; psychomotor performance; psychophysics; reaction time; statistical bias; young adult",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85005976158,Movies / Media
Breeden K.; Hanrahan P.,"Breeden, Katherine (55503896900); Hanrahan, Pat (7006336787)",55503896900; 7006336787,Gaze data for the analysis of attention in feature films,2017,ACM Transactions on Applied Perception,14,4,23,,,,18,10.1145/3127588,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029901079&doi=10.1145%2f3127588&partnerID=40&md5=b3355c24ff48828cb92a0954eae23ad7,"Film directors are masters at controlling what we look at when we watch a film. However, there have been few quantitative studies of how gaze responds to cinematographic conventions thought to influence attention. We have collected and are releasing a dataset designed to help investigate eye movements in response to higher level features such as faces, dialogue, camera movements, image composition, and edits. The dataset, which will be released to the community, includes gaze information for 21 viewers watching 15 clips from live action 2D films, which have been hand annotated for high level features. This work has implications for the media studies, display technology, immersive reality, and human cognition. © 2017 ACM.",Eye tracking; Film studies; Gaze behavior; Gaze direction; Psychophysics,Motion pictures; Eye-tracking; Film study; Gaze behavior; Gaze direction; Psychophysics; Eye movements,Article,Final,,Scopus,2-s2.0-85029901079,Movies / Media
van der Gijp A.; Ravesloot C.J.; Jarodzka H.; van der Schaaf M.F.; van der Schaaf I.C.; van Schaik J.P.J.; ten Cate T.J.,"van der Gijp, A. (56003868500); Ravesloot, C.J. (55521289400); Jarodzka, H. (26321686500); van der Schaaf, M.F. (8617998100); van der Schaaf, I.C. (6603450950); van Schaik, J.P.J. (7003519301); ten Cate, Th. J. (16317722200)",56003868500; 55521289400; 26321686500; 8617998100; 6603450950; 7003519301; 16317722200,How visual search relates to visual diagnostic performance: a narrative systematic review of eye-tracking research in radiology,2017,Advances in Health Sciences Education,22,3,,765,787,22.0,157,10.1007/s10459-016-9698-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978771290&doi=10.1007%2fs10459-016-9698-1&partnerID=40&md5=e03511671bdaa95544006f10f7dd39ef,"Eye tracking research has been conducted for decades to gain understanding of visual diagnosis such as in radiology. For educational purposes, it is important to identify visual search patterns that are related to high perceptual performance and to identify effective teaching strategies. This review of eye-tracking literature in the radiology domain aims to identify visual search patterns associated with high perceptual performance. Databases PubMed, EMBASE, ERIC, PsycINFO, Scopus and Web of Science were searched using ‘visual perception’ OR ‘eye tracking’ AND ‘radiology’ and synonyms. Two authors independently screened search results and included eye tracking studies concerning visual skills in radiology published between January 1, 1994 and July 31, 2015. Two authors independently assessed study quality with the Medical Education Research Study Quality Instrument, and extracted study data with respect to design, participant and task characteristics, and variables. A thematic analysis was conducted to extract and arrange study results, and a textual narrative synthesis was applied for data integration and interpretation. The search resulted in 22 relevant full-text articles. Thematic analysis resulted in six themes that informed the relation between visual search and level of expertise: (1) time on task, (2) eye movement characteristics of experts, (3) differences in visual attention, (4) visual search patterns, (5) search patterns in cross sectional stack imaging, and (6) teaching visual search strategies. Expert search was found to be characterized by a global-focal search pattern, which represents an initial global impression, followed by a detailed, focal search-to-find mode. Specific task-related search patterns, like drilling through CT scans and systematic search in chest X-rays, were found to be related to high expert levels. One study investigated teaching of visual search strategies, and did not find a significant effect on perceptual performance. Eye tracking literature in radiology indicates several search patterns are related to high levels of expertise, but teaching novices to search as an expert may not be effective. Experimental research is needed to find out which search strategies can improve image perception in learners. © 2016, The Author(s).",Eye tracking; Image interpretation; Medical education; Radiology; Search patterns; Visual diagnosis,"Attention; Clinical Competence; Education, Medical; Eye Movements; Humans; Radiology; Visual Perception; attention; clinical competence; education; eye movement; human; medical education; physiology; radiology; vision",Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84978771290,Movies / Media
Burris J.L.; Barry-Anwar R.A.; Rivera S.M.,"Burris, Jessica L. (57547657400); Barry-Anwar, Ryan A. (57192176264); Rivera, Susan M. (7005714540)",57547657400; 57192176264; 7005714540,An eye tracking investigation of attentional biases towards affect in young children,2017,Developmental Psychology,53,8,,1418,1427,9.0,38,10.1037/dev0000345,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021730756&doi=10.1037%2fdev0000345&partnerID=40&md5=e396acfa36d1cb62b83eb1759fc08ced,"This study examines attentional biases in the presence of angry, happy and neutral faces using a modified eye tracking version of the dot probe task (DPT). Participants were 111 young children between 9 and 48 months. Children passively viewed an affective attention bias task that consisted of a face pairing (neutral paired with either neutral, angry or happy) for 500 ms that was followed by a 1,500-ms asterisk probe on 1 side of the screen. Congruent trials were trials in which the probe appeared on the same side of the screen as the emotional face and incongruent trials were trials in which the probe appeared on the opposite side of the emotional face. The latency to fixate on the probe, rather than the traditional task's button press latency, was measured for both types of trials and a bias score was calculated by subtracting the latency to the probe on congruent trials from that on incongruent trials. The results of the current study indicate positive internal reliability of this modified version of the DPT as well as the presence of a bias toward both angry and happy faces during the first 4 years of life. The successful use of the modified version of the DPT for use on the eye tracker presents a promising methodological tool for research on early attentional behavior and provides a tool for comprehensive longitudinal studies of identified risk factors for anxiety. © 2017 American Psychological Association.",Attention bias; Early childhood; Emotion,"Age Factors; Attentional Bias; Child Development; Child, Preschool; Emotions; Eye Movements; Face; Female; Humans; Infant; Male; Photic Stimulation; Reaction Time; Reproducibility of Results; Time Factors; age; attentional bias; child development; emotion; eye movement; face; female; human; infant; male; photostimulation; physiology; preschool child; reaction time; reproducibility; time factor",Article,Final,,Scopus,2-s2.0-85021730756,Movies / Media
Crouzet S.M.; Kovalenko L.Y.; del Pin S.H.; Overgaard M.; Busch N.A.,"Crouzet, Sébastien M. (56915599800); Kovalenko, Lyudmyla Y. (54880761800); del Pin, Simon Hviid (56384491300); Overgaard, Morten (55908063100); Busch, Niko A. (7006235162)",56915599800; 54880761800; 56384491300; 55908063100; 7006235162,"Early visual processing allows for selective behavior, shifts of attention, and conscious visual experience in spite of masking",2017,Consciousness and Cognition,54,,,89,100,11.0,9,10.1016/j.concog.2017.01.021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013409016&doi=10.1016%2fj.concog.2017.01.021&partnerID=40&md5=e4017b1b37bcc10add60ed7a8970fc4e,"Object-substitution masking (OSM) occurs when a briefly displayed target in a search array is surrounded by a mask, which remains onscreen after the target has disappeared. It has been suggested that OSM results from a specific interference with reentrant visual processing, while the initial feedforward processing is left intact. Here, we tested the prediction that the fastest saccadic responses towards a masked target, supposedly triggered before the onset of reentrant processing, are not impaired by OSM. Indeed, saccades faster than 350 ms “escaped” the influence of the mask. Notably, participants’ judgements of subjective awareness indicated that stimulus processing during this early stage is not entirely devoid of conscious awareness. Furthermore, the N2pc event-related potential component indicated shifts of spatial attention towards the masked targets on trials with correct fast saccades, suggesting that both target detection and spatial attention can be based on the computations accomplished during the initial feedforward sweep. © 2017 Elsevier Inc.",,"Adult; Attention; Awareness; Consciousness; Electroencephalography; Electrooculography; Evoked Potentials; Female; Humans; Male; Pattern Recognition, Visual; Perceptual Masking; Psychomotor Performance; Reaction Time; Saccades; Space Perception; Young Adult; awareness; decision making; event related potential; human; masking; prediction; saccadic eye movement; stimulus; vision; adult; attention; awareness; consciousness; depth perception; electroencephalography; electrooculography; evoked response; female; male; masking; pattern recognition; physiology; psychomotor performance; reaction time; young adult",Article,Final,,Scopus,2-s2.0-85013409016,Movies / Media
Naughtin C.K.; Horne K.; Schneider D.; Venini D.; York A.; Dux P.E.,"Naughtin, Claire K. (39861952900); Horne, Kristina (57194632071); Schneider, Dana (36994181700); Venini, Dustin (56016982600); York, Ashley (57194634307); Dux, Paul E. (7004246809)",39861952900; 57194632071; 36994181700; 56016982600; 57194634307; 7004246809,Do implicit and explicit belief processing share neural substrates?,2017,Human Brain Mapping,38,9,,4760,4772,12.0,35,10.1002/hbm.23700,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021313418&doi=10.1002%2fhbm.23700&partnerID=40&md5=2c51eabd20ae7da334b08710bd51f441,"Humans rely on their ability to infer another person's mental state to understand and predict others' behavior (“theory of mind,” ToM). Multiple lines of research suggest that not only are humans able to consciously process another person's belief state, but also are able to do so implicitly. Here we explored how general implicit belief states are represented in the brain, compared to those substrates involved in explicit ToM processes. Previous work on this topic has yielded conflicting results, and thus, the extent to which the implicit and explicit ToM systems draw on common neural bases is unclear. Participants were presented with “Sally-Anne” type movies in which a protagonist was falsely led to believe a ball was in one location, only for a puppet to later move it to another location in their absence (false-belief condition). In other movies, the protagonist had their back turned the entire time the puppet moved the ball between the two locations, meaning that they had no opportunity to develop any pre-existing beliefs about the scenario (no-belief condition). Using a group of independently localized explicit ToM brain regions, we found greater activity for false-belief trials, relative to no-belief trials, in the right temporoparietal junction, right superior temporal sulcus, precuneus, and left middle prefrontal gyrus. These findings extend upon previous work on the neural bases of implicit ToM by showing substantial overlap between this system and the explicit ToM system, suggesting that both abilities might recruit a common set of mentalizing processes/functional brain regions. Hum Brain Mapp 38:4760–4772, 2017. © 2017 Wiley Periodicals, Inc. © 2017 Wiley Periodicals, Inc.",fMRI; implicit theory of mind; mentalizing; social cognition; temporoparietal junction,"Awareness; Brain; Brain Mapping; Eye Movement Measurements; Female; Fixation, Ocular; Humans; Magnetic Resonance Imaging; Male; Motion Perception; Motion Pictures; Neural Pathways; Neuropsychological Tests; Social Perception; Theory of Mind; Thinking; Young Adult; adult; Article; BOLD signal; brain function; brain region; controlled study; explicit memory; eye movement; follow up; health belief; human; implicit memory; low frequency noise; male; mental health; precuneus; priority journal; questionnaire; superior temporal sulcus; temporoparietal junction; theory of mind; young adult; awareness; brain; brain mapping; comparative study; diagnostic imaging; eye fixation; female; movement perception; movie; nerve tract; neuropsychological test; nuclear magnetic resonance imaging; oculography; perception; physiology; thinking",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85021313418,Movies / Media
Król M.; Kilan-Banach M.; Strzelecka R.,"Król, Magdalena (57208580432); Kilan-Banach, Magdalena (57193778244); Strzelecka, Renata (57193776314)",57208580432; 57193778244; 57193776314,The role of stimulus predictability in the allocation of attentional resources: an eye-tracking study,2017,Cognitive Processing,18,3,,335,342,7.0,1,10.1007/s10339-017-0806-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016505036&doi=10.1007%2fs10339-017-0806-9&partnerID=40&md5=2b7aa68bbae3fabd84c813a929c1b685,"By allocating less attention to predictable events we are able to focus on novel, unpredictable and unexpected events that require more extensive processing. This strategy should result in improved performance by optimizing the use of brain’s limited resources. Participants’ task was to look at two types of stimuli presented simultaneously at the opposite sides of a computer screen: “static” stimuli, i.e. emotionally neutral photographs; and “dynamic” stimuli, i.e. video clips presenting a moving dot. The dot moved along a predictable, semi-predictable or random trajectory. This was followed by a memory test of the static stimuli. Participants spent more time looking at the dynamic stimuli when its trajectory was less predictable. Additionally, participants who readily adjusted their dwell time allocation to the dot trajectory performed better in the memory test, as demonstrated by a positive correlation between memory test sensitivity and the rate of eye movement patterns adjustment to stimulus predictability. This suggests that people adjust gaze duration to stimulus predictability and that doing so optimizes attentional resource allocation and improves performance. However, study design did not allow to distinguish between spatial and temporal predictability, so it is impossible to estimate the impact of each type of predictability specifically. © 2017, Marta Olivetti Belardinelli and Springer-Verlag Berlin Heidelberg.",Eye tracking; Prediction; Top down; Visual attention,Adult; Attention; Emotions; Eye Movement Measurements; Eye Movements; Female; Humans; Male; Memory; Middle Aged; Motion Perception; Visual Perception; Young Adult; adult; Article; attention; brain function; computer; controlled study; dynamic stimulation; eye movement; eye tracking; female; gaze; human; male; memory test; mental performance; prediction; priority journal; process optimization; sensitivity analysis; static stimulation; stimulation; attention; emotion; memory; middle aged; movement perception; oculography; physiology; vision; young adult,Article,Final,,Scopus,2-s2.0-85016505036,Movies / Media
Kashkouli M.B.; Abdolalizadeh P.; Abolfathzadeh N.; Sianati H.; Sharepour M.; Hadi Y.,"Kashkouli, Mohsen Bahmani (55664450600); Abdolalizadeh, Parya (57191198629); Abolfathzadeh, Navid (57194151106); Sianati, Hamed (37066556400); Sharepour, Maria (36970253400); Hadi, Yasaman (57194146206)",55664450600; 57191198629; 57194151106; 37066556400; 36970253400; 57194146206,Periorbital facial rejuvenation; applied anatomy and pre-operative assessment,2017,Journal of Current Ophthalmology,29,3,,154,168,14.0,51,10.1016/j.joco.2017.04.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018936240&doi=10.1016%2fj.joco.2017.04.001&partnerID=40&md5=f8ef1be8b6f13e21ac1a6145211a74c6,"Purpose Since different subspecialties are currently performing a variety of upper facial rejuvenation procedures, and the level of knowledge on the ocular and periocular anatomy and physiology is different, this review aims to highlight the most important preoperative examinations and tests with special attention to the eye and periocular adnexal structures for general ophthalmologist and specialties other than oculo-facial surgeons in order to inform them about the fine and important points that should be considered before surgery to have both cosmetic and functional improvement. Methods English literature review was performed using PubMed with the different keywords of “periorbital rejuvenation”, “blepharoptosis”, “eyebrow ptosis”, “blepharoplasty”, “eyelid examination”, “facial assessment”, and “lifting”. Initial screening was performed by the senior author to include the most pertinent articles. The full text of the selected articles was reviewed, and some articles were added based upon the references of the initial articles. Included articles were then reviewed with special attention to the preoperative assessment of the periorbital facial rejuvenation procedures. Results There were 254 articles in the initial screening from which 84 articles were found to be mostly related to the topic of this review. The number finally increased to 112 articles after adding the pertinent references of the initial articles. Conclusion Static and dynamic aging changes of the periorbital area should be assessed as an eyelid-eyebrow unit paying more attention to the anthropometric landmarks. Assessing the facial asymmetry, performing comprehensive and detailed ocular examination, and asking about patients' expectation are three key elements in this regard. Furthermore, taking standard facial pictures, obtaining special consent form, and finally getting feedback are also indispensable tools toward a better outcome. © 2017 Iranian Society of Ophthalmology",Blepharoplasty; Cheek; Eyebrow; Eyelid; Lifting; Rejuvenation,bone; capsulopalpebral fascia; corrugator muscle; deep temporal fascia; depressors supercilii muscle; dry eye; expectation; eye movement; eyebrow; eyebrow rejuvenation; eyelid; eyelid rejuvenation; face asymmetry; facial nerve; fascia; fat pad; frontal bone; frontalis muscle; galea fat pad; hair; human; lacrimal gland disease; lacrimal gland prolapse; lateral hooding; ligament; Lockwood suspensory ligament; medial canthal tendon; medical history; muscle contraction; orbicularis oculi muscle; osteocutaneous ligament; photography; preaponeurotic fat pad; preoperative evaluation; preseptal fat pad; procerus muscle; psychologic assessment; ptosis; rejuvenation; Review; skeletal muscle; skin; supraorbital rim; surgical anatomy; systematic review; tattoo; tendon; vision; Whitnall ligament,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85018936240,Movies / Media
Zantinge G.; van Rijn S.; Stockmann L.; Swaab H.,"Zantinge, Gemma (57193904575); van Rijn, Sophie (8296112100); Stockmann, Lex (6508276418); Swaab, Hanna (8296112400)",57193904575; 8296112100; 6508276418; 8296112400,Psychophysiological responses to emotions of others in young children with autism spectrum disorders: Correlates of social functioning,2017,Autism Research,10,9,,1499,1509,10.0,27,10.1002/aur.1794,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017460078&doi=10.1002%2faur.1794&partnerID=40&md5=24c4414a548a32258226de96c40281a5,"Studying cognitive and affective mechanisms of social behavior could lead to identifying early indicators of derailing social behavior in young children with Autism Spectrum Disorders (ASD). The present study combined sensitive and objective techniques, such as eyetracking and psychophysiology, to provide insight into early neurodevelopmental mechanisms that are more difficult to uncover when relying on behavioral measures. Social attention towards faces and changes in affective arousal were investigated together in 28 young children with ASD (42–75 months) and 45 nonclinical controls (41–81 months). Children were shown a social-emotional video clip while eyetracking and heart rate were measured. Children with ASD fixated less on key social-emotional features within the clip as compared to controls, even though both groups attended equally toward the screen. In contrast to the control group, children with ASD did not show an increase or modulation in affective arousal in response to the social-emotional scenes. Severity of ASD symptoms, specifically social problems, was associated with arousal modulation and social attention within the ASD group. Early ASD symptoms are associated with impairments in fundamental building blocks of social behavior as expressed in a lack in spontaneous social attention and affective arousal. Such sensitive and objective measures of underlying mechanisms might serve as indicators for tailored approaches in treatment and may help in evaluating effectiveness of early interventions aimed at positively influencing social development and related quality of life in individuals with ASD. Autism Res 2017, 10: 1499–1509. © 2017 International Society for Autism Research, Wiley Periodicals, Inc. © 2017 International Society for Autism Research, Wiley Periodicals, Inc.",autism spectrum disorder; eye tracking; psychophysiology; social attention; social behavior; young children,"Autism Spectrum Disorder; Child; Child, Preschool; Emotions; Face; Female; Heart Rate; Humans; Male; Social Behavior; arousal; Article; attention; autism; child; child health; clinical article; clinical feature; controlled study; disease severity; emotion; female; human; male; nervous system development; priority journal; psychophysiology; quality of life; social evolution; social problem; social psychology; autism; emotion; face; heart rate; pathophysiology; physiology; preschool child; psychology; social behavior",Article,Final,,Scopus,2-s2.0-85017460078,Movies / Media
Ferguson H.J.; Apperly I.; Cane J.E.,"Ferguson, Heather J. (23666805400); Apperly, Ian (6602736995); Cane, James E. (55192250000)",23666805400; 6602736995; 55192250000,Eye tracking reveals the cost of switching between self and other perspectives in a visual perspective-taking task,2017,Quarterly Journal of Experimental Psychology,70,8,,1646,1660,14.0,48,10.1080/17470218.2016.1199716,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976528396&doi=10.1080%2f17470218.2016.1199716&partnerID=40&md5=bef95d94d124713528a598886618754e,"Previous studies have shown that while people can rapidly and accurately compute their own and other people’s visual perspectives, they experience difficulty ignoring the irrelevant perspective when the two perspectives differ. We used the “avatar” perspective-taking task to examine the mechanisms that underlie these egocentric (i.e., interference from their own perspective) and altercentric (i.e., interference from the other person’s perspective) tendencies. Participants were eye-tracked as they verified the number of discs in a visual scene according to either their own or an on-screen avatar’s perspective. Crucially in some trials the two perspectives were inconsistent (i.e., each saw a different number of discs), while in others they were consistent. To examine the effect of perspective switching, performance was compared for trials that were preceded with the same versus a different perspective cue. We found that altercentric interference can be reduced or eliminated when participants stick with their own perspective across consecutive trials. Our eye-tracking analyses revealed distinct fixation patterns for self and other perspective taking, suggesting that consistency effects in this paradigm are driven by implicit mentalizing of what others can see, and not automatic directional cues from the avatar. © 2016 The Experimental Psychology Society.",Eye tracking; Perspective switching; Self/other; Theory of mind; Visual perspective taking,Adolescent; Analysis of Variance; Attention; Eye Movements; Female; Humans; Judgment; Male; Online Systems; Photic Stimulation; Reaction Time; Self Concept; Visual Perception; Young Adult; adolescent; analysis of variance; attention; decision making; eye movement; female; human; male; online system; photostimulation; physiology; reaction time; self concept; vision; young adult,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84976528396,Movies / Media
Demšar U.; Çöltekin A.,"Demšar, Urška (57203701221); Çöltekin, Arzu (8598265600)",57203701221; 8598265600,Quantifying gaze and mouse interactions on spatial visual interfaces with a new movement analytics methodology,2017,PLoS ONE,12,8,e0181818,,,,17,10.1371/journal.pone.0181818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026812809&doi=10.1371%2fjournal.pone.0181818&partnerID=40&md5=c4300ded3e6e703f031eb4264f8f6ce2,"Eye movements provide insights into what people pay attention to, and therefore are commonly included in a variety of human-computer interaction studies. Eye movement recording devices (eye trackers) produce gaze trajectories, that is, sequences of gaze location on the screen. Despite recent technological developments that enabled more affordable hardware, gaze data are still costly and time consuming to collect, therefore some propose using mouse movements instead. These are easy to collect automatically and on a large scale. If and how these two movement types are linked, however, is less clear and highly debated. We address this problem in two ways. First, we introduce a new movement analytics methodology to quantify the level of dynamic interaction between the gaze and the mouse pointer on the screen. Our method uses volumetric representation of movement, the space-time densities, which allows us to calculate interaction levels between two physically different types of movement. We describe the method and compare the results with existing dynamic interaction methods from movement ecology. The sensitivity to method parameters is evaluated on simulated trajectories where we can control interaction levels. Second, we perform an experiment with eye and mouse tracking to generate real data with real levels of interaction, to apply and test our new methodology on a real case. Further, as our experiment tasks mimics route-tracing when using a map, it is more than a data collection exercise and it simultaneously allows us to investigate the actual connection between the eye and the mouse. We find that there seem to be natural coupling when eyes are not under conscious control, but that this coupling breaks down when instructed to move them intentionally. Based on these observations, we tentatively suggest that for natural tracing tasks, mouse tracking could potentially provide similar information as eye-tracking and therefore be used as a proxy for attention. However, more research is needed to confirm this. © 2017 Demšar, Çöltekin. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Adult; Attention; Diagnosis, Computer-Assisted; Eye Movement Measurements; Eye Movements; Female; Fixation, Ocular; Humans; Male; Middle Aged; Spatial Processing; User-Computer Interface; Visual Perception; attention; ecology; exercise; eye tracking; gaze; information processing; quantitative study; simulation; adult; computer assisted diagnosis; computer interface; devices; eye fixation; eye movement; female; human; male; middle aged; oculography; physiology; procedures; spatial behavior; vision",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85026812809,Movies / Media
Horst F.; Den Oudsten B.; Zijlstra W.; de Jongh A.; Lobbestael J.; De Vries J.,"Horst, Ferdinand (57189593973); Den Oudsten, Brenda (19638376300); Zijlstra, Wobbe (22982534900); de Jongh, Ad (7007023691); Lobbestael, Jill (23393450600); De Vries, Jolanda (35462571500)",57189593973; 19638376300; 22982534900; 7007023691; 23393450600; 35462571500,Cognitive behavioral therapy vs. eye movement desensitization and reprocessing for treating panic disorder: A randomized controlled trial,2017,Frontiers in Psychology,8,AUG,1409,,,,31,10.3389/fpsyg.2017.01409,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027572327&doi=10.3389%2ffpsyg.2017.01409&partnerID=40&md5=5bfc758d4d644ccb66e53a4f6a73d69a,"Objective: Cognitive Behavioral Therapy (CBT) is an effective intervention for patients with panic disorder (PD). From a theoretical perspective, Eye Movement Desensitization and Reprocessing (EMDR) therapy could also be useful in the treatment of PD because: (1) panic attacks can be experienced as life threatening; (2) panic memories specific to PD resemble traumatic memories as seen in posttraumatic stress disorder (PTSD); and (3) PD often develops following a distressing life event. The primary objective of this Randomized Controlled Trial (RCT), was to compare EMDR therapy with CBT for PD and determine whether EMDR is not worse than CBT in reducing panic symptoms and improving Quality Of Life (QOL). Methods: Two-arm (CBT and EMDR) parallel RCT in patients with PD (N = 84). Patients were measured at baseline (T1), directly after the last therapy session (T2), and 3 months after ending therapy (T3). Non-inferiority testing (linear mixed model with intention-to-treat analysis) was applied. Patients were randomly assigned to 13 weekly 60-min sessions of CBT (N = 42) or EMDR therapy (N = 42). Standard protocols were used. The primary outcome measure was severity of PD at T3, as measured with the Agoraphobic Cognitions Questionnaire (ACQ), the Body Sensations Questionnaire (BSQ), and the Mobility Inventory (MI). The secondary outcome measure was QOL, as measured with the World Health Organization Quality of Life short version (WHOQOL-Bref), at T3. Results: The severity of PD variables ACQ and BSQ showed non-inferiority of EMDR to CBT, while MI was inconclusive (adjusted analyses). Overall QOL and general health, Psychological health, Social relationships, and Environment showed non-inferiority of EMDR to CBT, while Physical health was inconclusive. Conclusion: EMDR therapy proved to be as effective as CBT for treating PD patients. Trial Registration: Dutch Trial Register, Nr. 3134 http://www.trialregister.nl/trialreg/ admin/rctview.asp?TC=3134 © 2017 Horst, Den Oudsten, Zijlstra, de Jongh, Lobbestael and De Vries.",CBT; EMDR; Panic disorder; Psychotherapy; RCT,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85027572327,Movies / Media
Ding J.; Jiang S.-M.; Yuan Y.-S.; Tong Q.; Zhang L.; Xu Q.-R.; Zhang K.-Z.,"Ding, Jian (56658936100); Jiang, Si-Ming (56658909600); Yuan, Yong-Sheng (55676507900); Tong, Qing (55676641300); Zhang, Li (56282181400); Xu, Qin-Rong (56281568500); Zhang, Ke-Zhong (55475003000)",56658936100; 56658909600; 55676507900; 55676641300; 56282181400; 56281568500; 55475003000,The Relationship Between Fatigue and Other Non-Motor Symptoms in Parkinson's Disease in Chinese Population,2017,International Journal of Gerontology,11,3,,171,175,4.0,2,10.1016/j.ijge.2016.05.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028325797&doi=10.1016%2fj.ijge.2016.05.011&partnerID=40&md5=53ebe6a62f071f900ba8b0a7e0f1d37c,"Background The aim of our study was to explore in detail the relationship between fatigue and other non-motor symptoms in Parkinson's disease (PD). Methods One hundred and four PD patients took part in our study. The Fatigue Severity Scale (FSS) was used to measure the severity of fatigue and a cut-off of 4 was used to define the presence of fatigue. Patients who scored more than 4 were divided into the “fatigue group” while the other patients were allocated to the “no fatigue group”. The Non-motor Symptoms Scale (NMSS) was used to screen other non-motor symptoms. The Parkinson's disease Sleep Scale (PDSS), Rapid Eye Movement Sleep Behavior Disorders Scale (RBD) and Epworth Sleepiness Scale (ESS) were used to measure different kinds of sleep disorders, and the affective sphere were measured with the Hamilton Anxiety Scale (HAMA) and the Hamilton Depression Scale (HAMD). Result Patients with fatigue in PD had higher levels in domain 2 (sleep disorders) (p < 0.001) and domain 3 (mood/anxiety) (p < 0.05) of the NMSS. The severity of fatigue was positively associated with excessive daytime sleepiness (rs = 0.254, p = 0.009), anxiety (rs = 0.268, p = 0.006) and depression (rs = 0.264, p = 0.007). Conclusion Forty patients (42.4%) showed notable complaints of fatigue with FSS scores > 4. Among the patients with fatigue, the severity of fatigue in PD patients was related to sleep and affective disorders. Of the disorders, excessive daytime sleepiness, anxiety and depression were particularly linked to fatigue in PD. © 2017",fatigue; non-motor symptoms; Parkinson's disease,adult; anxiety; Article; Chinese; controlled study; daytime somnolence; depression; disease severity; diseases; Epworth sleepiness scale; fatigue; Fatigue Severity Scale; female; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; human; major clinical study; male; middle aged; mood disorder; neurologic disease assessment; non motor symptom; Non motor Symptoms Scale; Parkinson disease; Parkinson Disease Sleep Scale; priority journal; Rapid Eye Movement Sleep Behavior Disorders Scale; rating scale; sleep disorder; symptom,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85028325797,Movies / Media
Keller J.; Krimly A.; Bauer L.; Schulenburg S.; Böhm S.; Aho-Özhan H.E.A.; Uttner I.; Gorges M.; Kassubek J.; Pinkhardt E.H.; Abrahams S.; Ludolph A.C.; Lulé D.,"Keller, Jürgen (56666591900); Krimly, Amon (57193954214); Bauer, Lisa (58432496800); Schulenburg, Sarah (57193958092); Böhm, Sarah (7103212836); Aho-Özhan, Helena E. A. (56667756500); Uttner, Ingo (6602803090); Gorges, Martin (55807948200); Kassubek, Jan (7003511907); Pinkhardt, Elmar H. (15835468200); Abrahams, Sharon (57206430024); Ludolph, Albert C. (26643359400); Lulé, Dorothée (10141622200)",56666591900; 57193954214; 58432496800; 57193958092; 7103212836; 56667756500; 6602803090; 55807948200; 7003511907; 15835468200; 57206430024; 26643359400; 10141622200,A first approach to a neuropsychological screening tool using eye-tracking for bedside cognitive testing based on the Edinburgh Cognitive and Behavioural ALS Screen,2017,Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration,18,6-May,,443,450,7.0,17,10.1080/21678421.2017.1313869,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017640264&doi=10.1080%2f21678421.2017.1313869&partnerID=40&md5=e72f6e1a27fb232b73cdc4a0df24d2bd,"Objective: Reliable assessment of cognitive functions is a challenging task in amyotrophic lateral sclerosis (ALS) patients unable to speak and write. We therefore present an eye-tracking based neuropsychological screening tool based on the Edinburgh Cognitive and Behavioural ALS Screen (ECAS), a standard screening tool for cognitive deficits in ALS. Methods: In total, 46 ALS patients and 50 healthy controls matched for age, gender and education were tested with an oculomotor based and a standard paper-and-pencil version of the ECAS. Results: Significant correlation between both versions was observed for ALS patients and healthy controls in the ECAS total score and in all of its ALS-specific domains (all r > 0.3; all p < 0.05). The eye-tracking version of the ECAS reliably distinguished between ALS patients and healthy controls in the ECAS total score (p < 0.05). Also, cognitively impaired and non-impaired patients could be reliably distinguished with a specificity of 95%. Conclusion: This study provides first evidence that the eye-tracking based ECAS version is a promising approach for assessing cognitive deficits in ALS patients who are unable to speak or write. © 2017 World Federation of Neurology on behalf of the Research Group on Motor Neuron Diseases.",amyotrophic lateral sclerosis; cognition; Edinburgh Cognitive and Behavioural ALS Screen; Eye-tracking; motor neuron disease,Adult; Aged; Amyotrophic Lateral Sclerosis; Cognition; Cognition Disorders; Eye Movements; Female; Humans; Male; Mental Disorders; Middle Aged; Neuropsychological Tests; Photic Stimulation; Point-of-Care Testing; Random Allocation; adult; amyotrophic Edinburgh Cognitive and Behavioural ALS Screen; amyotrophic lateral sclerosis; Article; clinical article; clinical assessment tool; controlled study; education; eye tracking; female; human; male; middle aged; neuropsychological test; priority journal; aged; amyotrophic lateral sclerosis; cognition; cognitive defect; eye movement; mental disease; neuropsychological test; photostimulation; physiology; point of care testing; procedures; psychology; randomization,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85017640264,Movies / Media
Schmidt L.J.; Belopolsky A.V.; Theeuwes J.,"Schmidt, Lisette J. (55180822800); Belopolsky, Artem V. (6602139967); Theeuwes, Jan (7006932399)",55180822800; 6602139967; 7006932399,The time course of attentional bias to cues of threat and safety,2017,Cognition and Emotion,31,5,,845,857,12.0,32,10.1080/02699931.2016.1169998,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962407688&doi=10.1080%2f02699931.2016.1169998&partnerID=40&md5=2a361fbc0bda4dea3385506d3f4d45dd,"It is well known that relative to neutral stimuli, attention is biased towards processing stimuli that convey threat. In a previous study in which a particular stimulus (e.g. a blue diamond) was associated with the delivery of an electrical shock, the presence of the fear-conditioned stimulus interfered with the execution of voluntary eye movements to other locations. Here, we show that this effect not only occurs early in time, but remains present long after the fear-conditioned stimulus was removed from the screen. In a subsequent experiment, we associated the presence of a particular stimulus with safety, that is, when this stimulus was present it was certain that no electrical shock would be delivered. The presence of the safety signalling stimulus also interfered with the execution of voluntary saccades, but only when the time between stimulus and cue presentation was relatively long. The results indicate that both signals of threat and signals of safety interfere with execution of a saccade long after the source of threat or safety has been removed. However, only threatening stimuli affect saccade execution early in time, suggesting that threatening stimuli drive selection exogenously. © 2016 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",Emotion; eye movements; fear conditioning,"Adult; Attentional Bias; Conditioning, Classical; Cues; Electric Stimulation; Fear; Female; Humans; Male; Photic Stimulation; Saccades; Time Factors; Young Adult; adult; Article; association; attentional bias; clinical article; comparative study; electric shock; electrostimulation; experimental study; eye tracking; fear conditioning test; female; human; latent period; male; priority journal; response time; saccadic eye movement; safety; threat; validity; young adult; association; attentional bias; conditioned reflex; fear; photostimulation; physiology; time factor",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84962407688,Movies / Media
Bröhl C.; Theis S.; Rasche P.; Wille M.; Mertens A.; Schlick C.M.,"Bröhl, Christina (55802629900); Theis, Sabine (55787666300); Rasche, Peter (56919666400); Wille, Matthias (55787695600); Mertens, Alexander (35746549300); Schlick, Christopher M. (59872957900)",55802629900; 55787666300; 56919666400; 55787695600; 35746549300; 59872957900,Neuroergonomic analysis of perihand space: effects of hand proximity on eye-tracking measures and performance in a visual search task,2017,Behaviour and Information Technology,36,7,,737,744,7.0,9,10.1080/0144929X.2016.1278561,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009291711&doi=10.1080%2f0144929X.2016.1278561&partnerID=40&md5=b36c3a7d7bf1a3d59c3baccd21b6fc86,"According to recent studies, cognitive processes are modulated by the proximity of the hands to a stimulus. Specifically, hand proximity (also known as nearby-hand or hand-presence effects) induces a bias to process information near the hands more precisely and this effect can be facilitative or debilitative depending on the task context. Two different distances of the hands in reference to the screen were studied as independent variables: hands placed on the screen and hands placed on the lap. The dependent variables were search times and different eye-tracking parameters. Given the age-related decline in the perception of peripersonal space, the results were analysed for two different age groups. Overall, we found a more detailed evaluation of information near the hands depending on age. In conclusion, the study presents a cognitive behavioural evaluation of human–computer interaction which can be used for touchscreen interface and interaction design as well as modelling human–system interaction. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",cognition; elderly people; hand-held device; Information presentation; usability,Behavioral research; Hand held computers; cognition; Elderly people; Hand held device; Information presentation; usability; dependent variable; eye tracking; human; model; perception; Human computer interaction,Article,Final,,Scopus,2-s2.0-85009291711,Movies / Media
Xu Y.; Xu S.-T.; Liu X.-T.; Meng F.,"Xu, Ying (59051529600); Xu, Su-Ting (57202215963); Liu, Xing-Tong (57202223648); Meng, Fang (8278618400)",59051529600; 57202215963; 57202223648; 8278618400,Analysis on the validity of eye movement data during video viewing,2017,"Proceedings - 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2017",2018-January,,,1,5,4.0,0,10.1109/CISP-BMEI.2017.8301902,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047474578&doi=10.1109%2fCISP-BMEI.2017.8301902&partnerID=40&md5=b0675dd7b40f8b6dca78c309b0e52d35,"In recent years, eye trackers have become widely applied to the collection and analyses of eye movement data in video viewing. However, some behaviors, for example, inattention during video viewing, will lead to large amounts of invalid eye movement data, which may interfere with the subsequent analyses. The main work of this paper is analyzing and processing invalid eye movement data in video viewing. Firstly, this paper introduced the concept of invalid eye movement data during video viewing process. After that, the paper analyzed the characteristics of eye movement indicators such as the spatial position of fixation points and the number of fixations. By doing that, we drew a conclusion that if users were not concentrated in video viewing, the eye movement data showed following characteristics: a lower degree of concern to significant area, fewer fixation points, longer blink duration and more frequent blinks. Finally, the application of eye movement indicators in the subjective image quality assessment was discussed. Experimental results showed that indicators discussed in the paper laid the groundwork for further identification and removal of invalid eye movement data, and provided a theoretical basis for screening the invalid eye movement data to improve the validity. © 2017 IEEE.",Eye movement experiment; Invalid data; Video viewing; Visual attention,Behavioral research; Eye movement datum; Eye movement experiment; Eye trackers; Fixation point; Invalid data; Large amounts; Spatial positions; Video viewing; Viewing process; Visual Attention; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85047474578,Movies / Media
Hwang Y.M.; Lee K.C.,"Hwang, Yoon Min (35435393400); Lee, Kun Chang (35330125000)",35435393400; 35330125000,Using Eye Tracking to Explore Consumers' Visual Behavior According to Their Shopping Motivation in Mobile Environments,2017,"Cyberpsychology, Behavior, and Social Networking",20,7,,442,447,5.0,18,10.1089/cyber.2016.0235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042126583&doi=10.1089%2fcyber.2016.0235&partnerID=40&md5=26b32ac20ac0ee27459313ee28a10c93,"Despite a strong shift to mobile shopping trends, many in-depth questions about mobile shoppers' visual behaviors in mobile shopping environments remain unaddressed. This study aims to answer two challenging research questions (RQs): (a) how much does shopping motivation like goal orientation and recreation influence mobile shoppers' visual behavior toward displays of shopping information on a mobile shopping screen and (b) how much of mobile shoppers' visual behavior influences their purchase intention for the products displayed on a mobile shopping screen? An eye-tracking approach is adopted to answer the RQs empirically. The experimental results showed that goal-oriented shoppers paid closer attention to products' information areas to meet their shopping goals. Their purchase intention was positively influenced by their visual attention to the two areas of interest such as product information and consumer opinions. In contrast, recreational shoppers tended to visually fixate on the promotion area, which positively influences their purchase intention. The results contribute to understanding mobile shoppers' visual behaviors and shopping intentions from the perspective of mindset theory. © 2017, Mary Ann Liebert, Inc.",eye-tracking; mindset theory; Mobile shopping; shopping motivation; visual behavior,Adult; Attention; Consumer Behavior; Eye Movements; Female; Humans; Male; Mobile Applications; Motivation; article; consumer; eye tracking; human; motivation; recreation; shopping; visual attention; adult; attention; consumer attitude; eye movement; female; male; mobile application; motivation; physiology,Article,Final,,Scopus,2-s2.0-85042126583,Movies / Media
Bahle B.; Mills M.; Dodd M.D.,"Bahle, Brett (57194187535); Mills, Mark (36629060600); Dodd, Michael D. (7103061070)",57194187535; 36629060600; 7103061070,Human classifier: Observers can deduce task solely from eye movements,2017,"Attention, Perception, and Psychophysics",79,5,,1415,1425,10.0,8,10.3758/s13414-017-1324-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019151632&doi=10.3758%2fs13414-017-1324-7&partnerID=40&md5=a244e8fb5d9c840d42daf8f28c5c0a3f,"Computer classifiers have been successful at classifying various tasks using eye movement statistics. However, the question of human classification of task from eye movements has rarely been studied. Across two experiments, we examined whether humans could classify task based solely on the eye movements of other individuals. In Experiment 1, human classifiers were shown one of three sets of eye movements: Fixations, which were displayed as blue circles, with larger circles meaning longer fixation durations; Scanpaths, which were displayed as yellow arrows; and Videos, in which a neon green dot moved around the screen. There was an additional Scene manipulation in which eye movement properties were displayed either on the original scene where the task (Search, Memory, or Rating) was performed or on a black background in which no scene information was available. Experiment 2 used similar methods but only displayed Fixations and Videos with the same Scene manipulation. The results of both experiments showed successful classification of Search. Interestingly, Search was best classified in the absence of the original scene, particularly in the Fixation condition. Memory also was classified above chance with the strongest classification occurring with Videos in the presence of the scene. Additional analyses on the pattern of correct responses in these two conditions demonstrated which eye movement properties successful classifiers were using. These findings demonstrate conditions under which humans can extract information from eye movement characteristics in addition to providing insight into the relative success/failure of previous computer classifiers. © 2017, The Psychonomic Society, Inc.",Categorization; Cognitive; Eye movements; Visual search,"Attention; Eye Movements; Female; Fixation, Ocular; Humans; Male; Memory; Photic Stimulation; Psychomotor Performance; Random Allocation; Young Adult; attention; eye fixation; eye movement; female; human; male; memory; photostimulation; physiology; procedures; psychomotor performance; randomization; young adult",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85019151632,Movies / Media
Binetti N.; Harrison C.; Mareschal I.; Johnston A.,"Binetti, Nicola (56380384400); Harrison, Charlotte (57190305378); Mareschal, Isabelle (6602146747); Johnston, Alan (57217503729)",56380384400; 57190305378; 6602146747; 57217503729,Temporal order judgements of dynamic gaze stimuli reveal a postdictive prioritisation of averted over direct shifts,2017,i-Perception,8,4,,,,14.0,3,10.1177/2041669517720808,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026763018&doi=10.1177%2f2041669517720808&partnerID=40&md5=0ad6d7cde20d0f018b2923b130b79aa4,"We studied temporal order judgements (TOJs) of gaze shift behaviours and evaluated the impact of gaze direction (direct and averted gaze) and face context information (both eyes set within a single face or each eye within two adjacent hemifaces) on TOJ performance measures. Avatar faces initially gazed leftwards or rightwards (Starting Gaze Direction). This was followed by sequential and independent left and right eye gaze shifts with various amounts of stimulus onset asynchrony. Gaze shifts could be either Matching (both eyes end up pointing direct or averted) or Mismatching (one eye ends up pointing direct, the other averted). Matching shifts revealed an attentional cueing mechanism, where TOJs were biased in favour of the eye lying in the hemispace cued by the avatar’s Starting Gaze Direction. For example, the left eye was more likely to be judged as shifting first when the avatar initially gazed toward the left side of the screen. Mismatching shifts showed biased TOJs in favour of the eye performing the averted shift, but only in the context of two separate hemifaces that does not violate expectations of directional gaze shift congruency. This suggests a postdictive inferential strategy that prioritises eye movements based on the type of gaze shift, independently of where attention is initially allocated. Averted shifts are prioritised over direct, as these might signal the presence of behaviourally relevant information in the environment. © The Author(s) 2017.",Gaze cueing; Gaze shifts; Prior entry; Social communication; Stimulus onset asynchrony; Temporal order judgements,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85026763018,Movies / Media
Pal R.; Roy D.,"Pal, Rajarshi (57204588196); Roy, Dipanjan (57192239701)",57204588196; 57192239701,Enhancing Saliency of an Object Using Genetic Algorithm,2017,"Proceedings - 2017 14th Conference on Computer and Robot Vision, CRV 2017",2018-January,,,337,344,7.0,8,10.1109/CRV.2017.33,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048036004&doi=10.1109%2fCRV.2017.33&partnerID=40&md5=f18143f7cf159c587939555869af1ef1,"It is often required to emphasize an object in an image. Artists, illustrators, cinematographers and photographers have long used the principles of contrast and composition to guide visual attention. In order to achieve this, a novel perceptually-driven approach is put forth which leads to the enhancement of visual saliency of target object without destroying the naturalness of the contents of the image. The proposed approach computes new feature values for the intended object by maximizing the feature dissimilarity (which is weighted by positional proximity) with other objects. Too much change in feature values in the target segment may destroy naturality of the image. This poses as the constraint in the proposed maximization problem. Genetic algorithm has been used, in this context, to find the feature values which maximize the saliency of the target object. Experimental validation through objective evaluation metrics using saliency maps, as well as analysis of eye-tracking data, establish the success of the proposed method. © 2017 IEEE.",attention; enhancement; genetic algorithm; Visual saliency,Behavioral research; Eye tracking; Image enhancement; Image segmentation; Visualization; Attention; Enhancement; Experimental validations; Feature values; Maximization problem; Naturality; Objective evaluation; Target object; Visual Attention; Visual saliency; Genetic algorithms,Conference paper,Final,,Scopus,2-s2.0-85048036004,Movies / Media
Kornrumpf B.; Dimigen O.; Sommer W.,"Kornrumpf, Benthe (56659472900); Dimigen, Olaf (23469367300); Sommer, Werner (7103373518)",56659472900; 23469367300; 7103373518,Lateralization of posterior alpha EEG reflects the distribution of spatial attention during saccadic reading,2017,Psychophysiology,54,6,,809,823,14.0,24,10.1111/psyp.12849,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013974656&doi=10.1111%2fpsyp.12849&partnerID=40&md5=4a20eccc4c23f52edf1c39590fd3f8d4,"Visuospatial attention is an important mechanism in reading that governs the uptake of information from foveal and parafoveal regions of the visual field. However, the spatiotemporal dynamics of how attention is allocated during eye fixations are not completely understood. The current study explored the use of EEG alpha-band oscillations to investigate the spatial distribution of attention during reading. We reanalyzed two data sets, focusing on the lateralization of alpha activity at posterior scalp sites. In each experiment, participants read short lists of German nouns in two paradigms: either by freely moving their eyes (saccadic reading) or by fixating the screen center while the text moved passively from right to left at the same average speed (RSVP paradigm). In both paradigms, upcoming words were either visible or masked, and foveal processing load was manipulated by varying the words' lexical frequencies. Posterior alpha lateralization revealed a sustained rightward bias of attention during saccadic reading, but not in the RSVP paradigm. Interestingly, alpha lateralization was not influenced by word frequency (foveal load) or preview during the preceding fixation. Hence, alpha did not reflect transient attention shifts within a given fixation. However, in both experiments, we found that in the saccadic reading condition a stronger alpha lateralization shortly before a saccade predicted shorter fixations on the subsequently fixated word. These results indicate that alpha lateralization can serve as a measure of attention deployment and its link to oculomotor behavior in reading. © 2017 Society for Psychophysiological Research",Alpha lateralization; Attention; Eye tracking; Parafoveal vision; Rapid serial visual presentation; Saccadic reading,Adolescent; Adult; Attention; Cerebral Cortex; Comprehension; Electroencephalography; Eye Movement Measurements; Female; Fovea Centralis; Functional Laterality; Humans; Language; Male; Reading; Saccades; Visual Fields; Young Adult; adolescent; adult; attention; brain cortex; comprehension; electroencephalography; female; hemispheric dominance; human; language; male; oculography; physiology; reading; retina fovea; saccadic eye movement; visual field; young adult,Article,Final,,Scopus,2-s2.0-85013974656,Movies / Media
Winoto P.; Tang T.Y.,"Winoto, Pinata (6602499798); Tang, Tiffany Y. (7401988695)",6602499798; 7401988695,A multi-user tabletop application to train children with autism Social attention coordination skills without forcing eye-gaze following,2017,IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children,,,,527,532,5.0,7,10.1145/3078072.3084320,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026319695&doi=10.1145%2f3078072.3084320&partnerID=40&md5=e89311f38d8165b7db753c259be83154,"Social attention coordination skills are central to the overall joint attention development. Previous research for children with neurotypical developing (NT) and autism spectrum disorder (ASD) has largely focused on one pathway of coordinating visual attention via gaze following with a social partner. However given the much higher reluctance of individuals with ASD to make eye contact, other pathways of visual attention coordination might be more satisfying. Such a possible pathway might be the hand-eye coordination which was observed to lead to successful social attention coordination between physically active infants and their parents. Motivated by prior works on the benefits of tabletop-based applications for ASD children, in this paper, we unfold a multi-user tabletop patternmatching game to train ASD children social attention coordination skills via hand-eye coupling, that is, manipulation of screen-objects (puzzles with different patterns) in goal-directed tasks is achieved by alternating eye-gaze between screen-objects in one's own private space and another one in a shared space. © 2017 Copyright is held by the owner/author(s).",Autism; Eye-hand coupling; Free-play; Joint attention; Multi-user play; Social coordination; Tabletop,Diseases; Autism; Free-play; Joint attention; Multi-user; Social coordination; Tabletop; Education,Conference paper,Final,,Scopus,2-s2.0-85026319695,Movies / Media
Milone R.; Valetto A.; Bertini V.; Sicca F.,"Milone, Roberta (55756145100); Valetto, Angelo (6602546345); Bertini, Veronica (7003291562); Sicca, Federico (7801420531)",55756145100; 6602546345; 7003291562; 7801420531,Benign infantile seizures followed by autistic regression in a boy with 16p11.2 deletion,2017,Epileptic Disorders,19,2,,222,225,3.0,3,10.1684/epd.2017.0909,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022324930&doi=10.1684%2fepd.2017.0909&partnerID=40&md5=58f3c3b3f469d723f6f539567dbc24ed,"Benign infantile seizures (BIS) are usually a self-limiting condition, which may be associated with heterozygous mutations in the PRRT2 gene at chromosome 16p11.2. Here, we report a boy with a deletion in 16p11.2, presenting with BIS and typical neurodevelopment in the first year of life, unexpectedly followed by severe autistic regression. 16p11.2 deletions are typically associated with intellectual disability, autism, and language disorders, and only rarely with BIS. This clinical report shows that the neurodevelopmental prognosis in BIS patients may not always be benign, and suggests that array CGH screening should be considered for affected infants in order to rule out deletions at 16p11.2 and long-term clinical follow-up. © 2017 Epileptic Disorders",16p11.2 deletion; autism; benign infantile seizure; PRRT2; regression,"Autistic Disorder; Child, Preschool; Chromosome Deletion; Chromosome Disorders; Chromosomes, Human, Pair 16; Epilepsy, Benign Neonatal; Humans; Intellectual Disability; Male; Article; auditory response; autism; behavior disorder; benign childhood epilepsy; case report; child; circadian rhythm sleep disorder; cognition assessment; comparative genomic hybridization; emotional disorder; eye movement disorder; gaze; gene deletion; gene duplication; gene mutation; gesture; human; intellectual impairment; language disability; male; preschool child; priority journal; tendon reflex; autism; benign childhood epilepsy; chromosome 16; chromosome deletion; chromosome disorder; pathophysiology",Article,Final,,Scopus,2-s2.0-85022324930,Movies / Media
Naples A.J.; Wu J.; Mayes L.C.; McPartland J.C.,"Naples, Adam J. (15751541600); Wu, Jia (55557379400); Mayes, Linda C. (7006290250); McPartland, James C. (7005050670)",15751541600; 55557379400; 7006290250; 7005050670,Event-related potentials index neural response to eye contact,2017,Biological Psychology,127,,,18,24,6.0,13,10.1016/j.biopsycho.2017.04.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019055632&doi=10.1016%2fj.biopsycho.2017.04.006&partnerID=40&md5=11bc7da2eb4934f573726b97a7b6a3b0,"Sensitivity to eye-contact is a foundation upon which social cognition is built. However, there are no known neural markers characterizing response to reciprocal gaze. Using co-registered EEG and eye-tracking, we measured brain activity while participants viewed faces that responded to their looking patterns. Contingent upon participant gaze, onscreen faces opened their eyes or mouths; in this way we measured brain response to reciprocal eye-contact. We identified two ERP components that were largest in response to reciprocal eye-contact: the N170 and the P300. The magnitude of the components’ differences between reciprocal eye-contact and mouth movement predicted self-reported social function. Individuals with greater brain response to reciprocal eye-contact reported more normative scores on measures of autistic traits. These results present the first neural markers of eye-contact, revealing that reciprocal eye-contact is identified in less than 500 ms. Furthermore, individual differences in brain response to eye-contact predict meaningful variability in self-reports of social performance. © 2017 Elsevier B.V.",EEG; Eye-contact; Face processing; N170,"Adult; Brain; Communication; Evoked Potentials; Face; Female; Fixation, Ocular; Humans; Individuality; Male; Mouth; Photic Stimulation; Social Behavior; Visual Perception; Young Adult; action potential amplitude; adult; Article; autism; electroencephalogram; event related potential; eye contact; eye tracking; female; gaze; hemispheric dominance; human; human experiment; language; male; mouth movement; movement (physiology); nerve potential; personality; prediction; priority journal; self report; sensitivity analysis; social status; visual system function; brain; evoked response; eye fixation; face; individuality; interpersonal communication; mouth; photostimulation; physiology; procedures; social behavior; vision; young adult",Article,Final,,Scopus,2-s2.0-85019055632,Movies / Media
Poletti B.; Carelli L.; Solca F.; Lafronza A.; Pedroli E.; Faini A.; Ticozzi N.; Ciammola A.; Meriggi P.; Cipresso P.; Lulé D.; Ludolph A.C.; Riva G.; Silani V.,"Poletti, Barbara (16646951300); Carelli, Laura (25926814500); Solca, Federica (54385936000); Lafronza, Annalisa (56716478300); Pedroli, Elisa (55225670600); Faini, Andrea (23979799200); Ticozzi, Nicola (23062054500); Ciammola, Andrea (6505767145); Meriggi, Paolo (16175827600); Cipresso, Pietro (36717478000); Lulé, Dorothée (10141622200); Ludolph, Albert C. (26643359400); Riva, Giuseppe (56962750600); Silani, Vincenzo (7006146949)",16646951300; 25926814500; 54385936000; 56716478300; 55225670600; 23979799200; 23062054500; 6505767145; 16175827600; 36717478000; 10141622200; 26643359400; 56962750600; 7006146949,An eye-tracker controlled cognitive battery: overcoming verbal-motor limitations in ALS,2017,Journal of Neurology,264,6,,1136,1145,9.0,29,10.1007/s00415-017-8506-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019245752&doi=10.1007%2fs00415-017-8506-z&partnerID=40&md5=10cf3cfcf7d22ff44aa1ff7350ae2bf0,"We assessed language, attention, executive, and social cognition abilities in a sample of patients with Amyotrophic Lateral Sclerosis (ALS) by means of a recently developed cognitive battery based on oculomotor control with eye-tracking (ET) technology. Twenty-one ALS patients and 21 age- and education-matched healthy subjects underwent the ET-based cognitive assessment, together with the standard cognitive screening tools [Frontal Assessment Battery (FAB); Montreal Cognitive Assessment (MoCA); and Digit Sequencing Task]. Psychological measures of anxiety (State-Trait Anxiety Inventory-Y) and depression (Beck Depression Inventory) were also collected, and an ET usability questionnaire was administered. For patients, clinical and respiratory examinations were also performed, together with behavioural assessment (Frontal Behavioural Inventory). The developed battery discriminated among patients and controls with regard to measures of verbal fluency, frontal abilities, and social cognition. Measures of diagnostic utility confirmed a higher diagnostic accuracy of such ET-based tests with respect to FAB; similar diagnostic accuracy emerged when comparing them to the other standard cognitive tools (MoCA, WM). Usability ratings about the ET tests were comparable among the two groups. The ET-based neuropsychological battery demonstrated good levels of diagnostic accuracy and usability in a clinical population of non-demented ALS patients, compared to matched healthy controls. Future studies will be aimed at further investigate validity and usability components by recruiting larger sample of patients, both in moderate-to-severe stages of the disease and affected by more severe cognitive impairment. © 2017, Springer-Verlag Berlin Heidelberg.",Amyotrophic lateral sclerosis; Behavioural assessment; Cognitive assessment; Eye tracker; Oculomotor control; Verbal-motor limitations,Aged; Amyotrophic Lateral Sclerosis; Attention; Attention Deficit Disorder with Hyperactivity; Case-Control Studies; Cognition Disorders; Eye Movements; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Psychiatric Status Rating Scales; Psychological Tests; ROC Curve; Vital Capacity; adult; amyotrophic lateral sclerosis; anxiety; Article; attention; Beck Depression Inventory; behavior change; clinical article; comparative study; controlled study; convergent validity; depression; diagnostic accuracy; diagnostic value; Digit Sequencing Task; executive function; eye movement control; eye tracking; female; Frontal Assessment Battery; human; language; male; middle aged; Montreal cognitive assessment; neuropsychological test; personality disorder; physical disability; priority journal; psychologic assessment; social cognition; State Trait Anxiety Inventory; aged; amyotrophic lateral sclerosis; attention deficit disorder; case control study; cognitive defect; complication; eye movement; physiology; psychologic test; psychological rating scale; receiver operating characteristic; vital capacity,Article,Final,,Scopus,2-s2.0-85019245752,Movies / Media
Aznar-Casanova J.A.; Romeo A.; Gómez A.T.; Enrile P.M.,"Aznar-Casanova, J. Antonio (6508031834); Romeo, August (36640294800); Gómez, Aurora Torrents (7003607593); Enrile, Pedro Martin (57192008684)",6508031834; 36640294800; 7003607593; 57192008684,Visual fatigue while watching 3D stimuli from different positions; [Fatiga visual al observar estímulos en 3D desde diferentes posiciones],2017,Journal of Optometry,10,3,,149,160,11.0,24,10.1016/j.optom.2016.07.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995893199&doi=10.1016%2fj.optom.2016.07.002&partnerID=40&md5=b58e5f30c84cd640b19269541b10b4e1,"Purpose When observers focus their stereoscopic visual system for a long time (e.g., watching a 3D movie) they may experience visual discomfort or asthenopia. We tested two types of models for predicting visual fatigue in a task in which subjects were instructed to discriminate between 3D characters. One model was based on viewing distance (focal distance, vergence distance) and another in visual direction (oculomotor imbalance). Method A 3D test was designed to assess binocular visual fatigue while looking at 3D stimuli located in different visual directions and viewed from two distances from the screen. The observers were tested under three conditions: (a) normal vision; (b) wearing a lens (−2 diop.); (c) wearing a base-out prism (2▿) over each eye. Sensitivity and specificity were calculated (as Signal Detection Theory parameters: SDT). Results An ANOVA and SDT analyses revealed that impaired visual performance were directly related to short distance and larger deviation in visual direction, particularly when the stimuli were located nearer and at more than 24° to the centre of the screen in dextroversion and beyond. Conclusion This results support a mixed model, combining a model based on the visual angle (related to viewing distance) and another based on the oculomotor imbalance (related to visual direction). This mixed model could help to predict the distribution of seats in the cinema room ranging from those that produce greater visual comfort to those that produce more visual discomfort. Also could be a first step to pre-diagnosis of binocular vision disorders. © 2016 Spanish General Council of Optometry",Accommodation; Asthenopia; Binocular vision; Stereopsis; Vergence; Visual fatigue,"Accommodation, Ocular; Adult; Asthenopia; Depth Perception; Eye Movements; Female; Healthy Volunteers; Humans; Imaging, Three-Dimensional; Male; Photic Stimulation; Vision Tests; Vision, Binocular; Young Adult; accommodation; adult; asthenopia; binocular vision; depth perception; eye movement; female; human; male; normal human; pathophysiology; photostimulation; physiology; procedures; three dimensional imaging; vision test; young adult",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84995893199,Movies / Media
Molina-Cantero A.J.; Guerrero-Cubero J.; Gómez-González I.M.; Merino-Monge M.; Silva-Silva J.I.,"Molina-Cantero, Alberto J. (55872888200); Guerrero-Cubero, Jaime (57194685172); Gómez-González, Isabel M. (7102588735); Merino-Monge, Manuel (56456740000); Silva-Silva, Juan I. (57194684509)",55872888200; 57194685172; 7102588735; 56456740000; 57194684509,Characterizing computer access using a one-channel EEG wireless sensor,2017,Sensors (Switzerland),17,7,1525,,,,12,10.3390/s17071525,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021656841&doi=10.3390%2fs17071525&partnerID=40&md5=5691ea0f430c1b4f32f2c30f5c0aa2ad,"This work studies the feasibility of using mental attention to access a computer. Brain activity was measured with an electrode placed at the Fp1 position and the reference on the left ear; seven normally developed people and three subjects with cerebral palsy (CP) took part in the experimentation. They were asked to keep their attention high and low for as long as possible during several trials. We recorded attention levels and power bands conveyed by the sensor, but only the first was used for feedback purposes. All of the information was statistically analyzed to find the most significant parameters and a classifier based on linear discriminant analysis (LDA) was also set up. In addition, 60% of the participants were potential users of this technology with an accuracy of over 70%. Including power bands in the classifier did not improve the accuracy in discriminating between the two attentional states. For most people, the best results were obtained by using only the attention indicator in classification. Tiredness was higher in the group with disabilities (2.7 in a scale of 3) than in the other (1.5 in the same scale); and modulating the attention to access a communication board requires that it does not contain many pictograms (between 4 and 7) on screen and has a scanning period of a relatively high tscan ≈ 10 s. The information transfer rate (ITR) is similar to the one obtained by other brain computer interfaces (BCI), like those based on sensorimotor rhythms (SMR) or slow cortical potentials (SCP), and makes it suitable as an eye-gaze independent BCI. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.",Attention; Brain computer interface; Cerebral palsy; Linear discriminant analysis; Wireless EEG sensor,Attention; Brain-Computer Interfaces; Communication Aids for Disabled; Computers; Electroencephalography; Humans; Wireless Technology; Brain; Classification (of information); Discriminant analysis; Diseases; Interfaces (computer); Attention; Cerebral palsy; Communication board; Cortical potentials; Information transfer rate; Linear discriminant analysis; Potential users; Sensorimotor rhythm (SMR); attention; brain computer interface; communication aid; computer; electroencephalography; human; wireless communication; Brain computer interface,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85021656841,Movies / Media
Vriends N.; Meral Y.; Bargas-Avila J.A.; Stadler C.; Bögels S.M.,"Vriends, Noortje (15069773800); Meral, Yasemin (57193538628); Bargas-Avila, Javier A. (16174255700); Stadler, Christina (7004708853); Bögels, Susan M. (6701768693)",15069773800; 57193538628; 16174255700; 7004708853; 6701768693,How do I look? Self-focused attention during a video chat of women with social anxiety (disorder),2017,Behaviour Research and Therapy,92,,,77,86,9.0,36,10.1016/j.brat.2017.02.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014634555&doi=10.1016%2fj.brat.2017.02.008&partnerID=40&md5=076bd3bdce23bdc58f4aca919d4486ac,"We investigated the role of self-focused attention (SFA) in social anxiety (disorder) in an ecologically valid way. In Experiment 1 high (n = 26) versus low (n = 25) socially anxious single women between 18 and 30 years had a video (“Skype”) conversation with an attractive male confederate, while seeing themselves and the confederate on-screen. The conversation was divided in four phases: (I) warm-up, (II) positive (confederate was friendly to the participant), (III) critical (confederate was critical to the participant), and (IV) active (participant was instructed to ask questions to the confederate). Participant's SFA was measured by eye-tracked gaze duration at their own image relative to the confederates’ video image and other places at the computer screen. Results show that high socially anxious participants were more self-focused in the critical phase, but less self-focused in the active phase than low socially anxious participants. In Experiment 2 women diagnosed with SAD (n = 32) and controls (n = 30) between 18 and 30 years conducted the same experiment. Compared to controls participants with SAD showed increased SFA across all four phases of the conversation, and SFA predicted increased self-rated anxiety during the conversation. In conclusion, in subclinical social anxiety SFA is high only when the interaction partner is critical, whereas instructions to ask questions to the confederate reduces subclinical socially anxious’ SFA, while clinical SAD is characterized by heightened self-focused attention throughout the interaction. Results support theories that social anxiety disorder is maintained by SFA, and imply that interventions that lower SFA may help prevent and treat social anxiety disorder, but that SFA can also be adaptive in certain types of interaction, such as when receiving compliments. © 2017 Elsevier Ltd",Arousal; Cognitive model; Eye-tracking; Self-focused attention; Social anxiety disorder,"Adolescent; Adult; Attention; Case-Control Studies; Eye Movements; Female; Humans; Phobia, Social; Photic Stimulation; Self Concept; Social Behavior; Videoconferencing; Young Adult; adult; anxiety; Article; clinical article; controlled study; correlational study; female; gaze; human; nervousness; pilot study; self concept; self focused attention; social interaction; social phobia; adolescent; attention; case control study; eye movement; pathophysiology; photostimulation; physiology; psychology; social behavior; social phobia; videoconferencing; young adult",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85014634555,Movies / Media
Galetta K.M.; Chapman K.R.; Essis M.D.; Alosco M.L.; Gillard D.; Steinberg E.; Dixon D.; Martin B.; Chaisson C.E.; Kowall N.W.; Tripodis Y.; Balcer L.J.; Stern R.A.,"Galetta, Kristin M. (15122242100); Chapman, Kimberly R. (57202050604); Essis, Maritza D. (57189702455); Alosco, Michael L. (36127374400); Gillard, Danielle (57190112496); Steinberg, Eric (35757927200); Dixon, Diane (56623892400); Martin, Brett (7402931389); Chaisson, Christine E. (6603806330); Kowall, Neil W. (7005740563); Tripodis, Yorghos (26642803400); Balcer, Laura J. (7004524080); Stern, Robert A. (35757958900)",15122242100; 57202050604; 57189702455; 36127374400; 57190112496; 35757927200; 56623892400; 7402931389; 6603806330; 7005740563; 26642803400; 7004524080; 35757958900,Screening Utility of the King-Devick Test in Mild Cognitive Impairment and Alzheimer Disease Dementia,2017,Alzheimer Disease and Associated Disorders,31,2,,152,158,6.0,33,10.1097/WAD.0000000000000157,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974660145&doi=10.1097%2fWAD.0000000000000157&partnerID=40&md5=c33ad77c29bbbb84bdf6cffc10921776,"The King-Devick (K-D) test is a 1 to 2 minute, rapid number naming test, often used to assist with detection of concussion, but also has clinical utility in other neurological conditions (eg, Parkinson disease). The K-D involves saccadic eye and other eye movements, and abnormalities thereof may be an early indicator of Alzheimer disease (AD)-associated cognitive impairment. No study has tested the utility of the K-D in AD and we sought to do so. The sample included 206 [135 controls, 39 mild cognitive impairment (MCI), and 32 AD dementia] consecutive subjects from the Boston University Alzheimer's Disease Center registry undergoing their initial annual evaluation between March 2013 and July 2015. The K-D was administered during this period. Areas under the receiver operating characteristic curves generated from logistic regression models revealed the K-D test distinguished controls from subjects with cognitive impairment (MCI and AD dementia) [area under the curve (AUC)=0.72], MCI (AUC=0.71) and AD dementia (AUC=0.74). K-D time scores between 48 and 52 seconds were associated with high sensitivity (>90.0%) and negative predictive values (>85.0%) for each diagnostic group. The K-D correlated strongly with validated attention, processing speed, and visual scanning tests. The K-D test may be a rapid and simple effective screening tool to detect cognitive impairment associated with AD. © 2016 Wolters Kluwer Health, Inc. All rights reserved.",Alzheimer disease; dementia; King-Devick test; mild cognitive impairment; saccadic eye movements; screening test,Aged; Alzheimer Disease; Cognitive Dysfunction; Female; Humans; Male; Neuropsychological Tests; Saccades; aged; Alzheimer disease; Article; attention; controlled study; diagnostic test accuracy study; disease association; female; human; King Devick test; major clinical study; male; mild cognitive impairment; neurologic examination; neuropsychological test; predictive value; priority journal; receiver operating characteristic; screening test; sensitivity and specificity; Alzheimer disease; cognitive defect; physiology; saccadic eye movement; statistics and numerical data,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84974660145,Movies / Media
Grzyb B.J.; Cangelosi A.; Cattani A.; Floccia C.,"Grzyb, Beata J. (25649411600); Cangelosi, Angelo (6701387796); Cattani, Allegra (8629334500); Floccia, Caroline (24376377900)",25649411600; 6701387796; 8629334500; 24376377900,Decreased attention to object size information in scale errors performers,2017,Infant Behavior and Development,47,,,72,82,10.0,9,10.1016/j.infbeh.2017.03.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016078948&doi=10.1016%2fj.infbeh.2017.03.001&partnerID=40&md5=c862172eb542e97b8ca1fa240af85919,"Young children sometimes make serious attempts to perform impossible actions on miniature objects as if they were full-size objects. The existing explanations of these curious action errors assume (but never explicitly tested) children's decreased attention to object size information. This study investigated the attention to object size information in scale errors performers. Two groups of children aged 18–25 months (N = 52) and 48–60 months (N = 23) were tested in two consecutive tasks: an action task that replicated the original scale errors elicitation situation, and a looking task that involved watching on a computer screen actions performed with adequate to inadequate size object. Our key finding − that children performing scale errors in the action task subsequently pay less attention to size changes than non-scale errors performers in the looking task −suggests that the origins of scale errors in childhood operate already at the perceptual level, and not at the action level. © 2017 Elsevier Inc.",Decreased attention; Object size; Scale errors,"Attention; Child; Child Development; Child, Preschool; Exploratory Behavior; Female; Humans; Infant; Male; Size Perception; age; Article; attention; child; color; eye fixation; eye movement; eye tracking; female; gender; human; human experiment; male; mental function; normal human; object size; perception; play; preschool child; scale error; stimulus; task performance; weight, mass and size; attention; child development; exploratory behavior; infant; physiology",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85016078948,Movies / Media
Guo W.; Wang J.,"Guo, Wei (58267133000); Wang, Jingtao (56962595200)",58267133000; 56962595200,SmartRSVP: Facilitating attentive speed reading on small screen wearable devices,2017,Conference on Human Factors in Computing Systems - Proceedings,Part F127655,,,1640,1647,7.0,3,10.1145/3027063.3053176,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019639087&doi=10.1145%2f3027063.3053176&partnerID=40&md5=6d4905b4d7f7a394984c5b8b006599d0,"Smart watches can enrich everyday interactions by providing both glanceable information and instant access to frequent tasks. However, reading text messages on a 1.5-inch screen is inherently challenging, especially when a user's attention is divided. We present SmartRSVP, an attentive speedreading system to facilitate text reading on small screen wearable devices. SmartRSVP leverages camera-based visual attention tracking as a play/pause control channel, and uses implicit physiological signal sensing to adjust speed in real-time to make text reading via Rapid Serial Visual Presentation (RSVP) more enjoyable and practical on smart watches. Through two pilot studies, we received positive feedback on the visual attention controlling feature and confirmed the feasibility of the speed adjusting feature of SmartRSVP. This paper reports the preliminary results of the studies. Copyright © 2017 by the Association for Computing Machinery, Inc. (ACM).",Cognitive workload; Gaze tracking; Heart rate variability; Ppg; RSVP; Smart watch; Visual attention,Feedback; Human engineering; Tracking (position); Watches; Wearable computers; Wearable technology; Cognitive workloads; Gaze tracking; Heart rate variability; RSVP; Visual Attention; Behavioral research,Conference paper,Final,,Scopus,2-s2.0-85019639087,Movies / Media
Estudillo A.J.; Bindemann M.,"Estudillo, Alejandro J. (54400980700); Bindemann, Markus (9336570700)",54400980700; 9336570700,Can gaze-contingent mirror-feedback from unfamiliar faces alter self-recognition?,2017,Quarterly Journal of Experimental Psychology,70,5,,944,958,14.0,25,10.1080/17470218.2016.1166253,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964089260&doi=10.1080%2f17470218.2016.1166253&partnerID=40&md5=c694b17389e65c4f138b83e3032dae8c,"This study focuses on learning of the self, by examining how human observers update internal representations of their own face. For this purpose, we present a novel gaze-contingent paradigm, in which an onscreen face mimics observers’ own eye-gaze behaviour (in the congruent condition), moves its eyes in different directions to that of the observers (incongruent condition), or remains static and unresponsive (neutral condition). Across three experiments, the mimicry of the onscreen face did not affect observers’ perceptual self-representations. However, this paradigm influenced observers’ reports of their own face. This effect was such that observers felt the onscreen face to be their own and that, if the onscreen gaze had moved on its own accord, observers expected their own eyes to move too. The theoretical implications of these findings are discussed. © 2016 The Experimental Psychology Society.",Mirror recognition; Self-face learning; Self-face recognition; Self-face representation,"Adolescent; Adult; Attention; Discrimination Learning; Face; Feedback, Sensory; Female; Fixation, Ocular; Humans; Imagination; Male; Pattern Recognition, Visual; Photic Stimulation; Recognition (Psychology); Self Concept; Surveys and Questionnaires; Young Adult; adolescent; adult; attention; discrimination learning; eye fixation; face; female; human; imagination; male; pattern recognition; photostimulation; physiology; questionnaire; recognition; self concept; sensory feedback; young adult",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84964089260,Movies / Media
Andrist S.; Gleicher M.; Mutlu B.,"Andrist, Sean (36717352400); Gleicher, Michael (6701816786); Mutlu, Bilge (15060220700)",36717352400; 6701816786; 15060220700,Looking coordinated: Bidirectional gaze mechanisms for collaborative interaction with virtual characters,2017,Conference on Human Factors in Computing Systems - Proceedings,2017-May,,,2571,2582,11.0,78,10.1145/3025453.3026033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030750059&doi=10.1145%2f3025453.3026033&partnerID=40&md5=d6c2e7d5ff7293cac8c457800f5c74d8,"Successful collaboration relies on the coordination and alignment of communicative cues. In this paper, we present mechanisms of bidirectional gaze - the coordinated production and detection of gaze cues - by which a virtual character can coordinate its gaze cues with those of its human user. We implement these mechanisms in a hybrid stochastic/heuristic model synthesized from data collected in human-human interactions. In three lab studies wherein a virtual character instructs participants in a sandwich-making task, we demonstrate how bidirectional gaze can lead to positive outcomes in error rate, completion time, and the agent's ability to produce quick, effective nonverbal references. The first study involved an on-screen agent and the participant wearing eye-tracking glasses. The second study demonstrates that these positive outcomes can be achieved using head-pose estimation in place of full eye tracking. The third study demonstrates that these effects also transfer into virtual-reality interactions. © 2017 ACM.",Bidirectional gaze; Dyadic gaze; Embodied agents; Gaze coordination; Interactive gaze; Joint attention; Verbal referencing,Human computer interaction; Human engineering; Image recognition; Stochastic models; Stochastic systems; Virtual reality; Bidirectional gaze; Dyadic gaze; Embodied agent; Gaze coordination; Interactive gaze; Joint attention; Verbal referencing; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85030750059,Movies / Media
Grusky M.; Jahani J.; Schwartz J.; Valente D.; Artzi Y.; Naaman M.,"Grusky, Max (57201445924); Jahani, Jeiran (57201446199); Schwartz, Josh (57201448922); Valente, Dan (57201446193); Artzi, Yoav (51664667500); Naaman, Mor (57204346960)",57201445924; 57201446199; 57201448922; 57201446193; 51664667500; 57204346960,Modeling sub-document attention using viewport time,2017,Conference on Human Factors in Computing Systems - Proceedings,2017-May,,,6475,6480,5.0,15,10.1145/3025453.3025916,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044846049&doi=10.1145%2f3025453.3025916&partnerID=40&md5=6444a10aa567a5995df40370b97c2c3e,"Website measures of engagement captured from millions of users, such as in-page scrolling and viewport position, can provide deeper understanding of attention than possible with simpler measures, such as dwell time. Using data from 1.2M news reading sessions, we examine and evaluate three increasingly sophisticated models of sub-document attention computed from viewport time, the time a page component is visible on the user display. Our modeling incorporates prior eye-tracking knowledge about onscreen reading, and we validate it by showing how, when used to estimate user reading rate, it aligns with known empirical measures. We then show how our models reveal an interaction between article topic and attention to page elements. Our approach supports refined large-scale measurement of user engagement at a level previously available only from lab-based eye-tracking studies. Copyright is held by the owner/author(s). Publication rights licensed to ACM. © 2017 ACM.",Attention; News articles; Reading; User modeling; Web analytics,Human computer interaction; Human engineering; Attention; News articles; Reading; User Modeling; Web analytics; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85044846049,Movies / Media
Eberz S.; Rasmussen K.B.; Lenders V.; Martinovic I.,"Eberz, Simon (55347743700); Rasmussen, Kasper B. (56414038400); Lenders, Vincent (12786066100); Martinovic, Ivan (14035985300)",55347743700; 56414038400; 12786066100; 14035985300,Evaluating behavioral biometrics for continuous authentication: Challenges and metrics,2017,ASIA CCS 2017 - Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security,,,,386,399,13.0,78,10.1145/3052973.3053032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021906089&doi=10.1145%2f3052973.3053032&partnerID=40&md5=76f570c11f2ef5fda70f61925ffb27d4,"In recent years, behavioral biometrics have become a popular approach to support continuous authentication systems. Most generally, a continuous authentication system can make two types of errors: false rejects and false accepts. Based on this, the most commonly reported metrics to evaluate systems are the False Reject Rate (FRR) and False Accept Rate (FAR). However, most papers only report the mean of these measures with little attention paid to their distribution. This is problematic as systematic errors allow attackers to perpetually escape detection while random errors are less severe. Using 16 biometric datasets we show that these systematic errors are very common in the wild. We show that some biometrics (such as eye movements) are particularly prone to systematic errors, while others (such as touchscreen inputs) show more even error distributions. Our results also show that the inclusion of some distinctive features lowers average error rates but significantly increases the prevalence of systematic errors. As such, blind optimization of the mean EER (through feature engineering or selection) can sometimes lead to lower security. Following this result we propose the Gini Coefficient (GC) as an additional metric to accurately capture different error distributions. We demonstrate the usefulness of this measure both to compare different systems and to guide researchers during feature selection. In addition to the selection of features and classifiers, some nonfunctional machine learning methodologies also affect error rates. The most notable examples of this are the selection of training data and the attacker model used to develop the negative class. 13 out of the 25 papers we analyzed either include imposter data in the negative class or randomly sample training data from the entire dataset, with a further 6 not giving any information on the methodology used. Using real-world data we show that both of these decisions lead to significant underestimation of error rates by 63% and 81%, respectively. This is an alarming result, as it suggests that researchers are either unaware of the magnitude of these effects or might even be purposefully attempting to over-optimize their EER without actually improving the system. © 2017 ACM.",,Authentication; Biometrics; Errors; Eye movements; Feature extraction; Systematic errors; Behavioral biometrics; Blind optimizations; Continuous authentications; Error distributions; False accept rate; False reject rate; Feature engineerings; Gini coefficients; Random errors,Conference paper,Final,,Scopus,2-s2.0-85021906089,Movies / Media
Poletti B.; Carelli L.; Solca F.; Lafronza A.; Pedroli E.; Faini A.; Zago S.; Ticozzi N.; Ciammola A.; Morelli C.; Meriggi P.; Cipresso P.; Lulé D.; Ludolph A.C.; Riva G.; Silani V.,"Poletti, Barbara (16646951300); Carelli, Laura (25926814500); Solca, Federica (54385936000); Lafronza, Annalisa (56716478300); Pedroli, Elisa (55225670600); Faini, Andrea (23979799200); Zago, Stefano (6602491810); Ticozzi, Nicola (23062054500); Ciammola, Andrea (6505767145); Morelli, Claudia (35242968500); Meriggi, Paolo (16175827600); Cipresso, Pietro (36717478000); Lulé, Dorothée (10141622200); Ludolph, Albert C. (26643359400); Riva, Giuseppe (56962750600); Silani, Vincenzo (7006146949)",16646951300; 25926814500; 54385936000; 56716478300; 55225670600; 23979799200; 6602491810; 23062054500; 6505767145; 35242968500; 16175827600; 36717478000; 10141622200; 26643359400; 56962750600; 7006146949,An eye-tracking controlled neuropsychological battery for cognitive assessment in neurological diseases,2017,Neurological Sciences,38,4,,595,603,8.0,23,10.1007/s10072-016-2807-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009240280&doi=10.1007%2fs10072-016-2807-3&partnerID=40&md5=c01a70857babd802f561fe571e25feb1,"Traditional cognitive assessment in neurological conditions involving physical disability is often prevented by the presence of verbal–motor impairment; to date, an extensive motor–verbal-free neuropsychological battery is not available for such purposes. We adapted a set of neuropsychological tests, assessing language, attentional abilities, executive functions and social cognition, for eye-tracking (ET) control, and explored its feasibility in a sample of healthy participants. Thirty healthy subjects performed a neuropsychological assessment, using an ET-based neuropsychological battery, together with standard “paper and pencil” cognitive measures for frontal (Frontal Assessment Battery—FAB) and working memory abilities (Digit Sequencing Task) and for global cognitive efficiency (Montreal Cognitive Assessment—MoCA). Psychological measures of anxiety (State-Trait Anxiety Inventory-Y—STAI-Y) and depression (Beck Depression Inventory—BDI) were also collected, and a usability questionnaire was administered. Significant correlations were observed between the “paper and pencil” screening of working memory abilities and the ET-based neuropsychological measures. The ET-based battery also correlated with the MoCA, while poor correlations were observed with the FAB. Usability aspects were found to be influenced by both working memory abilities and psychological components. The ET-based neuropsychological battery developed could provide an extensive assessment of cognitive functions, allowing participants to perform tasks independently from the integrity of motor or verbal channels. Further studies will be aimed at investigating validity and usability components in neurological populations with motor–verbal impairments. © 2017, Springer-Verlag Italia.",Eye-tracking; Motor–verbal limitations; Neurological diseases; Neuropsychological battery,"Attention; Cognition; Executive Function; Eye Movement Measurements; Feasibility Studies; Female; Humans; Language; Language Tests; Male; Memory, Short-Term; Middle Aged; Nervous System Diseases; Neuropsychological Tests; Social Behavior; Socioeconomic Factors; adult; anxiety; Article; Beck Depression Inventory; cognition; depression; executive function; eye tracking; female; Frontal Assessment Battery; human; human experiment; male; middle aged; Montreal cognitive assessment; neurologic disease; neuropsychological test; normal human; psychologic assessment; questionnaire; social cognition; working memory; attention; cognition; evaluation study; feasibility study; language; language test; Nervous System Diseases; oculography; psychology; short term memory; social behavior; socioeconomics",Article,Final,,Scopus,2-s2.0-85009240280,Movies / Media
Forschack N.; Andersen S.K.; Müller M.M.,"Forschack, Norman (55793043200); Andersen, Søren K. (24068643500); Müller, Matthias M. (35764074000)",55793043200; 24068643500; 35764074000,Global enhancement but local suppression in feature-based attention,2017,Journal of Cognitive Neuroscience,29,4,,619,627,8.0,30,10.1162/jocn_a_01075,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014407313&doi=10.1162%2fjocn_a_01075&partnerID=40&md5=0eec7f1e36cdad4c36796d2b54811c8f,"A key property of feature-based attention is global facilitation of the attended feature throughout the visual field. Previously, we presented superimposed red and blue randomly moving dot kinematograms (RDKs) flickering at a different frequency each to elicit frequency-specific steady-state visual evoked potentials (SSVEPs) that allowed us to analyze neural dynamics in early visual cortex when participants shifted attention to one of the two colors. Results showed amplification of the attended and suppression of the unattended color as measured by SSVEP amplitudes. Here, we tested whether the suppression of the unattended color also operates globally. To this end, we presented superimposed flickering red and blue RDKs in the center of a screen and a red and blue RDK in the left and right periphery, respectively, also flickering at different frequencies. Participants shifted attention to one color of the superimposed RDKs in the center to discriminate coherent motion events in the attended from the unattended color RDK, whereas the peripheral RDKs were task irrelevant. SSVEP amplitudes elicited by the centrally presented RDKs confirmed the previous findings of amplification and suppression. For peripherally located RDKs, we found the expected SSVEP amplitude in- crease, relative to precue baseline when color matched the one of the centrally attended RDK. We found no reduction in SSVEP amplitude relative to precuebaseline, when the peripheral color matched the unattended one of the central RDK, indicating that, while facilitation in feature-based attention operates glob- ally, suppression seems to be linked to the location of focused attention. © 2017 Massachusetts Institute of Technology.",,"Adult; Attention; Color Perception; Electroencephalography; Evoked Potentials, Visual; Female; Humans; Male; Motion Perception; Visual Cortex; Young Adult; Electrophysiology; Flickering; Coherent motion; Different frequency; Feature-based; Global enhancement; Neural dynamics; Steady state visual evoked potential (SSVEPs); Visual cortexes; Visual fields; adult; Article; association; behavior; color vision; controlled study; eye movement; facilitation; female; human; human experiment; male; normal human; priority journal; steady state visual evoked potential; visual attention; visual evoked potential; visual field; visual stimulation; attention; electroencephalography; movement perception; physiology; visual cortex; young adult; Color",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85014407313,Movies / Media
Miller L.M.S.; Applegate E.; Beckett L.A.; Wilson M.D.; Gibson T.N.,"Miller, Lisa M. Soederberg (26327018600); Applegate, Elizabeth (6701556797); Beckett, Laurel A. (7006825451); Wilson, MacHelle D. (55627877864); Gibson, Tanja N. (37011933500)",26327018600; 6701556797; 7006825451; 55627877864; 37011933500,Age differences in the use of serving size information on food labels: Numeracy or attention?,2017,Public Health Nutrition,20,5,,786,796,10.0,17,10.1017/S1368980016003219,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007417719&doi=10.1017%2fS1368980016003219&partnerID=40&md5=219b0a58feab0e1f88659d86c030d923,"Objective The ability to use serving size information on food labels is important for managing age-related chronic conditions such as diabetes, obesity and cancer. Past research suggests that older adults are at risk for failing to accurately use this portion of the food label due to numeracy skills. However, the extent to which older adults pay attention to serving size information on packages is unclear. We compared the effects of numeracy and attention on age differences in accurate use of serving size information while individuals evaluated product healthfulness. Design Accuracy and attention were assessed across two tasks in which participants compared nutrition labels of two products to determine which was more healthful if they were to consume the entire package. Participants' eye movements were monitored as a measure of attention while they compared two products presented side-by-side on a computer screen. Numeracy as well as food label habits and nutrition knowledge were assessed using questionnaires. Setting Sacramento area, California, USA, 2013-2014. Subjects Stratified sample of 358 adults, aged 20-78 years. Results Accuracy declined with age among those older adults who paid less attention to serving size information. Although numeracy, nutrition knowledge and self-reported food label use supported accuracy, these factors did not influence age differences in accuracy. Conclusions The data suggest that older adults are less accurate than younger adults in their use of serving size information. Age differences appear to be more related to lack of attention to serving size information than to numeracy skills. Copyright © The Authors 2016Â This is an Open Access article, distributed under the terms of the Creative Commons Attribution licence.",Food choice; Healthier choices; Nutrition label use; Serving size information,"Adult; Age Factors; Aged; Attention; California; Choice Behavior; Female; Food Labeling; Food Preferences; Health Behavior; Health Knowledge, Attitudes, Practice; Humans; Logistic Models; Male; Middle Aged; Risk Factors; Serving Size; Socioeconomic Factors; Surveys and Questionnaires; Young Adult; adult; age; aged; attention; attitude to health; California; decision making; female; food packaging; food preference; health behavior; human; male; middle aged; portion size; psychology; questionnaire; risk factor; socioeconomics; statistical model; young adult",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85007417719,Movies / Media
Luo S.; Hu Y.; Zhou Y.,"Luo, Shijian (55449833300); Hu, Yi (57190163619); Zhou, Yuxiao (53664999400)",55449833300; 57190163619; 53664999400,Factors attracting Chinese Generation Y in the smartphone application marketplace,2017,Frontiers of Computer Science,11,2,,290,306,16.0,5,10.1007/s11704-016-5022-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978115065&doi=10.1007%2fs11704-016-5022-8&partnerID=40&md5=e54cd91069494b365a5cc2b8043ef8c6,"Smartphone applications (apps) are becoming increasingly popular all over the world, particularly in the Chinese Generation Y population; however, surprisingly, only a small number of studies on app factors valued by this important group have been conducted. Because the competition among app developers is increasing, app factors that attract users’ attention are worth studying for sales promotion. This paper examines these factors through two separate studies. In the first study, i.e., Experiment 1, which consists of a survey, perceptual rating and verbal protocol methods are employed, and 90 randomly selected app websites are rated by 169 experienced smartphone users according to app attraction. Twelve of the most rated apps (six highest rated and six lowest rated) are selected for further investigation, and 11 influential factors that Generation Y members value are listed. A second study, i.e., Experiment 2, is conducted using the most and least rated app websites from Experiment 1, and eye tracking and verbal protocol methods are used. The eye movements of 45 participants are tracked while browsing these websites, providing evidence about what attracts these users’ attention and the order in which the app components are viewed. The results of these two studies suggest that Chinese Generation Y is a content-centric group when they browse the smartphone app marketplace. Icon, screenshot, price, rating, and name are the dominant and indispensable factors that influence purchase intentions, among which icon and screenshot should be meticulously designed. Price is another key factor that drives Chinese Generation Y’s attention. The recommended apps are the least dominant element. Design suggestions for app websites are also proposed. This research has important implications. © 2016, Higher Education Press and Springer-Verlag Berlin Heidelberg.",app marketplace design; eye tracking; Generation Y; HCI; online commerce,Commerce; Human computer interaction; Rating; Sales; Signal encoding; Smartphones; Websites; Design suggestions; Eye-tracking; Generation Y; Influential factors; Online commerce; Purchase intention; Sales promotions; Smart-phone applications; Eye movements,Article,Final,,Scopus,2-s2.0-84978115065,Movies / Media
Gillingham S.M.; Yunusova Y.; Ganda A.; Rogaeva E.; Black S.E.; Stuss D.T.; Zinman L.,"Gillingham, S.M. (13103115800); Yunusova, Y. (24464618800); Ganda, A. (38661190600); Rogaeva, E. (35372614800); Black, S.E. (35400981300); Stuss, D.T. (56116676300); Zinman, L. (7004020872)",13103115800; 24464618800; 38661190600; 35372614800; 35400981300; 56116676300; 7004020872,Assessing cognitive functioning in ALS: A focus on frontal lobe processes,2017,Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration,18,4-Mar,,182,192,10.0,20,10.1080/21678421.2016.1248977,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003890132&doi=10.1080%2f21678421.2016.1248977&partnerID=40&md5=cc6623476094eca92af75ec90d306e39,"Objective: It is generally acknowledged that at least 50% of individuals with amyotrophic lateral sclerosis (ALS) will exhibit cognitive deficits outside of the characteristic motor neuron involvement. However, a specific cognitive profile has been difficult to ascertain due to disease-related testing barriers and limitations in the sensitivity and specificity of available assessment methods. This study assessed the level of functioning of extramotor frontal cognitive processes in ALS, and the amount of change in the functioning in these processes over time as disease progresses. Methods: Empirical tests validated for a model of frontal lobe functioning were modified into an assessment battery appropriate for individuals with ALS in a clinical setting (the ALS-CFB, Computerised Frontal Battery). Twenty ALS participants and 36 age- and education-matched neurologically healthy controls were tested, and a sub-sample of each group (11 ALS and 20 controls) re-tested after approximately nine months. Results and conclusions: Compared to standard neuropsychological screening tests that did not show a difference between ALS participants and healthy controls, the ALS-CFB illustrated a profile of extramotor frontal dysfunction involving energisation (preparing the neural system to respond) and executive functions, a profile that may be indicative of the nature of neurodegeneration in ALS. © 2016 World Federation of Neurology on behalf of the Research Group on Motor Neuron Diseases.",ALS-CFB; Amyotrophic lateral sclerosis; cognition; frontal lobes; longitudinal,Age of Onset; Aged; Amyotrophic Lateral Sclerosis; Cognition; Cognition Disorders; Disease Progression; Executive Function; Female; Frontal Lobe; Humans; Male; Middle Aged; Neuropsychological Tests; Reaction Time; Saccades; Social Perception; Theory of Mind; adult; amyotrophic lateral sclerosis; Amyotrophic Lateral Sclerosis Computerised Frontal Battery; Article; clinical article; cognition; cognitive function test; controlled study; disease severity; executive function; female; frontal lobe; human; male; middle aged; motor dysfunction; neurologic disease assessment; priority journal; aged; amyotrophic lateral sclerosis; cognitive defect; disease exacerbation; frontal lobe; neuropsychological test; onset age; pathophysiology; perception; psychology; reaction time; saccadic eye movement; theory of mind,Article,Final,,Scopus,2-s2.0-85003890132,Movies / Media
Renner P.; Pfeiffer T.,"Renner, Patrick (56145227600); Pfeiffer, Thies (14027435500)",56145227600; 14027435500,Attention guiding techniques using peripheral vision and eye tracking for feedback in augmented-reality-based assistance systems,2017,"2017 IEEE Symposium on 3D User Interfaces, 3DUI 2017 - Proceedings",,,7893338,186,194,8.0,124,10.1109/3DUI.2017.7893338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018972206&doi=10.1109%2f3DUI.2017.7893338&partnerID=40&md5=cad53eaa65e2de27818364d0b4a4c245,"A limiting factor of current smart glasses-based augmented reality (AR) systems is their small field of view. AR assistance systems designed for tasks such as order picking or manual assembly are supposed to guide the visual attention of the user towards the item that is relevant next. This is a challenging task, as the user may initially be in an arbitrary position and orientation relative to the target. As a result of the small field of view, in most cases the target will initially not be covered by the AR display, even if it is visible to the user. This raises the question of how to design attention guiding for such 'off-screen gaze' conditions. © 2017 IEEE.",H.5.2 [Information Interfaces and Presentation (e.g. HCI)]: User Interfaces - Miscellaneous,Augmented reality; Behavioral research; Arbitrary positions; Assistance system; Augmented reality systems; Design attention; Information interfaces and presentations; Manual assembly; Peripheral vision; Visual Attention; User interfaces,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85018972206,Movies / Media
Toker D.; Lallé S.; Conati C.,"Toker, Dereck (55305531200); Lallé, Sébastien (55028192000); Conati, Cristina (6602976668)",55305531200; 55028192000; 6602976668,Pupillometry and head distance to the screen to predict skill acquisition during information visualization tasks,2017,"International Conference on Intelligent User Interfaces, Proceedings IUI",,,,221,231,10.0,22,10.1145/3025171.3025187,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016507120&doi=10.1145%2f3025171.3025187&partnerID=40&md5=6763389b8fb4334362abe03101ac1590,"In this paper we investigate using a variety of behavioral measures collectible with an eye tracker to predict a user's skill acquisition phase while performing various information visualization tasks with bar graphs. Our long term goal is to use this information in real-Time to create user-Adaptive visualizations that can provide personalized support to facilitate visualization processing based on the user's predicted skill level. We show that leveraging two additional content-independent data sources, namely information on a user's pupil dilation and head distance to the screen, yields a significant improvement for predictive accuracies of skill acquisition compared to predictions made using content-dependent information related to user eye gaze attention patterns, as was done in previous work. We show that including features from both pupil dilation and head distance to the screen improve the ability to predict users' skill acquisition state, beating both the baseline and a model using only content-dependent gaze information. © 2017 ACM.",Classification; Distance to the screen; Eye tracking; Information visualization; Pupil dilation; Skill acquisition; User modeling,Forecasting; Information analysis; Information systems; User interfaces; Visualization; Eye-tracking; Information visualization; Pupil dilation; Skill acquisition; User Modeling; Classification (of information),Conference paper,Final,,Scopus,2-s2.0-85016507120,Movies / Media
Papoutsaki A.; Laskey J.; Huang J.,"Papoutsaki, Alexandra (55634314200); Laskey, James (57192392824); Huang, Jeff (55742390500)",55634314200; 57192392824; 55742390500,SearchGazer: Webcam eye tracking for remote studies of web search,2017,CHIIR 2017 - Proceedings of the 2017 Conference Human Information Interaction and Retrieval,,,,17,26,9.0,95,10.1145/3020165.3020170,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016966958&doi=10.1145%2f3020165.3020170&partnerID=40&md5=1137894e9390551e335355018f9e3c2f,"We introduce SearchGazer, a web-based eye tracker for remote web search studies using common webcams already present in laptops and some desktop computers. SearchGazer is a pure JavaScript library that infers the gaze behavior of searchers in real time. The eye tracking model self-calibrates by watching searchers interact with the search pages and trains a mapping of eye features to gaze locations and search page elements on the screen. Contrary to typical eye tracking studies in information retrieval, this approach does not require the purchase of any additional specialized equipment, and can be done remotely in a user's natural environment, leading to cheaper and easier visual attention studies. While SearchGazer is not intended to be as accurate as specialized eye trackers, it is able to replicate many of the research findings of three seminal information retrieval papers: two that used eye tracking devices, and one that used the mouse cursor as a restricted focus viewer. Charts and heatmaps from those original papers are plotted side-by-side with SearchGazer results. While the main results are similar, there are some notable differences, which we hypothesize derive from improvements in the latest ranking technologies used by current versions of search engines and diligence by remote users. As part of this paper, we also release SearchGazer as a library that can be integrated into any search page. © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Gaze prediction; Online eye tracking; Remote user studies; User interactions; Web search behavior,Behavioral research; Information retrieval; Personal computers; Purchasing; Search engines; Web crawler; Websites; Eye tracking devices; Eye-tracking; Eye-tracking studies; Natural environments; Remote users; Specialized equipment; User interaction; Web search behavior; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85016966958,Movies / Media
Segijn C.M.; Voorveld H.A.M.; Vandeberg L.; Smit E.G.,"Segijn, Claire M. (56809451000); Voorveld, Hilde A. M. (35219387600); Vandeberg, Lisa (39962869900); Smit, Edith G. (14069091300)",56809451000; 35219387600; 39962869900; 14069091300,The Battle of the Screens: Unraveling Attention Allocation and Memory Effects When Multiscreening,2017,Human Communication Research,43,2,,295,314,19.0,54,10.1111/hcre.12106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013426798&doi=10.1111%2fhcre.12106&partnerID=40&md5=e4207a04d0c0fa27d70588f58e946414,"Multiscreening, the simultaneous usage of multiple screens, is a relatively understudied phenomenon that may have a large impact on media effects. First, we explored people's viewing behavior while multiscreening by means of an eye-tracker. Second, we examined people's reporting of attention, by comparing eye-tracker and self-reported attention measures. Third, we assessed the effects of multiscreening on people's memory, by comparing people's memory for editorial and advertising content when multiscreening (television–tablet) versus single screening. The results of the experiment (N = 177) show that (a) people switched between screens 2.5 times per minute, (b) people were capable of reporting their own attention, and (c) multiscreeners remembered content just as well as single screeners, when they devoted sufficient attention to the content. © 2017 International Communication Association",Eye-Tracking; Memory; Multiscreening; Viewing Behavior; Visual Attention,,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85013426798,Movies / Media
Sufrinko A.M.; Mucha A.; Covassin T.; Marchetti G.; Elbin R.J.; Collins M.W.; Kontos A.P.,"Sufrinko, Alicia M. (56582218000); Mucha, Anne (36554720000); Covassin, Tracey (6507350929); Marchetti, Greg (57217603503); Elbin, R.J. (24066225800); Collins, Michael W. (35557667100); Kontos, Anthony P. (7004528698)",56582218000; 36554720000; 6507350929; 57217603503; 24066225800; 35557667100; 7004528698,Sex differences in vestibular/ocular and neurocognitive outcomes after sport-related concussion,2017,Clinical Journal of Sport Medicine,27,2,,133,138,5.0,85,10.1097/JSM.0000000000000324,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977103704&doi=10.1097%2fJSM.0000000000000324&partnerID=40&md5=65be6acbccebf1aae8ca73d55df74f5b,"Objective: To examine sex differences in vestibular and oculomotor symptoms and impairment in athletes with sport-related concussion (SRC). The secondary purpose was to replicate previously reported sex differences in total concussion symptoms, and performance on neurocognitive and balance testing. Design: Prospective cross-sectional study of consecutively enrolled clinic patients within 21 days of a SRC. Setting: Specialty Concussion Clinic. Participants: Included male (n = 36) and female (n = 28) athletes ages 9 to 18 years. Interventions: Vestibular symptoms and impairment was measured with the Vestibular/Ocular Motor Screening (VOMS). Participants completed the Immediate Post-concussion Assessment and Cognitive Test (ImPACT), Post-concussion Symptom Scale (PCSS), and Balance Error Scoring System (BESS). Main Outcomes Measures: Sex differences on clinical measures. Results: Females had higher PCSS scores (P = 0.01) and greater VOMS vestibular ocular reflex (VOR) score (P = 0.01) compared with males. There were no sex differences on BESS or ImPACT. Total PCSS scores together with female sex accounted for 45% of the variance in VOR scores. Conclusions: Findings suggest higher VOR scores after SRC in female compared with male athletes. Findings did not extend to other components of the VOMS tool suggesting that sex differences may be specific to certain types of vestibular impairment after SRC. Additional research on the clinical significance of the current findings is needed. © 2016 Wolters Kluwer Health, Inc.",adolescents; concussion; ocular; sex differences; vestibular,"Adolescent; Athletic Injuries; Brain Concussion; Child; Cognition; Cross-Sectional Studies; Female; Humans; Male; Prospective Studies; Reflex, Vestibulo-Ocular; Sex Characteristics; adolescent; adult; Article; athlete; Balance Error Scoring System; child; clinical outcome; cognition assessment; concussion; cross-sectional study; eye movement disorder; female; human; Immediate Post concussion Assessment and Cognitive Test; major clinical study; male; mental performance; neurologic disease assessment; personal experience; Post concussion Symptom Scale; priority journal; prospective study; sex difference; sport; sport injury; vestibular disorder; brain concussion; cognition; pathophysiology; physiology; sexual development; sport injury; vestibuloocular reflex",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84977103704,Movies / Media
Kahn B.E.,"Kahn, Barbara E. (7102171412)",7102171412,Using Visual Design to Improve Customer Perceptions of Online Assortments,2017,Journal of Retailing,93,1,,29,42,13.0,151,10.1016/j.jretai.2016.11.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008186497&doi=10.1016%2fj.jretai.2016.11.004&partnerID=40&md5=a7da6c6782f45a185bd1fdda1672faa7,"In the future, we expect to see more shopping on-line or on smart phones. This suggests that understanding how visual design decisions can influence consumers’ reactions to online assortments is important. New advances in neuro-marketing techniques, such as sophisticated eye tracking methodology, can help understand exactly what drives consumers’ attention and processing efficiency. Visual stimuli on small screens is frequently processed very quickly leading to perceptions that form automatically often without cognitive intervention. Thus, savvy retailers should strategically use design elements of the assortments and of packaging to direct attention and increase the ease of processing. Assortments that are easier to process are liked more and are judged to have more perceived variety. Complexity must be minimized so that assortments can be parsed immediately. Categorization, organizational structure, filtering and other design elements can also help with choice overload. © 2016 New York University",Attention; Online retailing; Perceived variety; Perceptual fluency; Product assortment; Visual complexity,,Article,Final,,Scopus,2-s2.0-85008186497,Movies / Media
Maróti E.; Knakker B.; Vidnyánszky Z.; Weiss B.,"Maróti, Emese (57192907971); Knakker, Balázs (56481615600); Vidnyánszky, Zoltán (55989457800); Weiss, Béla (34168497800)",57192907971; 56481615600; 55989457800; 34168497800,The effect of beat frequency on eye movements during free viewing,2017,Vision Research,131,,,57,66,9.0,5,10.1016/j.visres.2016.12.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008939256&doi=10.1016%2fj.visres.2016.12.009&partnerID=40&md5=cbeaa12b2bee89cfe0a8da27629d4db9,"External periodic stimuli entrain brain oscillations and affect perception and attention. It has been shown that background music can change oculomotor behavior and facilitate detection of visual objects occurring on the musical beat. However, whether musical beats in different tempi modulate information sampling differently during natural viewing remains to be explored. Here we addressed this question by investigating how listening to naturalistic drum grooves in two different tempi affects eye movements of participants viewing natural scenes on a computer screen. We found that the beat frequency of the drum grooves modulated the rate of eye movements: fixation durations were increased at the lower beat frequency (1.7 Hz) as compared to the higher beat frequency (2.4 Hz) and no music conditions. Correspondingly, estimated visual sampling frequency decreased as fixation durations increased with lower beat frequency. These results imply that slow musical beats can retard sampling of visual information during natural viewing by increasing fixation durations. © 2016 Elsevier Ltd",Eyetracking; Free-view; Music; Rhythm; Synchronization; Visual perception,"Acoustic Stimulation; Adult; Analysis of Variance; Attention; Auditory Perception; Evoked Potentials, Auditory; Eye Movement Measurements; Eye Movements; Female; Humans; Male; Music; Psychomotor Performance; adult; Article; controlled study; eye fixation; eye movement; eye tracking; female; hearing; human; human experiment; male; music; normal human; priority journal; rhythm; vision; visual information; young adult; analysis of variance; attention; auditory evoked potential; auditory stimulation; devices; eye movement; oculography; physiology; psychomotor performance",Article,Final,,Scopus,2-s2.0-85008939256,Movies / Media
Sheehan J.C.; Kerns K.A.; Müller U.,"Sheehan, John C. (57191536255); Kerns, Kimberly A. (7005260091); Müller, Ulrich (55619304413)",57191536255; 7005260091; 55619304413,The effect of task complexity on planning in preterm-born children,2017,Clinical Neuropsychologist,31,2,,438,458,20.0,8,10.1080/13854046.2016.1244248,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991489939&doi=10.1080%2f13854046.2016.1244248&partnerID=40&md5=e48c440c4560d212beba5b95efb7cdb7,"Objective: Planning is an important executive function (EF) skill that is fundamental to the capacity to achieve everyday goals that require a series of intermediate steps. This study examined the effect of preterm birth on planning skills in early and middle childhood using Tower problems that made different cognitive workload demands. Method: We administered a novel touchscreen Tower of Hanoi task (Monkey Tree Task; MTT) in three age cohorts (3, 6, and 9 years) to 485 children born between 2000 and 2010 (105 extremely low birth weight [ELBW], 248 late preterm [LP], and 132 term-born [Term]). Results: Children born with ELBW completed significantly fewer Tower problems with higher cognitive demands than children born at Term or LP. Likewise, Term- and LP-born children completed more Tower problems than children born with ELBW. In the youngest cohort, Term-born children solved Tower problems more efficiently than either preterm group, and LP-born children solved problems more efficiently than those born with ELBW. However, there were no group differences in efficiency in the older age cohorts. Significant correlations between our MTT measures and performance on other EF tasks were found. Conclusions: The MTT captured significant performance differences in planning skills between children born term vs. preterm. This study provides important information on the impact that cognitive workload, as a function of Tower problem complexity, has on planning skills in preterm children. This study adds to a growing body of research that distinguishes LP birth as having subtle, but distinguishable, adverse neuropsychological outcomes at earlier ages. © 2016 Informa UK Limited, trading as Taylor & Francis Group.",children; Executive function; extremely low birth weight; planning; preterm birth,"Aging; Child; Child, Preschool; Cognition; Cohort Studies; Executive Function; Female; Humans; Infant, Extremely Low Birth Weight; Infant, Low Birth Weight; Infant, Premature; Male; Neuropsychological Tests; Problem Solving; Psychomotor Performance; Sex Characteristics; Space Perception; aging; child; cognition; cohort analysis; depth perception; executive function; extremely low birth weight; female; human; low birth weight; male; neuropsychological test; physiology; prematurity; preschool child; problem solving; psychology; psychomotor performance; sexual characteristics",Article,Final,,Scopus,2-s2.0-84991489939,Movies / Media
Brennstuhl M.-J.; Bassan F.; Tarquinio C.,"Brennstuhl, Marie-Jo (55014231700); Bassan, Fanny (54583198300); Tarquinio, Cyril (55930407400)",55014231700; 54583198300; 55930407400,Use of an Eye Movement Desensitization and Reprocessing (EMDR) therapy in chronic pain management: Case study; [Utilisation de la thérapie EMDR – Eye Movement Desensitization and Reprocessing – dans le cadre de la douleur chronique : études de cas],2017,Douleurs,18,1,,24,33,9.0,3,10.1016/j.douler.2017.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012916713&doi=10.1016%2fj.douler.2017.01.004&partnerID=40&md5=4955c35da0303d7934020f5bb04430f5,"Through this research, we wanted to test the relevance and effectiveness of the use of EMDR protocol specific to pain, in 5 sessions. Three students, a 19-year-old male suffering from migraines, a 24-year-old woman suffering from neck pain and a 34-year-old woman suffering from widespread pain, were treated by the EMDR therapy pain. We measured the traumatic impact with the PCL-S scale, perceptions and beliefs about pain with PBPI scale, the daily impact with the QCD scale, and the quantitative assessment of pain level with EVA and SUP scales. Although our small sample size did not allow us to achieve significant results, we see a tendential decrease of the scores in all our scales after 5 sessions of EMDR and one month after the treatment. The clinical and qualitative study of the three patients has allowed to see a unique interest in the use of this pain protocol: the emergence of life events in connection with the painful condition. These constatations made by the patients led to a modification of the traumatic impact and negative cognitions, allowing an overall reduction of the pain. The advantage of using a pain EMDR protocol lies in its overall effectiveness on pathology, but also in consecutives significant clinical changes. The pain would also considered as a symptom screen putting a veil on a deeper traumatic disease that the EMDR protocol would raise. © 2017 Elsevier Masson SAS",Case study; Chronic pain; EMDR; Psychotherapy; PTSD,adult; Article; attitude to illness; case report; case study; chronic pain; eye movement desensitization and reprocessing; female; human; male; migraine; neck pain; patient attitude; PBPI scale; PCL S scale; psychological rating scale; QCD scale; young adult,Article,Final,,Scopus,2-s2.0-85012916713,Movies / Media
,,,"1st Workshop on Eye Tracking and Visualization, ETVIS 2015",2017,Mathematics and Visualization,,,,1,257,256.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012257182&partnerID=40&md5=519fc08302173c22a0d15a81ad3e0bb5,The proceedings contain 14 papers. The special focus in this conference is on Eye Tracking and Visualization. The topics include: A task-based view on the visual analysis of eye tracking data; interactive visualization for understanding of attention patterns; a tool for exploring eye movements of visual-cognitive tasks using recurrence plots; gaze visualization for immersive video; characterizing visual-motor dynamics in touchscreen interactions; visualizing eye movements in formal cognitivemodels; word-sized eye tracking visualizations; a gaze-based reading and dynamic geographic information system; unsupervised clustering of EOG as a viable substitute for optical eye tracking; accuracy of monocular gaze tracking on 3D geometry; 3D saliency from eye tracking with tomography; visual data cleansing of low-level eye-tracking data and eye fixation metrics for large scale evaluation and comparison of information visualizations.,,,Conference review,Final,,Scopus,2-s2.0-85012257182,Movies / Media
Zhou W.; Mo F.; Zhang Y.; Ding J.,"Zhou, Wei (55475991100); Mo, Fei (57193002922); Zhang, Yunhong (56964064500); Ding, Jinhong (7402608703)",55475991100; 57193002922; 56964064500; 7402608703,Semantic and Syntactic Associations During Word Search Modulate the Relationship Between Attention and Subsequent Memory,2017,Journal of General Psychology,144,1,,69,88,19.0,4,10.1080/00221309.2016.1258389,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009962023&doi=10.1080%2f00221309.2016.1258389&partnerID=40&md5=782bf60682ccd85d8eef0e58e21f5b18,"Two experiments were conducted to investigate how linguistic information influences attention allocation in visual search and memory for words. In Experiment 1, participants searched for the synonym of a cue word among five words. The distractors included one antonym and three unrelated words. In Experiment 2, participants were asked to judge whether the five words presented on the screen comprise a valid sentence. The relationships among words were sentential, semantically related or unrelated. A memory recognition task followed. Results in both experiments showed that linguistically related words produced better memory performance. We also found that there were significant interactions between linguistic relation conditions and memorization on eye-movement measures, indicating that good memory for words relied on frequent and long fixations during search in the unrelated condition but to a much lesser extent in linguistically related conditions. We conclude that semantic and syntactic associations attenuate the link between overt attention allocation and subsequent memory performance, suggesting that linguistic relatedness can somewhat compensate for a relative lack of attention during word search. © 2017 Taylor & Francis Group, LLC.",Eye movements; memory; semantics; visual search,"Association Learning; Attention; Cues; Eye Movements; Female; Fixation, Ocular; Humans; Judgment; Linguistics; Male; Memory, Short-Term; Reading; Semantics; Young Adult; association; attention; decision making; eye fixation; eye movement; female; human; learning; linguistics; male; reading; semantics; short term memory; young adult",Article,Final,,Scopus,2-s2.0-85009962023,Movies / Media
Hirskyj-Douglas I.; Read J.C.; Cassidy B.,"Hirskyj-Douglas, I. (57188718395); Read, J.C. (15760807600); Cassidy, B. (55322060900)",57188718395; 15760807600; 55322060900,A dog centred approach to the analysis of dogs' interactions with media on TV screens,2017,International Journal of Human Computer Studies,98,,,208,220,12.0,31,10.1016/j.ijhcs.2016.05.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002654781&doi=10.1016%2fj.ijhcs.2016.05.007&partnerID=40&md5=73dd3a54a4361ca9c892d9996d73ab77,"Interactive technology for dogs is on the rise with there now being a whole TV channel supplying videos for dogs as well as several examples of interactive technology designed for the purpose of ‘entertaining’ dogs and other pet mammals. The Animal-Computer Interaction (ACI) research field has moved into the study of such technologies having earlier focussed mainly on technologies for working animals where there are two main stakeholders, the dogs and the humans, and where there is an expectation often, that the dog is doing a certain task. In studies of what might be referred to as entertainment interaction, there is a need to understand what, if anything, attracts a dog's attention whilst being mindful that where the only real stakeholder is the dog, there may be some methodological considerations in regards to the level of control and the level of autonomy given to the dog in such studies. This paper presents a study of dogs’ attention between three screens to explore the movement of attention between screens, and between videos in a relatively uncontrolled research environment. The study demonstrates that the method used, which was to be as ‘dog-centred’ as possible, yielded useful data. For the design community it is shown that the dogs were seen to attend mainly to a favoured screen (left and centre in this case) and three of the videos appeared to be preferred over the others. © 2016 Elsevier Ltd",Animal computer interaction; Dog computer interaction; Dogs preference; Gaze tracking; Screen choice,Tracking (position); Animal-computer interactions; Computer interaction; Design community; Dogs preference; Gaze tracking; Interactive technology; Level of autonomies; Research environment; Animals,Article,Final,,Scopus,2-s2.0-85002654781,Movies / Media
Ayasse N.D.; Lash A.; Wingfield A.,"Ayasse, Nicole D. (57193269048); Lash, Amanda (55676768400); Wingfield, Arthur (7004806366)",57193269048; 55676768400; 7004806366,Effort not speed characterizes comprehension of spoken sentences by older adults with mild hearing impairment,2017,Frontiers in Aging Neuroscience,8,JAN,329,,,,55,10.3389/fnagi.2016.00329,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012180422&doi=10.3389%2ffnagi.2016.00329&partnerID=40&md5=1cf7f8c478c068bdf777856a989187d0,"In spite of the rapidity of everyday speech, older adults tend to keep up relatively well in day-to-day listening. In laboratory settings older adults do not respond as quickly as younger adults in off-line tests of sentence comprehension, but the question is whether comprehension itself is actually slower. Two unique features of the human eye were used to address this question. First, we tracked eye-movements as 20 young adults and 20 healthy older adults listened to sentences that referred to one of four objects pictured on a computer screen. Although the older adults took longer to indicate the referenced object with a cursor-pointing response, their gaze moved to the correct object as rapidly as that of the younger adults. Second, we concurrently measured dilation of the pupil of the eye as a physiological index of effort. This measure revealed that although poorer hearing acuity did not slow processing, success came at the cost of greater processing effort. © 2017 Ayasse, Lash and Wingfield.",Aging; Cognitive effort; Eye tracking; Hearing loss; Pupillometry; Speech comprehension,adult; age; aged; Article; auditory stimulation; cognition; cognitive effort; comprehension; computer; controlled study; cornea reflex; disease severity; eye fixation; eye tracking; female; gaze; hearing acuity; hearing impairment; human; human experiment; male; mydriasis; normal human; response time; speech discrimination; stimulus response; very elderly; visual stimulation; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85012180422,Movies / Media
Gu Y.; Wang C.; Bixler R.; D'Mello S.,"Gu, Yi (36801540700); Wang, Chaoli (57203797020); Bixler, Robert (55789867400); D'Mello, Sidney (14053463100)",36801540700; 57203797020; 55789867400; 14053463100,ETGraph: A graph-based approach for visual analytics of eye-tracking data,2017,Computers and Graphics (Pergamon),62,,,1,14,13.0,6,10.1016/j.cag.2016.11.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007239957&doi=10.1016%2fj.cag.2016.11.001&partnerID=40&md5=a5fc528c355ce20d499cf6c5b71d6c27,"Mind wander(ing) (MW) or zoning out is a ubiquitous phenomenon where attention involuntary shifts from task-related processing to task-unrelated thoughts. Unfortunately, MW is a highly internal state so it cannot be readily inferred from overt behaviors and expressions. To help experts investigate mind wanderings, we present a graph-based approach for visual analytics of eye-tracking data, which utilizes the graph representations to illustrate the reading patterns and further help experts detect and verify mind wanderings based on the graph structures and other graph attributes. The input data are collected from multiple participants reading multiple pages of a book on a computer screen. Our approach first clusters fixations into fixation clusters, then creates the eye-tracking graph, i.e., ETGraph, for use in conjunction with the standard page view, time view, and statistics view. The graph view presents a visual representation of the actual reading patterns of a single participant or multiple participants and therefore serves as the main visual interface for exploration and navigation. We design a suite of techniques to help users identify common reading patterns and outliers for analytical reasoning at three different levels of detail: single participant single page, single participant multiple pages, and multiple participants single page. Interactive querying and filtering functions are provided for reducing visual clutter in the visualization and enabling users to answer questions and glean insights. Our tool also facilitates the detection and verification of mind wandering that the experts seek to investigate. We conduct a user study and an expert evaluation to assess the effectiveness of ETGraph in terms of its visual summarization and comparison capabilities. © 2016 Elsevier Ltd",Eye-tracking data; Graph layout; Participant comparison and clustering; Repeated scanpath detection; Saccade outlier detection; Visual analytics,Statistics; Visualization; Analytical reasoning; Graph layout; Graph representation; Interactive querying; Participant comparison and clustering; Scan path; Visual analytics; Visual representations; Eye tracking,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85007239957,Movies / Media
Walter R.,"Walter, Robert (36195691700)",36195691700,Visual Attention Analysis,2017,T-Labs Series in Telecommunication Services,,,,53,63,10.0,0,10.1007/978-981-10-4457-1_6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101127296&doi=10.1007%2f978-981-10-4457-1_6&partnerID=40&md5=22156ae72532b562b757b3ecc5c9ed7c,"While whole body interaction can enrich user experience on public displays, it remains unclear how common visualizations of user representations impact users’ ability to perceive content on the display. In the work covered in this chapter, we use a head-mounted eye tracker to record visual behavior of 25 users interacting with a public display game that uses a silhouette user representation, mirroring the users’ movements. Results from visual attention analysis as well as post-hoc recall and recognition tasks on display contents reveal that visual attention is mostly on the user’s silhouette while peripheral screen elements remain largely unattended. In our experiment, content attached to the user representation attracted significantly more attention than other screen contents, while content placed at the top and bottom of the screen attracted significantly less. Screen contents attached to the user representation were also significantly better remembered than those at the top and bottom of the screen. Our findings provide fundamental insights into visual attention on interactive displays, that help designers to improve the placement of content and messages on the screen. © 2017, Springer Nature Singapore Pte Ltd.",,Behavioral research; Eye movements; User interfaces; Eye trackers; Interactive display; Public display; User movement; Users' experiences; Visual Attention; Visual behavior; Whole-body interactions; Eye tracking,Book chapter,Final,,Scopus,2-s2.0-85101127296,Movies / Media
Hvelplund K.T.,"Hvelplund, Kristian Tangsgaard (56624532900)",56624532900,Translators' use of digital resources during translation,2017,Hermes (Denmark),,56,,71,87,16.0,46,10.7146/hjlcb.v0i56.97205,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033452336&doi=10.7146%2fhjlcb.v0i56.97205&partnerID=40&md5=33e840fe4f251f0e64c13aa1ad9b1270,"This paper presents the fndings from a study on translators' use of digital resources during the translation process. Eye tracking data and screen recording data from 18 professional translators are analysed in order to 1) examine how much time translators spend on digital resource consultation compared with translation drafting and translation revision, 2) examine how eye movements differ between translation drafting, revision and digital resource consultation and 3) investigate what types of digital resources are used by translators. The fndings demonstrate that digital resource consultation constitutes a considerable amount of the translation process. The fndings also show longer fxations and larger pupils during resource consultation, indicating heavier cognitive load, and fnally the study identifes considerable variation in the use of resources between translators.",Allocation of resources; Dictionaries; Digital resources; Eye tracking; Translation; Translation AIDS,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85033452336,Movies / Media
Moya J.; Parodi G.,"Moya, Joaquín (57193954268); Parodi, Giovanni (15756520400)",57193954268; 15756520400,Influence of the Spanish verbal system on 'gameplay' in videogames: Eye-movement recording with eye tracker; [¿Existe influencia del sistema verbal en la 'Jugabilidad' de un videojuego?: Registro de movimientos oculares con eye tracker],2017,Circulo de Linguistica Aplicada a la Comunicacion,69,,,276,305,29.0,0,10.5209/CLAC.55322,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017665387&doi=10.5209%2fCLAC.55322&partnerID=40&md5=6889bd1be794d66bdf57937b86031cca,"Influence of the Spanish verbal system on &#39;gameplay&#39; in videogames: Eye-movement recording with eye tracker. The goal of this article is to determine how the &#39;gameplay&#39; of a group of gamers is influenced by their level of attention to the verbal system in a first-person shooter videogame. To that end, the term videogame is conceptualized as a macrogenre constituted by distinctive features which are grouped in three interacting components: computational, game activity and multimodal or multisemiotic. Among its genres, the first-person shooter can be found. This genre is characterized by a high level of attention required in the center of the screen in light of the object manipulated in that area and a high number of stimuli generated by the visual system. In this study, 29 participants played a muted segment of the videogame Call of Duty: Modern Warfare 2 (Infinity Ward, 2009), in which two types of messages appear: &#39;warnings&#39; and &#39;orders&#39;. Gamers&#39; attention to the messages was recorded by an eye tracking system, while their performance was measured by a simple counting of deaths during their &#39;gameplay&#39;. The results suggest that there is no positive correlation between attention to the verbal system and performance; in other words, the attention to the verbal system is not conducive to a better performance. Moreover, when gamers attend to two systems that are perceived by the same input (in this case, visual input), they split their attention and choose the action. It remains unknown what would occur with the sound activated. © 2017 Joaquín Moya y Giovanni Parodi.",,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85017665387,Movies / Media
Hara M.; Hida O.; Nakajima M.; Osaki M.; Kinoshita S.; Mitsumura K.; Omura T.; Tokunaga E.,"Hara, Mutsuko (56281995500); Hida, Osamu (24068705200); Nakajima, Masami (57191439632); Osaki, Masami (15045409200); Kinoshita, Shingo (36542836300); Mitsumura, Kazuhiro (24491896500); Omura, Takayo (57191440029); Tokunaga, Eikichi (15045943900)",56281995500; 24068705200; 57191439632; 15045409200; 36542836300; 24491896500; 57191440029; 15045943900,Two cases of paraneoplastic neurological syndrome with dizziness,2017,Practica Oto-Rhino-Laryngologica,110,7,,455,460,5.0,0,10.5631/jibirin.110.455,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021801838&doi=10.5631%2fjibirin.110.455&partnerID=40&md5=019ab8503dc98dba27a263cab7cd4784,"Patients with abnormal eye movements and dizziness are often encountered at the department of otolaryngology. We report on 2 patients with dizziness who were referred to our otolaryngology department for examination, and were finally diagnosed as having paraneoplastic neurological syndrome (PNS). In cases with abnormal eye movements, attention should be paid to the neurologic symptoms. PNS should be considered in the differential diagnosis, as it represents an important clue to the presence of an underlying malignant tumor. It is necessary to perform whole-body CT or PET-CT, and tests for tumor markers and anti-neuronal autoantibodies. Since the neurologic symptoms often precede the discovery of the tumor and the initial tests for anti-neuronal autoantibodies could be negative, it is important to repeat these screening tests.",Dizziness; Eye movement; Neurologic symptoms; Paraneoplastic neurological syndrome,,Article,Final,,Scopus,2-s2.0-85021801838,Movies / Media
Zangemeister W.H.; Privitera C.M.,"Zangemeister, Wolfgang H. (7006368690); Privitera, Claudio M. (7004082256)",7006368690; 7004082256,What your eyes tell your brain about art: Insights from neuroaesthetics and scanpath eye movements,2017,What Your Eyes Tell Your Brain about Art: Insights from Neuroaesthetics and Scanpath Eye Movements,,,,1,179,178.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034764535&partnerID=40&md5=f1a84891c430a141b01c7b9048842e3d,"In the last decade, we have observed a continuous increase of interest in eye movement research. According to a recent investigation, eye movements are discussed in over one million publications. The number of publications with eye movement in the title or abstract has been steadily increasing over the years, with over 1,200 papers published alone in 2013. The last decade has also witnessed the emergence of many new sub-disciplines in the field of neuroscience and cognition - one of them is neuroaesthetics, which refers to the [neuro-]science of aesthetic perception of art. The title and contents of our book have been inspired by a very influential research article. It is one of the most cited scientific papers of all time, published in 1959 by a team of neurophysiologists and engineers, Lettvin, McCulloch and Pitts who are considered to be the founders of modern cybernetics. Their article, “What the Frog’s Eye Tells the Frog’s Brain,” refers to the role of internal cortical models in the communication or interfacing of the information in the outside world with the practical contextual task of the viewer. It shows how eye movements are the modality of this communication. The same duality between eye movements and internal models plays a fundamental role in humans. When we look, for example, at art, it explains those neurological processes involved in neuroaesthetics. Our book undertakes this innovative approach to neuroaesthetics. It explains this duality and discusses the communication between the artist and the viewer’s aesthetic perception. It is structured into five chapters. Chapter One discusses the neurology of aesthetics, the idea of art as a form of communication, and explains perception as an active matching between a “top” (the viewer’s mind) and a “down” (the viewer’s sensorial machinery). It goes deep into the philosophical quandary of what beauty is in terms of art. Chapter Two is about eye movements and the scanpath theory of vision perception. It discusses the role of visual attention for controlling active vision, the meaning of mental binding and the analysis of eye movements as the key to understanding aesthetic processes. Chapter Three introduces Claude Shannon’s information theory using it as a matrix into which to embed the top down active vision scanpath theory. The authors explain the main concept of neuroaesthetics as a form of communication mediated by the sequence of eye fixations. Chapter Four discusses art critique: The role of the viewer’s training and expectation, the dilemma of the aesthetics of art versus non-art and how all of this affects the viewing mode. Finally, Chapter Five treats the intimacy of the artistic process, showing the unique implementation of the communicative experience between the artist and the viewer - the relation between a pictorial representation defined by the artist and modes of AWE generated in the viewer during active looking. © 2017 by Nova Science Publishers, Inc.",,,Book,Final,,Scopus,2-s2.0-85034764535,Movies / Media
Matsuno S.; Ito Y.; Akehi K.; Itakura N.; Mizuno T.; Mito K.,"Matsuno, Shogo (55787308800); Ito, Yuta (56298173600); Akehi, Kota (56964223300); Itakura, Naoaki (7003912350); Mizuno, Tota (14030597600); Mito, Kazuyuki (12783245200)",55787308800; 56298173600; 56964223300; 7003912350; 14030597600; 12783245200,A multiple-choice input interface using slanting eye glance,2017,"IEEJ Transactions on Electronics, Information and Systems",137,4,,621,627,6.0,3,10.1541/ieejeiss.137.621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017025964&doi=10.1541%2fieejeiss.137.621&partnerID=40&md5=3ba99be0ab17a6c135c1b8574556ccac,"The eye gaze input is attracting attention as a method for operating an information device with hands-free. However, it is difficult to use gaze input system over a small screen such as a smart device because eye gaze input method must accurately measure gaze positions. In order to solve this problem, we have proposed the eye-glance input method to use operating a small information device like smart phone. The eye-glance input method is able to input multiple-choice using oblique direction reciprocating movement. Accordingly, enabling an input operation that is independent of the screen size. In this paper, we report result of evaluation experiment of numbers inputting of using our developed a Multiple-choice eye-glance input system that utilized electrooculography that amplified via an AC coupling. As the result of experiments, it was found that the average of the input success rate and the average of the input character number per a minute in real-time eye-glance input at the experimental display design was 91.5% and about 15.2 character for 10 subjects. © 2017 The Institute of Electrical Engineers of Japan.",Electrooculography; Eye gaze; Eye movement; Input interface,Electrooculography; Smartphones; Display designs; Evaluation experiments; Eye-gaze; Information devices; Input interface; Input systems; Multiple choice; Oblique direction; Eye movements,Article,Final,,Scopus,2-s2.0-85017025964,Movies / Media
Helmer D.; Geurten B.R.H.; Dehnhardt G.; Hanke F.D.,"Helmer, Desiree (57193222439); Geurten, Bart R.H. (22950880200); Dehnhardt, Guido (6603805216); Hanke, Frederike D. (10439485900)",57193222439; 22950880200; 6603805216; 10439485900,Saccadic movement strategy in common cuttlefish (Sepia officinalis),2017,Frontiers in Physiology,7,JAN,660,,,,19,10.3389/fphys.2016.00660,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011898332&doi=10.3389%2ffphys.2016.00660&partnerID=40&md5=f39ee8496617fa19985a951935afd7bd,"Most moving animals segregate their locomotion trajectories in short burst like rotations and prolonged translations, to enhance distance information from optic flow, as only translational, but not rotational optic flow holds distance information. Underwater, optic flow is a valuable source of information as it is in the terrestrial habitat, however, so far, it has gained only little attention. To extend the knowledge on underwater optic flow perception and use, we filmed the movement pattern of six common cuttlefish (Sepia officinalis) with a high speed camera in this study. In the subsequent analysis, the center of mass of the cuttlefish body was manually traced to gain thrust, slip, and yaw of the cuttlefish movements over time. Cuttlefish indeed performed short rotations, saccades, with rotational velocities up to 343°/s. They clearly separated rotations from translations in line with the saccadic movement strategy documented for animals inhabiting the terrestrial habitat as well as for the semiaquatic harbor seals before. However, this separation only occurred during fin motion. In contrast, during jet propelled swimming, the separation between rotational and translational movements and thus probably distance estimation on the basis of the optic flow field is abolished in favor of high movement velocities. In conclusion, this study provides first evidence that an aquatic invertebrate, the cuttlefish, adopts a saccadic movement strategy depending on the behavioral context that could enhance the information gained from optic flow. © 2017 Helmer, Geurten, Dehnhardt and Hanke.",Cephalopods; Motion vision; Optic flow; Prototypical movements; Saccades; Vision,animal experiment; Article; attention; contact angle; fin (organ); motion; nonhuman; optic flow; orientation; rotation; saccadic eye movement; Sepia officinalis; swimming; velocity,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85011898332,Movies / Media
Olesova V.; Benesova W.; Polatsek P.,"Olesova, Veronika (57195905338); Benesova, Wanda (8598267900); Polatsek, Patrik (57188677032)",57195905338; 8598267900; 57188677032,Visual attention in egocentric field-of-view using RGB-D data,2017,Proceedings of SPIE - The International Society for Optical Engineering,10341,,103410T,,,,5,10.1117/12.2268617,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029924145&doi=10.1117%2f12.2268617&partnerID=40&md5=95d5507ec4ea5d3a77b349f64d9b7284,"Most of the existing solutions predicting visual attention focus solely on referenced 2D images and disregard any depth information. This aspect has always represented a weak point since the depth is an inseparable part of the biological vision. This paper presents a novel method of saliency map generation based on results of our experiments with egocentric visual attention and investigation of its correlation with perceived depth. We propose a model to predict the attention using superpixel representation with an assumption that contrast objects are usually salient and have a sparser spatial distribution of superpixels than their background. To incorporate depth information into this model, we propose three different depth techniques. The evaluation is done on our new RGB-D dataset created by SMI eye-tracker glasses and KinectV2 device. © 2017 SPIE.",egocentric video; eye-tracker glasses; RGB-D data; Saliency map; visual attention,Computer vision; Glass; Pixels; egocentric video; Eye trackers; RGB-D data; Saliency map; Visual Attention; Behavioral research,Conference paper,Final,,Scopus,2-s2.0-85029924145,Movies / Media
Peltier C.; Becker M.W.,"Peltier, Chad (56740831500); Becker, Mark W. (36933635200)",56740831500; 36933635200,Working Memory Capacity Predicts Selection and Identification Errors in Visual Search,2017,Perception,46,1,,109,115,6.0,7,10.1177/0301006616678421,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008256471&doi=10.1177%2f0301006616678421&partnerID=40&md5=044d672ba970206708af29eab6dc6635,"As public safety relies on the ability of professionals, such as radiologists and baggage screeners, to detect rare targets, it could be useful to identify predictors of visual search performance. Schwark, Sandry, and Dolgov found that working memory capacity (WMC) predicts hit rate and reaction time in low prevalence searches. This link was attributed to higher WMC individuals exhibiting a higher quitting threshold and increasing the probability of finding the target before terminating search in low prevalence search. These conclusions were limited based on the methods; without eye tracking, the researchers could not differentiate between an increase in accuracy due to fewer identification errors (failing to identify a fixated target), selection errors (failing to fixate a target), or a combination of both. Here, we measure WMC and correlate it with reaction time and accuracy in a visual search task. We replicate the finding that WMC predicts reaction time and hit rate. However, our analysis shows that it does so through both a reduction in selection and identification errors. The correlation between WMC and selection errors is attributable to increased quitting thresholds in those with high WMC. The correlation between WMC and identification errors is less clear, though potentially attributable to increased item inspection times in those with higher WMC. In addition, unlike Schwark and coworkers, we find that these WMC effects are fairly consistent across prevalence rates rather than being specific to low-prevalence searches. © 2016, © The Author(s) 2016.",attention; low prevalence; visual search; working memory,article; attention; coworker; eye tracking; human; prevalence; reaction time; working memory,Article,Final,,Scopus,2-s2.0-85008256471,Movies / Media
Herman L.; Popelka S.; Hejlova V.,"Herman, Lukas (55864650200); Popelka, Stanislav (55341416700); Hejlova, Vendula (56341011200)",55864650200; 55341416700; 56341011200,Eye-tracking analysis of interactive 3D geovisualization,2017,Journal of Eye Movement Research,10,3,2,,,,25,10.16910/jemr.10.3.2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021781846&doi=10.16910%2fjemr.10.3.2&partnerID=40&md5=e73b1f45587a12d18927b676ff679879,"This paper describes a new tool for eye-tracking data and their analysis with the use of interactive 3D models. This tool helps to analyse interactive 3D models easier than by time-consuming, frame-by-frame investigation of captured screen recordings with superimposed scanpaths. The main function of this tool, called 3DgazeR, is to calculate 3D coordinates (X, Y, Z coordinates of the 3D scene) for individual points of view. These 3D coordinates can be calculated from the values of the position and orientation of a virtual camera and the 2D coordinates of the gaze upon the screen. The functionality of 3DgazeR is introduced in a case study example using Digital Elevation Models as stimuli. The purpose of the case study was to verify the functionality of the tool and discover the most suitable visualization methods for geographic 3D models. Five selected methods are presented in the results section of the paper. Most of the output was created in a Geographic Information System. 3DgazeR works with generic CSV files, SMI eye-tracker, and the low-cost EyeTribe tracker connected with open source application OGAMA. It can compute 3D coordinates from raw data and fixations.",3D analysis tool; 3D model; 3D visualization; Attention; Cartography; Eye-tracking; Geographic information system; Scan path; Usability,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85021781846,Movies / Media
Schrag A.; Siddiqui U.F.; Anastasiou Z.; Weintraub D.; Schott J.M.,"Schrag, Anette (55802371060); Siddiqui, Uzma Faisal (57192304955); Anastasiou, Zacharias (57192316585); Weintraub, Daniel (57203216133); Schott, Jonathan M (7103177641)",55802371060; 57192304955; 57192316585; 57203216133; 7103177641,Clinical variables and biomarkers in prediction of cognitive impairment in patients with newly diagnosed Parkinson's disease: a cohort study,2017,The Lancet Neurology,16,1,,66,,,334,10.1016/S1474-4422(16)30328-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003791553&doi=10.1016%2fS1474-4422%2816%2930328-3&partnerID=40&md5=308e89f08d2b37280f722361e04aed49,"Background Parkinson's disease is associated with an increased incidence of cognitive impairment and dementia. Predicting who is at risk of cognitive decline early in the disease course has implications for clinical prognosis and for stratification of participants in clinical trials. We assessed the use of clinical information and biomarkers as predictive factors for cognitive decline in patients with newly diagnosed Parkinson's disease. Methods The Parkinson's Progression Markers Initiative (PPMI) study is a cohort study in patients with newly diagnosed Parkinson's disease. We evaluated cognitive performance (Montreal Cognitive Assessment [MoCA] scores), demographic and clinical data, APOE status, and biomarkers (CSF and dopamine transporter [DAT] imaging results). Using change in MoCA scores over 2 years, MoCA scores at 2 years' follow-up, and a diagnosis of cognitive impairment (combined mild cognitive impairment or dementia) at 2 years as outcome measures, we assessed the predictive values of baseline clinical variables and separate or combined additions of APOE status, DAT imaging, and CSF biomarkers. We did univariate and multivariate linear analyses with MoCA change scores between baseline and 2 years, and with MoCA scores at 2 years as dependent variables, using backwards linear regression analysis. Additionally, we constructed a prediction model for diagnosis of cognitive impairment using logistic regression analysis. Findings 390 patients with Parkinson's disease recruited between July 1, 2010, and May 31, 2013, and for whom data on MoCA scores at baseline and 2 years were available. In multivariate analyses, baseline age, University of Pennsylvania Smell Inventory Test (UPSIT) scores, CSF amyloid — (Aβ42) to t-tau ratio, and APOE status were associated with change in MoCA scores over time. Baseline age, MoCA and UPSIT scores, and CSF Aβ42 to t-tau ratio were associated with MoCA score at 2 years (using a backwards p-removal threshold of 0·1). Accuracy of prediction of cognitive impairment using age alone (area under the curve 0·68, 95% CI 0·60–0·76) significantly improved by addition of clinical scores (UPSIT, Rapid Eye Movement Sleep Behaviour Disorder Screening Questionnaire [RBDSQ], Geriatric Depression Scale, and Movement Disorder Society Unified Parkinson's Disease Rating Scale motor scores; 0·76, 0·68–0·83), CSF variables (0·74, 0·68–0·81), or DAT imaging results (0·76, 0·68–0·83). In combination, the five variables showing the most significant associations with cognitive impairment (age, UPSIT, RBDSQ, CSF Aβ42, and caudate uptake on DAT imaging) allowed prediction of cognitive impairment at 2 years (0·80, 0·74–0·87; p=0·0003 compared to age alone). Interpretation In newly diagnosed Parkinson's disease, the occurrence of cognitive impairment at 2 year follow-up can be predicted with good accuracy using a model combining information on age, non-motor assessments, DAT imaging, and CSF biomarkers. Funding None. © 2016 Elsevier Ltd",,Aged; Amyloid beta-Peptides; Apolipoproteins E; Biomarkers; Cognition Disorders; Cohort Studies; Disease Progression; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Outcome Assessment (Health Care); Parkinson Disease; Peptide Fragments; Predictive Value of Tests; ROC Curve; Severity of Illness Index; tau Proteins; amyloid beta protein[1-42]; apolipoprotein E; biological marker; dopamine transporter; tau protein; amyloid beta protein; amyloid beta-protein (1-42); apolipoprotein E; biological marker; peptide fragment; tau protein; accuracy; adult; age; Article; behavior disorder assessment; cognitive defect; controlled study; dementia; dementia assessment; female; follow up; Geriatric Depression Scale; human; major clinical study; male; mild cognitive impairment; Montreal cognitive assessment; neuroimaging; Parkinson disease; patient information; prediction; predictive value; priority journal; protein cerebrospinal fluid level; Rapid Eye Movement Sleep Behaviour Disorder Screening Questionnaire; Unified Parkinson Disease Rating Scale; University of Pennsylvania Smell Inventory Test score; aged; cerebrospinal fluid; Cognition Disorders; cohort analysis; complication; disease course; genetics; metabolism; middle aged; neuropsychological test; outcome assessment; Parkinson disease; receiver operating characteristic; severity of illness index,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85003791553,Movies / Media
Garry C.; Cilia F.; Landuré M.; Aguillon-Hernandez N.; Rovira K.; Brisson J.,"Garry, Cécile (57063070700); Cilia, Federica (57200855464); Landuré, Marie (57208719218); Aguillon-Hernandez, Nadia (56281274500); Rovira, Katia (13002940500); Brisson, Julie (36088422800)",57063070700; 57200855464; 57208719218; 56281274500; 13002940500; 36088422800,A longitudinal study of social orienting in preschool children with ASD; [Étude longitudinale de l'orientation sociale chez les enfants avec TSA d'âge préscolaire],2017,Enfance,2017,4,,477,481,4.0,1,10.3917/enf1.174.0477,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065604474&doi=10.3917%2fenf1.174.0477&partnerID=40&md5=12f2ea51d12ef26ce1ef69f3158cddcc,"Children with ASD would show less social oriented behaviors, as demonstrated in ecological and also experimental situations. The main goal of this study is to understand the connection between the development of social orienting skills in these two situations. Once a month within a year, 13 preschool children with ASD were filmed during daily classroom interactions in order to study visual attention behaviors directed to adults (The Observer XT10 Noldus). In addition, these children have seen faces and objects in a preference task using eye tracking. On the longitudinal plane, a reduction of fixation count to face in eye-tracking task is related to an improvement of social orienting total duration in class. Children's progression can be related to their baseline score on the task and to their scores of ECSC scales at the beginning of the study. © NecPlus. Tous droits réservés pour tous pays.",Development; Individual profiles; Preschool children with asd; Social orienting,,Article,Final,,Scopus,2-s2.0-85065604474,Movies / Media
Teixeira C.S.C.; O'Brien S.,"Teixeira, Carlos S. C. (56200632300); O'Brien, Sharon (15925957200)",56200632300; 15925957200,Investigating the cognitive ergonomic aspects of translation tools in a workplace setting,2017,Translation Spaces(Netherland),6,1,,79,103,24.0,44,10.1075/ts.6.1.05tei,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031695918&doi=10.1075%2fts.6.1.05tei&partnerID=40&md5=0a6962911ce620c90e92ad6b992c156a,"This paper reports on an empirical study that investigates the translation process in the workplace from a cognitive ergonomic perspective. In particular, the interaction between ten translators employed by a language service provider and the tools they deploy are examined. To that end, we recorded the translators' workplace activities using keystroke logging, screen recording and eye tracking, combined with short retrospective interviews. We analysed their behaviour in terms of how they switched between the two screens on their desks, how they used different tools and where they invested their visual attention. Data related to productivity and quality are also presented. Among other findings, our data reveal that validation searches for terms and general expressions lead to considerable tool and task switching among professional translators. © 2017 John Benjamins Publishing Company.",CAT tools; Cognitive ergonomics; Eye tracking; Human-computer interaction; MemoQ; Terminology search; Translation technology; Workplace study,,Article,Final,,Scopus,2-s2.0-85031695918,Movies / Media
Chakraborty G.; Cheng L.C.; Chen L.S.; Bornand C.,"Chakraborty, Goutam (35565864200); Cheng, L.C. (57194073936); Chen, L.S. (35368069900); Bornand, Cedric (25724084800)",35565864200; 57194073936; 35368069900; 25724084800,Selecting important features related to efficacy of mobile advertisements,2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10191 LNAI,,,728,737,9.0,3,10.1007/978-3-319-54472-4_68,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018548275&doi=10.1007%2f978-3-319-54472-4_68&partnerID=40&md5=0cd010abf65c8baa71057e908634ef24,"With growing use of mobile devices, mobile advertisement is playing increasingly important role. It can reach potential customers at any time and place based on individual’s real-time needs. Factors for success of mobile advertisements are different from similar media like Television or large screen monitors. We investigated the important factors to enhance click through rate (CTR) for a mobile Ad. As CTR is directly related to revenue, it is used to measure success of a mobile Ad. To identify important factors that determine CTR, we took two approaches - one directly asking subjects, and the other, from analyzing their selective attention. Subjects were asked to respond to questionnaire. From the responses important features were selected using Least Absolute Shrinkage and Selection Operator (LASSO). For the other approach, selective attention was inferred from subjects’ eye-tracking data. When results from two approaches were compared, the findings were similar. Those features will be helpful for designing Ads favored by users, as well as could earn more revenues. © Springer International Publishing AG 2017.",Eye-tracking; LASSO; Mobile advertisement; Selective attention,Database systems; Click-through rate; Eye-tracking; Important features; LASSO; Least absolute shrinkage and selection operators; Mobile advertisement; Potential customers; Selective attention; Research laboratories,Conference paper,Final,,Scopus,2-s2.0-85018548275,Movies / Media
Enns J.T.; Brennan A.A.; Whitwell R.L.,"Enns, James T. (7005300992); Brennan, Allison A. (37025709500); Whitwell, Robert L. (23037707900)",7005300992; 37025709500; 23037707900,Attention in action and perception: Unitary or separate mechanisms of selectivity?,2017,Progress in Brain Research,236,,,25,52,27.0,1,10.1016/bs.pbr.2017.08.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029158385&doi=10.1016%2fbs.pbr.2017.08.004&partnerID=40&md5=68c47cb49cfd5ec57a8117524d1fd921,"What is the relation between the two visual stream hypothesis and selective visual attention? In this chapter, we first consider this question at a theoretical level before presenting an example of work from our lab that examines the question: Under what conditions does the emotional content of a visual object influence visually guided action? Previous research has demonstrated that fear can influence perception, both consciously and unconsciously, but it is unclear when fear influences visually guided action. The study tested participants with varying degrees of spiderphobia on two visually guided pointing tasks, while manipulating the emotional valence of the target (positive and negative) and the cognitive load of the participant (single vs dual task). Participants rapidly moved their finger from a home position to a suddenly appearing target image on a touch screen. The images were emotionally negative (e.g., spiders and scorpions) or positive (e.g., flowers and food). In order to test the effect of emotional valence on the online control of the reach, the target either remained static or jumped to a new location. In both the single and dual tasks, a stream of digits were presented on the screen near the finger's starting location, but only in the dual task were participants asked to identify a letter somewhere in the stream. In the single task, increased fear of spiders reduced the speed and accuracy of the movement. In the dual task, increased fear impaired letter identification, but pointing actions were now equally efficient for low- and high-fear participants. These results imply that the finger's autopilot is influenced by emotional content only when attention can be fully devoted to the identification of the emotion-evoking images. As such, the results support the view that the mechanisms of selection are not the same in the two visual streams. © 2017 Elsevier B.V.",Attention; Emotion; Reaching; Two visual stream hypothesis; Visually guided action,Adult; Attention; Emotions; Female; Humans; Male; Phobic Disorders; Psychomotor Performance; Visual Perception; Young Adult; accuracy; adult; cognition; controlled study; dual-task performance (test); emotion; emotionality; eye movement; fear; female; flower; food; home; human; human experiment; index finger; male; negative feedback; normal human; online monitoring; positive feedback; scorpion; selective attention; semantic memory; spider; spider phobia; task performance; vision; visual attention; visual evoked potential; visual system; young adult; attention; pathophysiology; phobia; physiology; psychomotor performance; vision,Book chapter,Final,,Scopus,2-s2.0-85029158385,Movies / Media
Raudonis V.; Maskeliūnas R.; Stankevičius K.; Damaševičius R.,"Raudonis, Vidas (24723196100); Maskeliūnas, Rytis (27467587600); Stankevičius, Karolis (57195286150); Damaševičius, Robertas (6603451290)",24723196100; 27467587600; 57195286150; 6603451290,"Gender, age, colour, position and stress: How they influence attention at workplace?",2017,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),10408 LNCS,,,248,264,16.0,14,10.1007/978-3-319-62404-4_19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026782401&doi=10.1007%2f978-3-319-62404-4_19&partnerID=40&md5=4789aca17b76dec374e7e76b49bccf9b,"We explore the relationship between attention and action, and focus on human reaction to stress in the Supervisory Control and Data Acquisition (SCADA) based Human Computer Interface (HCI) environment aiming to measure the reaction time and warn against attention deficit. To provoke human reaction we simulate several provocative situations mimicking real-world accidents while working on the industrial production line. During the simulation of the industrial line control, the subjects are presented on screen with affective visual stimuli imitating the possible accident and the reaction of subjects is tracked with a gaze tracker. We measure a subjects’ response time from stimuli onset to the eye fixation (gaze time) and to the pressing of “line stop” button (press time). The reaction time patterns are analysed with respect to subject’s gender, age, colour and position of stop sign. The results confirm the significance of gender, age, sign colour and position factors. © Springer International Publishing AG 2017.",Attention focus; Cognitive; Gaze-tracking; SCADA HCI; Stress,Accidents; Color; Data acquisition; Human computer interaction; Human reaction time; Stresses; Attention deficit; Attention focus; Cognitive; Human computer interfaces; Industrial production lines; Real world accidents; Supervisory control and data acquisition; Visual stimulus; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85026782401,Movies / Media
Palma M.A.; Behe B.K.; Hall C.R.; Huddleston P.T.; Fernandez T.,"Palma, Marco A. (16040447300); Behe, Bridget K. (6603673063); Hall, Charles R. (7403016403); Huddleston, Patricia T. (6603683811); Fernandez, Tom (58437112400)",16040447300; 6603673063; 7403016403; 6603683811; 58437112400,Tracking position premiums in discrete choice experiments,2016,Applied Economics Letters,23,18,,1269,1273,4.0,5,10.1080/13504851.2016.1150941,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959213003&doi=10.1080%2f13504851.2016.1150941&partnerID=40&md5=9ad0e2789da4829132ac7606fb884ac7,"Eye-tracking was used to identify potential location ‘premiums’ in discrete choice experiments for certain positions in the computer screen in terms of increasing the visibility, general interest and attention of respondents. The search dynamics to choose the optimal alternative closely resembled the natural process of reading in a ‘Z’ motion going from left to right and top to bottom. An empirical application of water conservation showed that conservation practices in the production process were not statistically different than zero. On the other hand, respondents are interested in water conservation practices in their landscapes where they benefit directly from the sustainable practice. © 2016 Taylor & Francis.",Eye-tracking; mixlogit; water conservation practices; willingness-to-pay,conservation planning; discrete choice analysis; sustainability; water management; willingness to pay,Article,Final,,Scopus,2-s2.0-84959213003,Movies / Media
Zhang X.; Liu S.,"Zhang, Xueqing (57195068590); Liu, Sanya (24481510400)",57195068590; 24481510400,Understanding reading comprehension in multi-display presenting system: Visual distribution and cognitive effect,2017,Communications in Computer and Information Science,714,,,207,214,7.0,4,10.1007/978-3-319-58753-0_32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025150146&doi=10.1007%2f978-3-319-58753-0_32&partnerID=40&md5=bb58f68a34a7d4a74fb86f129bc512a8,"This study aims to investigate students’ reading comprehension and cognitive load changes under multi-display presenting system in an experimental setting. It is part of the project that has been established in order to develop multi-display interaction system in real classroom for all students. A dual-screen presenting system, two-adjacent screens for presentation, was utilized to facilitate students’ reading compared to single-screen. The presentation was set up in the formats of text-only, text-image, and image-only. 34 participants were tested from Central China Normal University. Their visual distribution and attention levels were recorded by means of SMI’s eye-tracking device and NeuroSky’s EEG device. The results proved that the attention levels were increased on the dual-screen system. The reading formats of text-only or text-image took more fixation time and attracted more attention on both single- and dual-screen system. Multi-display presenting system could have a positive effect on Chinese reading comprehension and increase the students’ attention levels. © Springer International Publishing AG 2017.",Cognition; Instructional design; Multi-display; Reading comprehension,Education; Students; Cognition; Cognitive effects; Cognitive loads; Eye tracking devices; Instructional designs; Multi displays; Multi-display interactions; Reading comprehension; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85025150146,Movies / Media
Goodwin A.; Salomone S.; Bolton P.; Charman T.; Jones E.J.H.; Pickles A.; Robinson E.; Smith T.; Sonuga-Barke E.J.S.; Wass S.; Johnson M.H.,"Goodwin, Amy (57192697030); Salomone, Simona (55596710100); Bolton, Patrick (22946425500); Charman, Tony (7006913774); Jones, Emily J.H. (13408335100); Pickles, Andrew (35974712300); Robinson, Emily (57189463801); Smith, Tim (55568512084); Sonuga-Barke, Edmund J.S. (7005682785); Wass, Sam (36169394400); Johnson, Mark H. (36072829800)",57192697030; 55596710100; 22946425500; 7006913774; 13408335100; 35974712300; 57189463801; 55568512084; 7005682785; 36169394400; 36072829800,Attention training for infants at familial risk of ADHD (INTERSTAARS): Study protocol for a randomised controlled trial,2016,Trials,17,1,608,,,,21,10.1186/s13063-016-1727-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007488762&doi=10.1186%2fs13063-016-1727-0&partnerID=40&md5=fad1cb6a1ba7db9bae9f467a3d7c2a8a,"Background: Attention deficit hyperactivity disorder (ADHD) is a prevalent neurodevelopmental disorder that can negatively impact on an individual's quality of life. It is pathophysiologically complex and heterogeneous with different neuropsychological processes being impaired in different individuals. Executive function deficits, including those affecting attention, working memory and inhibitory control, are common. Cognitive training has been promoted as a treatment option, based on the notion that by strengthening the neurocognitive networks underlying these executive processes, ADHD symptoms will also be reduced. However, if implemented in childhood or later, when the full disorder has become well-established, cognitive training has only limited value. INTERSTAARS is a trial designed to test a novel approach to intervention, in which cognitive training is implemented early in development, before the emergence of the disorder. The aim of INTERSTAARS is to train early executive skills, thereby increasing resilience and reducing later ADHD symptoms and associated impairment. Methods/design: Fifty 10-14-month-old infants at familial risk of ADHD will participate in INTERSTAARS. Infants will be randomised to an intervention or a control group. The intervention aims to train early attention skills by using novel eye-tracking technology and gaze-contingent training paradigms. Infants view animated games on a screen and different events take place contingent on where on the screen the infant is looking. Infants allocated to the intervention will receive nine weekly home-based attention training sessions. Control group infants will also receive nine weekly home visits, but instead of viewing the training games during these visits they will view non-gaze-contingent age-appropriate videos. At baseline and post treatment, infant attention control will be assessed using a range of eye-tracking, observational, parent-report and neurophysiological measures. The primary outcome will be a composite of eye-tracking tasks used to assess infant attention skills. Follow-up data will be collected on emerging ADHD symptoms when the infants are 2 and 3 years old. Discussion: This is the first randomised controlled trial to assess the potential efficacy of cognitive training as a prevention measure for infants at familial risk of ADHD. If successful, INTERSTAARS could offer a promising new approach for developing early interventions for ADHD. Trial registration: International Standard Randomised Controlled Trial registry: ISRCTN37683928. Registered on 22 June 2015. © 2016 The Author(s).",ADHD; Attention; Cognitive training; Early intervention; Familial risk; Infancy,"Age Factors; Attention; Attention Deficit Disorder with Hyperactivity; Child Development; Child, Preschool; Clinical Protocols; Cognition; Cognitive Therapy; Double-Blind Method; Early Medical Intervention; Executive Function; Female; Genetic Predisposition to Disease; Heredity; Humans; Infant; Infant Behavior; London; Male; Psychology, Child; Research Design; Resilience, Psychological; Time Factors; Treatment Outcome; Video Games; Visual Perception; Article; attention; attention deficit disorder; behavior change; behavior therapy; child behavior; clinical article; clinical protocol; controlled study; disease association; executive function; eye tracking; follow up; home care; human; infant; medical education; observational study; outcome assessment; randomized controlled trial; risk assessment; risk factor; sensitivity analysis; skill; symptom; task performance; therapy effect; age; attention; attention deficit disorder; child behavior; child development; child psychology; clinical trial; cognition; cognitive therapy; double blind procedure; early intervention; England; female; genetic predisposition; genetics; heredity; male; methodology; multicenter study; phase 2 clinical trial; preschool child; procedures; psychological resilience; psychology; time factor; treatment outcome; video game; vision",Article,Final,,Scopus,2-s2.0-85007488762,Movies / Media
Ayneto A.; Sebastian-Galles N.,"Ayneto, Alba (56610307700); Sebastian-Galles, Nuria (6701832236)",56610307700; 6701832236,The influence of bilingualism on the preference for the mouth region of dynamic faces,2017,Developmental Science,20,1,e12446,,,,47,10.1111/desc.12446,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971411306&doi=10.1111%2fdesc.12446&partnerID=40&md5=aca10900e24a1b30b6644182ad6f72cd,"Bilingual infants show an extended period of looking at the mouth of talking faces, which provides them with additional articulatory cues that can be used to boost the challenging situation of learning two languages (Pons, Bosch & Lewkowicz, 2015). However, the eye region also provides fundamental cues for emotion perception and recognition, as well as communication. Here, we explored whether the adaptations resulting from learning two languages are specific to linguistic content or if they also influence the focus of attention when looking at dynamic faces. We recorded the eye gaze of bilingual and monolingual infants (8- and 12-month-olds) while watching videos of infants and adults portraying different emotional states (neutral, crying, and laughing). When looking at infant faces, bilinguals looked longer at the mouth region as compared to monolinguals regardless of age. However, when presented with adult faces, 8-month-old bilingual infants looked longer at the mouth region and less at the eye region compared to 8-month-old monolingual infants, but no effect of language exposure was found at 12 months of age. These findings suggest that the bias to the mouth region in bilingual infants at 8 months of age can be generalized to other audiovisual dynamic faces that do not contain linguistic information. We discuss the potential implications of such bias in early social and communicative development. © 2016 John Wiley & Sons Ltd",,"Attention; Cues; Face; Facial Expression; Fixation, Ocular; Humans; Infant; Mouth; Multilingualism; association; attention; eye fixation; face; facial expression; human; infant; mouth; multilingualism; physiology",Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84971411306,Movies / Media
Fox W.,"Fox, Wendy (57202038756)",57202038756,Integrated titles: An improved viewing experience?,2016,Eyetracking and Applied Linguistics,,,,5,29,24.0,45,10.17169/langsci.b108.233,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199017039&doi=10.17169%2flangsci.b108.233&partnerID=40&md5=5480332acb4b06e96493323de6e745d3,"While there are a few examples of (sub)titles placed individually in the image as a means of translation of an additional language into the film's main language, this practice has not yet been used to commercially translate a complete film for a foreign target audience. Using eye tracking data, this study examines to what extent the placement and design of (sub)titles affect reading time and the visual perception of the image. The applied placement strategies were based on the undistracted focus points of 14 English native participants and image composition principles from film studies. Additional 31 German participants with little or no knowledge of English watched the English film with traditional subtitles or integrated titles. The results of the eye tracking data analysis indicate that, while reaction time (time to first fixation) increases, the reading time (total visit duration) for integrated titles decreases, the viewers are less likely to focus on the title area before the title appears and their focus resembles the undistracted gaze behaviour of the native participants to a much greater degree. Additionally, the split attention between image and title shifts towards the image. Integrated titles appear to motivate the viewer to return to the focal points faster and spend more time exploring the image in between titles. Their placement allows for shorter saccades and thereby decreases the time in which no visual information is obtained. © 2016, the authors.",,,Book chapter,Final,,Scopus,2-s2.0-85199017039,Movies / Media
Kleim B.; Wysokowsky J.; Schmid N.; Seifritz E.; Rasch B.,"Kleim, Birgit (22835121500); Wysokowsky, Julia (57192252669); Schmid, Nuria (57192234069); Seifritz, Erich (57203074345); Rasch, Björn (13607629500)",22835121500; 57192252669; 57192234069; 57203074345; 13607629500,Effects of sleep after experimental trauma on intrusive emotional memories,2016,Sleep,39,12,,2125,2132,7.0,97,10.5665/sleep.6310,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002375743&doi=10.5665%2fsleep.6310&partnerID=40&md5=26bd11397d007157c807b73f3b3071f1,"Study Objectives: To investigate sleep's effect in the immediate aftermath of experiencing an analog trauma in the laboratory on reducing intrusive emotional memory formation. Methods: Sixty-five healthy women were exposed to an experimental laboratory trauma. They viewed a neutral and a trauma film in the laboratory and were randomly allocated to either a group that slept following film viewing or a group that remained awake. Sleep was recorded with electroencephalogram in a subgroup of participants in the sleep group. All participants recorded intrusive memories in the week following the film. Results: The sleep group experienced fewer and less distressing intrusive trauma memories compared to the wake group. These effects were particularly evident toward the end of the week. Duration spent in stage N2 as opposed to light N1 sleep, a higher number of fast parietal sleep spindles and a lower rapid eye movement sleep density predicted intrusion frequency. Conclusions: Our results have clinical implications and set the ground for early-intervention sleep studies following trauma and prevention of chronic posttrauma disorders.",Emotional memory; Intrusion; Memory consolidation; PTSD; Sleep; Trauma,"Adult; Arousal; Attention; Female; Humans; Memory; Memory, Episodic; Sleep; Stress Disorders, Post-Traumatic; Violence; Wounds and Injuries; Young Adult; adult; Article; comparative study; electroencephalogram; electroencephalography; emotion; experimental injury; female; human; human experiment; intrusive emotional memory; memory; priority journal; REM sleep; sleep; sleep quality; sleep spindle; sleep stage; sleep time; slow wave sleep; wakefulness; young adult; arousal; attention; controlled study; episodic memory; injury; memory; posttraumatic stress disorder; psychology; randomized controlled trial; violence",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85002375743,Movies / Media
Kajimura S.; Nomura M.,"Kajimura, Shogo (55743744400); Nomura, Michio (57936333000)",55743744400; 57936333000,When we cannot speak: Eye contact disrupts resources available to cognitive control processes during verb generation,2016,Cognition,157,,,352,357,5.0,23,10.1016/j.cognition.2016.10.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991628196&doi=10.1016%2fj.cognition.2016.10.002&partnerID=40&md5=c0416df92a1f14987a3db856bcb9855e,"Although eye contact and verbal processing appear independent, people frequently avert their eyes from interlocutors during conversation. This suggests that there is interference between these processes. We hypothesized that such interference occurs because both processes share cognitive resources of a domain-general system and explored the influence of eye contact on simultaneous verb generation processes (i.e., retrieval and selection). In the present experiment, viewing a movie of faces with eyes directed toward the viewer delayed verbal generation more than a movie of faces with averted eyes; however, this effect was only present when both retrieval and selection demands were high. The results support the hypothesis that eye contact shares domain-general cognitive resource with verb generation. This further indicates that a full understanding of functional and dysfunctional communication must consider the interaction and interference of verbal and non-verbal channels. © 2016 Elsevier B.V.",Brain; Cognitive control; Eye contact; Verb generation; Verbal communication,Adult; Cognition; Executive Function; Eye Movements; Female; Humans; Linguistics; Male; Reaction Time; Social Behavior; Speech; Young Adult; adult; Article; executive function; facial expression; female; human; human experiment; Likert scale; male; normal human; power analysis; priority journal; task performance; verb generation task; verbal communication; visual-spatial ability test; young adult; cognition; eye movement; linguistics; reaction time; social behavior; speech,Article,Final,,Scopus,2-s2.0-84991628196,Movies / Media
Williams I.M.; Schofield P.; Khade N.; Abel L.A.,"Williams, Isla M. (35613129300); Schofield, Peter (16944064200); Khade, Neha (57192010380); Abel, Larry A. (7103217203)",35613129300; 16944064200; 57192010380; 7103217203,"Divided visual attention: A comparison of patients with multiple sclerosis and controls, assessed with an optokinetic nystagmus suppression task",2016,Journal of Clinical Neuroscience,34,,,187,192,5.0,2,10.1016/j.jocn.2016.06.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995872858&doi=10.1016%2fj.jocn.2016.06.015&partnerID=40&md5=65fda267fdb11d2ea9e4b4e7aa165499,"Multiple sclerosis (MS) frequently causes impairment of cognitive function. We compared patients with MS with controls on divided visual attention tasks. The MS patients’ and controls’ stare optokinetic nystagmus (OKN) was recorded in response to a 24°/s full field stimulus. Suppression of the OKN response, judged by the gain, was measured during tasks dividing visual attention between the fixation target and a second stimulus, central or peripheral, static or dynamic. All participants completed the Audio Recorded Cognitive Screen. MS patients had lower gain on the baseline stare OKN. OKN suppression in divided attention tasks was the same in MS patients as in controls but in both groups was better maintained in static than in dynamic tasks. In only dynamic tasks, older age was associated with less effective OKN suppression. MS patients had lower scores on a timed attention task and on memory. There was no significant correlation between attention or memory and eye movement parameters. Attention, a complex multifaceted construct, has different neural combinations for each task. Despite impairments on some measures of attention, MS patients completed the divided visual attention tasks normally. © 2016 Elsevier Ltd",Divided visual attention; Multiple sclerosis; OKN,"Adult; Attention; Eye Movements; Female; Fixation, Ocular; Humans; Male; Memory; Middle Aged; Multiple Sclerosis; Nystagmus, Optokinetic; Psychomotor Performance; Visual Perception; adult; Article; clinical article; eye movement; female; human; male; memory consolidation; multiple sclerosis; optokinetic nystagmus; priority journal; scoring system; stimulus response; task performance; visual attention; visual memory; visual stimulation; attention; comparative study; eye fixation; memory; middle aged; multiple sclerosis; psychology; psychomotor performance; vision",Article,Final,,Scopus,2-s2.0-84995872858,Movies / Media
Leng J.; Zhu J.; Wang X.; Gu X.,"Leng, Jing (56534653100); Zhu, Jiayu (57192591792); Wang, Xiaoting (57192590551); Gu, Xiaoqing (26323563700)",56534653100; 57192591792; 57192590551; 26323563700,Identifying the potential of danmaku video from eye gaze data,2016,"Proceedings - IEEE 16th International Conference on Advanced Learning Technologies, ICALT 2016",,,7756979,288,292,4.0,26,10.1109/ICALT.2016.155,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006851734&doi=10.1109%2fICALT.2016.155&partnerID=40&md5=05990ffa6aeb5baa74a1d6c5804e7b36,"Video-based learning has gained popularity in higher education in recent years. Danmaku video is a kind of video where the screen is overlaid with user comments. In this study, the user comments consist of ideas and explanations about important concepts in the video, thus providing domain-specific knowledge and reducing the cognitive load for comprehension. This study tries to understand the effect of the danmaku video compared to with the normal video. Two groups of sophomore students (N= 20) were exposed to digital videos with or without danmaku. Both groups took part in a pre- And post-test on the topic of the given video. Time-locked eye movements were recorded to characterize participants' attention allocation to the Area of Interest (AOIs) consisting of danmaku, subtitles and teacher's face across the learning period. The results showed that danmaku video group outperformed the normal video group based on the increment of pre- And post-tests. Further, the percentage of fixation duration on each of the AOI was analyzed, and a significant difference was found in the amount of attention paid on different AOIs. The purpose of this study is focused on exploring the effects of Danmaku video in improving students' learning outcomes. © 2016 IEEE.",Danmaku video; Eye gaze data; Video-based learning,Education; Engineering education; Eye movements; Multimedia systems; Teaching; Area of interest; Danmaku video; Domain-specific knowledge; Eye-gaze; Fixation duration; Higher education; Learning outcome; Video-based learning; Computer graphics,Conference paper,Final,,Scopus,2-s2.0-85006851734,Movies / Media
Watanabe T.; Tsutou K.; Saito K.; Ishida K.; Tanabe S.; Nojima I.,"Watanabe, Tatsunori (56726991900); Tsutou, Kotaro (57190346911); Saito, Kotaro (57190338886); Ishida, Kazuto (57190215555); Tanabe, Shigeo (14054974400); Nojima, Ippei (54927390900)",56726991900; 57190346911; 57190338886; 57190215555; 14054974400; 54927390900,Performance monitoring and response conflict resolution associated with choice stepping reaction tasks,2016,Experimental Brain Research,234,11,,3355,3365,10.0,12,10.1007/s00221-016-4733-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979263687&doi=10.1007%2fs00221-016-4733-2&partnerID=40&md5=df691b577dfd9dc2f6b030319e524a03,"Choice reaction requires response conflict resolution, and the resolution processes that occur during a choice stepping reaction task undertaken in a standing position, which requires maintenance of balance, may be different to those processes occurring during a choice reaction task performed in a seated position. The study purpose was to investigate the resolution processes during a choice stepping reaction task at the cortical level using electroencephalography and compare the results with a control task involving ankle dorsiflexion responses. Twelve young adults either stepped forward or dorsiflexed the ankle in response to a visual imperative stimulus presented on a computer screen. We used the Simon task and examined the error-related negativity (ERN) that follows an incorrect response and the correct-response negativity (CRN) that follows a correct response. Error was defined as an incorrect initial weight transfer for the stepping task and as an incorrect initial tibialis anterior activation for the control task. Results revealed that ERN and CRN amplitudes were similar in size for the stepping task, whereas the amplitude of ERN was larger than that of CRN for the control task. The ERN amplitude was also larger in the stepping task than the control task. These observations suggest that a choice stepping reaction task involves a strategy emphasizing post-response conflict and general performance monitoring of actual and required responses and also requires greater cognitive load than a choice dorsiflexion reaction. The response conflict resolution processes appear to be different for stepping tasks and reaction tasks performed in a seated position. © 2016, Springer-Verlag Berlin Heidelberg.",Anticipatory postural adjustments; Choice stepping reaction task; Correct-response negativity; Electroencephalography; Error-related negativity,Adult; Analysis of Variance; Choice Behavior; Conflict (Psychology); Electroencephalography; Electromyography; Evoked Potentials; Female; Humans; Male; Photic Stimulation; Posture; Psychomotor Performance; Reaction Time; Young Adult; adult; ankle; Article; artifact; brain cortex; clinical article; conflict management; electroencephalography; event related potential; eye movement; female; human; male; priority journal; response time; task performance; visual stimulation; young adult; analysis of variance; body position; conflict; decision making; electromyography; evoked response; photostimulation; physiology; psychomotor performance; reaction time,Article,Final,,Scopus,2-s2.0-84979263687,Movies / Media
Wilson K.A.; Heinselman P.L.; Kang Z.,"Wilson, Katie A. (57192714640); Heinselman, Pamela L. (6507215763); Kang, Ziho (56486906100)",57192714640; 6507215763; 56486906100,Exploring applications of eye tracking in operational meteorology research,2016,Bulletin of the American Meteorological Society,97,11,,2019,2025,6.0,10,10.1175/BAMS-D-15-00148.1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007613445&doi=10.1175%2fBAMS-D-15-00148.1&partnerID=40&md5=8ad2a88e10f3c24e85f6e2b6be065b68,"Eye tracking was used within the meteorology community to assess communications of weather information to the public. Researchers used eye tracking to study the impact of a weathercaster�s gesturing during a televised weather forecast on viewers� attention. Their analysis revealed that while gesturing did not impact viewers� retention of information, it did redirect viewers� attention to different elements on the screen. Eye tracking was also Used to investigate the impact of different legend colors and content in hurricane storm surge graphics on participants� ability to accurately interpret threat levels.",,Hurricanes; Weather forecasting; Hurricane storm surge; Threat levels; Weather information; Eye tracking,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85007613445,Movies / Media
Coco M.I.; Keller F.; Malcolm G.L.,"Coco, Moreno I. (35093644900); Keller, Frank (27169408700); Malcolm, George L. (15765578100)",35093644900; 27169408700; 15765578100,Anticipation in Real-World Scenes: The Role of Visual Context and Visual Memory,2016,Cognitive Science,40,8,,1995,2024,29.0,28,10.1111/cogs.12313,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949057659&doi=10.1111%2fcogs.12313&partnerID=40&md5=6bf86a817e3eed9ce2d9d75674ac2543,"The human sentence processor is able to make rapid predictions about upcoming linguistic input. For example, upon hearing the verb eat, anticipatory eye-movements are launched toward edible objects in a visual scene (Altmann & Kamide, 1999). However, the cognitive mechanisms that underlie anticipation remain to be elucidated in ecologically valid contexts. Previous research has, in fact, mainly used clip-art scenes and object arrays, raising the possibility that anticipatory eye-movements are limited to displays containing a small number of objects in a visually impoverished context. In Experiment 1, we confirm that anticipation effects occur in real-world scenes and investigate the mechanisms that underlie such anticipation. In particular, we demonstrate that real-world scenes provide contextual information that anticipation can draw on: When the target object is not present in the scene, participants infer and fixate regions that are contextually appropriate (e.g., a table upon hearing eat). Experiment 2 investigates whether such contextual inference requires the co-presence of the scene, or whether memory representations can be utilized instead. The same real-world scenes as in Experiment 1 are presented to participants, but the scene disappears before the sentence is heard. We find that anticipation occurs even when the screen is blank, including when contextual inference is required. We conclude that anticipatory language processing is able to draw upon global scene representations (such as scene type) to make contextual inferences. These findings are compatible with theories assuming contextual guidance, but posit a challenge for theories assuming object-based visual indices. Copyright © 2015 Cognitive Science Society, Inc.",Anticipation in language processing; Blank screen paradigm; Contextual guidance; Eye-tracking; Visual world,Adult; Attention; Eye Movements; Female; Humans; Male; Memory; Photic Stimulation; Visual Perception; Young Adult; adult; attention; eye movement; female; human; male; memory; photostimulation; physiology; vision; young adult,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84949057659,Movies / Media
Hanke M.; Adelhöfer N.; Kottke D.; Iacovella V.; Sengupta A.; Kaule F.R.; Nigbur R.; Waite A.Q.; Baumgartner F.; Stadler J.,"Hanke, Michael (35859076500); Adelhöfer, Nico (57191739045); Kottke, Daniel (56406325200); Iacovella, Vittorio (35332140400); Sengupta, Ayan (57191746950); Kaule, Falko R. (44861473300); Nigbur, Roland (14023424000); Waite, Alexander Q. (57191744719); Baumgartner, Florian (55318023700); Stadler, Jörg (22939640700)",35859076500; 57191739045; 56406325200; 35332140400; 57191746950; 44861473300; 14023424000; 57191744719; 55318023700; 22939640700,"A studyforrest extension, simultaneous fMRI and eye gaze recordings during prolonged natural stimulation",2016,Scientific Data,3,,160092,,,,72,10.1038/sdata.2016.92,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992568802&doi=10.1038%2fsdata.2016.92&partnerID=40&md5=81ad9d3914845307699375b8d13331d4,"Here we present an update of the studyforrest (http://studyforrest.org) dataset that complements the previously released functional magnetic resonance imaging (fMRI) data for natural language processing with a new two-hour 3 Tesla fMRI acquisition while 15 of the original participants were shown an audio-visual version of the stimulus motion picture. We demonstrate with two validation analyses that these new data support modeling specific properties of the complex natural stimulus, as well as a substantial within-subject BOLD response congruency in brain areas related to the processing of auditory inputs, speech, and narrative when compared to the existing fMRI data for audio-only stimulation. In addition, we provide participants' eye gaze location as recorded simultaneously with fMRI, and an additional sample of 15 control participants whose eye gaze trajectories for the entire movie were recorded in a lab setting - to enable studies on attentional processes and comparative investigations on the potential impact of the stimulation setting on these processes. © 2016 The Author(s).",,Acoustic Stimulation; Attention; Auditory Perception; Brain Mapping; Humans; Magnetic Resonance Imaging; attention; auditory stimulation; brain mapping; hearing; human; nuclear magnetic resonance imaging,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84992568802,Movies / Media
Dietze P.; Knowles E.D.,"Dietze, Pia (56646126000); Knowles, Eric D. (23011975300)",56646126000; 23011975300,Social Class and the Motivational Relevance of Other Human Beings: Evidence From Visual Attention,2016,Psychological Science,27,11,,1517,1527,10.0,103,10.1177/0956797616667721,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994262647&doi=10.1177%2f0956797616667721&partnerID=40&md5=a5f0c9ebd1b7442648bfbd0bb01d8eda,"We theorize that people’s social class affects their appraisals of others’ motivational relevance—the degree to which others are seen as potentially rewarding, threatening, or otherwise worth attending to. Supporting this account, three studies indicate that social classes differ in the amount of attention their members direct toward other human beings. In Study 1, wearable technology was used to film the visual fields of pedestrians on city streets; higher-class participants looked less at other people than did lower-class participants. In Studies 2a and 2b, participants’ eye movements were tracked while they viewed street scenes; higher class was associated with reduced attention to people in the images. In Study 3, a change-detection procedure assessed the degree to which human faces spontaneously attract visual attention; faces proved less effective at drawing the attention of high-class than low-class participants, which implies that class affects spontaneous relevance appraisals. The measurement and conceptualization of social class are discussed. © 2016, © The Author(s) 2016.",culture; open data; open materials; social class; social orientation; visual attention,"Adult; Attention; Behavior; Cognition; Culture; Eye Movements; Facial Expression; Female; Fixation, Ocular; Humans; Male; Motivation; Pedestrians; Social Class; Social Perception; Visual Fields; Visual Perception; Walking; adult; attention; behavior; cognition; cultural anthropology; eye fixation; eye movement; facial expression; female; human; male; motivation; pedestrian; perception; physiology; psychology; social class; statistics and numerical data; vision; visual field; walking",Article,Final,,Scopus,2-s2.0-84994262647,Movies / Media
Liu S.; Lv J.; Hou Y.; Shoemaker T.; Dong Q.; Li K.; Liu T.,"Liu, Sidi (57191898594); Lv, Jinglei (58131694200); Hou, Yimin (14831207400); Shoemaker, Ting (57191900567); Dong, Qinglin (57190214381); Li, Kaiming (56949392800); Liu, Tianming (57203377182)",57191898594; 58131694200; 14831207400; 57191900567; 57190214381; 56949392800; 57203377182,What makes a good movie trailer? Interpretation from simultaneous EEG and eyetracker recording,2016,MM 2016 - Proceedings of the 2016 ACM Multimedia Conference,,,,82,86,4.0,14,10.1145/2964284.2967187,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994558913&doi=10.1145%2f2964284.2967187&partnerID=40&md5=307be18bfe465e20e598efc84f653cfc,"What makes a good movie trailer? It's a big challenge to answer this question because of the complexity of multimedia in both low level sensory features and high level semantic features. However, human perception and reactivity could be straightforward evidence for evaluation. Modern Electroencephalography (EEG) technology provides measurement of consequential brain neural activity to external stimuli. Meanwhile, visual perception and attention could be captured and interpreted by Eye Tracking technology. Intuitively, simultaneous EEG and Eye Tracker recording of human audience with multimedia stimuli could bridge the gap between human comprehension and multimedia analysis, and provide a new way for movie trailer evaluation. In this paper, we propose a novel platform to simultaneously record EEG and eye movement for participants with video stimuli by integrating 256-channel EEG, Eye Tracker and video display device as a system. Based on the proposed system a novel experiment has been designed, in which independent and joint features of EEG and Eye tracking data were mined to evaluate the movie trailer. Our analysis has shown interesting features that are corresponding with trailer quality and video shoot changes. © 2016 ACM..",Electroencephalography; Eye-Tracker; Multimedia evaluation,Brain; Display devices; Electrophysiology; Eye movements; Motion pictures; Neurons; Quality control; Semantics; External stimulus; Eye trackers; Eye tracking technologies; High-level semantic features; Human comprehensions; Multi-media analysis; Multimedia evaluation; Visual perception; Electroencephalography,Conference paper,Final,,Scopus,2-s2.0-84994558913,Movies / Media
Danie F.; Morize A.; Brémond-Gignac D.; Kapoula Z.,"Danie, François (56995697100); Morize, Aurélien (57192294921); Brémond-Gignac, Dominique (55905090900); Kapoula, Zoï (7003732501)",56995697100; 57192294921; 55905090900; 7003732501,Benefits from vergence rehabilitation: Evidence for improvement of reading saccades and fixations,2016,Frontiers in Integrative Neuroscience,10,Oct-16,33,,,,17,10.3389/fnint.2016.00033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003520718&doi=10.3389%2ffnint.2016.00033&partnerID=40&md5=724b8099ca7181e2fc6d29e68a432dcf,"We hypothesize that binocular coordination of saccades is based on continuous neuroplasticity involving interactions of saccades and vergence. To test this hypothesis we study reading saccades in young students who were diagnosed for vergence disorders before and after vergence rehabilitation. Following orthoptic evaluation and symptomatology screening, 5 weekly sessions of vergence rehabilitation were applied with the REMOBI vergence double step protocole (see Kapoula et al., 2016). Using the Eyeseecam videoculography device we measured vergence as well as saccades and fixations during a reading test four times: at the beginning and at the end of the first and of the fifth vergence rehabilitation session. The results show elimination of symptoms, improvement of clinical orthoptic scores, and importantly increase of measured vergence gain and reduction of inter-trial variability. Improvement of the vergence was associated to a decrease of the disconjugacy of saccades during reading but also to shortening of fixation durations, to reduction of the number of regressive saccades and to a better correction of the intra-saccadic disconjugacy during the following fixation. The results corroborate the hypothesis of neuroplasticity based on saccade vergence interaction in young adults. It validates the clinical validity of the vergence double-step REMOBI method as a means to improve both, vergence and reading performances. It opens a new research approach on the link between fine binocular coordination of saccades, quality of the vergence response, attention, cognition and reading. © 2016 Daniel, Morize, Brémond-Gignac and Kapoula.",Cognition; Fixation; Reading saccades; Rehabilitation; Vergence eye movements,adult; attention; binocular convergence; coordination; diagnosis; human; human experiment; nerve cell plasticity; reading test; rehabilitation; saccadic eye movement; screening; student; symptom; validity; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85003520718,Movies / Media
Li Y.; Xu X.; Mu N.; Chen L.,"Li, Yunyang (57192109289); Xu, Xin (56500865300); Mu, Nan (56669535500); Chen, Li (57192579689)",57192109289; 56500865300; 56669535500; 57192579689,Eye-gaze tracking system by haar cascade classifier,2016,"Proceedings of the 2016 IEEE 11th Conference on Industrial Electronics and Applications, ICIEA 2016",,,7603648,564,567,3.0,17,10.1109/ICIEA.2016.7603648,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997191027&doi=10.1109%2fICIEA.2016.7603648&partnerID=40&md5=cd1c293c73543f9d53e96426b76563eb,"Human can quickly and effortlessly focus on a few most interesting points in an image. Different observers tend to have the same fixations towards the same scene. In order to predict observer's fixations, eye gaze information can be used to reveal human attention and interest. This paper presents a real-time eye gaze tracking system. Haar cascade classifier is used to calculate the position of eye gaze based on the rectangular features of human eye. Then this position is adopted to match the space coordinates of screen representing where an observer is looking. The experimental results from different kinds of scenes validate the effectiveness of our system. © 2016 IEEE.",eye gaze tracking; Haar cascade classifier; regions of interest; visual attention,Behavioral research; Classification (of information); Industrial electronics; Eye gaze tracking; Haar cascade classifiers; Human attention; Human eye; Interesting points; Regions of interest; Space coordinates; Visual Attention; Tracking (position),Conference paper,Final,,Scopus,2-s2.0-84997191027,Movies / Media
Dal Monte O.; Piva M.; Morris J.A.; Chang S.W.C.,"Dal Monte, Olga (36982886400); Piva, Matthew (55334500000); Morris, Jason A. (57198622021); Chang, Steve W. C. (55494250200)",36982886400; 55334500000; 57198622021; 55494250200,Live interaction distinctively shapes social gaze dynamics in rhesus macaques,2016,Journal of Neurophysiology,116,4,,1626,1643,17.0,19,10.1152/jn.00442.2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990020654&doi=10.1152%2fjn.00442.2016&partnerID=40&md5=772618f89cf00700143d698e2b3ab790,"The dynamic interaction of gaze between individuals is a hallmark of social cognition. However, very few studies have examined social gaze dynamics after mutual eye contact during real-time interactions. We used a highly quantifiable paradigm to assess social gaze dynamics between pairs of monkeys and modeled these dynamics using an exponential decay function to investigate sustained attention after mutual eye contact. When monkeys were interacting with real partners compared with static images and movies of the same monkeys, we found a significant increase in the proportion of fixations to the eyes and a smaller dispersion of fixations around the eyes, indicating enhanced focal attention to the eye region. Notably, dominance and familiarity between the interacting pairs induced separable components of gaze dynamics that were unique to live interactions. Gaze dynamics of dominant monkeys after mutual eye contact were associated with a greater number of fixations to the eyes, whereas those of familiar pairs were associated with a faster rate of decrease in this eye-directed attention. Our findings endorse the notion that certain key aspects of social cognition are only captured during interactive social contexts and dependent on the elapsed time relative to socially meaningful events. © 2016 the American Physiological Society.",Dual eye-tracking; Eye contact; Gaze dynamics; Live interaction; Social gaze,"Analysis of Variance; Animals; Attention; Cognition; Eye Movement Measurements; Eye Movements; Female; Head; Macaca mulatta; Male; Models, Theoretical; Photic Stimulation; Psychological Tests; Recognition (Psychology); Restraint, Physical; Sex Characteristics; Social Behavior; Time Factors; adult; animal behavior; animal experiment; Article; binocular convergence; eye fixation; female; gaze; macaque model; male; nonhuman; priority journal; rhesus monkey; sex difference; social cognition; social environment; social interaction; analysis of variance; animal; attention; cognition; exercise; eye movement; head; oculography; photostimulation; psychologic test; psychology; recognition; sexual development; social behavior; theoretical model; time factor",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84990020654,Movies / Media
Shayan S.; Abrahamson D.; Bakker A.; Duijzer C.A.C.G.; Van Der Schaaf M.,"Shayan, Shakila (36988351500); Abrahamson, Dor (14624980700); Bakker, Arthur (9634128500); Duijzer, Carolien A. C. G. (57193444406); Van Der Schaaf, Marieke (8617998100)",36988351500; 14624980700; 9634128500; 57193444406; 8617998100,Eye-tracking the emergence of attentional anchors in a mathematics learning tablet activity,2016,Eye-Tracking Technology Applications in Educational Research,,,,166,194,28.0,21,10.4018/978-1-5225-1005-5.ch009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016506487&doi=10.4018%2f978-1-5225-1005-5.ch009&partnerID=40&md5=1a1437e6c2040db80d4972296e2f9897,"Little is known about micro-processes by which sensorimotor interaction gives rise to conceptual development. Per embodiment theory, these micro-processes are mediated by dynamical attentional structures. Accordingly this study investigated eye-gaze behaviors during engagement in solving tablet-based bimanual manipulation tasks designed to foster proportional reasoning. Seventy-six elementary- and vocational-school students (9-15 yo) participated in individual task-based clinical interviews. Data gathered included action-logging, eye-tracking, and videography. Analyses revealed the emergence of stable eye-path gaze patterns contemporaneous with first enactments of effective manipulation and prior to verbal articulations of manipulation strategies. Characteristic gaze patterns included consistent or recurring attention to screen locations that bore non-salient stimuli or no stimuli at all yet bore invariant geometric relations to dynamical salient features. Arguably, this research validates empirically hypothetical constructs from constructivism, particularly reflective abstraction. © 2017 by IGI Global. All rights reserved.",,,Book chapter,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85016506487,Movies / Media
Drost R.; Casteel M.; Libarkin J.; Thomas S.; Meister M.,"Drost, Robert (55550919100); Casteel, Mark (56052266500); Libarkin, Julie (8303685700); Thomas, Stephen (56623717900); Meister, Matt (57196488611)",55550919100; 56052266500; 8303685700; 56623717900; 57196488611,Severe weather warning communication: Factors impacting audience attention and retention of information during tornado warnings,2016,"Weather, Climate, and Society",8,4,,361,372,11.0,20,10.1175/WCAS-D-15-0035.1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991824203&doi=10.1175%2fWCAS-D-15-0035.1&partnerID=40&md5=655095796c1eb4f664c24bf57488681e,"Weather hazards in the United States inflict both personal and economic tolls on the public. Communicating warnings about weather hazards is an important duty of TV weathercasters. Televised weather warnings are typically conveyed through live radar, live coverage, and warning scrolls.However, these traditional approaches may not be entirely effective given the limited attention some members of the public pay to these warnings. A study comparing individual responses to a traditional warning, an animated warning, and an audio warning was undertaken to evaluate the impact of delivery methods on viewer attention, retention, and preferences during viewing of severe weather warnings.ATobii T60 eye tracker was used to document visual interactions with onscreen warnings and surveys were used to collect evidence of warning retention and preference. Demographic variables were also collected to describe the study population. Results indicate that viewers of the animated warning retained more pertinent information about the tornado warning than viewers of the traditional warning, and retention during the traditional warning was equivalent to that of the audio warning. In addition, gaze patterns for the traditional warning were muchmore diffuse than for the animatedwarning, suggesting that attention was more focused on the animation than the live video. In addition, modifications to reduce visual complexity of traditional warnings may positively impact viewer attention to individual warning elements. Future studies will consider the effectiveness of a hybrid warning containing both traditional and animated components.The current research study can be used to advance current severeweather warning communication techniques and increase public awareness during severe weather events. © 2016 American Meteorological Society.",,United States; demographic survey; hazard assessment; information management; information system; radar; social media; tornado; warning system; weather forecasting,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-84991824203,Movies / Media
Lander C.,"Lander, Christian (55785449200)",55785449200,Methods for calibration free and multi-user eye tracking,2016,"Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct, MobileHCI 2016",,,,899,900,1.0,5,10.1145/2957265.2963116,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991101939&doi=10.1145%2f2957265.2963116&partnerID=40&md5=e021f95674ada55ac8ad2baf1ffa90a8,"Human beings sense and perceive most of the world through their eyes. The point of gaze clearly reflects our visual attention indicating our interests. Hence gaze can be used as a powerful tool in different research areas (e.g., marketing, psychology). The progress made over the years in eye tracking enables the creation of gaze-based interactive interfaces. However, these interfaces lack of generic usability outside a controlled environment in a spontaneous pervasive way. The main objective of this research is to investigate eye-tracking technologies by means of calibration. Since calibration is user, location, orientation and target dependent, it prevents from Multi-User interaction and gaze estimation on multiple various objects (e.g., multiple screens of different sizes). Tackling these issues, new mobile as well as remote interfaces are explored and new design spaces are opened.",Calibration; Eye tracking; Gaze; Multi-user,Behavioral research; Calibration; Mobile devices; Controlled environment; Eye tracking technologies; Eye-tracking; Gaze; Interactive interfaces; Multi-user; Multi-user interaction; Remote interfaces; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-84991101939,Movies / Media
Müller N.; Baumeister S.; Dziobek I.; Banaschewski T.; Poustka L.,"Müller, Nico (57194605525); Baumeister, Sarah (57210652265); Dziobek, Isabel (14023902800); Banaschewski, Tobias (6603935963); Poustka, Luise (12798596800)",57194605525; 57210652265; 14023902800; 6603935963; 12798596800,Validation of the Movie for the Assessment of Social Cognition in Adolescents with ASD: Fixation Duration and Pupil Dilation as Predictors of Performance,2016,Journal of Autism and Developmental Disorders,46,9,,2831,2844,13.0,43,10.1007/s10803-016-2828-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982856717&doi=10.1007%2fs10803-016-2828-z&partnerID=40&md5=ceef124e91ac55074921672fe23e6ed9,"Impaired social cognition is one of the core characteristics of autism spectrum disorders (ASD). Appropriate measures of social cognition for high-functioning adolescents with ASD are, however, lacking. The Movie for the Assessment of Social Cognition (MASC) uses dynamic social stimuli, ensuring ecological validity, and has proven to be a sensitive measure in adulthood. In the current study, 33 adolescents with ASD and 23 controls were administered the MASC, while concurrent eye tracking was used to relate gaze behavior to performance levels. The ASD group exhibited reduced MASC scores, with social cognition performance being explained by shorter fixation duration on eyes and decreased pupil dilation. These potential diagnostic markers are discussed as indicators of different processing of social information in ASD. © 2016, Springer Science+Business Media New York.",Adolescence; Autism spectrum disorder; Ecological validity; Eye-tracking; Pupil dilation; Social cognition,Adolescent; Autism Spectrum Disorder; Case-Control Studies; Cognition; Dilatation; Eye Movements; Female; Humans; Male; Motion Pictures as Topic; Pupil; Social Behavior; Time Factors; adolescent; Article; autism; clinical article; cognition assessment; controlled study; discriminant validity; eye tracking; female; gaze; human; internal consistency; male; movie; movie for the assessment of social cognition; priority journal; social cognition; Autism Spectrum Disorder; case control study; cognition; dilatation; eye movement; movie; pathophysiology; physiology; psychology; pupil; social behavior; time factor; validation study,Article,Final,,Scopus,2-s2.0-84982856717,Movies / Media
Chynal P.; Sobecki J.,"Chynal, Piotr (36647291800); Sobecki, Janusz (6602425969)",36647291800; 6602425969,Application of thermal imaging camera in eye tracking evaluation,2016,"Proceedings - 2016 9th International Conference on Human System Interactions, HSI 2016",,,7529673,451,457,6.0,2,10.1109/HSI.2016.7529673,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992183862&doi=10.1109%2fHSI.2016.7529673&partnerID=40&md5=b6d905b3544cb413181de0b6dc85d577,"This paper presents a method for applying a thermal imaging camera to enhance eyetracking usability testing. The first part of the article introduces the eye tracking, one of the most popular usability evaluation method. Eyetracking records the position of participants' gaze on the screen with a dedicated camera. Eyetracking is a very efficient usability testing method. It allows determining which elements of user interface attract users' attention and which are not noticed by them. The second part of the article focuses on thermal imaging camera. Some theoretical background is provided on how such cameras work. Furthermore, paper contains instructions on how to conduct usability testing using eyetracker and the infrared camera, as well as a description of a case study - evaluation of SimplyTick web application. The proposed method allows researchers to enhance the standard eye tracking test with recording of thermal image of the participant's face, from which it is possible to recognize emotions during the course of the study. This enables us to obtain an extra measure of usability associated with emotions and user satisfaction. © 2016 IEEE.",emotion recognition; eye tracking; HCI; thermal imaging; usability,Human computer interaction; Image recording; Infrared imaging; Temperature indicating cameras; Usability engineering; User interfaces; Emotion recognition; Eye-tracking; Infra-red cameras; Thermal imaging cameras; usability; Usability evaluation methods; Usability testing methods; User satisfaction; Cameras,Conference paper,Final,,Scopus,2-s2.0-84992183862,Movies / Media
Vonk J.,"Vonk, Jennifer (7006334135)",7006334135,Apes have eyes to the future,2016,Learning and Behavior,44,3,,207,208,1.0,0,10.3758/s13420-016-0213-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983744531&doi=10.3758%2fs13420-016-0213-6&partnerID=40&md5=d843df5c5731baac6455ed7c5a481cdf,"Kano and Hirata (Current Biology, 25, 2513–2517, 2015) recently showed that apes process object and location information and anticipate the repeated presentation of such events in short film clips. Their methodology, using eyetracking, can provide a foundation for further explications of long-term prospective and episodic memory in nonverbal species. © 2016, Psychonomic Society, Inc.",Anticipation; Apes; Episodic memory; Eye-tracking,"Animals; Cognition; Hominidae; Memory, Episodic; Nigeria; animal; cognition; episodic memory; hominid; Nigeria",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-84983744531,Movies / Media
Jariwala K.; Dalal U.; Vincent A.,"Jariwala, Krupa (57191608233); Dalal, Upena (56032021200); Vincent, Amal (57203514766)",57191608233; 56032021200; 57203514766,A robust eye gaze estimation using geometric eye features,2016,"2016 3rd International Conference on Digital Information Processing, Data Mining, and Wireless Communications, DIPDMWC 2016",,,7529379,142,147,5.0,4,10.1109/DIPDMWC.2016.7529379,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992036178&doi=10.1109%2fDIPDMWC.2016.7529379&partnerID=40&md5=3bbdf6438fe8cc122752cce20a5f2821,"Gaze estimation is the process of determining the point of gaze in the space, or the visual axis of an eye. It plays an important role in representing human attention; therefore, it can be most appropriately used in Human Computer Interaction as a means of an advance computer input. Here, the focus is to develop a gaze estimation method for Human Computer Interaction using an ordinary webcam mounted on the top of the computer screen without any additional or specialized hardware. The eye center coordinates are obtained with the geometrical eye model and edge gradients. To improve the reliability, the estimates from two eye centers are combined to reduce the noise and improve the accuracy. Facial land marking is done to identify a precise reference point on the face between the nose. The ellipse fitting and RANSAC method is used to estimate the gaze coordinates and to reject the outliers. This approach can estimate the gaze coordinates with high degree of accuracy even when significant numbers of outliers are present in the data set. Several refinements such as feedback and masking, queuing and averaging are proposed to make the system more stable and useful practically. The results show that the proposed method can be successfully applied to commercial gaze tracking systems using ordinary webcams. © 2016 IEEE.",computer vision; eye tracking; image processing,Computer hardware; Computer vision; Data handling; Data mining; Image processing; Information science; Statistics; Tracking (position); Wireless telecommunication systems; Computer screens; Eye-tracking; Gaze estimation; Gaze tracking system; High degree of accuracy; Human attention; Reference points; Specialized hardware; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-84992036178,Movies / Media
Ai G.; Sato N.; Singh B.; Wagatsuma H.,"Ai, Guangyi (56592209500); Sato, Naoyuki (35263051300); Singh, Balbir (56937412900); Wagatsuma, Hiroaki (6603005439)",56592209500; 35263051300; 56937412900; 6603005439,Direction and viewing area-sensitive influence of EOG artifacts revealed in the EEG topographic pattern analysis,2016,Cognitive Neurodynamics,10,4,,301,314,13.0,11,10.1007/s11571-016-9382-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960119779&doi=10.1007%2fs11571-016-9382-4&partnerID=40&md5=5160be951757d09b1c1334ec4c089556,"The influence of eye movement-related artifacts on electroencephalography (EEG) signals of human subjects, who were requested to perform a direction or viewing area dependent saccade task, was investigated by using a simultaneous recording with ocular potentials as electro-oculography (EOG). In the past, EOG artifact removals have been studied in tasks with a single fixation point in the screen center, with less attention to the sensitivity of cornea-retinal dipole orientations to the EEG head map. In the present study, we hypothesized the existence of a systematic EOG influence that differs according to coupling conditions of eye-movement directions with viewing areas including different fixation points. The effect was validated in the linear regression analysis by using 12 task conditions combining horizontal/vertical eye-movement direction and three segregated zones of gaze in the screen. In the first place, event-related potential topographic patterns were analyzed to compare the 12 conditions and propagation coefficients of the linear regression analysis were successively calculated in each condition. As a result, the EOG influences were significantly different in a large number of EEG channels, especially in the case of horizontal eye-movements. In the cross validation, the linear regression analysis using the appropriate dataset of the target direction/viewing area combination demonstrated an improved performance compared with the traditional methods using a single fixation at the center. This result may open a potential way to improve artifact correction methods by considering the systematic EOG influence that can be predicted according to the view angle such as using eye-tracker systems. © 2016, Springer Science+Business Media Dordrecht.",Artifact correction; Electro-oculogram (EOG); Electroencephalogram (EEG); Event-related potential (ERP); Linear regression analysis,artifact; attention; cornea; dipole; electroencephalogram; electroencephalography; electrooculogram; electrooculography; event related potential; gaze; head; human; linear regression analysis; retina; saccadic eye movement; validation process,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84960119779,Movies / Media
Chita-Tegmark M.,"Chita-Tegmark, Meia (56700303500)",56700303500,Attention Allocation in ASD: a Review and Meta-analysis of Eye-Tracking Studies,2016,Review Journal of Autism and Developmental Disorders,3,3,,209,223,14.0,103,10.1007/s40489-016-0077-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006207143&doi=10.1007%2fs40489-016-0077-x&partnerID=40&md5=7908eed203e6e716ac177a475c849d9e,"Research on attention allocation to social and non-social stimuli in autism spectrum disorder (ASD) has produced mixed results, with some studies suggesting that attention allocation is atypical in ASD (e.g., Klin, Jones, Schultz, Vokmar, & Cohen, 2002) and others finding no significant differences in attention allocation patterns when comparing individuals with ASD to typically developing (TD) controls (e.g., Parish-Morris et al. 2013). This meta-analysis aggregates results from 68 articles that compared individuals with ASD with TD controls, using eye-tracking measures of attention. As an index of attention allocation, mean effect sizes for looking time to six areas of interest (AOIs) are computed in this meta-analysis: eyes, mouth, face, body, non-social elements, and the whole screen. The results suggest the presence of atypical attention allocation in ASD, indicated by small but significant effect sizes: overall reduced attention to the eyes (d = 0.33), mouth (d = 0.25), and face (d = 0.4); increased attention to the body (d = −0.48) and non-social elements (d = −0.34); and reduced attention to the screen (d = 0.53). This pattern of findings suggests less accessing of social information by individuals with ASD. The results are discussed in light of future research directions. © 2016, Springer Science+Business Media New York.",ASD; Attention; Eye-tracking; Meta-analysis; Social attention,,Article,Final,,Scopus,2-s2.0-85006207143,Movies / Media
Shirong C.; Anqi Q.; Birit F.P.B.; Eric Q.W.; Peter D.G.; Keith M.G.; Seang M.S.; Shu-E S.; Kenneth K.; Chong Y.-S.; Michael J.M.; Michael S.K.; Anne R.-G.,"Shirong, Cai (56124055600); Anqi, Qiu (57195195460); Birit, F. P. Broekman (57191531126); Eric, Qinlong Wong (57191527493); Peter, D. Gluckman (57191523329); Keith, M. Godfrey (57190838193); Seang, Mei Saw (7006402006); Shu-E, Soh (57191529139); Kenneth, Kwek (57190841116); Chong, Yap-Seng (7201371807); Michael, J. Meaney (57191522950); Michael, S. Kramer (25932148600); Anne, Rifkin-Graboi (57211249392)",56124055600; 57195195460; 57191531126; 57191527493; 57191523329; 57190838193; 7006402006; 57191529139; 57190841116; 7201371807; 57191522950; 25932148600; 57211249392,The influence of gestational diabetes on neurodevelopment of children in the first two years of life: A prospective study,2016,PLoS ONE,11,9,e0162113,,,,59,10.1371/journal.pone.0162113,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991294482&doi=10.1371%2fjournal.pone.0162113&partnerID=40&md5=82ca0c406204e6427e9b6228ed8ea1ba,"Objective Analyze the relation of gestational diabetes and maternal blood glucose levels to early cognitive functions in the first two years of life. Methods In a prospective Singaporean birth cohort study, pregnant women were screened for gestational diabetes at 26-28 weeks gestation using a 75-g oral glucose tolerance test. Four hundred and seventy three children (n = 74 and n = 399 born to mothers with and without gestational diabetes respectively) underwent neurocognitive assessments at 6, 18, and/or 24 month, including electrophysiology during an attentional task and behavioral measures of attention, memory and cognition. Results Gestational diabetes is related to left hemisphere EPmax amplitude differences (oddball versus standard) at both six (P = 0.039) and eighteen months (P = 0.039), with mean amplitudes suggesting offspring of mothers with gestational diabetes exhibit greater neuronal activity to standard stimuli and less to oddball stimuli. Associations between 2-hour maternal glucose levels and the difference in EPmax amplitude were marginal at 6 months [adjusted β = -0.19 (95% CI: -0.42 to +0.04) μV, P = 0.100] and significant at 18 months [adjusted β = -0.27 (95% CI: -0.49 to -0.06) μV, P = 0.014], and the EPmax amplitude difference (oddball-standard) associated with the Bayley Scales of Infant and toddler Development-III cognitive score at 24 months [β = 0.598 (95% CI: 0.158 to 1.038), P = 0.008]. Conclusion Gestational diabetes and maternal blood glucose levels are associated with offspring neuronal activity during an attentional task at both six and eighteen months. Such electrophysiological differences are likely functionally important, having been previously linked to attention problems later in life. © 2016 Cai et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Adult; Attention; Behavior; Case-Control Studies; Cerebrum; Child; Diabetes, Gestational; Electrodes; Evoked Potentials; Female; Humans; Infant; Nervous System; Pregnancy; Prospective Studies; action potential amplitude; adult; Article; attention test; Bayley Scales of Infant Development; behavior assessment; child; cognition assessment; cohort analysis; controlled study; event related potential; eye tracking; female; gestational age; glucose blood level; human; infant; left hemisphere; major clinical study; maternal blood; memory assessment; nerve cell; nerve cell differentiation; nervous system electrophysiology; oral glucose tolerance test; pregnancy diabetes mellitus; progeny; prospective study; screening test; task performance; attention; behavior; brain; case control study; electrode; evoked response; growth, development and aging; nervous system; pathophysiology; physiology; pregnancy; pregnancy diabetes mellitus",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84991294482,Movies / Media
Vigier T.; Perreira Da Silva M.; Le Callet P.,"Vigier, Toinon (55206851100); Perreira Da Silva, Matthieu (24337440300); Le Callet, Patrick (57200770358)",55206851100; 24337440300; 57200770358,Impact of visual angle on attention deployment and robustness of visual saliency models in videos: From SD to UHD,2016,"Proceedings - International Conference on Image Processing, ICIP",2016-August,,7532445,689,693,4.0,2,10.1109/ICIP.2016.7532445,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006757567&doi=10.1109%2fICIP.2016.7532445&partnerID=40&md5=132727f45a8d40d2e2060e28e5ad31f8,"The emergence of UHD video format induces larger screens and involves a wider stimulated visual angle. Therefore, its effect on visual attention can be questioned since it can impact quality assessment, metrics but also the whole chain of video processing and creation. Moreover, changes in visual attention from different viewing conditions challenge visual attention models. In this paper, we present a comparative study of visual attention and viewing behavior on three video datasets in SD, HD and UHD conditions. Then, we propose and assess an improvement for video visual attention models by applying a stimulated visual angle dependent center model. © 2016 IEEE.",Eye tracking; UHD; Video; Visual attention; Visual saliency model,Image processing; Video signal processing; Visualization; Comparative studies; Eye-tracking; Quality assessment; Video; Viewing conditions; Visual Attention; Visual attention model; Visual saliency model; Behavioral research,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85006757567,Movies / Media
Weggelaar-Jansen A.M.; van Buren-Jansen E.; van 't Schip S.; Pel J.J.M.; Nieboer A.P.; Helder O.K.,"Weggelaar-Jansen, Anne Marie (56074136100); van Buren-Jansen, Esther (57188652833); van 't Schip, Sabine (57188657852); Pel, Johan J.M. (7003380897); Nieboer, Anna P. (6506518114); Helder, Onno K. (24337884200)",56074136100; 57188652833; 57188657852; 7003380897; 6506518114; 24337884200,Design study to develop screen savers aimed at improving hand hygiene behavior,2016,American Journal of Infection Control,44,8,,860,867,7.0,2,10.1016/j.ajic.2016.01.028,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962086871&doi=10.1016%2fj.ajic.2016.01.028&partnerID=40&md5=13d32d12065a4a2c504ec32d91e6a2a1,"Background Displaying screen savers with gain-framed messages are effective to improve hand hygiene, but the design of screen savers has not been studied yet. Methods Based on the literature, scientific propositions were developed for the design of screen savers, exploring 2 strategies to subconsciously influence hand hygiene behavior; the first was to gain attention, and the second was to exert peer pressure. The designed screen savers were tested for attention with an eye-tracking study (N = 27) and for the influence of peer pressure with a questionnaire (N = 25). Results Twenty-five propositions for gaining attention concerned the format and color of the screen saver itself and color, position, and style of visual and text elements. Seven propositions for peer pressure concerned the influence of peers, role models, and feelings of being watched. Eye-tracking measurements showed that text on the 4 screen savers based on propositions gained more, earlier, and longer attention and the visual elements gained earlier and longer attention than the control screen savers. The questionnaire results showed that feelings of peer pressure were evoked by 3 screen savers; of these, one was not based on propositions. Conclusions Screen savers designed according to scientific propositions for visual attention and peer pressure have the potential to alter hand hygiene behavior. © 2016 Association for Professionals in Infection Control and Epidemiology, Inc.",design study; eye tracking; hand hygiene; Infection control; screen saver,Behavior Therapy; Computer Graphics; Guideline Adherence; Hand Hygiene; Humans; Peer Influence; Surveys and Questionnaires; attention; clinical article; controlled study; eye tracking; hygiene; model; peer pressure; questionnaire; behavior therapy; computer graphics; hand washing; human; procedures; protocol compliance; utilization,Article,Final,,Scopus,2-s2.0-84962086871,Movies / Media
Bennett J.K.; Sridharan S.; John B.; Bailey R.,"Bennett, Justin K. (57193236512); Sridharan, Srinivas (25722300800); John, Brendan (57205639875); Bailey, Reynold (16641965200)",57193236512; 25722300800; 57205639875; 16641965200,Looking at faces: Autonomous perspective invariant facial gaze analysis,2016,"Proceedings of the ACM Symposium on Applied Perception, SAP 2016",,,,105,112,7.0,4,10.1145/2931002.2931005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012008975&doi=10.1145%2f2931002.2931005&partnerID=40&md5=0013564b1cd452b51aff9c8d3494b5a8,"Eye-tracking provides a mechanism for researchers to monitor where subjects deploy their visual attention. Eye-tracking has been used to gain insights into how humans scrutinize faces, however the majority of these studies were conducted using desktop-mounted eye-trackers where the subject sits and views a screen during the experiment. The stimuli in these experiments are typically photographs or videos of human faces. In this paper we present a novel approach using head-mounted eye-trackers which allows for automatic generation of gaze statistics for tasks performed in real-world environments. We use a trained hierarchy of Haar cascade classifiers to automatically detect and segment faces in the eye-tracker's scene camera video. We can then determine if fixations fall within the bounds of the face or other possible regions of interest and report relevant gaze statistics. Our method is easily adaptable to any feature-trained cascade to allow for rapid object detection and tracking. We compare our results with previous research on the perception of faces in social environments. We also explore correlations between gaze and confidence levels measured during a mock interview experiment. © 2016 ACM.",Eye-tracking; Face detection and tracking; Gaze statistics,Behavioral research; Classification (of information); Eye movements; Tracking (position); Automatic Generation; Eye-tracking; Face detection and tracking; Haar cascade classifiers; Object detection and tracking; Real world environments; Regions of interest; Social environment; Face recognition,Conference paper,Final,,Scopus,2-s2.0-85012008975,Movies / Media
Toscano-Zapién A.L.; Velázquez-López D.; Velázquez-Martínez D.N.,"Toscano-Zapién, Anna L. (57190732999); Velázquez-López, Daniel (57190733044); Velázquez-Martínez, David N. (7003467307)",57190732999; 57190733044; 7003467307,Attentional mechanisms during the performance of a subsecond timing task,2016,PLoS ONE,11,7,e0158508,,,,3,10.1371/journal.pone.0158508,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982693896&doi=10.1371%2fjournal.pone.0158508&partnerID=40&md5=efb45efc0658c612bbaf62805e0b1a40,"There is evidence that timing processes in the suprasecond scale are modulated by attentional mechanisms; in addition, some studies have shown that attentional mechanisms also affect timing in the subsecond scale. Our aim was to study eye movements and pupil diameter during a temporal bisection task in the subsecond range. Subjects were trained to discriminate anchor intervals of 200 or 800 msec, and were then confronted with intermediate durations. Eye movements revealed that subjects used different cognitive strategies during the bisection timing task. When the stimulus to be timed appeared randomly at a central or 4 peripheral positions on a screen, some subjects choose to maintain their gaze toward the central area while other followed the peripheral placement of the stimulus; some others subjects used both strategies. The time of subjective equality did not differ between subjects who employed different attentional mechanisms. However, differences emerged in the timing variance and attentional indexes (time taken to initial fixation, latency to respond, pupil dilatation and duration and number of fixations to stimulus areas). Timing in the subsecond range seems invariant despite the use of different attentional strategies. Future research should determine whether the selection of attentional mechanisms is related to particular timing tasks or instructions or whether it represents idiosyncratic cognitive ""styles"". © 2016 Toscano-Zapién et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Adult; Attention; Female; Fixation, Ocular; Humans; Male; Pupil; Task Performance and Analysis; Time Perception; Young Adult; adult; Article; attention; attention test; bisection timing task; brain function; cognition assessment; eye fixation; eye movement; gaze; human; human experiment; latent period; normal human; perceptive discrimination; psychomotor performance; pupil; response time; task performance; visual system parameters; female; male; physiology; pupil; task performance; time perception; young adult",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84982693896,Movies / Media
Paulus M.; Murillo E.; Sodian B.,"Paulus, Markus (35173533200); Murillo, Esther (57189225532); Sodian, Beate (6602480008)",35173533200; 57189225532; 6602480008,When the body reveals the mind: Children's use of others' body orientation to understand their focus of attention,2016,Journal of Experimental Child Psychology,148,,,101,118,17.0,6,10.1016/j.jecp.2016.03.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966415433&doi=10.1016%2fj.jecp.2016.03.013&partnerID=40&md5=528e841a1d8fe3d2e526f6de05ed5c3a,"A considerable amount of research has examined children's ability to rely on explicit social cues such as pointing to understand others' referential intentions. Yet, skillful social interaction also requires reliance on and learning from implicit cues (i.e., cues that are not displayed with the explicit intention to teach or inform someone). From an embodied point of view, orienting movements and body orientation are salient cues that reveal something about a person's intentional relations without being explicit communicative cues. In three experiments, the current study investigated the development of the ability to use body information in a word learning situation. To this end, we presented 2-year-old children, 3.5-year-old children, and adults with movies on an eye-tracking screen in which an actor oriented her upper body to one of two objects while uttering a novel word. The results show that the 3.5-year-old children and adults, but not the 2-year-old children, related the novel word to the referred object (Experiments 1 and 2). Yet, when the actor oriented her body to one object while pointing to the other object, children of both age groups relied on the pointing cue (Experiment 3). This suggests that by 3.5 years children use another's body orientation as an indicator of her intentional relations but that they prioritize explicit social cues over the implicit body posture cues. Overall, the study supports theoretical views that an appreciation of others' intentional relations does not emerge as an all-or-nothing ability but rather emerges gradually during the course of early development. © 2016 Elsevier Inc.",Body cues; Joint attention; Posture perception; Social cognition; Toddlerhood; Word learning,"Adult; Attention; Child; Communication; Comprehension; Cues; Female; Humans; Intention; Interpersonal Relations; Male; Orientation; Orientation, Spatial; Posture; Theory of Mind; adult; attention; body posture; child; eye tracking; human; human experiment; joint; learning; movie; perception; social cognition; theoretical model; association; attention; behavior; body position; comprehension; female; human relation; interpersonal communication; male; orientation; physiology; spatial orientation; theory of mind",Article,Final,,Scopus,2-s2.0-84966415433,Movies / Media
Suchan J.; Bhatt M.; Yu S.,"Suchan, Jakob (55767093900); Bhatt, Mehul (8925250400); Yu, Stella (7405731763)",55767093900; 8925250400; 7405731763,The perception of symmetry in the moving image: Multi-level computational analysis of cinematographic scene structure and its visual reception,2016,"Proceedings of the ACM Symposium on Applied Perception, SAP 2016",,,,142,,,1,10.1145/2931002.2948721,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012008507&doi=10.1145%2f2931002.2948721&partnerID=40&md5=1c33e88668ef9720b837a32c2263870a,"This research is driven by visuo-spatial perception focussed cognitive film studies, where the key emphasis is on the systematic study and generation of evidence that can characterise and establish correlates between principles for the synthesis of the moving image, and its cognitive (e.g., embodied visuo-auditory, emotional) recipient effects on observers [Suchan and Bhatt 2016b; Suchan and Bhatt 2016a]. Within this context, we focus on the case of ""symmetry"" in the cinematographic structure of the moving image, and propose a multi-level model of interpreting symmetric patterns therefrom. This provides the foundation for integrating scene analysis with the analysis of its visuo-spatial perception based on eye-tracking data. This is achieved by the integration of: computational semantic interpretation of the scene [Suchan and Bhatt 2016b]-involving scene objects (people, objects in the scene), cinematographic aids (camera movement, shot types, cuts and scene structure)- and perceptual artefacts (fixations, saccades, scan-path, areas of attention). © 2016 Copyright held by the owner/author(s).",,Eye movements; Semantics; Camera movement; Computational analysis; Computational semantics; Multilevel model; Scene structure; Spatial perception; Symmetric patterns; Systematic study; Behavioral research,Conference paper,Final,,Scopus,2-s2.0-85012008507,Movies / Media
Kyritsis M.; Gulliver S.R.; Feredoes E.,"Kyritsis, Markos (14019633900); Gulliver, Stephen R. (6603891003); Feredoes, Eva (15753701000)",14019633900; 6603891003; 15753701000,Environmental factors and features that influence visual search in a 3D WIMP interface,2016,International Journal of Human Computer Studies,92-93,,,30,43,13.0,4,10.1016/j.ijhcs.2016.04.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966711381&doi=10.1016%2fj.ijhcs.2016.04.009&partnerID=40&md5=c1c38e83cac3f31b1b452a1be01bd412,"The challenge of moving past the classic Window Icons Menus Pointer (WIMP) interface, i.e. by turning it '3D', has resulted in much research and development. To evaluate the impact of 3D on the 'finding a target picture in a folder' task, we built a 3D WIMP interface that allowed the systematic manipulation of visual depth, visual aides, semantic category distribution of targets versus non-targets; and the detailed measurement of lower-level stimuli features. Across two separate experiments, one large sample web-based experiment, to understand associations, and one controlled lab environment, using eye tracking to understand user focus, we investigated how visual depth, use of visual aides, use of semantic categories, and lower-level stimuli features (i.e. contrast, colour and luminance) impact how successfully participants are able to search for, and detect, the target image. Moreover in the lab-based experiment, we captured pupillometry measurements to allow consideration of the influence of increasing cognitive load as a result of either an increasing number of items on the screen, or due to the inclusion of visual depth. Our findings showed that increasing the visible layers of depth, and inclusion of converging lines, did not impact target detection times, errors, or failure rates. Low-level features, including colour, luminance, and number of edges, did correlate with differences in target detection times, errors, and failure rates. Our results also revealed that semantic sorting algorithms significantly decreased target detection times. Increased semantic contrasts between a target and its neighbours correlated with an increase in detection errors. Finally, pupillometric data did not provide evidence of any correlation between the number of visible layers of depth and pupil size, however, using structural equation modelling, we demonstrated that cognitive load does influence detection failure rates when there is luminance contrasts between the target and its surrounding neighbours. Results suggest that WIMP interaction designers should consider stimulus-driven factors, which were shown to influence the efficiency with which a target icon can be found in a 3D WIMP interface. © 2016 Elsevier Ltd. All rights reserved.",3D WIMP; Cognitive load; Eye tracking; Perceptual sorting algorithms; Target detection; Visual search,Errors; Failure analysis; Luminance; Semantic Web; Semantics; Sorting; Target tracking; 3D WIMP; Cognitive loads; Eye-tracking; Sorting algorithm; Visual search; Feature extraction,Article,Final,,Scopus,2-s2.0-84966711381,Movies / Media
Li X.; Zhou Z.; Jia S.; Hou C.; Zheng W.; Rong P.; Jiao J.,"Li, Xudong (13908143400); Zhou, Zhi (56693225800); Jia, Shuhong (56119767100); Hou, Chunlei (57189294867); Zheng, Wenjing (57189293960); Rong, Pei (55514801000); Jiao, Jinsong (7102382957)",13908143400; 56693225800; 56119767100; 57189294867; 57189293960; 55514801000; 7102382957,Cognitive study on Chinese patients with idiopathic REM sleep behavior disorder,2016,Journal of the Neurological Sciences,366,,,82,86,4.0,17,10.1016/j.jns.2016.04.047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968538198&doi=10.1016%2fj.jns.2016.04.047&partnerID=40&md5=30dc0b6c75140bd59dd5240292f524f9,"Aims We investigated cognitive abnormalities using standard tests in Chinese patients with idiopathic rapid eye movement (REM) sleep behavior disorder (iRBD) compared with those in normal controls. Methods Twenty-three patients with iRBD and 23 normal controls were included in this study. All of the participants underwent one night of video-polysomnography (PSG) monitoring to certify REM sleep without atonia or abnormal behaviors. The cognitive assessments were administered and scored according to a standard procedure, including global cognitive screening and attention/processing speed, executive function, memory, language, and visuospatial ability testing. Results Patients with iRBD had similar scores of the Mini Mental State Examination (MMSE) but lower Montreal Cognitive Assessment (MoCA) scores compared with controls (p > 0.05, p = 0.013). The iRBD patients performed poorly on verbal memory tests, which included immediate recall (p < 0.001), delayed recall (p < 0.001), and false recognitions (p = 0.002) of the Rey Auditory Verbal Learning Test (RAVLT). The visual memory and visuospatial abilities were also impaired in iRBD patients, as reflected by the copy (p = 0.005) and immediate (p = 0.004) and delayed (p = 0.003) recall of the Rey-Osterrieth complex figure, although no difference was found after Bonferroni correction. The duration of RBD was 6.98 ± 8.10 years. After controlling for age, the duration of RBD was only correlated with the Trail Making Test B (r = 0.613, p = 0.045) and block design (r = - 0.667, p = 0.025). Conclusions Impaired verbal memory was observed in iRBD patients who identified as Chinese. MoCA could detect cognitive abnormalities and serve as a screening scale. The present study further confirmed cognitive deficits in iRBD as an early clinical marker in the prodromal stage of synucleinopathy. © 2015 Elsevier B.V. All rights reserved.",Cognition; Idiopathic REM sleep behavior disorder; Polysomnography; Synucleinopathy,"Aged; Aged, 80 and over; China; Cognition; Cognition Disorders; Female; Humans; Male; Memory; Memory Disorders; Middle Aged; Neuropsychological Tests; Polysomnography; REM Sleep Behavior Disorder; Video Recording; adult; age distribution; aged; Article; Chinese; clinical article; cognitive defect; controlled clinical trial; controlled study; depth perception; disease duration; electroencephalograph; electroencephalography; executive function; executive function test; female; human; idiopathic disease; idiopathic REM sleep behavior disorder; language; male; memory disorder; middle aged; Mini Mental State Examination; Montreal cognitive assessment; neuromonitoring; polysomnography; priority journal; recall; Rey auditory verbal learning test; Rey Osterrieth complex figure test; trail making test; velocity; verbal memory test; very elderly; visual memory; China; cognition; Cognition Disorders; complication; memory; Memory Disorders; neuropsychological test; parasomnia; pathophysiology; psychology; videorecording",Article,Final,,Scopus,2-s2.0-84968538198,Movies / Media
Saitovitch A.; Popa T.; Lemaitre H.; Rechtman E.; Lamy J.-C.; Grévent D.; Calmon R.; Meunier S.; Brunelle F.; Samson Y.; Boddaert N.; Zilbovicius M.,"Saitovitch, Ana (55165364600); Popa, Traian (6602333530); Lemaitre, Hervé (8524298900); Rechtman, Elza (57189681502); Lamy, Jean-Charles (24540496600); Grévent, David (27067666400); Calmon, Raphael (35363679700); Meunier, Sabine (7007079044); Brunelle, Francis (7103049469); Samson, Yves (7006646196); Boddaert, Nathalie (57203073518); Zilbovicius, Monica (7003390309)",55165364600; 6602333530; 8524298900; 57189681502; 24540496600; 27067666400; 35363679700; 7007079044; 7103049469; 7006646196; 57203073518; 7003390309,Tuning Eye-Gaze Perception by Transitory STS Inhibition,2016,Cerebral Cortex,26,6,,2823,2831,8.0,26,10.1093/cercor/bhw045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974605081&doi=10.1093%2fcercor%2fbhw045&partnerID=40&md5=b9fdb1bb415a06cb3ffb903c5bbf981e,"Processing eye-gaze information is a key step to human social interaction. Neuroimaging studies have shown that superior temporal sulcus (STS) is highly implicated in eye-gaze perception. In autism, a lack of preference for the eyes, as well as anatomo-functional abnormalities within the STS, has been described. To date, there are no experimental data in humans showing whether it is possible to interfere with eye-gaze processing by modulating STS neural activity. Here, we measured eye-gaze perception before and after inhibitory transcranial magnetic stimulation (TMS) applied over the posterior STS (pSTS) in young healthy volunteers. Eye-gaze processing, namely overt orienting toward the eyes, was measured using eye tracking during passive visualization of social movies. Inhibition of the right pSTS led participants to look less to the eyes of characters during visualization of social movies. Such effect was specific for the eyes and was not observed after inhibition of the left pSTS nor after placebo TMS. These results indicate for the first time that interfering with the right pSTS neural activity transitorily disrupts the behavior of orienting toward the eyes and thus indirectly gaze perception, a fundamental process for human social cognition. These results could open up new perspectives in therapeutic interventions in autism. © 2016 The Author. Published by Oxford University Press.",Eye-gaze perception; Social cognition; STS; TMS,"Cognition; Eye Movement Measurements; Female; Fixation, Ocular; Humans; Magnetic Resonance Imaging; Male; Neural Inhibition; Social Perception; Temporal Lobe; Transcranial Magnetic Stimulation; Visual Perception; Young Adult; adult; Article; autism; body movement; comparative study; diagnostic accuracy; eye gaze processing; eye movement; eye tracking; female; frameless stereotactic procedure; functional magnetic resonance imaging; functional neuroimaging; gaze; human; human experiment; male; normal human; nuclear magnetic resonance scanner; primary motor cortex; priority journal; sensory stimulation; social cognition; social interaction; superior temporal sulcus; transcranial magnetic stimulation; vision; cognition; diagnostic imaging; eye fixation; nerve cell inhibition; nuclear magnetic resonance imaging; oculography; perception; physiology; temporal lobe; young adult",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84974605081,Movies / Media
Jakobsen A.L.,"Jakobsen, Arnt Lykke (35107279700)",35107279700,Are gaze shifts a key to a translator's text segmentation?,2016,Poznan Studies in Contemporary Linguistics,52,2,,149,173,24.0,12,10.1515/psicl-2016-0015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976625089&doi=10.1515%2fpsicl-2016-0015&partnerID=40&md5=c44e151bd36d0773b233a4c69ed20fa4,"Keystroke logging has demonstrated that a translator's text production can be broken down into units separated by pause boundaries (Dragsted 2004, 2005, 2010). Reading research has not identified analogous boundaries, as the only interruptions in a reader's visual attention to a text are often only blinks. However, in an experimental setup with tracking of a translator's gaze movements across a screen showing the source text and (emerging) target text, gaze data show the translator's shifts of visual attention between the two texts. Can such shifts be seen as an index of content processing units? And do such shifts give us more accurate information about segmentation or more information than keystroke intervals? Using a rather poorly calibrated recording of just one translator's translation of a single sentence (within a longer task) for illustration, the paper seeks to tentatively explore the feasibility of identifying segments, understood as processing units, on the basis of gaze shifts, and to inquire into what motivates gaze shifts. It also seeks to illustrate how much our interpretation of gaze representations, not least suboptimal representations, depend on a theory of reading. © 2016 Faculty of English, Adam Mickiewicz University, Poznań, Poland 2016.",attention shifts; attention units; eye tracking; processing units; segmentation; Translation process research; translation units,,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84976625089,Movies / Media
Hartmann M.; Mast F.W.; Fischer M.H.,"Hartmann, Matthias (55174904500); Mast, Fred W. (7006023670); Fischer, Martin H. (7402920854)",55174904500; 7006023670; 7402920854,Counting is a spatial process: evidence from eye movements,2016,Psychological Research,80,3,,399,409,10.0,44,10.1007/s00426-015-0722-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948147416&doi=10.1007%2fs00426-015-0722-5&partnerID=40&md5=e53a50ebd289c19ca8de1c210a41090a,"Spatial–numerical associations (small numbers—left/lower space and large numbers—right/upper space) are regularly found in simple number categorization tasks. These associations were taken as evidence for a spatially oriented mental number line. However, the role of spatial–numerical associations during more complex number processing, such as counting or mental arithmetic is less clear. Here, we investigated whether counting is associated with a movement along the mental number line. Participants counted aloud upward or downward in steps of 3 for 45 s while looking at a blank screen. Gaze position during upward counting shifted rightward and upward, while the pattern for downward counting was less clear. Our results, therefore, confirm the hypothesis of a movement along the mental number line for addition. We conclude that space is not only used to represent number magnitudes but also to actively operate on numbers in more complex tasks such as counting, and that the eyes reflect this spatial mental operation. © 2015, Springer-Verlag Berlin Heidelberg.",,Adult; Attention; Eye Movements; Female; Humans; Male; Mathematics; Space Perception; adult; attention; depth perception; eye movement; female; human; male; mathematics; physiology,Article,Final,,Scopus,2-s2.0-84948147416,Movies / Media
Vigier T.; Rousseau J.; Perreira Da Silva M.; Le Callet P.,"Vigier, Toinon (55206851100); Rousseau, Josselin (57189663285); Perreira Da Silva, Matthieu (24337440300); Le Callet, Patrick (57200770358)",55206851100; 57189663285; 24337440300; 57200770358,A new HD and UHD video eye tracking dataset,2016,"Proceedings of the 7th International Conference on Multimedia Systems, MMSys 2016",,,2910622,368,373,5.0,14,10.1145/2910017.2910622,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973875433&doi=10.1145%2f2910017.2910622&partnerID=40&md5=e16e78552b092ccfe94346f22a4b9f5f,"The emergence of UHD video format induces larger screens and involves a wider stimulated visual angle. Therefore, its effect on visual attention can be questioned since it can impact quality assessment, metrics but also the whole chain of video processing and creation. Moreover, changes in visual attention from different viewing conditions challenge visual attention models. In this paper, we present a new HD and UHD video eye tracking dataset composed of 37 high quality videos observed by more than 35 naive observers. This dataset can be used to compare viewing behavior and visual saliency in HD and UHD, as well as for any study on dynamic visual attention in videos. It is available at http://ivc.univ-nantes.fr/en/databases/HD-UHD-Eyetracking-Videos/. © 2016 ACM.",Eye tracking; UHD; Video,Behavioral research; Multimedia systems; Eye-tracking; High quality video; Quality assessment; Video; Video processing; Viewing conditions; Visual Attention; Visual attention model; Video signal processing,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84973875433,Movies / Media
Tsiami A.; Katsamanis A.; Maragos P.; Vatakis A.,"Tsiami, Antigoni (56414740900); Katsamanis, Athanasias (57188534717); Maragos, Petros (35243026700); Vatakis, Argiro (9740148700)",56414740900; 57188534717; 35243026700; 9740148700,Towards a behaviorally-validated computational audiovisual saliency model,2016,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",2016-May,,7472197,2847,2851,4.0,11,10.1109/ICASSP.2016.7472197,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973311492&doi=10.1109%2fICASSP.2016.7472197&partnerID=40&md5=4d30a84f1f6ef43584e4f70140b9e012,"Computational saliency models aim at predicting, in a bottom-up fashion, where human attention is drawn in the presented (visual, auditory or audiovisual) scene and have been proven useful in applications like robotic navigation, image compression and movie summarization. Despite the fact that well-established auditory and visual saliency models have been validated in behavioral experiments, e.g., by means of eye-tracking, there is no established computational audiovisual saliency model validated in the same way. In this work, building on biologically-inspired models of visual and auditory saliency, we present a joint audiovisual saliency model and introduce the validation approach we follow to show that it is compatible with recent findings of psychology and neuroscience regarding multimodal integration and attention. In this direction, we initially focus on the «pip and pop» effect which has been observed in behavioral experiments and indicates that visual search in sequences of cluttered images can be significantly aided by properly timed non-spatial auditory signals presented alongside the target visual stimuli. © 2016 IEEE.",audiovisual saliency model; behaviorally-validated; biologically-inspired; multisensory integration,,Conference paper,Final,,Scopus,2-s2.0-84973311492,Movies / Media
Vater C.; Kredel R.; Hossner E.-J.,"Vater, Christian (56385626400); Kredel, Ralf (55872226300); Hossner, Ernst-Joachim (26648242500)",56385626400; 55872226300; 26648242500,Detecting single-target changes in multiple object tracking: The case of peripheral vision,2016,"Attention, Perception, and Psychophysics",78,4,,1004,1019,15.0,25,10.3758/s13414-016-1078-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960122792&doi=10.3758%2fs13414-016-1078-7&partnerID=40&md5=d81d5def09b315c2d2272a0e00017242,"In the present study, we investigated whether peripheral vision can be used to monitor multiple moving objects and to detect single-target changes. For this purpose, in Experiment 1, a modified multiple object tracking (MOT) setup with a large projection screen and a constant-position centroid phase had to be checked first. Classical findings regarding the use of a virtual centroid to track multiple objects and the dependency of tracking accuracy on target speed could be successfully replicated. Thereafter, the main experimental variations regarding the manipulation of to-be-detected target changes could be introduced in Experiment 2. In addition to a button press used for the detection task, gaze behavior was assessed using an integrated eyetracking system. The analysis of saccadic reaction times in relation to the motor response showed that peripheral vision is naturally used to detect motion and form changes in MOT, because saccades to the target often occurred after target-change offset. Furthermore, for changes of comparable task difficulties, motion changes are detected better by peripheral vision than are form changes. These findings indicate that the capabilities of the visual system (e.g., visual acuity) affect change detection rates and that covert-attention processes may be affected by vision-related aspects such as spatial uncertainty. Moreover, we argue that a centroid-MOT strategy might reduce saccade-related costs and that eyetracking seems to be generally valuable to test the predictions derived from theories of MOT. Finally, we propose implications for testing covert attention in applied settings. © 2016, The Psychonomic Society, Inc.",Covert attention; Eyetracking; Motor control; Perception; Saccadic latency; Sports,Attention; Female; Humans; Male; Motion Perception; Photic Stimulation; Reaction Time; Saccades; Visual Fields; Young Adult; attention; female; human; male; movement perception; photostimulation; physiology; procedures; reaction time; saccadic eye movement; visual field; young adult,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84960122792,Movies / Media
Pierce K.; Marinero S.; Hazin R.; McKenna B.; Barnes C.C.; Malige A.,"Pierce, Karen (7101864147); Marinero, Steven (56604294900); Hazin, Roxana (37034118900); McKenna, Benjamin (19337628200); Barnes, Cynthia Carter (35110355700); Malige, Ajith (57210404249)",7101864147; 56604294900; 37034118900; 19337628200; 35110355700; 57210404249,Eye tracking reveals abnormal visual preference for geometric images as an early biomarker of an autism spectrum disorder subtype associated with increased symptom severity,2016,Biological Psychiatry,79,8,,657,666,9.0,272,10.1016/j.biopsych.2015.03.032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961166096&doi=10.1016%2fj.biopsych.2015.03.032&partnerID=40&md5=a0c61c4bbba0db2aaf261724580ad0a7,"Background Clinically and biologically, autism spectrum disorder (ASD) is heterogeneous. Unusual patterns of visual preference as indexed by eye tracking are hallmarks; however, whether they can be used to define an early biomarker of ASD as a whole or leveraged to define a subtype is unclear. To begin to examine this issue, large cohorts are required. Methods A sample of 334 toddlers from six distinct groups (115 toddlers with ASD, 20 toddlers with ASD features, 57 toddlers with developmental delay, 53 toddlers with other conditions [e.g., premature birth, prenatal drug exposure], 64 toddlers with typical development, and 25 unaffected toddlers with siblings with ASD) was studied. Toddlers watched a movie containing geometric and social images. Fixation duration and number of saccades within each area of interest and validation statistics for this independent sample were computed. Next, to maximize power, data from our previous study (n = 110) were added for a total of 444 subjects. A subset of toddlers repeated the eye-tracking procedure. Results As in the original study, a subset of toddlers with ASD fixated on geometric images >69% of the time. Using this cutoff, sensitivity for ASD was 21%, specificity was 98%, and positive predictive value was 86%. Toddlers with ASD who strongly preferred geometric images had 1) worse cognitive, language, and social skills relative to toddlers with ASD who strongly preferred social images and 2) fewer saccades when viewing geometric images. Unaffected siblings of ASD probands did not show evidence of heightened preference for geometric images. Test-retest reliability was good. Examination of age effects suggested that this test may not be appropriate with children >4 years old. Conclusions Enhanced visual preference for geometric repetition may be an early developmental biomarker of an ASD subtype with more severe symptoms. © 2016 Society of Biological Psychiatry.",Autism spectrum disorder; Early detection; Eye gaze; Eye tracking; Geometric preference; Visual attention,"Attention; Autism Spectrum Disorder; Child, Preschool; Cohort Studies; Eye Movement Measurements; Eye Movements; Female; Humans; Infant; Linear Models; Male; Photic Stimulation; Psychiatric Status Rating Scales; Reproducibility of Results; ROC Curve; Sensitivity and Specificity; Severity of Illness Index; Siblings; Visual Perception; Article; attention; autism; child; child development; cognition; cohort analysis; controlled study; disease marker; disease severity assessment; eye fixation; eye tracking; female; human; infant; language; major clinical study; male; predictive value; prematurity; prenatal drug exposure; priority journal; saccadic eye movement; sensitivity and specificity; sibling; social adaptation; social behavior; television viewing; test retest reliability; toddler; Autism Spectrum Disorder; eye movement; oculography; pathophysiology; photostimulation; physiology; preschool child; procedures; psychological rating scale; psychology; receiver operating characteristic; reproducibility; severity of illness index; statistical model; vision",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84961166096,Movies / Media
Mandelkow H.; De Zwart J.A.; Duyn J.H.,"Mandelkow, Hendrik (14123542700); De Zwart, Jacco A. (6701587772); Duyn, Jeff H. (35515600800)",14123542700; 6701587772; 35515600800,Linear discriminant analysis achieves high classification accuracy for the BOLD fMRI response to naturalistic movie stimuli,2016,Frontiers in Human Neuroscience,10,Mar-16,,1,12,11.0,41,10.3389/fnhum.2016.00128,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964772093&doi=10.3389%2ffnhum.2016.00128&partnerID=40&md5=6febc4495a6ae00bcfd96ce7c0d0b9c9,"Naturalistic stimuli like movies evoke complex perceptual processes, which are of great interest in the study of human cognition by functional MRI (fMRI). However, conventional fMRI analysis based on statistical parametric mapping (SPM) and the general linear model (GLM) is hampered by a lack of accurate parametric models of the BOLD response to complex stimuli. In this situation, statistical machine-learning methods, a.k.a. multivariate pattern analysis (MVPA), have received growing attention for their ability to generate stimulus response models in a data-driven fashion. However, machine-learning methods typically require large amounts of training data as well as computational resources. In the past, this has largely limited their application to fMRI experiments involving small sets of stimulus categories and small regions of interest in the brain. By contrast, the present study compares several classification algorithms known as Nearest Neighbor (NN), Gaussian Naïve Bayes (GNB), and (regularized) Linear Discriminant Analysis (LDA) in terms of their classification accuracy in discriminating the global fMRI response patterns evoked by a large number of naturalistic visual stimuli presented as a movie. Results show that LDA regularized by principal component analysis (PCA) achieved high classification accuracies, above 90% on average for single fMRI volumes acquired 2 s apart during a 300 s movie (chance level 0.7% = 2s/300s). The largest source of classification errors were autocorrelations in the BOLD signal compounded by the similarity of consecutive stimuli. All classifiers performed best when given input features from a large region of interest comprising around 25% of the voxels that responded significantly to the visual stimulus. Consistent with this, the most informative principal components represented widespread distributions of co-activated brain regions that were similar between subjects and may represent functional networks. In light of these results, the combination of naturalistic movie stimuli and classification analysis in fMRI experiments may prove to be a sensitive tool for the assessment of changes in natural cognitive processes under experimental manipulation. © 2016 Mandelkow, de Zwart and Duyn.",BOLD fMRI; Classification; Gaussian Naïve Bayes (GNB); Linear discriminant analysis (LDA); Movies; Multivariate pattern analysis (MVPA); Naturalistic stimuli; Nearest-neighbor,adult; analytical error; Article; audiovisual equipment; BOLD signal; brain region; classification algorithm; discriminant analysis; eye tracking; female; functional magnetic resonance imaging; Gaussian Naive Bayes; human; image display; linear discriminant analysis; male; multivariate analysis; naturalistic stimulus; nearest neighbor; nuclear magnetic resonance scanner; principal component analysis; signal noise ratio; stimulus; stimulus response; support vector machine; visual stimulation; voxel; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84964772093,Movies / Media
Sussman E.S.; Ho A.L.; Pendharkar A.V.; Ghajar J.,"Sussman, Eric S. (35325699900); Ho, Allen L. (56689163900); Pendharkar, Arjun V. (24537606400); Ghajar, Jamshid (7003903051)",35325699900; 56689163900; 24537606400; 7003903051,Clinical evaluation of concussion: The evolving role of oculomotor assessments,2016,Neurosurgical Focus,40,4,E7,,,,59,10.3171/2016.1.FOCUS15610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963680059&doi=10.3171%2f2016.1.FOCUS15610&partnerID=40&md5=c2ee64a32e93a39ac34e2b4d4018b90c,"Sports-related concussion is a change in brain function following a direct or an indirect force to the head, identified in awake individuals and accounting for a considerable proportion of mild traumatic brain injury. Although the neurological signs and symptoms of concussion can be subtle and transient, there can be persistent sequelae, such as impaired attention and balance, that make affected patients particularly vulnerable to further injury. Currently, there is no accepted definition or diagnostic criteria for concussion, and there is no single assessment that is accepted as capable of identifying all patients with concussion. In this paper, the authors review the available screening tools for concussion, with particular emphasis on the role of visual function testing. In particular, they discuss the oculomotor assessment tools that are being investigated in the setting of concussion screening. © AANS, 2016.",Concussion diagnosis; Concussion screening; Eye tracking; Oculomotor tracking; Traumatic brain injury; Vision tracking,Brain; Brain Concussion; Humans; Motor Activity; Neuropsychological Tests; Oculomotor Muscles; Visual Acuity; brain; brain concussion; extraocular muscle; human; motor activity; neuropsychological test; pathophysiology; physiology; visual acuity,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84963680059,Movies / Media
Ki J.J.; Kelly S.P.; Parra L.C.,"Ki, Jason J. (57162856400); Kelly, Simon P. (35567885800); Parra, Lucas C. (7006251470)",57162856400; 35567885800; 7006251470,Attention strongly modulates reliability of neural responses to naturalistic narrative stimuli,2016,Journal of Neuroscience,36,10,,3092,3101,9.0,134,10.1523/JNEUROSCI.2942-15.2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960375554&doi=10.1523%2fJNEUROSCI.2942-15.2016&partnerID=40&md5=825b188a574e9dd807964f41a1d9e0fe,"Attentional engagement is a major determinant of how effectively we gather information through our senses. Alongside the sheer growth in the amount and variety of information content that we are presented with through modern media, there is increased variability in the degree to which we “absorb” that information. Traditional research on attention has illuminated the basic principles of sensory selection to isolated features or locations, but it provides little insight into the neural underpinnings of our attentional engagement with modern naturalistic content. Here, we show in human subjects that the reliability of an individual’s neural responses with respect to a larger group provides a highly robust index of the level of attentional engagement with a naturalistic narrative stimulus. Specifically, fast electroencephalographic evoked responses were more strongly correlated across subjects when naturally attending to auditory or audiovisual narratives than when attention was directed inward to a mental arithmetic task during stimulus presentation. This effect was strongest for audiovisual stimuli with a cohesive narrative and greatly reduced for speech stimuli lacking meaning. For compelling audiovisual narratives, the effect is remarkably strong, allowing perfect discrimination between attentional state across individuals. Control experiments rule out possible confounds related to altered eye movement trajectories or order of presentation. We conclude that reliability of evoked activity reproduced across subjects viewing the same movie is highly sensitive to the attentional state of the viewer and listener, which is aided by a cohesive narrative. © 2016 Ki et al.",Attention; Intersubject correlation; Natural narrative,Acoustic Stimulation; Adolescent; Adult; Alpha Rhythm; Analysis of Variance; Attention; Auditory Perception; Brain; Brain Mapping; Eye Movements; Female; Humans; Male; Photic Stimulation; Reproducibility of Results; Visual Perception; Young Adult; adult; Article; artifact; attention; audiovisual response; auditory response; controlled study; electroencephalography; electrooculography; event related potential; evoked response; eye movement; female; human; human experiment; male; mathematical computing; naturalistic narrative stimuli; nerve potential; principal component analysis; priority journal; receiver operating characteristic; stimulus; adolescent; alpha rhythm; analysis of variance; attention; auditory stimulation; brain; brain mapping; hearing; photostimulation; physiology; reproducibility; vision; young adult,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84960375554,Movies / Media
Dingler T.; Agroudy P.E.; Matheis G.; Schmidt A.,"Dingler, Tilman (36731098500); Agroudy, Passant El (57196002644); Matheis, Gerd (57191038522); Schmidt, Albrecht (55596321600)",36731098500; 57196002644; 57191038522; 55596321600,Reading-based screenshot summaries for supporting awareness of desktop activities,2016,ACM International Conference Proceeding Series,25-27-February-2016,,a27,,,,5,10.1145/2875194.2875224,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985905248&doi=10.1145%2f2875194.2875224&partnerID=40&md5=0eefcd749bf343f20654a1ca233f2310,"Lifelogging augments people's ability to keep track of their daily activities and helps them create rich archives and foster memory. Information workers perform a lot of their key activities throughout the day on their desktop computers. We argue that activity summaries can be informed by eye tracking data. Therefore we investigate 3 heuristics to create such summaries based on screenshots to help reconstruct people's work day: A fixed time interval, people's focus of attention as indicated by their eye gaze, and a reading de- Tection algorithm. In a field study with 12 participants who logged their desktop activities for 3 consecutive days we evaluated the usefulness of screenshot summaries based on these heuristics. Our results show the utility of eye tracking data, and more specifically of using reading detection to determine key activities throughout the day to inform the creation of activity summaries that are more relevant and require less time to review. © 2016 ACM.",Desktop activities; Lifelogging; Memory augmentation; Productivity; Recall; Smart summaries,Computer applications; Computer programming; Productivity; Desktop activities; Lifelogging; Memory augmentation; Recall; Smart summaries; Personal computers,Conference paper,Final,,Scopus,2-s2.0-84985905248,Movies / Media
Zhang J.-R.; Chen J.; Yang Z.-J.; Zhang H.-J.; Fu Y.-T.; Shen Y.; He P.-C.; Mao C.-J.; Liu C.-F.,"Zhang, Jin-Ru (57132755500); Chen, Jing (55974911600); Yang, Zi-Jiao (57131575100); Zhang, Hui-Jun (56022806400); Fu, Yun-Ting (57131750100); Shen, Yun (55921732600); He, Pei-Cheng (56611213900); Mao, Cheng-Jie (23970983200); Liu, Chun-Feng (28767739400)",57132755500; 55974911600; 57131575100; 56022806400; 57131750100; 55921732600; 56611213900; 23970983200; 28767739400,Rapid eye movement sleep behavior disorder symptoms correlate with domains of cognitive impairment in parkinson’s disease,2016,Chinese Medical Journal,129,4,,379,385,6.0,50,10.4103/0366-6999.176077,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958974498&doi=10.4103%2f0366-6999.176077&partnerID=40&md5=3ea7c43b745f0b1a691da65773fe3596,"Background: Rapid eye movement (REM) sleep behavior disorder (RBD) may be a risk factor for cognitive impairment in patients with Parkinson’s disease (PD). However, little is known regarding the relation between the severity of RBD and the different domains of cognitive impairment. The aim of this study was: (1) to investigate the domains of cognitive impairment in patients with PD and RBD, and (2) to explore risk factors for PD‑mild cognitive impairment (PD‑MCI) and the relationship between RBD severity and impairment in different cognitive domains in PD. Methods: The participants were grouped as follows: PD without RBD (PD‑RBD; n = 42), PD with RBD (PD + RBD; n = 32), idiopathic RBD (iRBD; n = 15), and healthy controls (HCs; n = 36). All participants completed a battery of neuropsychological assessment of attention and working memory, executive function, language, memory, and visuospatial function. The information of basic demographics, diseases and medication history, and motor and nonmotor manifestations was obtained and compared between PD‑RBD and PD + RBD groups. Particular attention was paid to the severity of RBD assessed by the RBD Questionnaire‑Hong Kong (RBDQ‑HK) and the RBD Screening Questionnaire (RBDSQ), then we further examined associations between the severity of RBD symptoms and cognitive levels via correlation analysis. Results: Compared to PD‑RBD subjects, PD + RBD patients were more likely to have olfactory dysfunction and their Epworth Sleepiness Scale scores were higher (P < 0.05). During neuropsychological testing, PD + RBD patients performed worse than PD‑RBD patients, including delayed memory function, especially. The MCI rates were 33%, 63%, 33%, and 8% for PD‑RBD, PD + RBD, iRBD, and HC groups, respectively. RBD was an important factor for the PD‑MCI variance (odds ratio = 5.204, P = 0.018). During correlation analysis, higher RBDSQ and RBDQ‑HK scores were significantly associated with poorer performance on the Trail Making Test‑B (errors) and Auditory Verbal Learning Test (delayed recall) and higher RBD‑HK scores were also associated with Rey–Osterrieth complex figure (copy) results. Conclusions: When PD‑RBD and PD + RBD patients have equivalent motor symptoms, PD + RBD patients still have more olfactory dysfunction and worse daytime somnolence. RBD is an important risk factor for MCI, including delayed memory. Deficits in executive function, verbal delayed memory, and visuospatial function were consistently associated with more severe RBD symptoms. © 2016 Chinese Medical Journal.",Mild cognitive impairment; Parkinson’s disease; Rapid eye movement sleep behavior disorder,"Aged; Aged, 80 and over; Cognitive Dysfunction; Humans; Logistic Models; Middle Aged; Parkinson Disease; REM Sleep Behavior Disorder; adult; aged; anxiety; Article; assessment of humans; attention; cognitive defect; constipation; controlled study; depression; depth perception; disease association; disease severity; executive function; female; human; hypersalivation; language; major clinical study; male; neuropsychological test; parasomnia; Parkinson disease; REM sleep; Rey auditory verbal learning test; Rey Osterrieth complex figure test; risk factor; trail making test; urinary urgency; working memory; Cognitive Dysfunction; complication; middle aged; parasomnia; Parkinson disease; statistical model; very elderly",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84958974498,Movies / Media
Alsalaheen B.; Haines J.; Yorke A.; Diebold J.,"Alsalaheen, B. (36098928900); Haines, J. (56970611600); Yorke, A. (56145532900); Diebold, J. (57002587700)",36098928900; 56970611600; 56145532900; 57002587700,King-Devick Test reference values and associations with balance measures in high school American football players,2016,Scandinavian Journal of Medicine and Science in Sports,26,2,,235,239,4.0,32,10.1111/sms.12628,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956583666&doi=10.1111%2fsms.12628&partnerID=40&md5=74b54a73a71b2f48b3eabcc73336fbc4,"The King-Devick test appears to be a promising tool in screening for concussions. However, limited evidence exists on the baseline associations between the K-D test and age and baseline screening tools used after concussion. Additionally, there are no published reference values for the K-D test in high school football players. The K-D test, the Balance Error Scoring System, and the Limits of Stability (LOS) test were administered to 157 high school football players. Additionally, a subsample of 62 participants completed the test twice to examine the reliability of K-D test. There was no relationship between the K-D test and the BESS, or the reaction time and directional control of LOS test. Students aged between 16 and 18 years demonstrated faster K-D test performance compared to students between 13 and 15 years of age. However, there was no association between K-D test and history of concussion. The reliability of the K-D test was (ICC2,1 = 0.89), and the minimal detectable change was 6.10 s. Normative reference values for high school football players are presented in this study. © 2016 John Wiley & Sons A/S.",Adolescents; Concussion; Head injury; Minimum detectable change; Normative values; Reliability; Screening; Validity; Visual,"Adolescent; Age Factors; Attention; Brain Concussion; Diagnostic Tests, Routine; Football; Humans; Male; Postural Balance; Reference Values; Reproducibility of Results; Saccades; Speech; United States; adolescent; age; attention; body equilibrium; brain concussion; diagnostic test; football; human; injuries; male; reference value; reproducibility; saccadic eye movement; speech; standards; United States",Article,Final,,Scopus,2-s2.0-84956583666,Movies / Media
Vallejo V.; Cazzoli D.; Rampa L.; Zito G.A.; Feuerstein F.; Gruber N.; Müri R.M.; Mosimann U.P.; Nef T.,"Vallejo, Vanessa (57038547800); Cazzoli, Dario (23990403100); Rampa, Luca (56331322900); Zito, Giuseppe A. (24375945000); Feuerstein, Flurin (57191431829); Gruber, Nicole (55759968900); Müri, René M. (7003342964); Mosimann, Urs P. (6603639434); Nef, Tobias (15726063900)",57038547800; 23990403100; 56331322900; 24375945000; 57191431829; 55759968900; 7003342964; 6603639434; 15726063900,"Effects of Alzheimer's disease on visual target detection: A ""peripheral bias""",2016,Frontiers in Aging Neuroscience,8,AUG,200,,,,15,10.3389/fnagi.2016.00200,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990061888&doi=10.3389%2ffnagi.2016.00200&partnerID=40&md5=6e59f398033a97c98230f00f23851d4f,"Visual exploration is an omnipresent activity in everyday life, and might represent an important determinant of visual attention deficits in patients with Alzheimer's Disease (AD). The present study aimed at investigating visual search performance in AD patients, in particular target detection in the far periphery, in daily living scenes. Eighteen AD patients and 20 healthy controls participated in the study. They were asked to freely explore a hemispherical screen, covering ±90°, and to respond to targets presented at 10°, 30°, and 50° eccentricity, while their eye movements were recorded. Compared to healthy controls, AD patients recognized less targets appearing in the center. No difference was found in target detection in the periphery. This pattern was confirmed by the fixation distribution analysis. These results show a neglect for the central part of the visual field for AD patients and provide new insights by mean of a search task involving a larger field of view. © 2016 Vallejo, Cazzoli, Rampa, Zito, Feuerstein, Gruber, Müri, Mosimann and Nef.",Alzheimer's disease; Eye movements; Large hemispherical screen; Search strategy; Target detection; Visual attention; Visual exploration,aged; Alzheimer disease; Article; clinical article; controlled study; daily life activity; distractibility; eye movement; female; human; male; recognition; response time; stimulus response; visual attention; visual deprivation; visual discrimination; visual field,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84990061888,Movies / Media
Gregori Grgič R.; Calore E.; de'Sperati C.,"Gregori Grgič, Regina (36991882900); Calore, Enrico (26326130600); de'Sperati, Claudio (6603030096)",36991882900; 26326130600; 6603030096,Covert enaction at work: Recording the continuous movements of visuospatial attention to visible or imagined targets by means of Steady-State Visual Evoked Potentials (SSVEPs),2016,Cortex,74,,,31,52,21.0,12,10.1016/j.cortex.2015.10.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947740644&doi=10.1016%2fj.cortex.2015.10.008&partnerID=40&md5=2d8ec992f856f19b99a90f542e7a2aeb,"Whereas overt visuospatial attention is customarily measured with eye tracking, covert attention is assessed by various methods. Here we exploited Steady-State Visual Evoked Potentials (SSVEPs) - the oscillatory responses of the visual cortex to incoming flickering stimuli - to record the movements of covert visuospatial attention in a way operatively similar to eye tracking (attention tracking), which allowed us to compare motion observation and motion extrapolation with and without eye movements. Observers fixated a central dot and covertly tracked a target oscillating horizontally and sinusoidally. In the background, the left and the right halves of the screen flickered at two different frequencies, generating two SSVEPs in occipital regions whose size varied reciprocally as observers attended to the moving target. The two signals were combined into a single quantity that was modulated at the target frequency in a quasi-sinusoidal way, often clearly visible in single trials. The modulation continued almost unchanged when the target was switched off and observers mentally extrapolated its motion in imagery, and also when observers pointed their finger at the moving target during covert tracking, or imagined doing so. The amplitude of modulation during covert tracking was ~25-30% of that measured when observers followed the target with their eyes. We used 4 electrodes in parieto-occipital areas, but similar results were achieved with a single electrode in Oz. In a second experiment we tested ramp and step motion. During overt tracking, SSVEPs were remarkably accurate, showing both saccadic-like and smooth pursuit-like modulations of cortical responsiveness, although during covert tracking the modulation deteriorated. Covert tracking was better with sinusoidal motion than ramp motion, and better with moving targets than stationary ones. The clear modulation of cortical responsiveness recorded during both overt and covert tracking, identical for motion observation and motion extrapolation, suggests to include covert attention movements in enactive theories of mental imagery. © 2015 Elsevier Ltd.",Mental imagery; Motion extrapolation; Smooth pursuit eye movements; SSVEPs; Visuospatial attention,"Adult; Attention; Electroencephalography; Evoked Potentials, Visual; Eye Movements; Female; Humans; Male; Middle Aged; Photic Stimulation; Space Perception; Visual Cortex; Visual Perception; Young Adult; adult; Article; attention; electrode; electroencephalogram; evoked visual response; eye tracking; female; human; human experiment; imagery; male; normal human; oscillation; smooth pursuit eye movement; steady state visual evoked potential; visual cortex; visuospatial attention; attention; depth perception; electroencephalography; eye movement; middle aged; photostimulation; physiology; vision; visual evoked potential; young adult",Article,Final,,Scopus,2-s2.0-84947740644,Movies / Media
Eisenberg M.L.; Zacks J.M.,"Eisenberg, Michelle L. (54400888500); Zacks, Jeffrey M. (7003373705)",54400888500; 7003373705,Ambient and focal visual processing of naturalistic activity,2016,Journal of Vision,16,2,5,,,,50,10.1167/16.2.5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979797009&doi=10.1167%2f16.2.5&partnerID=40&md5=2667ce550ff53c7166efb35ee41db526,"When people inspect a picture, they progress through two distinct phases of visual processing: an ambient, or exploratory, phase that emphasizes input from peripheral vision and rapid acquisition of low-frequency information, followed by a focal phase that emphasizes central vision, salient objects, and high-frequency information. Does this qualitative shift occur during dynamic scene viewing? If so, when? One possibility is that shifts to exploratory processing are triggered at subjective event boundaries. This shift would be adaptive, because event boundaries typically occur when activity features change and when activity becomes unpredictable. Here, we used a perceptual event segmentation task, in which people identified boundaries between meaningful units of activity, to test this hypothesis. In two studies, an eye tracker recorded eye movements and pupil size while participants first watched movies of actors engaged in everyday activities and then segmented them into meaningful events. Saccade amplitudes and fixation durations during the initial viewings suggest that event boundaries function much like the onset of a new picture during static picture presentation: Viewers initiate an ambient processing phase and then progress to focal viewing as the event progresses. These studies suggest that this shift in processing mode could play a role in the formation of mental representations of the current environment.",Ambient and focal processing; Event cognition; Eye tracking; Fixation duration; Pupil size; Saccade amplitude,"Adolescent; Adult; Female; Fixation, Ocular; Humans; Male; Memory, Short-Term; Psychomotor Performance; Pupil; Saccades; Visual Perception; Young Adult; adolescent; adult; eye fixation; female; human; male; physiology; psychomotor performance; pupil; saccadic eye movement; short term memory; vision; young adult",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84979797009,Movies / Media
Tong J.; Maruta J.; Heaton K.J.; Maule A.L.; Rajashekar U.; Spielman L.A.; Ghajar J.,"Tong, Jianliang (59122755700); Maruta, Jun (10439234200); Heaton, Kristin J. (7103392992); Maule, Alexis L. (55606989200); Rajashekar, Umesh (57198522057); Spielman, Lisa A. (7004206470); Ghajar, Jamshid (7003903051)",59122755700; 10439234200; 7103392992; 55606989200; 57198522057; 7004206470; 7003903051,Degradation of binocular coordination during sleep deprivation,2016,Frontiers in Neurology,7,JUN,90,,,,7,10.3389/fneur.2016.00090,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977624567&doi=10.3389%2ffneur.2016.00090&partnerID=40&md5=19360ef499ed100a799f36bcb6096511,"To aid a clear and unified visual perception while tracking a moving target, both eyes must be coordinated, so the image of the target falls on approximately corresponding areas of the fovea of each eye. The movements of the two eyes are decoupled during sleep, suggesting a role of arousal in regulating binocular coordination. While the absence of visual input during sleep may also contribute to binocular decoupling, sleepiness is a state of reduced arousal that still allows for visual input, providing a context within which the role of arousal in binocular coordination can be studied. We examined the effects of sleep deprivation on binocular coordination using a test paradigm that we previously showed to be sensitive to sleep deprivation. We quantified binocular coordination with the SD of the distance between left and right gaze positions on the screen. We also quantified the stability of conjugate gaze on the target, i.e., gaze-target synchronization, with the SD of the distance between the binocular average gaze and the target. Sleep deprivation degraded the stability of both binocular coordination and gaze-target synchronization, but between these two forms of gaze control the horizontal and vertical components were affected differently, suggesting that disconjugate and conjugate eye movements are under different regulation of attentional arousal. The prominent association found between sleep deprivation and degradation of binocular coordination in the horizontal direction may be used for a fit-for-duty assessment. © 2016 Tong, Maruta, Heaton, Maule, Rajashekar, Spielman and Ghajar.",Alertness; Attention; Fatigue; Ocular pursuit; Screening,accuracy; adult; arousal; Article; attention; binocular coordination; controlled study; eye movement; eye movement control; eye tracking; fatigue; female; gaze; human; image analysis; male; motor control; sleep deprivation; somnolence; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84977624567,Movies / Media
Hout M.C.; Godwin H.J.; Fitzsimmons G.; Robbins A.; Menneer T.; Goldinger S.D.,"Hout, Michael C. (56673964200); Godwin, Hayward J. (7005586351); Fitzsimmons, Gemma (42261301100); Robbins, Arryn (56915335500); Menneer, Tamaryn (23012600500); Goldinger, Stephen D. (6701644402)",56673964200; 7005586351; 42261301100; 56915335500; 23012600500; 6701644402,Using multidimensional scaling to quantify similarity in visual search and beyond,2016,"Attention, Perception, and Psychophysics",78,1,,3,20,17.0,40,10.3758/s13414-015-1010-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953638645&doi=10.3758%2fs13414-015-1010-6&partnerID=40&md5=2606288f2dee3034583bc3a6fe5cb5b8,"Visual search is one of the most widely studied topics in vision science, both as an independent topic of interest, and as a tool for studying attention and visual cognition. A wide literature exists that seeks to understand how people find things under varying conditions of difficulty and complexity, and in situations ranging from the mundane (e.g., looking for one’s keys) to those with significant societal importance (e.g., baggage or medical screening). A primary determinant of the ease and probability of success during search are the similarity relationships that exist in the search environment, such as the similarity between the background and the target, or the likeness of the non-targets to one another. A sense of similarity is often intuitive, but it is seldom quantified directly. This presents a problem in that similarity relationships are imprecisely specified, limiting the capacity of the researcher to examine adequately their influence. In this article, we present a novel approach to overcoming this problem that combines multi-dimensional scaling (MDS) analyses with behavioral and eye-tracking measurements. We propose a method whereby MDS can be repurposed to successfully quantify the similarity of experimental stimuli, thereby opening up theoretical questions in visual search and attention that cannot currently be addressed. These quantifications, in conjunction with behavioral and oculomotor measures, allow for critical observations about how similarity affects performance, information selection, and information processing. We provide a demonstration and tutorial of the approach, identify documented examples of its use, discuss how complementary computer vision methods could also be adopted, and close with a discussion of potential avenues for future application of this technique. © 2015, The Psychonomic Society, Inc.",Eye-movements; Methods; Multi-dimensional scaling; Similarity; Visual search,"Animals; Attention; Eye Movements; Humans; Multivariate Analysis; Pattern Recognition, Visual; Photic Stimulation; animal; attention; eye movement; human; multivariate analysis; pattern recognition; photostimulation; physiology; procedures",Review,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-84953638645,Movies / Media
Mannaru P.; Balasingam B.; Pattipati K.; Sibley C.; Coyne J.,"Mannaru, Pujitha (57164857800); Balasingam, Balakumar (34968982000); Pattipati, Krishna (7006476249); Sibley, Ciara (36070781100); Coyne, Joseph (8905031900)",57164857800; 34968982000; 7006476249; 36070781100; 8905031900,Cognitive context detection in UAS operators using eye-gaze patterns on computer screens,2016,Proceedings of SPIE - The International Society for Optical Engineering,9851,,98510F,,,,11,10.1117/12.2224184,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989327815&doi=10.1117%2f12.2224184&partnerID=40&md5=7c0f4c73b4058fced77457d6178460e9,"In this paper, we demonstrate the use of eye-gaze metrics of unmanned aerial systems (UAS) operators as effective indices of their cognitive workload. Our analyses are based on an experiment where twenty participants performed pre-scripted UAS missions of three different difficulty levels by interacting with two custom designed graphical user interfaces (GUIs) that are displayed side by side. First, we compute several eye-gaze metrics, traditional eye movement metrics as well as newly proposed ones, and analyze their effectiveness as cognitive classifiers. Most of the eye-gaze metrics are computed by dividing the computer screen into ""cells"". Then, we perform several analyses in order to select metrics for effective cognitive context classification related to our specific application; the objective of these analyses are to (i) identify appropriate ways to divide the screen into cells; (ii) select appropriate metrics for training and classification of cognitive features; and (iii) identify a suitable classification method. © 2016 SPIE.",cognitive work load; eye movement metrics; eye-gaze metrics; human computer interaction; operator fatigue detection; Unmanned aerial systems; unmanned aerial vehicles,Cognitive systems; Graphical user interfaces; Human computer interaction; Unmanned aerial vehicles (UAV); User interfaces; Classification methods; Cognitive classifiers; Cognitive work; Context classification; Eye-gaze; Fatigue detection; Graphical user interface (GUIs); Unmanned aerial systems; Eye movements,Conference paper,Final,,Scopus,2-s2.0-84989327815,Movies / Media
Oksama L.; Hyönä J.,"Oksama, Lauri (6506041419); Hyönä, Jukka (7003576401)",6506041419; 7003576401,Position tracking and identity tracking are separate systems: Evidence from eye movements,2016,Cognition,146,,,393,409,16.0,41,10.1016/j.cognition.2015.10.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945538075&doi=10.1016%2fj.cognition.2015.10.016&partnerID=40&md5=7b373e3717ea9e8ec96a28a1ec6c2000,"How do we track multiple moving objects in our visual environment? Some investigators argue that tracking is based on a parallel mechanism (e.g., Cavanagh & Alvarez, 2005; Pylyshyn, 1989), others argue that tracking contains a serial component (e.g. Holcombe & Chen, 2013; Oksama & Hyönä, 2008). In the present study, we put previous theories into a direct test by registering observers' eye movements when they tracked identical moving targets (the MOT task) or when they tracked distinct object identities (the MIT task). The eye movement technique is a useful tool to study whether overt focal attention is exploited during tracking. We found a qualitative difference between these tasks in terms of eye movements. When the participants tracked only position information (MOT), the observers had a clear preference for keeping their eyes fixed for a rather long time on the same screen position. In contrast, active eye behavior was observed when the observers tracked the identities of moving objects (MIT). The participants updated over four target identities with overt attention shifts. These data suggest that there are two separate systems involved in multiple object tracking. The position tracking system keeps track of the positions of the moving targets in parallel without the need of overt attention shifts in the form of eye movements. On the other hand, the identity tracking system maintains identity-location bindings in a serial fashion by utilizing overt attention shifts. © 2015 The Authors.",Eye movements; Multiple identity tracking; Multiple object tracking; Visual attention; Visual scanning,Adult; Attention; Eye Movement Measurements; Female; Humans; Male; Space Perception; Visual Perception; Young Adult; adult; Article; attention; eye movement; eye position; eye tracking; female; human; human experiment; male; normal human; prediction; priority journal; qualitative analysis; screening; task performance; young adult; depth perception; oculography; physiology; vision,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-84945538075,Movies / Media
Tangmanee C.,"Tangmanee, Chatpong (55583338200)",55583338200,Fixation and recall of YouTube ad banners: An eye-tracking study,2016,International Journal of Electronic Commerce Studies,7,1,,49,76,27.0,19,10.7903/ijecs.1404,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971568063&doi=10.7903%2fijecs.1404&partnerID=40&md5=43a8f69a195486f8f7373e294e4f6706,"Attaching an ad banner on a clip in a video-sharing website such as YouTube has become common although eye-tracking studies have concluded that this fails to secure visitors' attention. To date, there have been no studies verifying whether ad banners on a video clip can ensure eye fixation from viewers. Through eye-tracking, this study investigates whether YouTube visitors fixate on ad banners, what the correlations between fixation duration on banners and overall fixation counts are, and the extent to which site visitors are able to recall details of ad banners and of the clip viewed. Using a Miramatrix eye-tracker to record YouTube viewers' eye movements, this study showed that nearly all fixated at least once on an ad banner in a clip. However, less than 10% were able to correctly recall the ad content viewed. Nevertheless, about half of viewers were able to correctly recall clip details. Fixation duration on the banner and fixation counts on the clip are negatively correlated, but the relationship between fixation duration and counts on the banner was insignificant. This study sheds new light on YouTube advertising through the use of eye-tracking and advises advertisers to be attentive in selecting clips on which ad banners will appear. © Društvo psihologov Slovenije.",Ad banner; Eye-tracking; Fixation; Recall; YouTube,advertising; correlation; electronic commerce; Internet; perception; tracking,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-84971568063,Movies / Media
Kirkorian H.; Pempek T.; Choi K.,"Kirkorian, Heather (6505817429); Pempek, Tiffany (6504020550); Choi, Koeun (57188555765)",6505817429; 6504020550; 57188555765,The role of online processing in young children’s learning from interactive and noninteractive digital media,2016,Media Exposure During Infancy and Early Childhood: The Effects of Content and Context on Learning and Development,,,,65,89,24.0,25,10.1007/978-3-319-45102-2_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009673805&doi=10.1007%2f978-3-319-45102-2_5&partnerID=40&md5=439eb0121ddc51f425620f3027d48de8,"In the current chapter, we consider the role of information processing in young children’s learning from screens. We describe methods for assessing online processing while children watch video, including physiological measures such as eye movements and heart rate, and argue for the importance of considering both selective and sustained attention in order to fully understand how children process digital media content. We also explore techniques that have proven successful in facilitating transfer from screens to real-life objects. In particular, we discuss the benefits of clarifying the symbolic nature of screen media, reducing cognitive load, and creating interactive experiences with screens. We conclude with a synthesis of these disparate literatures and suggestions for future research. © Springer International Publishing Switzerland 2017.",Educational media; Eye tracking; Infants; Information processing; Learning Online processing; Selective attention; Sustained attention; Transfer deficit; Video comprehension; Video deficit; Young children,,Book chapter,Final,,Scopus,2-s2.0-85009673805,Movies / Media
Damasceno N.A.; Damasceno E.F.,"Damasceno, Nadyr Antonia (35247766200); Damasceno, Eduardo de França (35107162700)",35247766200; 35107162700,Refraction and visual fatigue syndrome on watching the ULTRA HD 4k television curved screen system,2016,Revista Brasileira de Oftalmologia,75,4,,314,319,5.0,1,10.5935/0034-7280.20160062,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992168462&doi=10.5935%2f0034-7280.20160062&partnerID=40&md5=6c6a27114c956c12eea121d966ea9d07,"Purpose: To evaluate eye sensitivity disorder (similar to glare), with symptoms of visual fatigue, through watching television ULTRA HD- 3D-55-inch 4K curved screen among volunteers with normal eye examination. Methods: A prospective, longitudinal, case-control study, with inclusion and exclusion criteria and groups formation enrolled by age range. A comparison of a video documentary presented with the ULTRA HD TV 4K and with the FULL HD TV before and after the previous tele-audience, consisting of an evaluation of three phases of the study regarding the case-control criteria. The main variable analyzed was a questionnaire of visual fatigue syndrome complaints which was compared with secondary variables as the contrast sensitivity test, amplitude of accommodation test, blink frequency test, and test of conjugated saccadic eye movements of big amplitude.Tablets with digital camera equipment were used for video recording of the blink frequency, and saccadic eye movements throughout the television audience. Statistical analysis with Chi Square test. Results: Eighty healthy volunteers were evaluated and assessed as expressiveness of statistical inference alpha (a) of 10%, without obtaining significance of 5% for complaints of a questionnaire Visual Fatigue Syndrome. Other statistical tests showed 5% of significance of data in a global inference research on the frequency of blinking and combined saccadic movements of great amplitude.Conclusion: High resolution television screens ULTRA HD 4K may cause complaints of eyestrain in a population with some uncommon characteristics (low eyelid blink frequency and conjugated saccades movements). The low statistical significant index could be increased in a research with a higher number of participants. The authors call attention to the possibility of increasing this visual fatigue effect in the future advent of Television System ULTRA HD 8K.","Accommodation, ocular; Asthenopia; Audiovisual aids; Blinking; Contrast sensitivity; Refraction; Saccades; Vision, ocular/physiology",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84992168462,Movies / Media
Fernández A.; Ortega M.; Penedo M.G.; Vázquez C.; Gigirey L.M.,"Fernández, Alba (36170381500); Ortega, Marcos (24475406900); Penedo, Manuel González (7004450125); Vázquez, Covadonga (57201502131); Gigirey, Luz M. (7801515590)",36170381500; 24475406900; 7004450125; 57201502131; 7801515590,A methodology for the analysis of spontaneous reactions in automated hearing assessment,2016,IEEE Journal of Biomedical and Health Informatics,20,1,6915839,376,386,10.0,4,10.1109/JBHI.2014.2360061,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971612112&doi=10.1109%2fJBHI.2014.2360061&partnerID=40&md5=19abfab3d97a2d3d81d046257d429365,"Audiology is the science of hearing and auditory processes study. The evaluation of hearing capacity is commonly performed by an audiologist using an audiometer, where the patient is asked to show some kind of sign when he or she recognizes the stimulus. This evaluation becomes much more complicated when the patient suffers some type of cognitive decline that hinders the emission of visible signs of recognition. With this group of patients, a typical question-answer interaction is not applicable, so the audiologist must focus his attention on the patient's spontaneous gestural reactions. This manual evaluation entails a number of problems: it is highly subjective, difficult to determine in real time (since the expert must pay attention simultaneously to the audiological process and the patient's reactions), etc. Considering this, in this paper, we present an automatic methodology for processing video sequences recorded during the performance of the hearing test in order to assist the audiologist in the detection of these spontaneous reactions. This screening method analyzes the movements that occur within the eye area, which has been pointed out by the audiologists as the most representative for these patients. By the analysis of these movements, the system helps the audiologist to determine when a positive gestural reaction has taken place increasing the objectivity and reproducibility. © 2014 IEEE.",,"Aged; Aged, 80 and over; Audiology; Blinking; Databases, Factual; Eye Movements; Face; Female; Hearing Tests; Humans; Image Processing, Computer-Assisted; Male; Middle Aged; Video Recording; Diagnosis; Eye movements; Auditory process; Cognitive decline; Hearing tests; Real time; Reproducibilities; Screening methods; Spontaneous reactions; Video sequences; attention; audiologist; hearing test; human; reproducibility; screening; videorecording; aged; audiology; blinking; eye movement; face; factual database; female; hearing test; image processing; male; middle aged; physiology; procedures; very elderly; Audition",Article,Final,,Scopus,2-s2.0-84971612112,Movies / Media
Laeng B.; Suegami T.; Aminihajibashi S.,"Laeng, Bruno (6603814176); Suegami, Takashi (36455426600); Aminihajibashi, Samira (55994045600)",6603814176; 36455426600; 55994045600,Wine labels: an eye-tracking and pupillometry study,2016,International Journal of Wine Business Research,28,4,,327,348,21.0,38,10.1108/IJWBR-03-2016-0009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998977813&doi=10.1108%2fIJWBR-03-2016-0009&partnerID=40&md5=16b63c5074ffbfc8f27c41bf6ea0b996,"Purpose: The purpose of this paper was to investigate how attention to wine labels related to preference by using quantitative measures of gaze and of the diameter of the eye pupil. We assessed whether eye fixations could predict choices and willingness to pay and whether pupil size could index the aesthetic value of wine labels. More specific goals were to identify which elements of a wine label captured attention the most and to assess whether an authentic label would be preferred by naïve consumers over other alternative labels, also designed by the same studio but excluded from the market. Design/methodology/approach: Infrared eye-tracking was used to measure the amount of time spent on a specific label among four that were simultaneously shown on the computer screen. Participants also made explicit decisions about preferred labels and provided price estimates. Pupillometry was used for labels shown in isolation to obtain a physiological index of their arousing effect and aesthetic appeal. Eye fixations provided an index of what was selected by attention, whereas changes in the pupillary diameter indexed how intensively attention was focused on an item. Findings: A strong positive relationship was found between the dwelling of gaze over a specific label and the degree in which a wine bottle was preferred and (virtually) chosen. The pictorial elements of the labels were fixated the most, whereas verbal information was looked at the least. Attractiveness scores of each bottle collected with one independent group of observers were able to predict the willingness to pay in another group. Moreover, pupil size changed non-linearly in relation to the hedonic values of the wine labels, indicating greater responses to the most as well as least attractive labels (i.e. for the most arousing labels). Research limitations/implications: A limitation of the present experiments was that only choices and behavior of wine “novices” were probed; hence, the present findings might not be generalized to other segments (e.g. wine connoisseurs). Moreover, the present study could not specify which visual properties of a label affect preference, aesthetic value and estimates of price, as the study of these effects would require a large number and variety of label stimuli. Practical implications: Eye monitoring methods could assist marketing studies of preferences and decision-making. Both wine label designers and wine producers could benefit from eye-tracking methods to improve label selection and optimize the design process of a wine label. Originality/value: Although both eye-tracking and pupillometry have been used to the investigate aesthetic preferences for at least the past 50 years, the measurement of pupil diameter and eye movements to study attributes of (authentic) wine labels and their effectiveness is entirely novel. The present study confirms that measures based on eye-tracking combined to explicit choices or ratings provide complementary types of market-relevant information. Both methods provide objective, quantitative, information of the effect of the labels on consumers that is independent but predictive of actual choices and verbally reported preferences. Moreover, they appear to index different processes, pupillometry being a proxy of aesthetic value and gaze a reliable index of choice. Thus, the present findings can be of value to the academic researcher as well as industry and design practitioners. © 2016, © Emerald Group Publishing Limited.",Aesthetics; Eye-tracking; Italy; Labelling; Packaging; Preference; Pricing; Pupillometry; Wine labels; Wines,,Article,Final,,Scopus,2-s2.0-84998977813,Movies / Media
Wipfli R.; Ehrler F.; Bediang G.; Bétrancourt M.; Lovis C.,"Wipfli, Rolf (57216534748); Ehrler, Frederic (22634033200); Bediang, Georges (36647266700); Bétrancourt, Mireille (6602857958); Lovis, Christian (55046580400)",57216534748; 22634033200; 36647266700; 6602857958; 55046580400,How regrouping alerts in computerized physician order entry layout influences physicians' prescription behavior: Results of a crossover randomized trial,2016,JMIR Human Factors,3,1,e15,,,,6,10.2196/humanfactors.5320,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040515238&doi=10.2196%2fhumanfactors.5320&partnerID=40&md5=bd84fde75177dd07bb47757edd321943,"Background: As demonstrated in several publications, low positive predictive value alerts in computerized physician order entry (CPOE) induce fatigue and may interrupt physicians unnecessarily during prescription of medication. Although it is difficult to increase the consideration of medical alerts by physician through an improvement of their predictive value, another approach consists to act on the way they are presented. The interruption management model inspired us to propose an alternative alert display strategy of regrouping the alerts in the screen layout, as a possible solution for reducing the interruption in physicians' workflow. Objective: In this study, we compared 2 CPOE designs based on a particular alert presentation strategy: one design involved regrouping the alerts in a single place on the screen, and in the other, the alerts were located next to the triggering information. Our objective was to evaluate experimentally whether the new design led to fewer interruptions in workflow and if it affected alert handling. Methods: The 2 CPOE designs were compared in a controlled crossover randomized trial. All interactions with the system and eye movements were stored for quantitative analysis. Results: The study involved a group of 22 users consisting of physicians and medical students who solved medical scenarios containing prescription tasks. Scenario completion time was shorter when the alerts were regrouped (mean 117.29 seconds, SD 36.68) than when disseminated on the screen (mean 145.58 seconds, SD 75.07; P=.045). Eye tracking revealed that physicians fixated longer on alerts in the classic design (mean 119.71 seconds, SD 76.77) than in the centralized alert design (mean 70.58 seconds, SD 33.53; P=.001). Visual switches between prescription and alert areas, indicating interruption, were reduced with centralized alerts (mean 41.29, SD 21.26) compared with the classic design (mean 57.81, SD 35.97; P=.04). Prescription behavior (ie, prescription changes after alerting), however, did not change significantly between the 2 strategies of display. The After-Scenario Questionnaire (ASQ) that was filled out after each scenario showed that overall satisfaction was significantly rated lower when alerts were regrouped (mean 4.37, SD 1.23) than when displayed next to the triggering information (mean 5.32, SD 0.94; P=.02). Conclusions: Centralization of alerts in a table might be a way to motivate physicians to manage alerts more actively, in a meaningful way, rather than just being interrupted by them. Our study could not provide clear recommendations yet, but provides objective data through a cognitive psychological approach. Future tests should work on standardized scenarios that would enable. © 2016 JMIR Human Factors. All rights reserved.",Adverse drug reaction reporting systems; Clinical decision support systems; Eye tracking; Medical order entry systems; User-Computer Interface,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85040515238,Movies / Media
Hörstermann T.; Pit-Ten Cate I.M.; Krolak-Schwerdt S.; Glock S.,"Hörstermann, Thomas (36992224200); Pit-Ten Cate, Ineke M. (6506055888); Krolak-Schwerdt, Sabine (6602976574); Glock, Sabine (35248188700)",36992224200; 6506055888; 6602976574; 35248188700,"Primacy effects in attention, recall and judgment patterns of simultaneously presented student information: Evidence from an eye-tracking study",2016,"Student Achievement: Perspectives, Assessment and Improvement Strategies",,,,1,28,27.0,6,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029952751&partnerID=40&md5=3cc6591de70539c6bddc61cabb8ab0c0,"Social cognition research has demonstrated that processes of memory and judgment formation are not only affected by information type but also the sequence in which this information is received. These sequence (i.e., primacy and recency) effects are of special interest if the first or last information activates a social category, as this may increase the risk of stereotypical biases in decision making. This may be especially pertinent to the educational domain as studies have shown that teachers’ judgments are influenced not only by students’ academic achievement but also their social background. Therefore, this study investigated primacy effects in the assessment of student performance. This study not only assessed the impact of sequence on memory and judgment but also measured attention via eye-tracking techniques, hence offering a more detailed test of the assumption of the primacy effect (i.e., increased attention to the first piece of information). Forty participants were presented with four student descriptions, containing information on the student’s grades, standardized test results, working behavior and social background. For half of the participants, social demographic information was presented in the top left position on the screen and grade information in the top right position. For the other half, these positions were switched. The sequence of information was therefore not predefined by the experimenter but left to the participant. However, given the left-to-right and top-to-bottom orientation common in Western European languages, the information in the top left position was expected to draw the initial attention of participants. After reading each student description, participants recommended a fitting secondary school track and later recalled student information. The study applied a 2 × 2 factorial design, with the position order (social demographic vs. grade information in the top left position) as a between-subject factor and type of information (social background vs. grades) as a within-subject factor. In accordance with our expectations, eye-movements (i.e., fixations), showed a significant effect of position order. Information presented in the top left position received not only more initial attention but also more attention throughout than the same information positioned in the top right position, thus indicating a primacy effect in attention. This result was only partially reflected in the recall data, whereas no primacy effect was observed in the accuracy of judgments. The results confirmed that the positioning of simultaneously presented information leads to a primacy effect in attention, but does not produce primacy effects in subsequent recall and judgments. In regard to the common structure of various dossiers and records, which often list a student’s name and personal information first, these findings imply that such presentation format may maximize teachers’ attention to social background information, thereby generating a potential source of social disparities in educational systems. © 2017 by Nova Science Publishers, Inc.",,,Book chapter,Final,,Scopus,2-s2.0-85029952751,Movies / Media
Javaid F.Z.; Brenton J.; Guo L.; Cordeiro M.F.,"Javaid, Fatimah Zara (57193589401); Brenton, Jonathan (57189629963); Guo, Li (42561262400); Cordeiro, Maria F. (57210287162)",57193589401; 57189629963; 42561262400; 57210287162,Visual and ocular manifestations of Alzheimer's disease and their use as biomarkers for diagnosis and progression,2016,Frontiers in Neurology,7,APR,55,,,,149,10.3389/fneur.2016.00055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973580317&doi=10.3389%2ffneur.2016.00055&partnerID=40&md5=6f0a1ebbf2cad6053f7fda523d8d72bc,"Alzheimer's disease (AD) is the most common form of dementia affecting the growing aging population today, with prevalence expected to rise over the next 35 years. Clinically, patients exhibit a progressive decline in cognition, memory, and social functioning due to deposition of amyloid β (Aβ) protein and intracellular hyperphosphorylated tau protein. These pathological hallmarks of AD are measured either through neuroimaging, cerebrospinal fluid analysis, or diagnosed post-mortem. Importantly, neuropathological progression occurs in the eye as well as the brain, and multiple visual changes have been noted in both human and animal models of AD. The eye offers itself as a transparent medium to cerebral pathology and has thus potentiated the development of ocular biomarkers for AD. The use of non-invasive screening, such as retinal imaging and visual testing, may enable earlier diagnosis in the clinical setting, minimizing invasive and expensive investigations. It also potentially improves disease management and quality of life for AD patients, as an earlier diagnosis allows initiation of medication and treatment. In this review, we explore the evidence surrounding ocular changes in AD and consider the biomarkers currently in development for early diagnosis. © 2016 Javaid, Brenton, Guo and Cordeiro.",Alzheimer's disease; Animal models of neurodegenerative disease; Biomarkers; Neurodegereration; Visual changes,amyloid beta protein; biological marker; tau protein; Alzheimer disease; chorioretinopathy; clinical feature; color vision; contrast sensitivity; depth perception; disease course; disease marker; early diagnosis; eye disease; eye movement disorder; human; lens disease; movement perception; non invasive procedure; nonhuman; optic nerve disease; pupil disease; quality of life; retina disease; retinal thickness; Review; stereoscopic vision; visual disorder; visual field defect,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84973580317,Movies / Media
Julayanont P.; Nasreddine Z.S.,"Julayanont, Parunyou (56066491500); Nasreddine, Ziad S. (6508119657)",56066491500; 6508119657,Montreal Cognitive Assessment (MoCA): Concept and clinical review,2016,Cognitive Screening Instruments: A Practical Approach,,,,139,195,56.0,143,10.1007/978-3-319-44775-9_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013140141&doi=10.1007%2f978-3-319-44775-9_7&partnerID=40&md5=a046ae708d4d70e595ba946d215723ca,"The Montreal Cognitive Assessment (MoCA) is a cognitive screening instrument developed to detect mild cognitive impairment (MCI). It is a simple 10 min paper and pencil test that assesses multiple cognitive domains including memory, language, executive functions, visuospatial skills, calculation, abstraction, attention, concentration, and orientation. Its validity has been established to detect mild cognitive impairment in patients with Alzheimer’s disease and other pathologies in cognitively impaired subjects who scored in the normal range on the MMSE. MoCA’s sensitivity and specificity to detect subjects with MCI due to Alzheimer’s disease and distinguish them from healthy controls are excellent. MoCA is also sensitive to detect cognitive impairment in cerebrovascular disease and Parkinson’s disease, Huntington’s disease, brain tumors, systemic lupus erythematosus, substance use disorders, idiopathic rapid eye movement sleep behavior disorder, obstructive sleep apnea, risk of falling, rehabilitation outcome, epilepsy, chronic obstructive pulmonary disease and human immunodeficiency virus infection. There are several features in MoCA’s design that likely explain its superior sensitivity for detecting MCI. MoCA’s memory testing involves more words, fewer learning trials, and a longer delay before recall than the MMSE. Executive functions, higher-level language abilities, and complex visuospatial processing can also be mildly impaired in MCI participants of various etiologies and are assessed by the MoCA with more numerous and demanding tasks than the MMSE. MoCA was developed in a memory clinic setting and normed in a highly educated population. A new version of the MoCA called MoCA-Basic (MoCA-B) was developed to fulfill the limitation of the MoCA among the low educated and illiterate population. MoCA Memory Index Score is a newly devised score that can help clinicians better predict which patients with MCI are most likely to convert to dementia. The MoCA is freely accessible for clinical and educational purposes (www.mocatest.org), and is available in 56 languages and dialects. © Springer International Publishing Switzerland 2017.",Alzheimer’s disease; Dementia; Mild cognitive impairment; Montreal Cognitive Assessment (MoCA); Vascular cognitive impairment,,Book chapter,Final,,Scopus,2-s2.0-85013140141,Movies / Media
Gramatikov B.I.; Rangarajan S.; Irsch K.; Guyton D.L.,"Gramatikov, Boris I. (6701345883); Rangarajan, Shreya (57189376039); Irsch, Kristina (24074172600); Guyton, David L. (7004398660)",6701345883; 57189376039; 24074172600; 7004398660,Attention attraction in an ophthalmic diagnostic device using sound-modulated fixation targets,2016,Medical Engineering and Physics,38,8,,818,821,3.0,4,10.1016/j.medengphy.2016.05.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970024574&doi=10.1016%2fj.medengphy.2016.05.004&partnerID=40&md5=91bf19509cc9d287a7b38a101f0e68d7,"This study relates to eye fixation systems with combined optical and audio systems. Many devices for eye diagnostics and some devices for eye therapeutics require the patient to fixate on a small target for a certain period of time, during which the eyes do not move and data from substructures of one or both eyes are acquired and analyzed. With young pediatric patients, a monotonously blinking target is not sufficient to retain attention steadily. We developed a method for modulating the intensity of a point fixation target using sounds appropriate to the child's age and preference. The method was realized as a subsystem of a Pediatric Vision Screener which employs retinal birefringence scanning for detection of central fixation. Twenty-one children, age 2–18, were studied. Modulation of the fixation target using sounds ensured the eye fixated on the target, and with appropriate choice of sounds, performed significantly better than a monotonously blinking target accompanied by a plain beep. The method was particularly effective with children of ages up to 10, after which its benefit disappeared. Typical applications of target modulation would be as supplemental subsystems in pediatric ophthalmic diagnostic devices, such as scanning laser ophthalmoscopes, optical coherence tomography units, retinal birefringence scanners, fundus cameras, and perimeters. © 2016 IPEM",Attention attraction; Pediatric Vision Screener; Sound-modulated fixation target,"Adolescent; Attention; Child; Child, Preschool; Female; Fixation, Ocular; Humans; Male; Ophthalmoscopes; Sound; Audio systems; Birefringence; Diagnosis; Modulation; Ophthalmology; Optical tomography; Pediatrics; Scanning; Attention attraction; Central fixation; Diagnostic device; Pediatric patients; Retinal birefringence scanning; Scanning laser ophthalmoscope; Small targets; Typical application; adolescent; adult; age; Article; attention; birefringence; child; clinical article; eye fixation; female; human; male; ophthalmological diagnostic device; preschool child; priority journal; sound; strabismus; vision test; attention; eye fixation; ophthalmoscope; sound; Eye movements",Article,Final,,Scopus,2-s2.0-84970024574,Movies / Media
Juhaniak T.; Hlavac P.; Moro R.; Simko J.; Bielikova M.,"Juhaniak, Tomas (57190945426); Hlavac, Patrik (57190949399); Moro, Robert (53984737600); Simko, Jakub (36631117900); Bielikova, Maria (6603891237)",57190945426; 57190949399; 53984737600; 36631117900; 6603891237,Pupillary response: Removing screen luminosity effects for clearer implicit feedback,2016,CEUR Workshop Proceedings,1618,,,,,,2,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984629290&partnerID=40&md5=0185cadc87a9952ff11bb8844f0cf0c8,"Pupillary dilation measured by eye-tracking can be useful source of implicit feedback for system adaptation and personalization. For example, cognitive load or emotional excitation can be inferred from it. However, practical exploitation of this phenomenon (e.g., in adaptive systems or user studies) has been limited due to other factors that influence pupillary dilation, namely changing luminosity of device screen. In this work, we present a personalized pupillary dilation model, which is able to predict the effects of screen luminosity on participant's pupil diameter. This information is useful for tracking true effects of cognitive load or emotional excitation of users. We demonstrate our model in a controlled eye-tracking study with 73 participants.",Cognitive load; Luminosity; Personalized model; Pupillary response,Cognitive loads; Eye-tracking studies; Implicit feedback; Personalizations; Personalized model; Pupillary dilation; Pupillary response; System adaptation; Luminance,Conference paper,Final,,Scopus,2-s2.0-84984629290,Movies / Media
Orava A.T.; Hänninen J.; Korhonen V.M.; Savolainen K.E.; Jokinen S.O.,"Orava, Antti T. (57203463813); Hänninen, Johanna (57203454093); Korhonen, Virpi M. (55955499600); Savolainen, Kaisa E. (57526115000); Jokinen, Satu O. (57192928411)",57203463813; 57203454093; 55955499600; 57526115000; 57192928411,Advantages and challenges of conducting eye tracking studies in physical and virtual environments: Case: Packaging redesign for a ready meal (10),2016,"IAPRI 2016 - 20th World Conference on Packaging: Innovation, Development and Sustainability in Packaging, Proceedings",2016-June,,,90,95,5.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051777243&partnerID=40&md5=11f16a2d474d03125198c43b57400f88,"In packaging related studies, eye tracking has been utilized as a tool for increasing the understanding of consumers' purchase and decision-making processes. With eye tracking, it is possible to discover which elements of packaging design capture consumers' attention and which products they consider before making final purchase decisions. This paper discusses the advantages and challenges of implementing eye tracking experiments in physical and virtual retail environments. The studies were conducted to gather information for a packaging re-design process of a ready meal package. The data consist of 180 eye tracking studies conducted in physical (N=60) and virtual (N=120) retail environments. The virtual environments were examined on a 144-inch projection screen (N=60), and on a 17.3-inch computer display (N=60). Within each group, half of the respondents were exposed to the current package, while the other half saw the new design. The shop on the virtual platform was modelled from photographs taken in the actual physical grocery store environment. The physical environment data were collected with Tobii Pro 2 Glasses, while the virtual studies were conducted with a Tobii X60 remote eye tracker in front of a 144-inch projection screen or with a Tobii X2-60 remote eye tracker installed below a 17.3-inch computer screen. © 2018 CETEA - Packaging Technology Center. All rights reserved.",Consumer study; Eye tracking; Packaging design; Virtual store,Decision making; Packaging; Product design; Projection screens; Sales; Sustainable development; Virtual reality; Computer display; Consumer studies; Decision making process; Eye-tracking studies; Packaging designs; Physical environments; Purchase decision; Virtual stores; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85051777243,Movies / Media
Qing L.; Li M.,"Qing, Li (57193611442); Li, Miao (57193811949)",57193611442; 57193811949,The study on the eye tracking data collected from watching animated movies,2016,"Applied System Innovation - Proceedings of the International Conference on Applied System Innovation, ICASI 2015",,,,919,922,3.0,0,10.1201/b21811-183,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016822713&doi=10.1201%2fb21811-183&partnerID=40&md5=f57d79b2ea4b7cf99a607b8829899dde,"The acquirement of target viewers’ feedback on an animated movie, plays a critical role in the movie’s post-production as well as its distribution strategy into market. The traditional acquisition methods, such as surveys, test screenings, and interviews, could be easily impacted by the viewers’ social desirability effect and recall errors. In this study, the team applied eye tracker, which has been used widely in advertising and marketing, to collect viewer’s visual responses to selected animation clips. The raw data collected by eye tracker were summarized into 4 key measurements we defined to suit the animation product’s unique features. The defined measurements are eye wandering rate, character attention density, visual guidance effect, and visual resistance. © 2016 Taylor & Francis Group, London.",Animation; Eye tracker; Visualization,Animation; Commerce; Flow visualization; Marketing; Motion pictures; Distribution strategies; Eye trackers; Social desirability; Unique features; Visual guidance; Visual response; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85016822713,Movies / Media
Ghaderi Berntsson S.; Katsarogiannis E.; Lourenço F.; Moraes-Fontes M.F.,"Ghaderi Berntsson, Shala (26643752800); Katsarogiannis, Evangelos (37101584200); Lourenço, Filipa (57516189100); Moraes-Fontes, Maria Francisca (8267772800)",26643752800; 37101584200; 57516189100; 8267772800,Progressive Multifocal Leukoencephalopathy and Systemic Lupus Erythematosus: Focus on Etiology,2016,Case Reports in Neurology,8,1,,59,65,6.0,15,10.1159/000444874,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961200978&doi=10.1159%2f000444874&partnerID=40&md5=2e0f5a990ffd400073cf55688f4b9ec6,"Progressive multifocal leukoencephalopathy (PML) caused by reactivation of the JC virus (JCV), a human polyomavirus, occurs in autoimmune disorders, most frequently in systemic lupus erythematosus (SLE). We describe a HIV-negative 34-year-old female with SLE who had been treated with immunosuppressant therapy (IST; steroids and azathioprine) since 2004. In 2011, she developed decreased sensation and weakness of the right hand, followed by vertigo and gait instability. The diagnosis of PML was made on the basis of brain MRI findings (posterior fossa lesions) and JCV isolation from the cerebrospinal fluid (700 copies/ml). IST was immediately discontinued. Cidofovir, mirtazapine, mefloquine and cycles of cytarabine were sequentially added, but there was progressive deterioration with a fatal outcome 1 year after disease onset. This report discusses current therapeutic choices for PML and the importance of early infection screening when SLE patients present with neurological symptoms. In the light of recent reports of PML in SLE patients treated with rituximab or belimumab, we highlight that other IST may just as well be implicated. We conclude that severe lymphopenia was most likely responsible for JCV reactivation in this patient and discuss how effective management of lymphopenia in SLE and PML therapy remains an unmet need. © 2016 The Author(s). Published by S. Karger AG, Basel.",Lymphopenia; Progressive multifocal leukoencephalopathy; Systemic lupus erythematosus,antinuclear antibody; azathioprine; belimumab; cidofovir; cytarabine; deflazacort; double stranded DNA; gadolinium; histone antibody; mefloquine; mirtazapine; nucleosome antibody; ribonucleoprotein; rituximab; Sm antibody; steroid; adult; alopecia; antibody titer; arm weakness; arthralgia; arthropathy; Article; ataxia; ataxic gait; case report; CD4 CD8 ratio; cerebellar peduncle; cerebrospinal fluid; confusion; depression; deterioration; diplopia; drug withdrawal; dysarthria; dysphagia; electromyography; fatality; fatigue; female; flow cytometry; follow up; gait; hemiparesis; hopelessness; hospital admission; human; Human immunodeficiency virus; hypergammaglobulinemia; hypocomplementemia; immunofluorescence test; immunosuppressive treatment; insomnia; jaccoud arthropathy; JC virus; lethargy; loss of appetite; lymphocyte count; lymphocytopenia; magnetic resonance angiography; mood change; nausea; neuroimaging; neurologic disease; nuclear magnetic resonance imaging; nystagmus; persistent vegetative state; personal experience; photosensitivity; pneumonia; Portuguese (citizen); priority journal; progressive multifocal leukoencephalopathy; recurrent infection; saccadic eye movement; systemic lupus erythematosus; treatment duration; vertigo; virus isolation; virus reactivation; vomiting,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-84961200978,Movies / Media
Mills C.; Bixler R.; Wang X.; D'Mello S.K.,"Mills, Caitlin (40661587800); Bixler, Robert (55789867400); Wang, Xinyi (57211027176); D'Mello, Sidney K. (14053463100)",40661587800; 55789867400; 57211027176; 14053463100,Automatic gaze-based detection of mind wandering during narrative film comprehension,2016,"Proceedings of the 9th International Conference on Educational Data Mining, EDM 2016",,,,30,37,7.0,35,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072287925&partnerID=40&md5=6449f242a1318645539f4328743048a0,"Mind wandering (MW) reflects a shift in attention from task-related to task-unrelated thoughts. It is negatively related to performance across a range of tasks, suggesting the importance of detecting and responding to MW in real-time. Currently, there is a paucity of research on MW detection in contexts other than reading. We addressed this gap by using eye gaze to automatically detect MW during narrative film comprehension, an activity that is used across a range of learning environments. In the current study, students self-reported MW as they watched a 32.5-minute commercial film. Students’ eye gaze was recorded with an eye tracker. Supervised machine learning models were used to detect MW using global (content-independent), local (content-dependent), and combined global+local features. We achieved a student-independent score (MW F1) of .45, which reflected a 29% improvement over a chance baseline. Models built using local features were more accurate than the global and combined models. An analysis of diagnostic features revealed that MW primarily manifested as a breakdown in attentional synchrony between eye gaze and visually salient areas of the screen. We consider limitations, applications, and refinements of the MW detector. © 2016 International Educational Data Mining Society. All rights reserved.",Eye gaze; Film comprehension; Machine learning; Mind wandering,Computer aided instruction; Data mining; Learning systems; Machine learning; Students; Supervised learning; Combined model; Content dependent; Diagnostic features; Eye-gaze; Learning environments; Local feature; Mind wandering; Supervised machine learning; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85072287925,Movies / Media
Mannaru P.; Balasingam B.; Pattipati K.; Sibley C.; Coyne J.,"Mannaru, Pujitha (57164857800); Balasingam, Balakumar (34968982000); Pattipati, Krishna (7006476249); Sibley, Ciara (36070781100); Coyne, Joseph (8905031900)",57164857800; 34968982000; 7006476249; 36070781100; 8905031900,On the use of hidden Markov models for gaze pattern modeling,2016,Proceedings of SPIE - The International Society for Optical Engineering,9851,,98510R,,,,4,10.1117/12.2224190,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989360890&doi=10.1117%2f12.2224190&partnerID=40&md5=5daf74bfc9c454a82572cd694be82607,"Some of the conventional metrics derived from gaze patterns (on computer screens) to study visual attention, engagement and fatigue are saccade counts, nearest neighbor index (NNI) and duration of dwells/fixations. Each of these metrics has drawbacks in modeling the behavior of gaze patterns; one such drawback comes from the fact that some portions on the screen are not as important as some other portions on the screen. This is addressed by computing the eye gaze metrics corresponding to important areas of interest (AOI) on the screen. There are some challenges in developing accurate AOI based metrics: firstly, the definition of AOI is always fuzzy; secondly, it is possible that the AOI may change adaptively over time. Hence, there is a need to introduce eye-gaze metrics that are aware of the AOI in the field of view; at the same time, the new metrics should be able to automatically select the AOI based on the nature of the gazes. In this paper, we propose a novel way of computing NNI based on continuous hidden Markov models (HMM) that model the gazes as 2D Gaussian observations (x-y coordinates of the gaze) with the mean at the center of the AOI and covariance that is related to the concentration of gazes. The proposed modeling allows us to accurately compute the NNI metric in the presence of multiple, undefined AOI on the screen in the presence of intermittent casual gazing that is modeled as random gazes on the screen. © 2016 SPIE.",cognitive workload; gaze metrics; hidden Markov models; Human computer interaction; nearest neighbor index; NNI.,Behavioral research; Eye movements; Human computer interaction; Markov processes; Trellis codes; X-Y model; Cognitive workloads; Computer screens; Continuous hidden Markov model; Field of views; Gaussians; gaze metrics; Nearest neighbors; Visual Attention; Hidden Markov models,Conference paper,Final,,Scopus,2-s2.0-84989360890,Movies / Media
Aurat D.; Leroy L.; Hugues O.; Fuchs P.,"Aurat, David (57193892114); Leroy, Laure (19640647700); Hugues, Olivier (36166890900); Fuchs, Philippe (52363482600)",57193892114; 19640647700; 36166890900; 52363482600,An adaptive blur in peripheral vision to reduce visual fatigue in stereoscopic vision,2016,IS and T International Symposium on Electronic Imaging Science and Technology,,,,,,,0,10.2352/ISSN.2470-1173.2016.5.SDA-438,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046055292&doi=10.2352%2fISSN.2470-1173.2016.5.SDA-438&partnerID=40&md5=24d2ea55aeed731fc354915a2bf89585,"For some years, a lot of Stereoscopic 3D contents have been released. Even if the depth sensation is realistic, it is still not perfect and uncomfortable. The objective of our work is to use the gaze of the user to bring closer artificial vision and natural vision to increase the precision of the perception and decrease visual fatigue. For example, a difference in artificial vision is the accommodation point and the convergence point of the eye. In natural vision, these points are the same whereas in artificial vision event if the convergence point is on the looked object, the accommodation point remains on the screen. This difference bring visual fatigue. In this article, we propose and evaluate the effect of an artificial blur in peripheral vision in order to reduce the accommodation vergence conflict and so the strain. We found that adding a blur in peripheral vision decreases the visual fatigue but this blur can't be used actually due to eye-Tracker latency. © 2016 Society for Imaging Science and Technology.",,Display devices; Stereo image processing; 3D content; Convergence points; Depth sensations; Eye trackers; Natural visions; Peripheral vision; Stereoscopic vision; Visual fatigue; Vision,Conference paper,Final,,Scopus,2-s2.0-85046055292,Movies / Media
Bröhl C.; Theis S.; Wille M.; Rasche P.; Mertens A.; Schlick C.M.,"Bröhl, Christina (55802629900); Theis, Sabine (55787666300); Wille, Matthias (55787695600); Rasche, Peter (56919666400); Mertens, Alexander (35746549300); Schlick, Christopher M. (59872957900)",55802629900; 55787666300; 55787695600; 56919666400; 35746549300; 59872957900,Age-differentiated analysis of the hand proximity effect by means of eye-tracking,2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),9754,,,301,308,7.0,0,10.1007/978-3-319-39943-0_29,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978817924&doi=10.1007%2f978-3-319-39943-0_29&partnerID=40&md5=9e86b59259c856689c49654b1da6c80d,"Research focusing on the position of the hands with regard to visual stimuli has recently received a great deal of attention. One of the main findings is that stimuli that are close to the hands are perceived and processed more precisely than those that are more distant. In this study, the effect of hand proximity was studied using a visual search task and analyzed regarding fixation durations. The hands were placed in varying positions: directly at the screen, on the table and on the lap. As performance in information processing is highly dependent on the subject’s age, effects were analyzed in an age-differentiated manner. Results showed a significant effect regarding hand positions moderated by age: Fixation durations were shorter for positions of the hands at the screen and longer for positions away from the screen in the younger age group. In the older age group the effect was vice versa, fixation durations were longer for the position of the hand at the screen and shorter for positions away from the screen. © Springer International Publishing Switzerland 2016.",Age-robust design; Ergonomic design; Eye-tracking; Hand proximity; Nearby hands; Peripersonal space; Visual search,Ergonomics; Human computer interaction; Ergonomic design; Eye-tracking; Hand proximity; Nearby hands; Peripersonal space; Robust designs; Visual search; Palmprint recognition,Conference paper,Final,,Scopus,2-s2.0-84978817924,Movies / Media
Suchan J.; Bhatt M.,"Suchan, Jakob (55767093900); Bhatt, Mehul (8925250400)",55767093900; 8925250400,Semantic question-answering with video and eye-tracking data: AI foundations for human visual perception driven cognitive film studies,2016,IJCAI International Joint Conference on Artificial Intelligence,2016-January,,,2633,2639,6.0,28,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006147319&partnerID=40&md5=f2f5fde8114ba9c70c04ebb296e56e68,"We present a computational framework for the grounding and semantic interpretation of dynamic visuo-spatial imagery consisting of video and eyetracking data. Driven by cognitive film studies and visual perception research, we demonstrate key technological capabilities aimed at investigating attention and recipient effects vis-a-vis the motion picture; this encompasses high-level analysis of subject's visual fixation patterns and correlating this with (deep) semantic analysis of the dynamic visual data (e.g., fixation on movie characters, influence of cinematographic devices such as cuts). The framework and its application as a general AI-based assistive technology platform -integrating vision and KR- for cognitive film studies is highlighted.",,Artificial intelligence; Semantics; Vision; Assistive technology; Computational framework; High-level analysis; Human visual perception; Question Answering; Semantic analysis; Semantic interpretation; Technological capability; Motion pictures,Conference paper,Final,,Scopus,2-s2.0-85006147319,Movies / Media
Desjardins J.L.,"Desjardins, Jamie L. (28567672200)",28567672200,The effects of hearing aid directional microphone and noise reduction processing on listening effort in older adults with hearing loss,2016,Journal of the American Academy of Audiology,27,1,,29,41,12.0,43,10.3766/jaaa.15030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957095100&doi=10.3766%2fjaaa.15030&partnerID=40&md5=4d84f92110f03d063fc285a17e1dafb5,"Background: Older listeners with hearing loss may exert more cognitive resources to maintain a level of listening performance similar to that of younger listeners with normal hearing. Unfortunately, this increase in cognitive load, which is often conceptualized as increased listening effort, may come at the cost of cognitive processing resources that might otherwise be available for other tasks. Purpose: The purpose of this study was to evaluate the independent and combined effects of a hearing aid directional microphone and a noise reduction (NR) algorithm on reducing the listening effort older listeners with hearing loss expend on a speech-in-noise task. Research Design: Participants were fitted with study worn commercially available behind-the-ear hearing aids. Listening effort on a sentence recognition in noise task was measured using an objective auditory-visual dual-task paradigm. The primary task required participants to repeat sentences presented in quiet and in a four-talker babble. The secondary task was a digital visual pursuit rotor-tracking test, for which participants were instructed to use a computer mouse to track a moving target around an ellipse that was displayed on a computer screen. Each of the two tasks was presented separately and concurrently at a fixed overall speech recognition performance level of 50% correct with and without the directional microphone and/or the NR algorithm activated in the hearing aids. In addition, participants reported how effortful it was to listen to the sentences in quiet and in background noise in the different hearing aid listening conditions. Study Sample: Fifteen older listeners with mild sloping to severe sensorineural hearing loss participated in this study. Results: Listening effort in background noise was significantly reduced with the directional microphones activated in the hearing aids. However, there was no significant change in listening effort with the hearing aid NR algorithm compared to no noise processing. Correlation analysis between objective and self-reported ratings of listening effort showed no significant relation. Conclusions: Directional microphone processing effectively reduced the cognitive load of listening to speech in background noise. This is significant because it is likely that listeners with hearing impairment will frequently encounter noisy speech in their everyday communications.",Aging; Cognition; Directional microphones; Hearing aids; Hearing loss; Listening effort; Noise reduction algorithm,"Aged; Hearing Aids; Hearing Loss, Sensorineural; Humans; Middle Aged; Noise; Speech Perception; aged; air conduction; Article; bone conduction; cognition; digit symbol substitution test; dual-task performance (test); eye tracking; feedback system; female; frequency modulation; hearing; hearing aid; hearing aid directional microphone; human; human experiment; male; microphone; noise reduction; otorhinolaryngology therapeutic device; perception deafness; priority journal; self evaluation; self report; speech discrimination; Wechsler adult intelligence scale; working memory; middle aged; noise; perception deafness; speech perception",Article,Final,,Scopus,2-s2.0-84957095100,Movies / Media
Westhoven M.; Plegge C.; Henrich T.; Alexander T.,"Westhoven, Martin (56964308200); Plegge, Christian (57190278921); Henrich, Timo (57190278057); Alexander, Thomas (7101893679)",56964308200; 57190278921; 57190278057; 7101893679,Posture based recognition of the visual focus of attention for adaptive mobile information systems,2016,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),9743,,,416,427,11.0,3,10.1007/978-3-319-39955-3_39,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978818948&doi=10.1007%2f978-3-319-39955-3_39&partnerID=40&md5=392cd70bea2b170a65a53d01c1851783,"This paper presents a method to estimate the visual focus of attention from body posture in a system consisting of a head-mounted display and an arm-mounted smartphone. The approach aims at fast and robust detection without using additional hardware, even when walking. Knowledge about the visual focus of attention can be used to adapt user interfaces. E.g. eye-tracking can yield precise measurements for stationary systems. This it is not always possible using mobile devices due to body movement dynamics. A practical solution is achieved through a combination of orientation information and known anatomical limitations. The approach was parameterized and evaluated, reaching mean detection rates of over 97 %. Generalized parameters allow for usage without individual configuration. Used as a screen unlocking mechanism for smartphones, faster access can be realized in comparison to manual unlocking. © Springer International Publishing Switzerland 2016.",Information ergonomics; Mobile HCI; Wearable computing,Cognitive systems; Ergonomics; Helmet mounted displays; Mobile devices; Mobile telecommunication systems; Neurology; Smartphones; User interfaces; Head mounted displays; Individual configuration; Mobile HCI; Mobile information systems; Orientation information; Precise measurements; Visual focus of attentions; Wearable computing; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-84978818948,Movies / Media
Pereira M.S.; Cozijn R.; Postma E.; Shahid S.; Swerts M.,"Pereira, Mariana Serras (57188717594); Cozijn, Reinier (12546062800); Postma, Eric (7003597730); Shahid, Suleman (23398723200); Swerts, Marc (7003962295)",57188717594; 12546062800; 7003597730; 23398723200; 7003962295,Comparing a perceptual and an automated vision-based method for lie detection in younger children,2016,Frontiers in Psychology,7,DEC,1936,,,,4,10.3389/fpsyg.2016.01936,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009168988&doi=10.3389%2ffpsyg.2016.01936&partnerID=40&md5=43541cf5b52e09ed3462052d29b15041,"The present study investigates how easily it can be detected whether a child is being truthful or not in a game situation, and it explores the cue validity of bodily movements for such type of classification. To achieve this, we introduce an innovative methodology - the combination of perception studies (in which eye-tracking technology is being used) and automated movement analysis. Film fragments from truthful and deceptive children were shown to human judges who were given the task to decide whether the recorded child was being truthful or not. Results reveal that judges are able to accurately distinguish truthful clips from lying clips in both perception studies. Even though the automated movement analysis for overall and specific body regions did not yield significant results between the experimental conditions, we did find a positive correlation between the amount of movement in a child and the perception of lies, i.e., the more movement the children exhibited during a clip, the higher the chance that the clip was perceived as a lie. The eye-tracking study revealed that, even when there is movement happening in different body regions, judges tend to focus their attention mainly on the face region. This is the first study that compares a perceptual and an automated method for the detection of deceptive behavior in children whose data have been elicited through an ecologically valid paradigm. © 2016 Serras Pereira, Cozijn, Postma, Shahid and Swerts.","Children; Eye-tracking; Lie detection; Methodology; Motion, non-verbal signals; Video analysis",,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85009168988,Movies / Media
Nussenbaum K.; Amso D.,"Nussenbaum, Kate (57115445700); Amso, Dima (6506971908)",57115445700; 6506971908,An Attentional Goldilocks Effect: An Optimal Amount of Social Interactivity Promotes Word Learning From Video,2016,Journal of Cognition and Development,17,1,,30,40,10.0,19,10.1080/15248372.2015.1034316,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958047858&doi=10.1080%2f15248372.2015.1034316&partnerID=40&md5=855bccd6d5fce24a05b1bba56e949d54,"Television can be a powerful education tool; however, content makers must understand the factors that engage attention and promote learning from screen media. Prior research has suggested that social engagement is critical for learning and that interactivity may enhance the educational quality of children’s media. The present study examined the effects of increasing the social interactivity of television on children’s visual attention and word learning. Three- to 5-year-old (Mage = 4;5, SD = 9 months) children completed a task in which they viewed videos of an actress teaching them the Swahili label for an on-screen image. Each child viewed these video clips in 4 conditions that parametrically manipulated social engagement and interactivity. We then tested whether each child had successfully learned the Swahili labels. Though 5-year-old children were able to learn words in all conditions, we found that there was an optimal level of social engagement that best supported learning for all participants, defined by engaging the child but not distracting from word labeling. Our eye-tracking data indicated that children in this condition spent more time looking at the target image and less time looking at the actress’s face as compared with the most interactive condition. These findings suggest that social interactivity is critical to engaging attention and promoting learning from screen media up until a certain point, after which social stimuli may draw attention away from target images and impair children’s word learning. © 2016 Taylor & Francis Group, LLC.",,Article; attentional goldilocks effect; audio recording; child; eye tracking; female; giraffe; human; language ability; major clinical study; male; paired associate learning; selective attention; social interaction; television; videorecording; word list recall,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-84958047858,Movies / Media
,,,Procedia Computer Science,2016,Procedia Computer Science,84,,,,,207.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994358474&partnerID=40&md5=7a69acae40a55c020c91f9877ece893a,The proceedings contain 29 papers. The topics discussed include: single channel speech enhancement: using wiener filtering with recursive noise estimation; bispectral analysis of EEG for emotion recognition; analysis of human kinetics using millimeter-wave micro-Doppler radar; hand drawn optical circuit recognition; initial implementation of natural language turn-based dialog system; digitally transparent interface using eye tracking; phrase and idiom identification in Assamese; measurement of cognitive load in HCI systems using EEG power spectrum: an experimental study; using hall effect sensors for 3D space text entry on smartwatches; and semi-supervised aspect based sentiment analysis for movies using review filtering.,,,Conference review,Final,,Scopus,2-s2.0-84994358474,Movies / Media
Garciá A.; Ramírez C.; Valdez P.,"Garciá, Aída (7404609190); Ramírez, Candelaria (7102424180); Valdez, Pablo (6602728377)",7404609190; 7102424180; 6602728377,"Circadian variations in self-monitoring, a component of executive functions",2016,Biological Rhythm Research,47,1,,7,23,16.0,4,10.1080/09291016.2015.1075722,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946492932&doi=10.1080%2f09291016.2015.1075722&partnerID=40&md5=5fd4d79b5d19ea5ab4e2707b59a26f7f,"The objective of this study was to identify circadian rhythms in self-monitoring, a component of executive functions. Participants were 10 undergraduate students, age: 18.5 ± 2.68 years, two male and eight female. They were recorded on a 30-h constant routine protocol; rectal temperature was recorded every minute and performance on a tracking task was assessed every 100 min. Self-monitoring indicators were adjustments of responses to random changes of speed and trajectory of a circle moving on the computer screen. Participants showed better accuracy during the afternoon, with decreases in the morning (06:20 and 08:00 h). These variations showed a phase delay of 2:29 ± 2:19 h with respect to the circadian rhythm of body temperature. In conclusion, there are circadian variations in self-monitoring. The decline in this component of executive functions could cause serious accidents among people working or studying during a morning shift, as well as commuting to and from work or school. © 2015 Taylor and Francis.",circadian rhythms; cognitive performance; executive functions; self-monitoring,biomonitoring; body temperature; circadian rhythm; cognition; computer simulation; human behavior; performance assessment; adult; Article; body temperature; caloric intake; circadian rhythm; executive function; eye tracking; female; human; male; motor performance; normal human; rectum temperature; response time; self monitoring; task performance; undergraduate student,Article,Final,,Scopus,2-s2.0-84946492932,Movies / Media
Zangrossi A.; Cona G.; Celli M.; Zorzi M.; Corbetta M.,"Zangrossi, Andrea (56968075100); Cona, Giorgia (36246991700); Celli, Miriam (57267384700); Zorzi, Marco (7102431895); Corbetta, Maurizio (7003824365)",56968075100; 36246991700; 57267384700; 7102431895; 7003824365,Visual exploration dynamics are low-dimensional and driven by intrinsic factors,2021,Communications Biology,4,1,1100,,,,19,10.1038/s42003-021-02608-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115386529&doi=10.1038%2fs42003-021-02608-x&partnerID=40&md5=16f4514962d8fecd09a9e97603632e81,"When looking at visual images, the eyes move to the most salient and behaviourally relevant objects. Saliency and semantic information significantly explain where people look. Less is known about the spatiotemporal properties of eye movements (i.e., how people look). We show that three latent variables explain 60% of eye movement dynamics of more than a hundred observers looking at hundreds of different natural images. The first component explaining 30% of variability loads on fixation duration, and it does not relate to image saliency or semantics; it approximates a power-law distribution of gaze steps, an intrinsic dynamic measure, and identifies observers with two viewing styles: static and dynamic. Notably, these viewing styles were also identified when observers look at a blank screen. These results support the importance of endogenous processes such as intrinsic dynamics to explain eye movement spatiotemporal properties. © 2021, The Author(s).",,Adult; Attention; Eye Movements; Female; Humans; Italy; Male; Semantics; Students; Visual Perception; Young Adult; adult; attention; eye movement; female; human; Italy; male; semantics; student; vision; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85115386529,Movies / Media
Mori T.; Otomo T.; Nosaka Y.; Ishii E.; Hoshino Y.; Yamada M.,"Mori, Taiga (57207823738); Otomo, Takahide (57211111359); Nosaka, Yusuke (57220071683); Ishii, Eriko (57205999750); Hoshino, Yuko (55555640800); Yamada, Mitsuho (7405745700)",57207823738; 57211111359; 57220071683; 57205999750; 55555640800; 7405745700,Development of a web browsing support system using gaze information,2021,Proceedings of the International Display Workshops,27,,,953,956,3.0,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119969348&partnerID=40&md5=5c70c4599e634bb270477ad1bd7af192,"Eye-tracking technologies are currently receiving a lot of attention. Here, we attempt to develop a web-browsing support system using a contactless and low-cost gaze-input device. Our system automatically extracts a sentence from an HTML web page based on the gazing point. It then analyzes it to present supporting information about the viewing content. This system automatically derives search queries that can help to find related or additional information just by looking at the screen. Therefore, it is possible to support the user's web browsing by gaze information. This is a basic study to consider an interactive system that can be used with a low-cost gaze-input device for consumers. Since there are still few reports on such research or systems, we believe that this study will contribute to the development of gaze interaction systems that utilize gaze interfaces in the future. © 2020 ITE and SID.",Gaze; Gaze input device; Web-browsing support system,Costs; Knobs; Search engines; Websites; Contact less; Eye tracking technologies; Gaze; Gaze input device; Input devices; Interactive system; Low-costs; Search queries; Web browsing support system; Web-page; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85119969348,Movies / Media
Zahedi S.; Khoshsaligheh M.,"Zahedi, Saber (57556089700); Khoshsaligheh, Masood (56946904400)",57556089700; 56946904400,Eyetracking the impact of subtitle length and line number on viewers’ allocation of visual attention,2021,"Translation, Cognition and Behavior",4,2,,331,352,21.0,4,10.1075/tcb.00058.zah,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127331161&doi=10.1075%2ftcb.00058.zah&partnerID=40&md5=e841c88981095070de6644797e8531dc,"Compared to one-line subtitles, two-line subtitles are believed to receive more attention from viewers based on previous research. Yet, in the majority of these studies, two-liners are considerably longer than the one-line subtitles. The authors argue that the findings of the previous studies could have been affected by the difference in subtitle length, and there is a need to operationally distinguish between the impact of subtitle length and line number on viewers’ attention allocation. Therefore, an SMI eye tracker was used in this study to record the eye movements of 32 Iranian viewers while reading the Persian subtitles of a short segment of a feature film, A Prophet (Jacques Audiard 2009). The results showed that the viewers’ attention to one-line subtitles was significantly greater than the attention they allotted to two-line subtitles although they were of the same length. The attention allocated to the long subtitles was also significantly greater compared to the attention paid to the short subtitles. Retrospective interviews also showed that the participants favored short and two-line subtitles. © John Benjamins Publishing Company.",Eye tracking; Line number; Subtitle length; Subtitle reception,,Article,Final,,Scopus,2-s2.0-85127331161,Movies / Media
Raoli H.; Lina C.; Guoen C.; Yingqing W.; Xiaochun C.; Qinyong Y.,"Raoli, He (57796479000); Lina, Chen (58187150000); Guoen, Cai (57219100891); Yingqing, Wang (57219101328); Xiaochun, Chen (57219100916); Qinyong, Ye (8985907800)",57796479000; 58187150000; 57219100891; 57219101328; 57219100916; 8985907800,Side of oneset of motor symptoms influences sleep in Parkinson's disease; [帕金森病患者运动症状起病侧对睡眠的影响],2021,Chinese Journal of Neurology,54,12,,1241,1248,7.0,0,10.3760/cma.j.cn113694-20210426-00302,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133956739&doi=10.3760%2fcma.j.cn113694-20210426-00302&partnerID=40&md5=cd64f0460af37eb79330d0d93b6290d7,"Objective To evaluate the sleep disorders in patients with Parkinson's disease (PD) with different onset sides, and to analyze the correlation between PD kinesia-onset side and sleep disorders. Methods A total of 658 patients with primary PD admitted to the Special Outpatient Department of Parkinson's disease in Fujian Medical University Union Hospital from January 2015 to March 2021 were collected. According to the onset side of motor symptoms, they were divided into the left group (313 cases) and the right group (345 cases). The medical history collection and physical examination were conducted to evaluate the motor symptoms, non-motor symptoms [Non-Motor Symptom Scale (NMSS)], depression state and cognitive function of the patients. Parkinson's Disease Sleep Sclale-2 (PDSS-2) and the Rapid Eye Movement Sleep Behavior Disorder Screening Questionnaire (RBDSQ) were used to evaluate and analyze their sleep status, and comparisons were made between groups. Binary multivariate Logistic regression analysis was used to access the risk factors associated with sleep disorders in Parkinson's disease. Results The scores of daytime fatigue [2.00(0, 4.00)] and unexplained limb pain [4.00(0, 4.00)] in NMSS assessment of PD patients in the left onset group were significantly higher than those in the right onset group [1.00(0, 3.00), Z=-2.545, P=0.001; 2.00(0, 4.00), Z=-2.797, P=0.005]. There was no significant difference in the total score of PDSS-2 between the two groups, but there were significant differences in limb restlessness, periodic limb activity, muscle spasm and early drowsiness between the two groups. In the evaluation of rapid eye movement sleep behavior disorder (RBD), the total score of RBDSQ in the left onset group [2.00(0, 4.00)] was significantly higher than that in the right onset group [1.00(0, 3.00), Z=-4.363, P<0.001]. The incidence of dream content, nocturnal behavior, nocturnal exercise, self-injury and bed partner in dream, abnormal behavior at night, nighttime awakening, dream memory and sleep disorder in the left onset group was also higher than that in the right onset group. In addition, binary multivariate Logistic regression showed that PD-related sleep disorders were associated with onset of advanced age (OR=1.037, 95%CI 1.018-1.057, P< 0.001), course of disease (OR=1.014, 95%CI 1.010-1.018, P<0.001) and onset of abnormal postural gait (OR=1.505,95%CI 1.058-2.141,P=0.023). RBD in patients with PD was associated with left onset (OR=2.215, 95%CI 1.395-3.515, P=0.001), advanced age onset (OR=1.045, 95%CI 1.019-1.072, P= 0.001) and course of disease (OR=1.014, 95%CI 1.009-1.019, P<0.001). Conclusions PD patients with left onset are more likely to have sleep disorders such as limb restlessness, periodic limb activity, muscle spasm and early drowsiness. At the same time, the incidence and severity of RBD in patients with left onset of PD are significantly higher than those of patients with right onset of PD. The onset side of motor symptoms of PD is an important factor affecting sleep disorders, and the onset of left side may be a risk factor for PD patients with RBD. © 2021 Chinese Medical Association. All rights reserved.",Motor symptom; Non-motor symptom; Parkinson disease; Sleep disorders,abnormal behavior; adult; Article; automutilation; cognition; controlled study; depression; disease severity; drowsiness; exercise; fatigue; female; gait; human; incidence; limb pain; major clinical study; male; medical history; memory; memory disorder; motor dysfunction; muscle function; muscle spasm; nocturnal awakening; onset age; outpatient department; parasomnia; Parkinson disease; physical examination; questionnaire; restlessness; risk assessment; risk factor; sleep disorder,Article,Final,,Scopus,2-s2.0-85133956739,Movies / Media
Tal A.; Bloch A.; Cohen-Dallal H.; Aviv O.; Schwizer Ashkenazi S.; Bar M.; Vakil E.,"Tal, Amir (56085898400); Bloch, Ayala (56909570400); Cohen-Dallal, Haggar (57203150998); Aviv, Or (57208552246); Schwizer Ashkenazi, Simone (57208555562); Bar, Moshe (7007159918); Vakil, Eli (7005980705)",56085898400; 56909570400; 57203150998; 57208552246; 57208555562; 7007159918; 7005980705,Oculomotor anticipation reveals a multitude of learning processes underlying the serial reaction time task,2021,Scientific Reports,11,1,6190,,,,9,10.1038/s41598-021-85842-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102734123&doi=10.1038%2fs41598-021-85842-x&partnerID=40&md5=6fbcdd45c08518266906a133477a8c13,"Sequence learning is the cognitive faculty enabling everyday skill acquisition. In the lab, it is typically measured in speed of response to sequential stimuli, whereby faster responses are taken to indicate improved anticipation. However, response speed is an indirect measure of anticipation, that can provide only limited information on underlying processes. As a result, little is known about what is learned during sequence learning, and how that unfolds over time. In this work, eye movements that occurred before targets appeared on screen in an ocular serial reaction time (O-SRT) task provided an online indication of where participants anticipated upcoming targets. When analyzed in the context of the stimuli preceding them, oculomotor anticipations revealed several simultaneous learning processes. These processes influenced each other, as learning the task grammar facilitated acquisition of the target sequence. However, they were dissociable, as the grammar was similarly learned whether a repeating sequence inhabited the task or not. Individual differences were found in how the different learning processes progressed, allowing for similar performance to be produced for different latent reasons. This study provides new insights into the processes subserving sequence learning, and a new method for high-resolution study of it. © 2021, The Author(s).",,"Adolescent; Adult; Anticipation, Psychological; Cognition; Eye Movements; Female; Humans; Individuality; Learning; Male; Pattern Recognition, Visual; Photic Stimulation; Problem Solving; Psychomotor Performance; Reaction Time; adult; anticipation; article; dissociation; eye movement; female; grammar; human; human experiment; male; sequence learning; serial reaction time; adolescent; anticipation; cognition; individuality; learning; pattern recognition; photostimulation; physiology; problem solving; psychomotor performance; reaction time",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85102734123,Movies / Media
Dziura S.L.; Merchant J.S.; Alkire D.; Rashid A.; Shariq D.; Moraczewski D.; Redcay E.,"Dziura, Sarah L. (56418727700); Merchant, Junaid S. (55395781800); Alkire, Diana (56891564400); Rashid, Adnan (57267500500); Shariq, Deena (57224084554); Moraczewski, Dustin (57191160054); Redcay, Elizabeth (8615770000)",56418727700; 55395781800; 56891564400; 57267500500; 57224084554; 57191160054; 8615770000,Effects of social and emotional context on neural activation and synchrony during movie viewing,2021,Human Brain Mapping,42,18,,6053,6069,16.0,5,10.1002/hbm.25669,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115371250&doi=10.1002%2fhbm.25669&partnerID=40&md5=898af4ebe5103beb89222fb8d5a660f7,"Sharing emotional experiences impacts how we perceive and interact with the world, but the neural mechanisms that support this sharing are not well characterized. In this study, participants (N = 52) watched videos in an MRI scanner in the presence of an unfamiliar peer. Videos varied in valence and social context (i.e., participants believed their partner was viewing the same (joint condition) or a different (solo condition) video). Reported togetherness increased during positive videos regardless of social condition, indicating that positive contexts may lessen the experience of being alone. Two analysis approaches were used to examine both sustained neural activity averaged over time and dynamic synchrony throughout the videos. Both approaches revealed clusters in the medial prefrontal cortex that were more responsive to the joint condition. We observed a time-averaged social-emotion interaction in the ventromedial prefrontal cortex, although this region did not demonstrate synchrony effects. Alternatively, social-emotion interactions in the amygdala and superior temporal sulcus showed greater neural synchrony in the joint compared to solo conditions during positive videos, but the opposite pattern for negative videos. These findings suggest that positive stimuli may be more salient when experienced together, suggesting a mechanism for forming social bonds. © 2021 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.",affect; social attention; social context; social neuroscience,Adolescent; Adult; Brain Mapping; Cerebral Cortex; Cortical Synchronization; Electroencephalography; Emotions; Female; Humans; Male; Motion Pictures; Social Perception; Young Adult; adult; amygdala; Article; attention; controlled study; emotion; eye tracking; female; human; imaging; male; medial prefrontal cortex; social bonding; social environment; social status; superior temporal sulcus; television viewing; ventromedial prefrontal cortex; videorecording; adolescent; brain cortex; brain mapping; cortical synchronization; electroencephalography; emotion; movie; perception; physiology; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85115371250,Movies / Media
Koczulla A.R.; Stegemann A.; Gloeckl R.; Winterkamp S.; Sczepanski B.; Boeselt T.; Storre J.; Dreher M.,"Koczulla, Andreas Rembert (8741717400); Stegemann, Antje (57203942630); Gloeckl, Rainer (54390944600); Winterkamp, Sandra (57193825423); Sczepanski, Bernd (6506839374); Boeselt, Tobias (56142081200); Storre, Jan (6603497864); Dreher, Michael (8712437500)",8741717400; 57203942630; 54390944600; 57193825423; 6506839374; 56142081200; 6603497864; 8712437500,Newly detected rapid eye movement associated sleep apnea after coronavirus disease 2019 as a possible cause for chronic fatigue: two case reports,2021,Journal of Medical Case Reports,15,1,211,,,,13,10.1186/s13256-021-02819-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104600707&doi=10.1186%2fs13256-021-02819-0&partnerID=40&md5=cd896a79d4879dd4477fe47a8bfca02e,"Background: Coronavirus disease 2019 has become a health problem spreading worldwide with pandemic characteristics since March 2020. Post coronavirus disease 2019 symptoms are more frequent than initially expected, with fatigue as an often-mentioned issue. Case presentations: We describe a 32-year-old white male and a 55-year-old white female who suffered from post coronavirus disease 2019 fatigue syndrome. On polysomnography, rapid eye movement associated sleep apnea with an increased hypopnea index during rapid eye movement phases of 36.8 and 19.5 events per hour was found. Based on the patients’ burdensome fatigue symptoms, we initiated automatic positive airway pressure therapy, which diminished sleep apnea (rapid eye movement index: 0.0 in both patients) and, consequently, also the fatigue symptoms. Conclusions: Since sleep apnea and coronavirus disease 2019 are both associated with fatigue, a screening for sleep apnea might be considered in coronavirus disease 2019 patients with fatigue syndrome. © 2021, The Author(s).",APAP; Case report; COVID-19; CPAP; Fatigue syndrome; REM phase; Sleep apnea,"Adult; COVID-19; Fatigue; Female; Humans; Male; Middle Aged; Sleep Apnea Syndromes; Sleep, REM; adult; apnea hypopnea index; Article; automatic positive airway pressure; body mass; case report; Caucasian; chronic fatigue syndrome; clinical article; concentration loss; coronavirus disease 2019; disease burden; dysphasia; exercise test; female; human; male; memory disorder; middle aged; patient attitude; patient referral; physical performance; polysomnography; pulmonary rehabilitation; REM sleep; sleep disordered breathing; x-ray computed tomography; complication; fatigue; REM sleep; sleep disordered breathing; virology",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85104600707,Movies / Media
Papesh M.H.; Hout M.C.; Guevara Pinto J.D.; Robbins A.; Lopez A.,"Papesh, Megan H. (33267790500); Hout, Michael C. (56673964200); Guevara Pinto, Juan D. (56582373300); Robbins, Arryn (56915335500); Lopez, Alexis (57222008434)",33267790500; 56673964200; 56582373300; 56915335500; 57222008434,Eye movements reflect expertise development in hybrid search,2021,Cognitive Research: Principles and Implications,6,1,7,,,,16,10.1186/s41235-020-00269-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100919640&doi=10.1186%2fs41235-020-00269-8&partnerID=40&md5=aabae52a848c8c0654e481ed4235cf87,"Domain-specific expertise changes the way people perceive, process, and remember information from that domain. This is often observed in visual domains involving skilled searches, such as athletics referees, or professional visual searchers (e.g., security and medical screeners). Although existing research has compared expert to novice performance in visual search, little work has directly documented how accumulating experiences change behavior. A longitudinal approach to studying visual search performance may permit a finer-grained understanding of experience-dependent changes in visual scanning, and the extent to which various cognitive processes are affected by experience. In this study, participants acquired experience by taking part in many experimental sessions over the course of an academic semester. Searchers looked for 20 categories of targets simultaneously (which appeared with unequal frequency), in displays with 0–3 targets present, while having their eye movements recorded. With experience, accuracy increased and response times decreased. Fixation probabilities and durations decreased with increasing experience, but saccade amplitudes and visual span increased. These findings suggest that the behavioral benefits endowed by expertise emerge from oculomotor behaviors that reflect enhanced reliance on memory to guide attention and the ability to process more of the visual field within individual fixations. © 2021, The Author(s).",Expertise; Eye movements; Visual search,"Attention; Eye Movements; Fixation, Ocular; Humans; Reaction Time; Saccades; attention; eye fixation; eye movement; human; reaction time; saccadic eye movement",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85100919640,Movies / Media
Tseng C.-I.; Laubrock J.; Bateman J.A.,"Tseng, Chiao-I (55510122800); Laubrock, Jochen (6504602165); Bateman, John A. (7202065408)",55510122800; 6504602165; 7202065408,The impact of multimodal cohesion on attention and interpretation in film,2021,"Discourse, Context and Media",44,,100544,,,,21,10.1016/j.dcm.2021.100544,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115959363&doi=10.1016%2fj.dcm.2021.100544&partnerID=40&md5=33c37ab797c2978c4673bb73421eec6d,"This article presents results of an exploratory investigation combining multimodal cohesion analysis and eye-tracking studies. Multimodal cohesion, as a tool of multimodal discourse analysis, goes beyond linguistic cohesive mechanisms to enable the construction of cross-modal discourse structures that systematically relate technical details of audio, visual and verbal modalities. Patterns of multimodal cohesion from these discourse structures were used to design eye-tracking experiments and questionnaires in order to empirically investigate how auditory and visual cohesive cues affect attention and comprehension. We argue that the cross-modal structures of cohesion revealed by our method offer a strong methodology for addressing empirical questions concerning viewers’ comprehension of narrative settings and the comparative salience of visual, verbal and audio cues. Analyses are presented of the beginning of Hitchcock's The Birds (1963) and a sketch from Monty Python filmed in 1971. Our approach balances the narrative-based issue of how narrative elements in film guide meaning interpretation and the recipient-based question of where a film viewer's attention is directed during viewing and how this affects comprehension. © 2021 Elsevier Ltd",Attention; Cohesion; Discourse semantics; Eye-tracking; Film; Multimodality,,Article,Final,,Scopus,2-s2.0-85115959363,Movies / Media
Ermis U.; Rust M.I.; Bungenberg J.; Costa A.; Dreher M.; Balfanz P.; Marx G.; Wiesmann M.; Reetz K.; Tauber S.C.; Schulz J.B.,"Ermis, Ummehan (37018140400); Rust, Marcus Immanuel (57204012342); Bungenberg, Julia (56993906100); Costa, Ana (55311625400); Dreher, Michael (8712437500); Balfanz, Paul (57218693498); Marx, Gernot (8575218500); Wiesmann, Martin (57219381538); Reetz, Kathrin (24451065800); Tauber, Simone C. (8732296400); Schulz, Jörg B. (7201479829)",37018140400; 57204012342; 56993906100; 55311625400; 8712437500; 57218693498; 8575218500; 57219381538; 24451065800; 8732296400; 7201479829,Neurological symptoms in COVID-19: a cross-sectional monocentric study of hospitalized patients,2021,Neurological Research and Practice,3,1,17,,,,56,10.1186/s42466-021-00116-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109977712&doi=10.1186%2fs42466-021-00116-1&partnerID=40&md5=96bddb243fae099796e506c8835a83f4,"Background: The SARS-Coronavirus-2 (SARS-CoV-2) invades the respiratory system, causing acute and sometimes severe pulmonary symptoms, but turned out to also act multisystematically with substantial impact on the brain. A growing number of studies suggests a diverse spectrum of neurological manifestations. To investigate the spectrum of symptoms, we here describe the neurological manifestations and complications of patients with proven SARS-CoV-2 infection who have been hospitalized at the RWTH University Hospital Aachen, Germany. Methods: Between March and September 2020, we evaluated common symptoms, clinical characteristics, laboratory (including cerebrospinal fluid (CSF) analysis), radiological, and electroencephalography (EEG) data from 53 patients admitted with a positive SARS-CoV-2 polymerase chain reaction (PCR). We used the Montreal Cognitive Assessment Test (MoCA) to screen for cognitive impairment, when feasible. We compared critically ill and non-critically ill patients categorized according to the presence of Acute Respiratory Distress Syndrome (ARDS). Results: Major clinical neurological features of hospitalized COVID-19 patients were coordination deficits (74%), cognitive impairment (61.5%), paresis (47%), abnormal reflex status (45%), sensory abnormalities (45%), general muscle weakness and pain (32%), hyposmia (26%), and headache (21%). Patients with ARDS were more severely affected than non-ADRS patients. 29.6% of patients with ARDS presented with subarachnoid bleedings, and 11.1% showed ischemic stroke associated with SARS-CoV-2 infection. Cognitive deficits mainly affected executive functions, attention, language, and delayed memory recall. We obtained cerebrospinal fluid (CSF) by lumbar puncture in nine of the 53 patients, none of which had a positive SARS-CoV-2 PCR. Conclusions: In line with previous findings, our results provide evidence for a range of SARS-CoV-2-associated neurological manifestations. 26% of patients reported hyposmia, emphasizing the neuro-invasive potential of SARS-CoV-2, which can enter the olfactory bulb. It can therefore be speculated that neurological manifestations may be caused by direct invasion of the virus in the CNS; however, PCR did not reveal positive intrathecal SARS-CoV-2. Therefore, we hypothesize it is more likely that the para-infectious severe pro-inflammatory impact of COVID-19 is responsible for the neurological deficits including cognitive impairment. Future studies with comprehensive longitudinal assessment of neurological deficits are required to determine potential long-term complications of COVID-19. © 2021, The Author(s).",Cognitive impairment; COVID-19; Neuro-invasive potential; Neurological symptoms; SARS-CoV-2,calcium channel blocking agent; D dimer; dipeptidyl carboxypeptidase inhibitor; diuretic agent; ferritin; glucose; hydroxymethylglutaryl coenzyme A reductase inhibitor; interleukin 2; interleukin 6; lactic acid; neuron specific enolase; oligoclonal band; protein; tumor necrosis factor; virus RNA; adult; adult respiratory distress syndrome; aged; ageusia; anisocoria; aphasia; apparent diffusion coefficient; Article; ataxia; atrial fibrillation; attention disturbance; Babinski reflex; bladder dysfunction; blood brain barrier; blood cell count; brain atrophy; brain disease; brain ischemia; cardiovascular disease; cardiovascular surgery; cell count; cerebrospinal fluid analysis; cigarette smoking; clinical feature; cognitive defect; comorbidity; computer assisted tomography; continuous hemodialysis; controlled study; coordination disorder; coronavirus disease 2019; coughing; cranial nerve; critically ill patient; cross-sectional study; delirium; delta rhythm; diarrhea; diffusion weighted imaging; dizziness; dysarthria; dysphagia; dyspnea; electroencephalography; executive function; extracorporeal oxygenation; eye movement disorder; eye position; faintness; female; fever; gait disorder; Germany; Glasgow coma scale; headache; heart infarction; hospital patient; human; hypertension; hyposmia; immobility; incidental finding; intensive care unit; invasive ventilation; laboratory test; language disability; liver function test; lumbar puncture; lung lavage; major clinical study; male; medical history; memory disorder; meningism; microangiopathy; Montreal cognitive assessment; muscle weakness; myalgia; myopathy; nausea; neuralgia; neurologic disease; neurologic examination; neurological complication; neuropathy; nose smear; nuclear magnetic resonance imaging; nystagmus; oculomotor nerve disease; pain; paresis; pathological reflex; pleocytosis; priority journal; prospective study; ptosis (eyelid); pupil diameter; radiodiagnosis; sensory dysfunction; Severe acute respiratory syndrome coronavirus 2; sex ratio; subarachnoid hemorrhage; susceptibility weighted imaging; tendon reflex; tremor; unsteady gait; vertigo; vomiting; white matter lesion,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85109977712,Movies / Media
Liu Y.; Lawton M.A.; Lo C.; Bowring F.; Klein J.C.; Querejeta-Coma A.; Scotton S.; Welch J.; Razzaque J.; Barber T.; Ben-Shlomo Y.; Hu M.T.,"Liu, Yaping (55356814300); Lawton, Michael A. (57202798417); Lo, Christine (57201136420); Bowring, Francesca (57220572555); Klein, Johannes C. (26429517800); Querejeta-Coma, Agustin (57211110558); Scotton, Sangeeta (57219249975); Welch, Jessica (21744283600); Razzaque, Jamil (57232812400); Barber, Thomas (57192254924); Ben-Shlomo, Yoav (7006649063); Hu, Michele T. (57189494530)",55356814300; 57202798417; 57201136420; 57220572555; 26429517800; 57211110558; 57219249975; 21744283600; 57232812400; 57192254924; 7006649063; 57189494530,Longitudinal Changes in Parkinson's Disease Symptoms with and Without Rapid Eye Movement Sleep Behavior Disorder: The Oxford Discovery Cohort Study,2021,Movement Disorders,36,12,,2821,2832,11.0,37,10.1002/mds.28763,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113576071&doi=10.1002%2fmds.28763&partnerID=40&md5=fc3cd294f94e5666485e8fb8cfa2a596,"Background: Parkinson's disease (PD) comorbid with rapid eye movement sleep behavior disorder (RBD) may show more severe motor and nonmotor symptoms, suggesting a distinct PD subtype. Objective: The aim of this study was to investigate the impact of RBD on the longitudinal change of motor and nonmotor symptoms in patients with PD. Methods: Patients with early PD (diagnosed within 3.5 years) recruited from 2010 to 2019 were followed every 18 months in the Oxford Parkinson's Disease Centre Discovery cohort. At each visit, we used standard questionnaires and measurements to assess demographic features and motor and nonmotor symptoms (including RBD, daytime sleepiness, mood, autonomic symptoms, cognition, and olfaction). Data were analyzed with linear mixed effects and Cox regression models. Possible RBD (pRBD) was longitudinally determined according to RBD Screening Questionnaire scores. Results: A total of 923 patients were recruited (mean age: 67.1 ± 9.59 years; 35.9% female), and 788 had follow-up assessment(s) (mean: 4.8 ± 1.98 years, range: 1.3–8.3). Among them, 33.3% were identified as pRBD (PD + pRBD). Patients with PD + pRBD had more severe baseline symptoms and showed faster progression on Movement Disorder Society-Unified Parkinson's Disease Rating Scale parts I and III, Purdue Pegboard test, and Beck Depression Inventory scores. Moreover, PD + pRBD was associated with an increased level of risk for mild cognitive impairment (hazard ratio [HR] = 1.36, 95% confidence interval [CI]: 1.01–1.83), freezing of gait (HR = 1.42, 95% CI: 1.10–1.86), and frequent falling (HR = 1.62, 95% CI: 1.02–2.60). Conclusions: Patients with PD + pRBD progress faster on motor, mood, and cognitive symptoms, confirming a more aggressive PD subtype that can be identified at baseline and has major clinical implications. © 2021 International Parkinson and Movement Disorder Society. © 2021 International Parkinson and Movement Disorder Society",longitudinal study; motor and nonmotor symptoms; Parkinson's disease; progression; REM sleep behavior disorder,"Aged; Cohort Studies; Female; Gait Disorders, Neurologic; Humans; Male; Middle Aged; Parkinson Disease; REM Sleep Behavior Disorder; Surveys and Questionnaires; dopamine receptor stimulating agent; aged; Article; autonomic dysfunction; Beck Depression Inventory; behavior disorder; cognitive defect; cohort analysis; constipation; daytime somnolence; deterioration; diagnosis time; diastolic blood pressure; disease association; disease course; disease exacerbation; disease risk assessment; disease severity; educational status; ethnic group; fall risk; female; follow up; freezing of gait; Hospital Anxiety and Depression Scale; human; longitudinal study; major clinical study; male; marriage; MDS-Unified Parkinson Disease Rating Scale; mild cognitive impairment; Mini Mental State Examination; mood disorder; motor dysfunction; motor performance; Parkinson disease; pulse rate; Purdue pegboard test; questionnaire; REM sleep; sleep disorder; smelling disorder; survival rate; systolic blood pressure; time factor; timed up and go test; complication; middle aged; neurologic gait disorder; parasomnia; Parkinson disease; psychology",Article,Final,,Scopus,2-s2.0-85113576071,Movies / Media
George J.M.; Colditz P.B.; Chatfield M.D.; Fiori S.; Pannek K.; Fripp J.; Guzzetta A.; Rose S.E.; Ware R.S.; Boyd R.N.,"George, Joanne M. (56844371600); Colditz, Paul B. (7003908550); Chatfield, Mark D. (6603046947); Fiori, Simona (36480004900); Pannek, Kerstin (26425156800); Fripp, Jurgen (13605436500); Guzzetta, Andrea (6701554327); Rose, Stephen E. (7402127406); Ware, Robert S. (57208122739); Boyd, Roslyn N. (7401728682)",56844371600; 7003908550; 6603046947; 36480004900; 26425156800; 13605436500; 6701554327; 7402127406; 57208122739; 7401728682,Early clinical and MRI biomarkers of cognitive and motor outcomes in very preterm born infants,2021,Pediatric Research,90,6,,1243,1250,7.0,12,10.1038/s41390-021-01399-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101574152&doi=10.1038%2fs41390-021-01399-5&partnerID=40&md5=c75fda290d65552349312c814598364d,"Background: This study aimed to identify which MRI and clinical assessments, alone or in combination, from (i) early (32 weeks postmenstrual age, PMA), (ii) term equivalent age (TEA) and (iii) 3 months corrected age (CA) are associated with motor or cognitive outcomes at 2 years CA in infants born <31 weeks gestation. Methods: Prospective cohort study of 98 infants who underwent early and TEA MRI (n = 59 males; median birth gestational age 28 + 5 weeks). Hammersmith Neonatal Neurological Examination (HNNE), NICU Neonatal Neurobehavioural Scale and General Movements Assessment (GMs) were performed early and at TEA. Premie-Neuro was performed early and GMs, Test of Infant Motor Performance and visual assessment were performed at TEA and 3 months CA. Neurodevelopmental outcomes were determined using Bayley Scales of Infant and Toddler Development 3rd edition. Results: The best combined motor outcome model included 3-month GMs (β = −11.41; 95% CI = −17.34, −5.49), TEA MRI deep grey matter score (β = −6.23; 95% CI = −9.47, −2.99) and early HNNE reflexes (β = 3.51; 95% CI = 0.86, 6.16). Combined cognitive model included 3-month GMs (β = −10.01; 95% CI = −15.90, −4.12) and TEA HNNE score (β = 1.33; 95% CI = 0.57, 2.08). Conclusion: Early neonatal neurological assessment improves associations with motor outcomes when combined with term MRI and 3-month GMs. Term neurological assessment combined with 3-month GMs improves associations with cognitive outcomes. Impact: We present associations between 32- and 40-week MRI, comprehensive clinical assessments and later 2-year motor and cognitive outcomes for children born <31 weeks gestation.MRI and clinical assessment of motor, neurological and neurobehavioural function earlier than term equivalent age in very preterm infants is safe and becoming more available in clinical settings. Most of these children are discharged from hospital before term age and so completing assessments prior to discharge can assist with follow up.MRI and neurological assessment prior to term equivalent age while the child is still in hospital can provide earlier identification of children at highest risk of adverse outcomes and guide follow-up screening and intervention services. © 2021, The Author(s), under exclusive licence to the International Pediatric Research Foundation, Inc.",,"Cognition; Female; Humans; Infant, Extremely Premature; Infant, Newborn; Magnetic Resonance Imaging; Male; Motor Activity; Prospective Studies; biological marker; Article; Bayley Scales of Infant Development; birth weight; cerebellum; clinical assessment; cognition; cohort analysis; construct validity; controlled study; demography; eye movement; female; general movements assessment; gestational age; gray matter; hammersmith neonatal neurological examination; human; infant; interrater reliability; major clinical study; male; motor performance; neurologic examination; newborn; nuclear magnetic resonance imaging; prematurity; prospective study; scoring system; sensitivity and specificity; small for date infant; test of gross motor development; white matter; motor activity; nuclear magnetic resonance imaging; procedures",Article,Final,,Scopus,2-s2.0-85101574152,Movies / Media
Portugal A.M.; Bedford R.; Cheung C.H.M.; Mason L.; Smith T.J.,"Portugal, Ana Maria (57216949440); Bedford, Rachael (24079913800); Cheung, Celeste H. M. (55313330400); Mason, Luke (55783092600); Smith, Tim J. (55568512084)",57216949440; 24079913800; 55313330400; 55783092600; 55568512084,Longitudinal touchscreen use across early development is associated with faster exogenous and reduced endogenous attention control,2021,Scientific Reports,11,1,2205,,,,27,10.1038/s41598-021-81775-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099834444&doi=10.1038%2fs41598-021-81775-7&partnerID=40&md5=0cc55d0aa7e2659f70b63c2cb4df2233,"Childhood screen time is associated with both attentional difficulties (for television viewing) and benefits (in action video gamers), but few studies have investigated today’s pervasive touchscreen devices (e.g. smartphones and tablets), which combine salient features, interactive content, and accessibility from toddlerhood (a peak period of cognitive development). We tested exogenous and endogenous attention, following forty children who were stable high (HU) or low (LU) touchscreen users from toddlerhood to pre-school. HUs were slower to disengage attention, relative to their faster baseline orienting ability. In an infant anti-saccade task, HUs displayed more of a corrective strategy of orienting faster to distractors before anticipating the target. Results suggest that long-term high exposure to touchscreen devices is associated with faster exogenous attention and concomitant decreases in endogenous attention control. Future work is required to demonstrate causality, dissociate variants of use, and investigate how attention behaviours found in screen-based contexts translate to real-world settings. © 2021, The Author(s).",,"Attention; Child; Child Development; Female; Humans; Infant; Longitudinal Studies; Male; Models, Biological; Reaction Time; Saccades; Screen Time; Task Performance and Analysis; attention; biological model; child; child development; female; human; infant; longitudinal study; male; physiology; reaction time; saccadic eye movement; task performance",Article,Final,,Scopus,2-s2.0-85099834444,Movies / Media
Pjesivac I.; Wojdynski B.W.; Geidner N.,"Pjesivac, Ivanka (56422359900); Wojdynski, Bartosz W. (44861866100); Geidner, Nicholas (36924924100)",56422359900; 44861866100; 36924924100,Television Infographics as Orienting Response: An Eye-Tracking Study of the Role of Visuospatial Attention in Processing of Television News,2021,Electronic News,15,4-Mar,,159,178,19.0,2,10.1177/19312431211039500,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115615248&doi=10.1177%2f19312431211039500&partnerID=40&md5=de4ef498ad8deb234ab3e7ee3678415e,"This experimental study (N = 77) examined the role of infographics in orienting viewer's attention in television news. The results of pupil dilation measurements using the eye-tracking method showed that when used in the over-the-shoulder format, visual representation of numerical data triggers an orienting response and directs the viewer's attention to that part of the screen. The study also showed that bar graphs were more successful in holding viewer's attention than the simple tabular presentation of information, with a significant covariate of video viewer size, and that the presence of infographics and individuals’ quantitative ability both positively predicted information recall. © The Author(s) 2021.",attention; eye-tracking; Infographics; orienting response,,Article,Final,,Scopus,2-s2.0-85115615248,Movies / Media
Ye G.-Q.; Guo F.; Li F.-X.; Hu M.-C.,"Ye, Guo-Quan (57203980750); Guo, Fu (55202044200); Li, Feng-Xiang (57206674537); Hu, Ming-Cai (57194649073)",57203980750; 55202044200; 57206674537; 57194649073,Underlying Mechanisms of the Effectiveness of Brand Placement in Movies; [电影植入广告有效性的影响机制],2021,Dongbei Daxue Xuebao/Journal of Northeastern University,42,12,,1797,1804,7.0,0,10.12068/j.issn.1005-3026.2021.12.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121324729&doi=10.12068%2fj.issn.1005-3026.2021.12.018&partnerID=40&md5=e80bdb35d24d56bba504076bfec00ae1,"According to the limited capacity model of attention, persuasion knowledge model and elaboration likelihood model of persuasion, the theoretical models between brand prominence, need for cognition and brand responses(i.e. brand memory, brand attitude and purchase intention)were constructed. By conducting an eye-tracking experiment, the underlying mechanisms between brand prominence, need for cognition and brand responses were unraveled. The results showed that, brand prominence can significantly positively affect brand memory, but significantly negatively affect brand attitude and purchase intention; attention allocation and activation of conceptual persuasion knowledge play intermediary roles between brand prominence and brand memory; attention allocation, activation of conceptual and attitudinal persuasion knowledge play intermediary roles between brand prominence and brand attitude and purchasing intention; these influential mechanisms of brand prominence on brand responses were significant only for viewers high in need for cognition. © 2021, Editorial Department of Journal of Northeastern University. All right reserved.",Attention allocation; Attitudinal persuasion knowledge; Brand prominence; Brand responses; Conceptual persuasion knowledge; Need for cognition,Chemical activation; Eye tracking; Sales; Attention allocation; Attitudinal persuasion knowledge; Brand prominence; Brand response; Capacity modeling; Conceptual persuasion knowledge; Limited capacity; Models of attention; Need for cognitions; Purchase intention; Purchasing,Article,Final,,Scopus,2-s2.0-85121324729,Movies / Media
Grégoire L.; Landry L.; Gustafsson E.; Blanchette I.,"Grégoire, Laurent (55813918700); Landry, Lysanne (57291147700); Gustafsson, Erik (41161254200); Blanchette, Isabelle (6602224505)",55813918700; 57291147700; 41161254200; 6602224505,Alteration of early attentional processing after analogue trauma exposure: evidence from event-related potentials,2021,Experimental Brain Research,239,12,,3671,3686,15.0,1,10.1007/s00221-021-06234-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116776346&doi=10.1007%2fs00221-021-06234-1&partnerID=40&md5=0ced0cf736fe80662b26c31ed547245c,"The present study aimed to determine whether exposure to an analogue traumatic event affects attentional processing of emotional information. Two groups of non-clinical participants matched on anxiety level, depression symptoms and stressful life events viewed either a trauma or a neutral film. They then performed an emotional Stroop task during which both continuous electroencephalographic activity was recorded and intrusive memories were measured. Results revealed that the valence effect (measured by the difference between emotional and neutral conditions) for the P1 amplitude was significantly greater in participants who viewed the trauma film than in participants who viewed the neutral film. This interaction was specific to words semantically related to the analogue trauma event and did not extend to all negative words. Further analyses revealed a relationship between intrusions frequency, P1 amplitude and emotional Stroop interference, indicating a link between attention and intrusive memories. Our findings suggest that exposure to potentially traumatic events has an important impact on neurocognitive function, even in the absence of psychopathology, and that this impact occurs at an early, possibly automatic stage of processing. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Emotional Stroop; Event-related potentials; Intrusive memories; Selective attention; Trauma film,"Attention; Cognition; Emotions; Evoked Potentials; Humans; Motion Pictures; Stress Disorders, Post-Traumatic; adult; anger; arousal; Article; Beck Depression Inventory; brain electrophysiology; clinical article; consciousness; electroencephalogram; electroencephalography; electrooculogram; emotion; event related potential; eye movement; female; human; male; memory; powerlessness; psychotrauma; sadness; selective attention; self report; State Trait Anxiety Inventory; Stroop test; visual acuity; attention; cognition; evoked response; movie; posttraumatic stress disorder",Article,Final,,Scopus,2-s2.0-85116776346,Movies / Media
Jacob G.; Katti H.; Cherian T.; Das J.; Zhivago K.A.; Arun S.P.,"Jacob, Georgin (55567486100); Katti, Harish (25421611300); Cherian, Thomas (57222398340); Das, Jhilik (57205693560); Zhivago, K.A. (56440205100); Arun, S.P. (6503848470)",55567486100; 25421611300; 57222398340; 57205693560; 56440205100; 6503848470,A naturalistic environment to study visual cognition in unrestrained monkeys,2021,eLife,10,,e63816,,,,7,10.7554/eLife.63816,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120158985&doi=10.7554%2feLife.63816&partnerID=40&md5=06864980f82d849f3ded3cfae875d62d,"Macaque monkeys are widely used to study vision. In the traditional approach, monkeys are brought into a lab to perform visual tasks while they are restrained to obtain stable eye tracking and neural recordings. Here, we describe a novel environment to study visual cognition in a more natural setting as well as other natural and social behaviors. We designed a naturalistic environment with an integrated touchscreen workstation that enables high-quality eye tracking in unrestrained monkeys. We used this environment to train monkeys on a challenging same-different task. We also show that this environment can reveal interesting novel social behaviors. As proof of concept, we show that two naïve monkeys were able to learn this complex task through a combination of socially observing trained monkeys and through solo trialand-error. We propose that such naturalistic environments can be used to rigorously study visual cognition as well as other natural and social behaviors in freely moving monkeys. © 2021, eLife Sciences Publications Ltd. All rights reserved.",,Animals; Cognition; Learning; Macaca radiata; Male; Social Behavior; Visual Perception; animal experiment; article; cognition; eye tracking; Haplorhini; human; nonhuman; proof of concept; social behavior; animal; learning; Macaca radiata; male; physiology; social behavior; vision,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85120158985,Movies / Media
Dahl M.; Tryding M.; Heckler A.; Nyström M.,"Dahl, Mats (7202205101); Tryding, Mårten (57348580100); Heckler, Alexander (57348423800); Nyström, Marcus (8357720600)",7202205101; 57348580100; 57348423800; 8357720600,Quiet Eye and Computerized Precision Tasks in First-Person Shooter Perspective Esport Games,2021,Frontiers in Psychology,12,,676591,,,,11,10.3389/fpsyg.2021.676591,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119498485&doi=10.3389%2ffpsyg.2021.676591&partnerID=40&md5=ed79f8413253c9fa3020c2052a372bb2,"The gaze behavior in sports and other applied settings has been studied for more than 20 years. A common finding is related to the “quiet eye” (QE), predicting that the duration of the last fixation before a critical event is associated with higher performance. Unlike previous studies conducted in applied settings with mobile eye trackers, we investigate the QE in a context similar to esport, in which participants click the mouse to hit targets presented on a computer screen under different levels of cognitive load. Simultaneously, eye and mouse movements were tracked using a high-end remote eye tracker at 300 Hz. Consistent with previous studies, we found that longer QE fixations were associated with higher performance. Increasing the cognitive load delayed the onset of the QE fixation, but had no significant influence on the QE duration. We discuss the implications of our results in the context of how the QE is defined, the quality of the eye-tracker data, and the type of analysis applied to QE data. © Copyright © 2021 Dahl, Tryding, Heckler and Nyström.",cognitive load; e-sport; eye-tracking; FPS-game; quiet eye,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85119498485,Movies / Media
Xu H.; Xuan X.; Zhang L.; Zhang W.; Zhu M.; Zhao X.,"Xu, Hong (57220207199); Xuan, Xiaoyan (57346850100); Zhang, Li (57225059512); Zhang, Wenxin (57221809346); Zhu, Min (57207027703); Zhao, Xiaoke (55753856300)",57220207199; 57346850100; 57225059512; 57221809346; 57207027703; 55753856300,New Approach to Intelligence Screening for Children With Global Development Delay Using Eye-Tracking Technology: A Pilot Study,2021,Frontiers in Neurology,12,,723526,,,,6,10.3389/fneur.2021.723526,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119414084&doi=10.3389%2ffneur.2021.723526&partnerID=40&md5=6e41a89ddac72e1376c73721cb87186f,"Objective: There has become a consensus for detecting intellectual disability in its early stages and implementing effective intervention. However, there are many difficulties and limitations in the evaluation of intelligence-related scales in low-age children. Eye-tracking technology may effectively solve some of the pain points in the evaluation. Method: We used an eye-tracking technology for cognitive assessment. The subjects looked at a series of task pictures and short videos, the fixation points of which were recorded by the eye-movement analyzer, and the data were statistically analyzed. A total of 120 children aged between 1.5 and 4 years participated in the study, including 60 typically developing children and 60 children with global development delay, all of whom were assessed via the Bayley scale, Peabody Picture Vocabulary Test (PPVT), and Gesell scale. Results: Cognitive scores from eye-tracking technology are closely related to the scores of neuropsychological tests, which shows that the technique performs well as an early diagnostic test of children's intelligence. Conclusions: The results show that children's cognitive development can be quickly screened using eye-tracking technology and that it can track quantitative intelligence scores and sensitively detect intellectual impairment. Copyright © 2021 Xu, Xuan, Zhang, Zhang, Zhu and Zhao.",children; cognitive assessment; cognitive development; eye-tracking technology; global development delay,Article; Bayley Scales of Infant Development; child; child development; cognition assessment; controlled study; data analysis; developmental delay; diagnostic test; eye movement; eye-tracking technology; female; Gesell scale; human; image analysis; intellectual impairment; intelligence test; major clinical study; male; neuropsychological test; pain assessment; Peabody picture vocabulary test; pilot study; preschool child; quantitative analysis; screening; sensitivity analysis; videorecording,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85119414084,Movies / Media
Poletti B.; Solca F.; Carelli L.; Diena A.; Colombo E.; Torre S.; Maranzano A.; Greco L.; Cozza F.; Lizio A.; Ferrucci R.; Girotti F.; Verde F.; Morelli C.; Lunetta C.; Silani V.; Ticozzi N.,"Poletti, Barbara (16646951300); Solca, Federica (54385936000); Carelli, Laura (25926814500); Diena, Alberto (57376672400); Colombo, Eleonora (57531696700); Torre, Silvia (57211484836); Maranzano, Alessio (57216738733); Greco, Lucia (57196094606); Cozza, Federica (12807744400); Lizio, Andrea (55636430200); Ferrucci, Roberta (23484962100); Girotti, Floriano (7005144481); Verde, Federico (57201021914); Morelli, Claudia (35242968500); Lunetta, Christian (7801365932); Silani, Vincenzo (7006146949); Ticozzi, Nicola (23062054500)",16646951300; 54385936000; 25926814500; 57376672400; 57531696700; 57211484836; 57216738733; 57196094606; 12807744400; 55636430200; 23484962100; 7005144481; 57201021914; 35242968500; 7801365932; 7006146949; 23062054500,Association of Clinically Evident Eye Movement Abnormalities With Motor and Cognitive Features in Patients With Motor Neuron Disorders,2021,Neurology,97,18,,E1835,E1846,11.0,21,10.1212/WNL.0000000000012774,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121407818&doi=10.1212%2fWNL.0000000000012774&partnerID=40&md5=42b285b5b57dff46011281e10c0a4918,"Background and ObjectivesAlthough oculomotor abnormalities (OMAs) are not usually considered prominent features of amyotrophic lateral sclerosis (ALS), they may represent potential clinical markers of neurodegeneration, especially when investigated together with cognitive and behavioral alterations. The aim of our study was to identify patterns of clinically evident OMAs in patients with ALS and to correlate such findings with cognitive-behavioral data.MethodsThree consecutive inpatient cohorts of Italian patients with ALS and controls were retrospectively evaluated to assess the frequency of OMAs and cognitive-behavioral alterations. The ALS population was divided into a discovery cohort and a replication cohort. Controls included a cohort of cognitively impaired individuals and patients with Alzheimer disease (AD). Participants underwent bedside eye movement evaluation to determine the presence and pattern of OMAs. Cognitive assessment was performed with a standard neuropsychological battery (discovery ALS cohort and AD cohort) and the Italian Edinburgh Cognitive and Behavioural ALS Screen (ECAS) (replication ALS cohort).ResultsWe recruited 864 individuals with ALS (635 discovery, 229 replication), 798 who were cognitively unimpaired and 171 with AD. OMAs were detected in 10.5% of our ALS cohort vs 1.6% of cognitively unimpaired controls (p = 1.2 × 10-14) and 11.4% of patients with AD (p = NS). The most frequent deficits were smooth pursuit and saccadic abnormalities. OMA frequency was higher in patients with bulbar onset, prominent upper motor neuron signs, and advanced disease stages. Cognitive dysfunction was significantly more frequent in patients with OMAs in both ALS cohorts (p = 1.1 × 10-25). Furthermore, OMAs significantly correlated with the severity of cognitive impairment and with pathologic scores at the ECAS ALS-specific domains. Last, OMAs could be observed in 35.0% of cognitively impaired patients with ALS vs 11.4% of patients with AD (p = 6.4 × 10-7), suggesting a possible involvement of frontal oculomotor areas in ALS.ConclusionPatients with ALS showed a range of clinically evident OMAs, and these alterations were significantly correlated with cognitive, but not behavioral, changes. OMAs may be a marker of neurodegeneration, and bedside assessment represents a rapid, highly specific tool for detecting cognitive impairment in ALS.  © American Academy of Neurology.",,Amyotrophic Lateral Sclerosis; Cognition; Cognition Disorders; Eye Movements; Humans; Motor Neurons; Neuropsychological Tests; Retrospective Studies; amyotrophic lateral sclerosis; cognition; cognitive defect; complication; eye movement; human; motoneuron; neuropsychological test; physiology; retrospective study,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85121407818,Movies / Media
Glendon K.; Blenkinsop G.; Belli A.; Pain M.,"Glendon, K. (57223189168); Blenkinsop, G. (57189034672); Belli, A. (15055454800); Pain, M. (9943140500)",57223189168; 57189034672; 15055454800; 9943140500,Prospective study with specific Re-Assessment time points to determine time to recovery following a Sports-Related Concussion in university-aged student-athletes,2021,Physical Therapy in Sport,52,,,287,296,9.0,9,10.1016/j.ptsp.2021.10.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117906737&doi=10.1016%2fj.ptsp.2021.10.008&partnerID=40&md5=f22b6c0e1f7a38c45cac8a92d8eeae6b,"Background: Time to recovery for symptom burden and neurocognition following a Sports-Related Concussion (SRC) has previously been determined by consolidating varying re-assessment time points into a singular point, and has not been established for Vestibular-Ocular-Motor (VOM) function or academic ability. Objectives: Establish when recovery of symptom burden, neurocognition, VOM function, and academic ability occurs in university-aged student-athletes. Methods: Student-athletes completed an assessment battery (Post-Concussion Symptom Scale (PCSS), Immediate Post-Concussion Assessment and Cognitive Test (ImPACT), Vestibular Ocular-Motor Screening (VOMS), Perceived Academic Impairment Tool (PAIT)) during pre-season (n = 140), within 48 hours, 4, 8 and 14 days post-SRC and prior to Return To Play (RTP) and were managed according to the Rugby Football Union’ community pathway (n = 42). Student-athletes were deemed recovered or impaired according to Reliable Change Index’ (RCI) or compared to their individual baseline. Results: Symptom burden recovers by four days post-SRC on RCI and to baseline by eight days. VOM function and academic ability recovers by 8 days. Some student-athletes demonstrated worse performance at RTP on all tests by RCI and to baseline, except for on VOMS score and near point convergence by RCI change. Conclusions: Variation in individual university-aged student-athletes requires a multi-faceted approach to establish what dysfunctions post-SRC exist and when recovery occurs. © 2021 Elsevier Ltd",Academic impairment; Neurocognition; Recovery; Sports-related concussion; Vestibular ocular-motor function,Aged; Athletes; Athletic Injuries; Brain Concussion; Football; Humans; Prospective Studies; Students; Universities; academic achievement; adult; Article; athlete; cognition; concussion; convalescence; disease burden; eye movement control; female; human; major clinical study; male; prospective study; sport injury; university student; vestibular function; aged; brain concussion; football; sport injury; student; university,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85117906737,Movies / Media
Milyavskaya M.; Galla B.M.; Inzlicht M.; Duckworth A.L.,"Milyavskaya, Marina (33467887800); Galla, Brian M. (35931845700); Inzlicht, Michael (6507099680); Duckworth, Angela L. (11138779200)",33467887800; 35931845700; 6507099680; 11138779200,"More Effort, Less Fatigue: The Role of Interest in Increasing Effort and Reducing Mental Fatigue",2021,Frontiers in Psychology,12,,755858,,,,35,10.3389/fpsyg.2021.755858,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120611440&doi=10.3389%2ffpsyg.2021.755858&partnerID=40&md5=37b86ce6784bf48c029c6f7a941ddbc4,"People generally prefer easier over more difficult mental tasks. Using two different adaptations of a demand selection task, we show that interest can influence this effect, such that participants choose options with a higher cognitive workload. Interest was also associated with lower feelings of fatigue. In two studies, participants (N = 63 and N = 158) repeatedly made a choice between completing a difficult or easy math problem. Results show that liking math predicts choosing more difficult (vs. easy) math problems (even after controlling for perceived math skill). Two additional studies used the Academic Diligence Task (Galla et al., 2014), where high school students (N = 447 and N = 884) could toggle between a math task and playing a video game/watching videos. In these studies, we again find that math interest relates to greater proportion of time spent on the math problems. Three of these four studies also examined perceived fatigue, finding that interest relates to lower fatigue. An internal meta-analysis of the four studies finds a small but robust effect of interest on both the willingness to exert greater effort and the experience of less fatigue (despite engaging in more effort). Copyright © 2021 Milyavskaya, Galla, Inzlicht and Duckworth.",cognitive work; effort; fatigue; interest; self-efficacy,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85120611440,Movies / Media
Fan Y.; Zhang M.; Liang X.; Shen B.; Xu Z.; Li S.; Hu T.; Wu B.; Zhao J.; Sun Y.; Liu F.; Tang Y.; Wang J.,"Fan, Yun (57218260306); Zhang, Mengwei (57278157500); Liang, Xiaoniu (56763160700); Shen, Bo (57198796380); Xu, Zhiheng (57277822700); Li, Shiyu (57321138600); Hu, Tianyu (57321214400); Wu, Bin (57190975001); Zhao, Jue (56320709300); Sun, Yimin (56262499600); Liu, Fengtao (55639885900); Tang, Yilin (56320513100); Wang, Jian (55907493400)",57218260306; 57278157500; 56763160700; 57198796380; 57277822700; 57321138600; 57321214400; 57190975001; 56320709300; 56262499600; 55639885900; 56320513100; 55907493400,Determinants of quality of life in Parkinson’s disease: a perspective of novel clinical subtypes,2021,Annals of Clinical and Translational Neurology,8,11,,2174,2183,9.0,4,10.1002/acn3.51475,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118379453&doi=10.1002%2facn3.51475&partnerID=40&md5=5222b88ef8867b72a9dc483f74dd3675,"Objective: New subtyping classification systems of Parkinson’s disease (PD) have been proposed for phenotyping patients into three different subtypes: mild motor-predominant (PD-MMP), intermediate (PD-IM) and diffuse malignant (PD-DM). The quality of life (QoL) underlying the novel PD clinical subtypes is unknown. This study aimed explore the feasibility of the classification in Chinese PD patients and to investigate the potential heterogeneous determinants of QoL among the three subtypes. Methods: 298 PD patients were enrolled, including 129 PD-MMP patients, 121 PD-IM patients and 48 PD-DM patients. All patients completed the QoL assessment, clinical evaluations and neuropsychological tests. Univariate linear analysis and multiple stepwise regression analysis were performed to identify determinants of QoL. Results: Compared to PD-MMP patients, PD-IM and PD-DM patients had more impaired QoL. The Geriatric Depression Rating Scale (GDS) score, Non-Motor Symptoms Questionnaire (NMSQ) score, Unified Parkinson’s Disease Rating Scale part III (UPDRS-III) score and Epworth Sleepiness Score (ESS) were independent contributors to QoL in PD-MMP patients. The GDS score, ESS and sniffin’ sticks screening 12 test score were independent contributors to QoL in PD-IM patients. The GDS score and Mini Mental State Examination score were independent contributors to QoL in PD-DM patients. Interpretation: The new novel subtyping classification is feasible for Chinese PD patients. Although depression was the most crucial determinant for QoL in PD-MMP, PD-IM and PD-DM patients, the other contributors of QoL in the three subtypes were heterogeneous. These findings may prompt clinicians to target specific factors for improving QoL depending on PD subtypes. © 2021 The Authors. Annals of Clinical and Translational Neurology published by Wiley Periodicals LLC on behalf of American Neurological Association",,Adult; Aged; China; Feasibility Studies; Female; Humans; Male; Middle Aged; Parkinson Disease; Patient Acuity; Quality of Life; adult; animal fluency test; Article; assessment of humans; autonomic dysfunction related items in non motor symptom questionnaire; Boston naming test; clinical assessment; clinical evaluation; clock drawing test; cognition; cognitive function test; controlled study; cross-sectional study; daytime somnolence; disease duration; Epworth sleepiness scale; feasibility study; female; Geriatric Depression Scale; Hamilton Depression Rating Scale; Hoehn and Yahr scale; human; major clinical study; male; Mini Mental State Examination; motor dysfunction; neuropsychological test; non motor symptom questionnaire; Parkinson disease; phenotype; quality of life; quality of life assessment; questionnaire; rapid eye movement sleep behavior disorder screening questionnaire; Rey auditory verbal learning test; Rey Osterrieth complex figure test; sniffin stick screening 12 test; Stroop test; symbol digit modality test; trail making test; Unified Parkinson Disease Rating Scale; unified parkinsons disease rating scale part III; aged; China; classification; middle aged; Parkinson disease; pathophysiology; patient acuity,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85118379453,Movies / Media
Soans R.S.; Renken R.J.; John J.; Bhongade A.; Raj D.; Saxena R.; Tandon R.; Gandhi T.K.; Cornelissen F.W.,"Soans, Rijul Saurabh (57192318272); Renken, Remco J. (22958013000); John, James (57215436394); Bhongade, Amit (57302959100); Raj, Dharam (57302804600); Saxena, Rohit (7202189285); Tandon, Radhika (57203055366); Gandhi, Tapan Kumar (24343318600); Cornelissen, Frans W. (7003574141)",57192318272; 22958013000; 57215436394; 57302959100; 57302804600; 7202189285; 57203055366; 24343318600; 7003574141,Patients Prefer a Virtual Reality Approach Over a Similarly Performing Screen-Based Approach for Continuous Oculomotor-Based Screening of Glaucomatous and Neuro-Ophthalmological Visual Field Defects,2021,Frontiers in Neuroscience,15,,745355,,,,13,10.3389/fnins.2021.745355,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117507456&doi=10.3389%2ffnins.2021.745355&partnerID=40&md5=55a84782ac446b355b4814a5349bbdf9,"Standard automated perimetry (SAP) is the gold standard for evaluating the presence of visual field defects (VFDs). Nevertheless, it has requirements such as prolonged attention, stable fixation, and a need for a motor response that limit application in various patient groups. Therefore, a novel approach using eye movements (EMs) – as a complementary technique to SAP – was developed and tested in clinical settings by our group. However, the original method uses a screen-based eye-tracker which still requires participants to keep their chin and head stable. Virtual reality (VR) has shown much promise in ophthalmic diagnostics – especially in terms of freedom of head movement and precise control over experimental settings, besides being portable. In this study, we set out to see if patients can be screened for VFDs based on their EM in a VR-based framework and if they are comparable to the screen-based eyetracker. Moreover, we wanted to know if this framework can provide an effective and enjoyable user experience (UX) compared to our previous approach and the conventional SAP. Therefore, we first modified our method and implemented it on a VR head-mounted device with built-in eye tracking. Subsequently, 15 controls naïve to SAP, 15 patients with a neuro-ophthalmological disorder, and 15 glaucoma patients performed three tasks in a counterbalanced manner: (1) a visual tracking task on the VR headset while their EM was recorded, (2) the preceding tracking task but on a conventional screen-based eye tracker, and (3) SAP. We then quantified the spatio-temporal properties (STP) of the EM of each group using a cross-correlogram analysis. Finally, we evaluated the human–computer interaction (HCI) aspects of the participants in the three methods using a user-experience questionnaire. We find that: (1) the VR framework can distinguish the participants according to their oculomotor characteristics; (2) the STP of the VR framework are similar to those from the screen-based eye tracker; and (3) participants from all the groups found the VR-screening test to be the most attractive. Thus, we conclude that the EM-based approach implemented in VR can be a user-friendly and portable companion to complement existing perimetric techniques in ophthalmic clinics. © Copyright © 2021 Soans, Renken, John, Bhongade, Raj, Saxena, Tandon, Gandhi and Cornelissen.",cross-correlogram; eye movements; glaucoma; neuro-ophthalmology; perimetry; user experience; virtual reality; visual field defects,adult; Article; clinical article; clinical feature; controlled study; eye tracking; female; gaze; glaucoma; human; male; oculomotor system; reaction time; risk factor; virtual reality; visual field defect; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85117507456,Movies / Media
Steil J.N.; Friedrich C.K.; Schild U.,"Steil, Jessica N. (57302477100); Friedrich, Claudia K. (7202493467); Schild, Ulrike (24339510300)",57302477100; 7202493467; 24339510300,No Evidence of Robust Noun-Referent Associations in German-Learning 6- to 14-Month-Olds,2021,Frontiers in Psychology,12,,718742,,,,5,10.3389/fpsyg.2021.718742,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117438463&doi=10.3389%2ffpsyg.2021.718742&partnerID=40&md5=464fd7264eb392643846528df141a4bf,"Work with the looking-while-listening (LWL-) paradigm suggested that 6-month-old English-learning infants associated several labels for common nouns with pictures of their referents: While one distractor picture was present, infants systematically fixated the named target picture. However, recent work revealed constraints of infants' noun comprehension. The age at which these abilities can be obtained appears to relate to the infants' familiarity with the talker, the target language, and word frequency differences in target-distractor pairs. Here, we present further data to this newly established field of research. We tested 42 monolingual German-learning infants aged 6–14 months by means of the LWL-paradigm. Infants saw two pictures side-by-side on a screen, whilst an unfamiliar male talker named one of both. Overall, infants did not fixate the target picture more than the distractor picture. In line with previous results, infants' performance on the task was higher when target and distractor differed within their word frequency—as operationalized by the parental rating of word exposure. Together, our results add further evidence for constraints on early word learning. They point to cross-linguistic differences in early word learning and strengthen the view that infants might use extra-linguistic cues within the stimulus pairing, such as frequency imbalance, to disambiguate between two potential referents. © Copyright © 2021 Steil, Friedrich and Schild.",eye-tracking; infant cognition; language acquisition; word comprehension; word learning,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85117438463,Movies / Media
Zhou J.,"Zhou, Junyi (57193768298)",57193768298,Differences on Prosaccade Task in Skilled and Less Skilled Female Adolescent Soccer Players,2021,Frontiers in Psychology,12,,711420,,,,9,10.3389/fpsyg.2021.711420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118255233&doi=10.3389%2ffpsyg.2021.711420&partnerID=40&md5=1894ed16b7b92b06980098a48fc4d414,"Although the relationship between cognitive processes and saccadic eye movements has been outlined, the relationship between specific cognitive processes underlying saccadic eye movements and skill level of soccer players remains unclear. Present study used the prosaccade task as a tool to investigate the difference in saccadic eye movements in skilled and less skilled Chinese female adolescent soccer players. Fifty-six healthy female adolescent soccer players (range: 14–18years, mean age: 16.5years) from Fujian Youth Football Training Base (Fujian Province, China) took part in the experiment. In the prosaccade task, participants were instructed to fixate at the cross at the center of the screen as long as the target appeared peripherally. They were told to saccade to the target as quickly and accurately as possible once it appeared. The results indicated that skilled soccer players exhibited shorter saccade latency (p=0.031), decreased variability of saccade latency (p=0.013), and higher spatial accuracy of saccade (p=0.032) than their less skilled counterparts. The shorter saccade latency and decreased variability of saccade latency may imply that the attentional system of skilled soccer player is superior which leads to smaller attention fluctuation and less attentional lapse. Additionally, higher spatial accuracy of saccade may imply potential structural differences in brain underlying saccadic eye movement between skilled and less skilled soccer players. More importantly, the results of the present study demonstrated that soccer players’ cognitive capacities vary as a function of their skill levels. The limitations of the present study and future directions of research were discussed. © Copyright © 2021 Zhou.",adolescent soccer players; cognitive processes; prosaccade task; saccadic eye movement; skill level,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85118255233,Movies / Media
Maes P.; Stercq F.; Kissine M.,"Maes, Pauline (57219946834); Stercq, Fanny (57015470200); Kissine, Mikhail (24067166300)",57219946834; 57015470200; 24067166300,Attention to intentional versus incidental pointing gestures in young autistic children: An eye-tracking study,2021,Journal of Experimental Child Psychology,210,,105205,,,,8,10.1016/j.jecp.2021.105205,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107725648&doi=10.1016%2fj.jecp.2021.105205&partnerID=40&md5=2947da112489931e2379f36185161b2f,"Whereas a reduced tendency to follow pointing gestures is described as an early sign of autism, the literature on response to joint attention indicates that autistic children perform better when a point is added to other social cues such as eye gaze. The purpose of this study was to explore pointing processing in autism when it is the only available cue and to investigate whether autistic children discriminate intentional pointing gestures from incidental pointing gestures. Eye movements of 58 autistic children (48 male) and 61 typically developing children (36 male) aged 3–5 years were recorded as the children were watching videos of a person uttering a pseudoword and pointing intentionally with one hand and incidentally with the other hand. After 3 s, two different potential referents for the pseudoword gradually emerged in both pointed-at corners. In comparison with typically developing children, autistic children's fixations were significantly farther away from both pointed-at zones. Upon hearing a novel word, typically developing children shifted their visual attention toward the zone pointed intentionally. This trend did not emerge in the group of autistic children regardless of their level of vocabulary. Autistic children, independently of their level of language, pay little attention to pointing when no other social cues are available and fail to discriminate intentional pointing gestures from incidental ones. They seem to grasp neither the spatial nor the social value of pointing. © 2021 Elsevier Inc.",Autism spectrum disorder; Eye tracking; Incidental pointing; Intentional pointing; Minimally verbal; Response to joint attention,"Autistic Disorder; Child; Cues; Eye-Tracking Technology; Fixation, Ocular; Gestures; Humans; Male; association; autism; child; eye fixation; gesture; human; male",Article,Final,,Scopus,2-s2.0-85107725648,Movies / Media
Kose C.; Wood I.; Gwyther A.; Basnet S.; Gaskell C.; Gringras P.; Elphick H.; Evans H.; Hill C.M.,"Kose, Ceren (57297927700); Wood, Izabelle (57256852000); Gwyther, Amy (57192643318); Basnet, Susiksha (57297722100); Gaskell, Chloe (57204453241); Gringras, Paul (57202948079); Elphick, Heather (6701474236); Evans, Hazel (7401521078); Hill, Catherine M. (15757367600)",57297927700; 57256852000; 57192643318; 57297722100; 57204453241; 57202948079; 6701474236; 7401521078; 15757367600,Sleep-related rhythmic movement disorder in young children with down syndrome: Prevalence and clinical features,2021,Brain Sciences,11,10,1326,,,,7,10.3390/brainsci11101326,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117205453&doi=10.3390%2fbrainsci11101326&partnerID=40&md5=883f95ac22bc79fe40587d45ab0f6513,"Sleep-related Rhythmic Movement Disorder (RMD) affects around 1% of UK pre-school children. Little is known about RMD in Down syndrome (DS). We aimed to determine: (a) the prevalence of RMD in children with DS aged 1.5–8 years; (b) phenotypic and sleep quality differences between children with DS and RMD and sex-and age-matched DS controls; and (c) night-to-night variability in rhythmic movements (RMs). Parents who previously reported RMs from a DS research registry of 202 children were contacted. If clinical history suggested RMD, home videosomnography (3 nights) was used to confirm RMs and actigraphy (5 nights) was used to assess sleep quality. Phenotype was explored by demographic, strengths and difficulties, Q-CHAT-10/social communication and life events questionnaires. Eight children had confirmed RMD. Minimal and estimated maximal prevalence were 4.10% and 15.38%, respectively. Sleep efficiency was significantly lower in RMD-cases (69.1%) versus controls (85.2%), but there were no other phenotypic differences. There was considerable intra-individual night-to-night variability in RMs. In conclusion, RMD has a high prevalence in children with DS, varies from night to night and is associated with poor sleep quality but, in this small sample, no daytime phenotypic differences were found compared to controls. Children with DS should be screened for RMD, which is amenable to treatment. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Actigraphy; Body rocking; Down syndrome; Head banging; Jactatio capitis nocturna; Rhythmic movement disorder; Rhythmie du sommeil; Sleep; Videosomnography,valproic acid; actimetry; anxiety; Article; attention deficit disorder; demography; developmental delay; distress syndrome; Down syndrome; electroencephalography; electrooculography; eye movement; female; Hospital Anxiety and Depression Scale; human; human experiment; life event; major clinical study; male; motor dysfunction; parental consent; phenotype; physical activity; Pittsburgh Sleep Quality Index; prevalence; quality of life; questionnaire; REM sleep; sleep efficiency; sleep quality; sleep time,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85117205453,Movies / Media
Lenoble Q.; El Haj M.,"Lenoble, Quentin (55627973100); El Haj, Mohamad (54787705800)",55627973100; 54787705800,"Look at Me"" - Eye Movements during Autobiographical Retrieval in Face-to-Face Interactions",2021,Journal of Psychophysiology,35,4,,237,242,5.0,3,10.1027/0269-8803/a000276,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101367292&doi=10.1027%2f0269-8803%2fa000276&partnerID=40&md5=46b411326f73237a2c7899436b516b6b,"There has been a surge in social cognition and social neurosciences research comparing laboratory and real eye movements. Eye movements during the retrieval of autobiographical memories (i.e., personal memories) in laboratory situations are also receiving more attention. We compared eye movements during the retrieval of autobiographical memories using a strict laboratory design versus a design mimicking social interactions. In the first design, eye movements were recorded during autobiographical memory retrieval while participants were looking at a blank screen; in the second design, participants wore eye-tracking glasses and communicated autobiographical memories to the experimenter. Compared with the ""screen""design, the ""glasses""design yielded more fixations (p > .05), shorter duration of fixations (p > .001), more saccades (p > .01), and longer duration of saccades (p > .001). These findings demonstrate how eye movements during autobiographical memory retrieval differ between strict laboratory design and face-to-face interactions.  © 2021 Hogrefe Publishing.",autobiographical memory; eye movements; fixations; saccades,adult; Article; eye movement; Face to Face Interaction; facial expression; female; human; information retrieval; literature; male; normal human; saccadic eye movement; social interaction; undergraduate student; young adult,Article,Final,,Scopus,2-s2.0-85101367292,Movies / Media
Weilbächer R.A.; Krajbich I.; Rieskamp J.; Gluth S.,"Weilbächer, Regina Agnes (57192990234); Krajbich, Ian (26032079600); Rieskamp, Jörg (6507866774); Gluth, Sebastian (35799567200)",57192990234; 26032079600; 6507866774; 35799567200,The influence of visual attention on memory-based preferential choice,2021,Cognition,215,,104804,,,,17,10.1016/j.cognition.2021.104804,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108298426&doi=10.1016%2fj.cognition.2021.104804&partnerID=40&md5=2bf2411c0c191a842528fa9b0644b939,"Many decisions rely on past experiences. Recent research indicates that people's choices are biased towards choosing better-remembered options, even if these options are comparatively unattractive (i.e., a memory bias). In the current study, we used eye tracking to compare the influence of visual attention on preferential choice between memory-based and non-memory-based decisions. Participants completed the remember-and-decide task. In this task, they first learned associations between screen locations and snack items. Then, they made binary choices between snack items. These snacks were either hidden and required recall (memory-based decisions), or they were visible (non-memory-based decisions). Remarkably, choices were more strongly influenced by attention in memory-based compared to non-memory-based decisions. However, visual attention did not mediate the memory bias on preferential choices. Finally, we adopt and expand a recently proposed computational model to provide a comprehensive description of the role of attention in memory-based decisions. In sum, the present work elucidates how visual attention interacts with episodic memory and preference formation in memory-based decisions. © 2021 Elsevier B.V.",Episodic memory; Eye tracking.; Preferential choice; Sequential sampling models; Visual attention,Decision Making; Humans; Learning; Mental Recall; adult; article; computer model; episodic memory; eye tracking; female; human; human experiment; male; memory; memory bias; visual attention; decision making; learning; recall,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85108298426,Movies / Media
Zhu R.; Obregón M.; Kreiner H.; Shillcock R.,"Zhu, Ruomeng (57223998698); Obregón, Mateo (36973868900); Kreiner, Hamutal (6603070857); Shillcock, Richard (6603785348)",57223998698; 36973868900; 6603070857; 6603785348,Small temporal asynchronies between the two eyes in binocular reading: Crosslinguistic data and the implications for ocular prevalence,2021,"Attention, Perception, and Psychophysics",83,7,,3035,3045,10.0,2,10.3758/s13414-021-02286-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106713249&doi=10.3758%2fs13414-021-02286-1&partnerID=40&md5=19f3b1660051352e6fd82a9e6cf42471,"We investigated small temporal nonalignments between the two eyes’ fixations in the reading of English and Chinese. We define nine different patterns of asynchrony and report their spatial distribution across the screen of text. We interpret them in terms of their implications for ocular prevalence—prioritizing the input from one eye over the input from the other eye in higher perception/cognition, even when binocular fusion has occurred. The data are strikingly similar across the two very different orthographies. Asynchronies, in which one eye begins the fixation earlier and/or ends it later, occur most frequently in the hemifield corresponding to that eye. We propose that such small asynchronies cue higher processing to prioritize the input from that eye, during and after binocular fusion. © 2021, The Author(s).",Binocular reading; Chinese; English; Eye-tracking; Ocular prevalence,"Eye Movements; Fixation, Ocular; Humans; Prevalence; Reading; Vision, Binocular; binocular vision; eye fixation; eye movement; human; prevalence; reading",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85106713249,Movies / Media
Schröter I.; Grillo N.R.; Limpak M.K.; Mestiri B.; Osthold B.; Sebti F.; Mergenthaler M.,"Schröter, Iris (57209802989); Grillo, Nico Rolf (57295105800); Limpak, Margarethe Kristine (57295325800); Mestiri, Bilel (57295647500); Osthold, Benedikt (57295105900); Sebti, Fourat (57295540700); Mergenthaler, Marcus (25930999700)",57209802989; 57295105800; 57295325800; 57295647500; 57295105900; 57295540700; 25930999700,Webcam eye tracking for monitoring visual attention in hypothetical online shopping tasks,2021,Applied Sciences (Switzerland),11,19,9281,,,,11,10.3390/app11199281,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117045998&doi=10.3390%2fapp11199281&partnerID=40&md5=5f3a8229fd642308e1eb3e35f1f49181,"Online retailers are challenged to present their products in an appropriate way to attract customers’ attention. To test the impact of product presentation features on customers’ visual attention, webcam eye tracking might be an alternative to infrared eye tracking, especially in situations where face‐to‐face contact is difficult. The aim of this study was to examine whether webcam eye tracking is suitable for investigating the influence of certain exogenous factors on customers’ visual attention when visiting online clothing shops. For this purpose, screenshots of two websites of two well‐known online clothing retailers were used as stimuli. Linear regression analyses were conducted to determine the influence of the spatial position and the presence of a human model on the percentage of participants visiting a product depiction. The results show that products presented by human models and located in the upper middle area of a website were visited by more participants. From this, we were able to derive recommendations for optimising product presentation in online clothing shops. Our results fit well with those of other studies on visual attention conducted with infrared eye tracking, suggesting that webcam eye tracking could be an alternative to infrared eye tracking, at least for similar research questions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",Gaze behaviour; Human model; Online clothing retail; Spatial position; Webcam eye tracking; Website,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85117045998,Movies / Media
Woodard L.,"Woodard, Lawrence (57225930692)",57225930692,The Stability of the Red Reflex Produced by Different Surgical Ophthalmic Microscopes,2021,Ophthalmology and Therapy,10,3,,389,391,2.0,0,10.1007/s40123-021-00367-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110007699&doi=10.1007%2fs40123-021-00367-w&partnerID=40&md5=c5b5e4905ed553a846db0700b4be7a0b,"The red reflex is produced when coaxial light from the retina is reflected from patient to observer, and acts as an important tool in ophthalmic surgery owing to its application in screening various ocular abnormalities associated with the cornea and iris. Visualization of these intraocular structures could improve surgeons’ ability to perform ophthalmic procedures safely. The aim of this podcast, featuring Dr. Laurence Woodard (Medical Director of Omni Eye Services, Atlanta), is to highlight the clinical utility of red reflex stability and intensity provided by nearly collimated and focused beam microscope illumination systems used in ophthalmic surgery. Quantifying red reflex intensity can be challenging due to its subjective nature. Other factors such as phacoemulsification and individual characteristics of the eye, such as pupil size or iris pigment, may affect red reflex intensity. Red reflex stability and intensity may also be altered during the procedure because of excessive eye movement, lack of centering, or if the eye is not perpendicular to the light beam. In addition, differences in nearly collimated and focused illumination systems may affect surgeon fatigue and surgery success. The intensity of the red reflex dictates surgeons’ ability to maintain adequate visualization during surgery as well as identify ocular abnormalities. In conclusion, the more intense the red reflex, the more likely a surgeon will be able to maintain adequate visualization during surgery as well as identify corneal and anterior segment abnormalities. The podcast and transcript can be viewed below the abstract of the online version of the manuscript. Alternatively, the podcast can be downloaded here: https://doi.org/10.6084/m9.figshare.14779212. [MediaObject not available: see fulltext.]. © 2021, The Author(s).",Microscope illumination system; Ophthalmology; Red reflex,cataract extraction; cornea; cornea edema; eye disease; eye malformation; eye movement; fatigue; genetic transcription; glaucoma; human; illumination; intraocular pressure; iris; medical director; Note; ophthalmology; optical coherence tomography; phacoemulsification; podcast; pupil diameter; reflex; refraction error; regenerative medicine; retina detachment; retina fovea; surgeon; visual acuity,Note,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85110007699,Movies / Media
Li J.; Song J.; Huang Y.; Wang Y.; Zhang J.,"Li, Jutao (55211626400); Song, Jiutai (57226329420); Huang, Yanqun (53163952000); Wang, Yuzhen (57222995156); Zhang, Jie (57277010800)",55211626400; 57226329420; 53163952000; 57222995156; 57277010800,Effects of different interaction modes on fatigue and reading effectiveness with mobile phones,2021,International Journal of Industrial Ergonomics,85,,103189,,,,13,10.1016/j.ergon.2021.103189,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111187348&doi=10.1016%2fj.ergon.2021.103189&partnerID=40&md5=33037387aff4da4b92d825764893bc30,"Reading on touchscreen mobile devices is common in modern society. However, it is difficult to determine which interaction mode has the best reading effect when reading texts of different lengths. Using memory tests, eye-movement data analysis, and task load scale, we studied the effects of paging and vertical scrolling modes on the memory level, visual fatigue, task load, and reading speed of 28 participants reading both long and short texts. The results showed that vertical scrolling has a better memory effect than paging mode when reading short texts, but there was no difference in effect when reading long texts; the blink frequency in paging mode is higher than in scrolling mode whether reading long or short texts; no significant differences were found in reading speed in scrolling or paging mode when reading short or long texts; and in task load, the mental and temporal demands in scrolling mode were lower than in paging mode whether reading long or short texts. Considering that most current mobile readings do not differ in interaction mode according to the length of reading material, our conclusions provide valuable design recommendations to designers working on mobile reading apps. © 2021 Elsevier B.V.",Mobile reading; Paging; Reading efficiency; Scrolling; Text length,Biomedical engineering; Ergonomics; Blink frequencies; Design recommendations; Eye movement datum; Interaction modes; Memory effects; Memory tests; Reading speed; Visual fatigue; adult; Article; blinking; controlled study; exercise; eye movement; fatigue; female; frustration; human; human experiment; male; memory; mental fatigue; normal human; reading; task performance; visual fatigue; Eye movements,Article,Final,,Scopus,2-s2.0-85111187348,Movies / Media
Donnelly S.; Kidd E.,"Donnelly, Seamus (57192208454); Kidd, Evan (57200012621)",57192208454; 57200012621,Onset Neighborhood Density Slows Lexical Access in High Vocabulary 30-Month Olds,2021,Cognitive Science,45,9,e13022,,,,2,10.1111/cogs.13022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115221480&doi=10.1111%2fcogs.13022&partnerID=40&md5=d91ce375c0feeb06b8b17d22a285f0c2,"There is consensus that the adult lexicon exhibits lexical competition. In particular, substantial evidence demonstrates that words with more phonologically similar neighbors are recognized less efficiently than words with fewer neighbors. How and when these effects emerge in the child's lexicon is less clear. In the current paper, we build on previous research by testing whether phonological onset density slows lexical access in a large sample of 100 English-acquiring 30-month-olds. The children participated in a visual world looking-while-listening task, in which their attention was directed to one of two objects on a computer screen while their eye movements were recorded. We found moderate evidence of inhibitory effects of onset neighborhood density on lexical access and clear evidence for an interaction between onset neighborhood density and vocabulary, with larger effects of onset neighborhood density for children with larger vocabularies. Results suggest the lexicons of 30-month-olds exhibit lexical-level competition, with competition increasing with vocabulary size. © 2021 The Authors. Cognitive Science published by Wiley Periodicals LLC on behalf of Cognitive Science Society (CSS).",Language development; Lexicon; Vocabulary,Adult; Auditory Perception; Child; Eye Movements; Humans; Linguistics; Vocabulary; adult; child; eye movement; hearing; human; linguistics; vocabulary,Article,Final,,Scopus,2-s2.0-85115221480,Movies / Media
Liu H.; Hu X.; Ren Y.; Wang L.; Guo L.; Guo C.C.; Han J.,"Liu, Huan (57194836907); Hu, Xintao (56177187200); Ren, Yudan (57190221331); Wang, Liting (57194832125); Guo, Lei (56428255600); Guo, Christine Cong (55233468300); Han, Junwei (24450644400)",57194836907; 56177187200; 57190221331; 57194832125; 56428255600; 55233468300; 24450644400,Neural Correlates of Interobserver Visual Congruency in Free-Viewing Condition,2021,IEEE Transactions on Cognitive and Developmental Systems,13,3,9119136,546,554,8.0,1,10.1109/TCDS.2020.3002765,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086742337&doi=10.1109%2fTCDS.2020.3002765&partnerID=40&md5=97f30a3404634d4436ce555321f92aa3,"Dynamic visual scenes lead to varying consistency of observers' eye movements, reflecting one intrinsic characteristic of visual scenes, termed interobserver visual congruency (IOVC). However, the neural correlates underlying IOVC are largely unknown especially in the free-viewing condition. In this study, we explored the neural correlates of IOVC using functional magnetic resonance imaging (fMRI) and eye-tracking data acquired in a naturalistic paradigm. Specifically, we estimated IOVC of movie shots from eye-tracking data and then conducted two statistical analyses for functional inference, including a hypothesis-driven analyses [general linear model (GLM)] and a data-driven approach [intersubject correlation (ISC)]. The GLM analysis demonstrated that IOVC recruited two distinctive streams of neural systems. Specifically, neural activities in superior temporal gyrus, default mode network, and hippocampus were positively correlated with IOVC, whereas those in the primary and secondary visual cortices, as well as the dorsal attention network exhibited negative correlations. Further ISC analysis revealed that movie shots with higher IOVC evoked more synchronous brain activities in the primary auditory cortex, primary visual cortex, and superior parietal lobule compared to those shots with lower IOVC. This study provides some novel evidence of visual processing in the human brain in the free-viewing condition.  © 2016 IEEE.",Eye-tracking data; functional magnetic resonance imaging (fMRI); general linear model (GLM); interobserver visual congruency (IOVC); intersubject correlation (ISC); naturalistic paradigm,Brain; Eye movements; Eye tracking; Magnetic resonance imaging; Default-mode networks; Dynamic visual scenes; Functional magnetic resonance imaging; General linear modeling; Intrinsic characteristics; Negative correlation; Primary visual cortex; Superior temporal gyrus; Functional neuroimaging,Article,Final,,Scopus,2-s2.0-85086742337,Movies / Media
Minarikova E.; Smidekova Z.; Janik M.; Holmqvist K.,"Minarikova, Eva (56801691300); Smidekova, Zuzana (57222482601); Janik, Miroslav (23989196500); Holmqvist, Kenneth (8357720500)",56801691300; 57222482601; 23989196500; 8357720500,Teachers’ Professional Vision: Teachers’ Gaze During the Act of Teaching and After the Event,2021,Frontiers in Education,6,,716579,,,,15,10.3389/feduc.2021.716579,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115147009&doi=10.3389%2ffeduc.2021.716579&partnerID=40&md5=c317c04a9c62aba9b2ba18044278ae53,"To date most of our knowledge on professional vision has relied on verbal data or questionnaires that used classroom videos as prompts. This has been used to tell us about a teacher’s professional vision. Recently, however, new studies explore professional vision during the act of teaching through the use of mobile eye-tracking. This novel approach poses the question: how do these two “professional visions” differ? Visual attention represented by gaze was used as a proxy to studying professional vision (specifically its noticing component). To achieve this, eye-tracking as a data collection method was used. We worked with three teachers and employed eye-tracking glasses to record teacher eye movements during teaching (4 lessons per teacher; labelled as IN mode). After each lesson, we selected short clips from the lesson recorded by a static camera aimed at pupils and showed them to the same teacher (i.e., providing a similar setting as traditional studies on professional vision) while recording eye movements and gaze behavior data through a screen-based eye-tracker (labelled as ON mode). The two modes differ and due to these differences, comparison is difficult. However, by overlaying them and describing them in detail we want to highlight the exact variance observed. A comparison between IN vs ON condition in terms of dwell time on the same students in either condition was made using both quantitative (correlation) and qualitative (timeline comparison) methods. The findings suggest that the greatest differences in attention given to individual pupils occur when a pupil who was interacted with during the situation is missing from the view in the video recording. Even though individual differences are present in the patterns of gaze in IN and ON modes, the teachers in our sample consistently monitored more pupils more often in the ON mode than in the IN mode. On the other hand, the IN mode was mostly characterized by focused gaze on the pupil that the teacher interacted with in the moment with few side glances. The results aim to open a discussion about our understanding of professional vision in different contexts and about how current research may need to expand its outlook. © Copyright © 2021 Minarikova, Smidekova, Janik and Holmqvist.",eye-tracking; gaze; mobile; professional vision; remote; teacher,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85115147009,Movies / Media
Yin Y.; Jia J.S.; Zheng W.,"Yin, Yunlu (56688935700); Jia, Jayson S. (55611330600); Zheng, Wanyi (57216818115)",56688935700; 55611330600; 57216818115,The Effect of Slow Motion Video on Consumer Inference,2021,Journal of Marketing Research,58,5,,1007,1024,17.0,27,10.1177/00222437211025054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114997625&doi=10.1177%2f00222437211025054&partnerID=40&md5=04a63d4dedaac4e058755ded501c5592,"Video advertisements often show actors and influence agents consuming and enjoying products in slow motion. By prolonging depictions of influence agents’ consumption utility, slow motion cinematographic effects ostensibly enhance social proof and signal product qualities that are otherwise difficult to infer visually (e.g., pleasant tastes, smells, haptic sensations). In this research, seven studies, including an eye tracking study, a Facebook Ads field experiment, and lab and online experiments—all using real ads across diverse contexts—demonstrate that slow motion (vs. natural speed) can backfire and undercut product appeal by making the influence agent’s behavior seem more intentional and extrinsically motivated. The authors rule out several alternative explanations by showing that the effect attenuates for individuals with lower intentionality bias, is mitigated under cognitive load, and reverses when ads use nonhuman influence agents. The authors conclude by highlighting the potential for cross-pollination between visual information processing and social cognition research, particularly in contexts such as persuasion and trust, and they discuss managerial implications for visual marketing, especially on digital and social platforms. © American Marketing Association 2021.",audiovisual media; eye tracking; intentionality; slow motion video; visual marketing,,Article,Final,,Scopus,2-s2.0-85114997625,Movies / Media
Hartz A.; Guth B.; Jording M.; Vogeley K.; Schulte-Rüther M.,"Hartz, Arne (57200858069); Guth, Björn (57226861028); Jording, Mathis (55613252200); Vogeley, Kai (7004117310); Schulte-Rüther, Martin (18234240900)",57200858069; 57226861028; 55613252200; 7004117310; 18234240900,Temporal Behavioral Parameters of On-Going Gaze Encounters in a Virtual Environment,2021,Frontiers in Psychology,12,,673982,,,,6,10.3389/fpsyg.2021.673982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113167115&doi=10.3389%2ffpsyg.2021.673982&partnerID=40&md5=554746d7a279dcb8a8a618e421a4374b,"To navigate the social world, humans heavily rely on gaze for non-verbal communication as it conveys information in a highly dynamic and complex, yet concise manner: For instance, humans utilize gaze effortlessly to direct and infer the attention of a possible interaction partner. Many traditional paradigms in social gaze research though rely on static ways of assessing gaze interaction, e.g., by using images or prerecorded videos as stimulus material. Emerging gaze contingent paradigms, in which algorithmically controlled virtual characters can respond flexibly to the gaze behavior of humans, provide high ecological validity. Ideally, these are based on models of human behavior which allow for precise, parameterized characterization of behavior, and should include variable interactive settings and different communicative states of the interacting agents. The present study provides a complete definition and empirical description of a behavioral parameter space of human gaze behavior in extended gaze encounters. To this end, we (i) modeled a shared 2D virtual environment on a computer screen in which a human could interact via gaze with an agent and simultaneously presented objects to create instances of joint attention and (ii) determined quantitatively the free model parameters (temporal and probabilistic) of behavior within this environment to provide a first complete, detailed description of the behavioral parameter space governing joint attention. This knowledge is essential to enable the modeling of interacting agents with a high degree of ecological validity, be it for cognitive studies or applications in human-robot interaction. © Copyright © 2021 Hartz, Guth, Jording, Vogeley and Schulte-Rüther.",ecological validity; eye tracking; gaze contingency; human-agent interaction; joint attention; social gaze,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85113167115,Movies / Media
Ijuin K.; Ogata K.; Watanabe K.; Miwa H.; Yamamoto Y.,"Ijuin, Koki (56006019000); Ogata, Kunihiro (56596141600); Watanabe, Kentaro (57189015544); Miwa, Hiroyasu (7202031799); Yamamoto, Yoshinobu (57261718200)",56006019000; 56596141600; 57189015544; 7202031799; 57261718200,"Proposing remote video conversation system ""PARAPPA"": Delivering the gesture and body posture with rotary screen",2021,"2021 30th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2021",,,,1060,1065,5.0,2,10.1109/RO-MAN50785.2021.9515454,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115069085&doi=10.1109%2fRO-MAN50785.2021.9515454&partnerID=40&md5=8305e92d1c039efb435e81fd2546728e,"Globalization and the effect of recent infectious disease are changing the remote conversations as a new normal in business meetings, social provision and casual chatting. Previous research show that the remote conversations have a difficulty on showing the presence or attention to the other interlocutors, especially in the situation where the majority of interlocutor share the same place and one or a few interlocutor participate from difference place. This paper proposed ""Parappa"", a remote video conversation system, for those unbalanced condition by utilizing both physical and virtual approaches to share the nonverbal behaviors of remotely-participating interlocutor. The proposed system is constructed with a rotatable screen which projects the life-size avatar of remote interlocutor. The rotation of the screen represents the body posture and the projected avatar show the gesture. The results of preliminary analyses of eye gaze activities and frequency of the screen rotation during conversation suggests the possibilities that proposed system enables to show the presence of remote interlocutors. © 2021 IEEE.",,Agricultural robots; Body postures; Business meetings; Conversation systems; Infectious disease; Nonverbal behavior; Preliminary analysis; Rotary-screen; Unbalanced condition; Social robots,Conference paper,Final,,Scopus,2-s2.0-85115069085,Movies / Media
Tadokoro K.; Yamashita T.; Fukui Y.; Nomura E.; Ohta Y.; Ueno S.; Nishina S.; Tsunoda K.; Wakutani Y.; Takao Y.; Miyoshi T.; Higashi Y.; Osakada Y.; Sasaki R.; Matsumoto N.; Kawahara Y.; Omote Y.; Takemoto M.; Hishikawa N.; Morihara R.; Abe K.,"Tadokoro, Koh (57200915345); Yamashita, Toru (26637361200); Fukui, Yusuke (56113341700); Nomura, Emi (57195417599); Ohta, Yasuyuki (35729195700); Ueno, Setsuko (57211234694); Nishina, Saya (57224527204); Tsunoda, Keiichiro (57192255987); Wakutani, Yosuke (6701747112); Takao, Yoshiki (25226151200); Miyoshi, Takahiro (57224500034); Higashi, Yasuto (7202858936); Osakada, Yosuke (57210564421); Sasaki, Ryo (57192252146); Matsumoto, Namiko (57208160371); Kawahara, Yuko (56385112400); Omote, Yoshio (54411037400); Takemoto, Mami (7102026271); Hishikawa, Nozomi (6603348389); Morihara, Ryuta (56465917300); Abe, Koji (55326023200)",57200915345; 26637361200; 56113341700; 57195417599; 35729195700; 57211234694; 57224527204; 57192255987; 6701747112; 25226151200; 57224500034; 7202858936; 57210564421; 57192252146; 57208160371; 56385112400; 54411037400; 7102026271; 6603348389; 56465917300; 55326023200,Early detection of cognitive decline in mild cognitive impairment and Alzheimer's disease with a novel eye tracking test,2021,Journal of the Neurological Sciences,427,,117529,,,,45,10.1016/j.jns.2021.117529,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107745700&doi=10.1016%2fj.jns.2021.117529&partnerID=40&md5=e5e8d269f08091d05e1adaed2c0ce5ed,"Due to an increasing number of dementia patients, the development of a rapid and sensitive method for cognitive assessment is awaited. Here, we examined the usefulness of a novel and short (3 min) eye tracking device to evaluate the cognitive function of normal control (NC, n = 52), mild cognitive impairment (MCI, n = 52), and Alzheimer's disease (AD, n = 70) subjects. Eye tracking total score declined significantly in MCI (**p < 0.01 vs NC) and AD (**p < 0.01 vs NC, ##p < 0.01 vs MCI), and correlated well with the mini-mental state examination (MMSE) score (r = 0.57, *p < 0.05). Furthermore, the eye tracking test, especially memory and deductive reasoning tasks, effectively discriminated NC, MCI and AD. The present novel eye tracking test clearly discriminated cognitive functions among NC, MCI, and AD subjects, thereby providing an advantage for the early detection of MCI and AD in screening. © 2021 Elsevier B.V.",Alzheimer's disease; Cognitive assessment; Eye tracking technology; Mild cognitive impairment,Alzheimer Disease; Cognitive Dysfunction; Early Diagnosis; Eye-Tracking Technology; Humans; Mass Screening; Neuropsychological Tests; aged; Alzheimer disease; Article; attention; cognition; cognition assessment; cognitive defect; controlled study; deductive reasoning; early diagnosis; eye movement disorder; eye tracking; female; human; machine learning; major clinical study; male; memory; mild cognitive impairment; Mini Mental State Examination; working memory; Alzheimer disease; early diagnosis; mass screening; neuropsychological test,Article,Final,,Scopus,2-s2.0-85107745700,Movies / Media
Frazier T.W.; Uljarevic M.; Ghazal I.; Klingemier E.W.; Langfus J.; Youngstrom E.A.; Aldosari M.; Al-Shammari H.; El-Hag S.; Tolefat M.; Ali M.; Al-Shaban F.A.,"Frazier, Thomas W. (57202495851); Uljarevic, Mirko (42263043800); Ghazal, Iman (57205342041); Klingemier, Eric W. (57148189200); Langfus, Joshua (57193586326); Youngstrom, Eric A. (7003735731); Aldosari, Mohammed (6506776585); Al-Shammari, Hawraa (57208736112); El-Hag, Saba (57208738263); Tolefat, Mohamed (57205344542); Ali, Mogahed (57208742520); Al-Shaban, Fouad A. (56495402900)",57202495851; 42263043800; 57205342041; 57148189200; 57193586326; 7003735731; 6506776585; 57208736112; 57208738263; 57205344542; 57208742520; 56495402900,Social attention as a cross-cultural transdiagnostic neurodevelopmental risk marker,2021,Autism Research,14,9,,1873,1885,12.0,16,10.1002/aur.2532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105715542&doi=10.1002%2faur.2532&partnerID=40&md5=73fb9850a498402bf755c6a331113aca,"The primary objectives of this study were to evaluate the structure and age-related stability of social attention in English and Arabic-speaking youth and to compare social attention between children with autism spectrum disorder (ASD), other developmental disabilities (DD), and typically-developing controls. Eye-tracking data were collected from US (N = 270) and Qatari (N = 242) youth ages 1–17, including children evaluated for possible ASD. Participants viewed 44 stimuli from seven social paradigms. Fixation was computed for areas of interest within each stimulus. Latent variable models examined the structure of social attention. Generalized estimating equation models examined the effect of age, sex, culture, and diagnostic group on social attention. The best-fitting model included a general social attention factor and six specific factors. Cultural differences in social attention were minimal and social attention was stable across age (r = 0.03), but females showed significantly greater social attention than males (d = 0.28). Social attention was weaker in DD (d = −0.17) and lowest in ASD (d = −0.38) relative to controls. Differences were of sufficient magnitude across areas-of-interest to reliably differentiate DD from controls (AUC = 0.80) and ASD-only from all other cases (AUC = 0.76). A social attention dimension that represents an early-life preference for socially salient information was identified. This preference was cross-culturally consistent and stable across development but stronger in females and weaker in DD, especially ASD. Given rapid and easy-to-collect remote eye tracking administration, social attention measurement may be useful for developmental monitoring. Acquisition of population norms, analogous to height/weight/head circumference, might enhance early screening and tracking of neurodevelopment. Lay Summary: This research found that social attention is a single dimension of behavior that represents a strong preference for social stimuli, is consistent across cultures, stable across age, and stronger in females. Children with developmental disabilities had lower levels of social attention than neurotypical children and children with autism spectrum disorder had the lowest levels of social attention. © 2021 The Authors. Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.",autism; cross-cultural; developmental disability; risk marker; social attention; validation,"Adolescent; Attention; Autism Spectrum Disorder; Child; Child, Preschool; Cross-Cultural Comparison; Female; Goals; Humans; Infant; Male; Mass Screening; adolescent; Article; attention; autism; child; child development; controlled study; cultural anthropology; developmental delay; eye tracking; female; groups by age; human; information processing; major clinical study; male; monitoring; risk factor; sex; social aspect; attention; autism; cultural factor; infant; mass screening; motivation; preschool child",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85105715542,Movies / Media
Xia Y.; Melinscak F.; Bach D.R.,"Xia, Yanfang (57208548915); Melinscak, Filip (55913383600); Bach, Dominik R. (9746516300)",57208548915; 55913383600; 9746516300,Saccadic scanpath length: an index for human threat conditioning,2021,Behavior Research Methods,53,4,,1426,1439,13.0,9,10.3758/s13428-020-01490-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095695237&doi=10.3758%2fs13428-020-01490-5&partnerID=40&md5=a8f1f698a9202a7d7de17a0c296fb99e,"Threat-conditioned cues are thought to capture overt attention in a bottom-up process. Quantification of this phenomenon typically relies on cue competition paradigms. Here, we sought to exploit gaze patterns during exclusive presentation of a visual conditioned stimulus, in order to quantify human threat conditioning. To this end, we capitalized on a summary statistic of visual search during CS presentation, scanpath length. During a simple delayed threat conditioning paradigm with full-screen monochrome conditioned stimuli (CS), we observed shorter scanpath length during CS+ compared to CS- presentation. Retrodictive validity, i.e., effect size to distinguish CS+ and CS-, was maximized by considering a 2-s time window before US onset. Taking into account the shape of the scan speed response resulted in similar retrodictive validity. The mechanism underlying shorter scanpath length appeared to be longer fixation duration and more fixation on the screen center during CS+ relative to CS- presentation. These findings were replicated in a second experiment with similar setup, and further confirmed in a third experiment using full-screen patterns as CS. This experiment included an extinction session during which scanpath differences appeared to extinguish. In a fourth experiment with auditory CS and instruction to fixate screen center, no scanpath length differences were observed. In conclusion, our study suggests scanpath length as a visual search summary statistic, which may be used as complementary measure to quantify threat conditioning with retrodictive validity similar to that of skin conductance responses. © 2020, The Author(s).",Attentional bias; Fear conditioning; Pavlovian conditioning; Saccadic eye movement; Threat memory,"Attention; Conditioning, Classical; Conditioning, Operant; Cues; Extinction, Psychological; Fear; Humans; article; attentional bias; conditioned reflex; controlled study; effect size; electrodermal response; fear; gaze; human; human experiment; memory; quantitative analysis; saccadic eye movement; validity; velocity; association; attention; operant conditioning; reinforcement (psychology)",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85095695237,Movies / Media
Dong X.; Bao M.,"Dong, Xue (56218295000); Bao, Min (8570352300)",56218295000; 8570352300,The growing sensory suppression on visual perception during head-rotation preparation,2021,PsyCh Journal,10,4,,499,507,8.0,4,10.1002/pchj.438,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101903490&doi=10.1002%2fpchj.438&partnerID=40&md5=3acd11676a6594b76682ffaa2eb93e29,"Sensory perception is often impaired by self-generated movements. This effect of sensory suppression has been commonly observed in voluntary hand-movement-induced tactile sensation during the period of motor preparation and execution. However, it remains unclear whether such suppression also occurs in the visual domain and if it can be induced by the preparation of other body movements. To extend our knowledge about sensory suppression, the present study investigated visual sensitivity during the preparation of head rotation. Participants wore virtual reality goggles and rotated their heads horizontally according to a visual cue presented on the goggles screens. Before the start of head rotation, a target of Landolt C was displayed at a peripheral location that was directed by the head-rotation cue or a symmetric location in the opposite visual field. After each head rotation, participants reported the target's orientation, allowing the measurement of the discrimination threshold. Besides, the discrimination sensitivity was also measured in two head-still conditions with or without the presentation of a visual cue. The results showed that the discrimination performance was largely impaired by the preparation of head rotation. This effect of sensory attenuation increased with the approach of head-motion onset. However, the attenuation was not found on the discrimination of auditory stimuli during the preparation of head rotation, thus excluding the account of general dual-task requirement. In contrast to the previous findings of improved perception by preparation of saccade or reach, our findings indicate that sensory suppression rather than attention shift plays a major role during the preparation of head movement. © 2021 The Institute of Psychology, Chinese Academy of Sciences and John Wiley & Sons Australia, Ltd",head rotation; motor preparation; sensory suppression; visual perception,Attention; Humans; Movement; Psychomotor Performance; Rotation; Touch; Visual Perception; adult; article; attention; female; head movement; human; human experiment; male; protective glasses; saccadic eye movement; virtual reality; visual field; movement (physiology); psychomotor performance; rotation; touch; vision,Article,Final,,Scopus,2-s2.0-85101903490,Movies / Media
Reimann G.E.; Walsh C.; Csumitta K.D.; McClure P.; Pereira F.; Martin A.; Ramot M.,"Reimann, Gabrielle E. (57201975115); Walsh, Catherine (57209703156); Csumitta, Kelsey D. (57215011497); McClure, Patrick (53866904000); Pereira, Francisco (35194757000); Martin, Alex (35446495000); Ramot, Michal (35311632200)",57201975115; 57209703156; 57215011497; 53866904000; 35194757000; 35446495000; 35311632200,Gauging facial feature viewing preference as a stable individual trait in autism spectrum disorder,2021,Autism Research,14,8,,1670,1683,13.0,8,10.1002/aur.2540,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106017566&doi=10.1002%2faur.2540&partnerID=40&md5=8b680918ba1cf824bb5135ee124bee68,"Eye tracking provides insights into social processing deficits in autism spectrum disorder (ASD), especially in conjunction with dynamic, naturalistic free-viewing stimuli. However, the question remains whether gaze characteristics, such as preference for specific facial features, can be considered a stable individual trait, particularly in those with ASD. If so, how much data are needed for consistent estimations? To address these questions, we assessed the stability and robustness of gaze preference for facial features as incremental amounts of movie data were introduced for analysis. We trained an artificial neural network to create an object-based segmentation of naturalistic movie clips (14 s each, 7410 frames total). Thirty-three high-functioning individuals with ASD and 36 age- and IQ-equated typically developing individuals (age range: 12–30 years) viewed 22 Hollywood movie clips, each depicting a social interaction. As we evaluated combinations of one, three, five, eight, and 11 movie clips, gaze dwell times on core facial features became increasingly stable at within-subject, within-group, and between-group levels. Using a number of movie clips deemed sufficient by our analysis, we found that individuals with ASD displayed significantly less face-centered gaze (centralized on the nose; p < 0.001) but did not significantly differ from typically developing participants in eye or mouth looking times. Our findings validate gaze preference for specific facial features as a stable individual trait and highlight the possibility of misinterpretation with insufficient data. Additionally, we propose the use of a machine learning approach to stimuli segmentation to quickly and flexibly prepare dynamic stimuli for analysis. Lay Summary: Using a data-driven approach to segmenting movie stimuli, we examined varying amounts of data to assess the stability of social gaze in individuals with autism spectrum disorder (ASD). We found a reduction in social fixations in participants with ASD, driven by decreased attention to the center of the face. Our findings further support the validity of gaze preference for face features as a stable individual trait when sufficient data are used. Published 2021. This article is a U.S. Government work and is in the public domain in the USA.",autism spectrum disorder; machine learning; social behavior,"Adolescent; Adult; Autism Spectrum Disorder; Child; Face; Fixation, Ocular; Humans; Motion Pictures; Phenotype; Young Adult; adolescent; adult; Article; artificial neural network; autism; child; clinical article; controlled study; dwell time; eye movement; facies; gaze; human; intelligence quotient; machine learning; male; mouth; social interaction; television viewing; videorecording; eye fixation; face; movie; phenotype; young adult",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85106017566,Movies / Media
Zhao Z.; Tang H.; Zhang X.; Qu X.; Hu X.; Lu J.,"Zhao, Zhong (57008361600); Tang, Haiming (57221818139); Zhang, Xiaobin (57213160782); Qu, Xingda (57194640319); Hu, Xinyao (55345595400); Lu, Jianping (57203465974)",57008361600; 57221818139; 57213160782; 57194640319; 55345595400; 57203465974,Classification of children with autism and typical development using eye-tracking data from face-to-face conversations: Machine learning model development and performance evaluation,2021,Journal of Medical Internet Research,23,8,e29328,,,,56,10.2196/29328,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114021518&doi=10.2196%2f29328&partnerID=40&md5=e5b39f8b6edb14022b3380ecdb737cc2,"Background: Previous studies have shown promising results in identifying individuals with autism spectrum disorder (ASD) by applying machine learning (ML) to eye-tracking data collected while participants viewed varying images (ie, pictures, videos, and web pages). Although gaze behavior is known to differ between face-to-face interaction and image-viewing tasks, no study has investigated whether eye-tracking data from face-to-face conversations can also accurately identify individuals with ASD. Objective: The objective of this study was to examine whether eye-tracking data from face-to-face conversations could classify children with ASD and typical development (TD). We further investigated whether combining features on visual fixation and length of conversation would achieve better classification performance. Methods: Eye tracking was performed on children with ASD and TD while they were engaged in face-to-face conversations (including 4 conversational sessions) with an interviewer. By implementing forward feature selection, four ML classifiers were used to determine the maximum classification accuracy and the corresponding features: support vector machine (SVM), linear discriminant analysis, decision tree, and random forest. Results: A maximum classification accuracy of 92.31% was achieved with the SVM classifier by combining features on both visual fixation and session length. The classification accuracy of combined features was higher than that obtained using visual fixation features (maximum classification accuracy 84.62%) or session length (maximum classification accuracy 84.62%) alone. Conclusions: Eye-tracking data from face-to-face conversations could accurately classify children with ASD and TD, suggesting that ASD might be objectively screened in everyday social interactions. However, these results will need to be validated with a larger sample of individuals with ASD (varying in severity and balanced sex ratio) using data collected from different modalities (eg, eye tracking, kinematic, electroencephalogram, and neuroimaging). In addition, individuals with other clinical conditions (eg, developmental delay and attention deficit hyperactivity disorder) should be included in similar ML studies for detecting ASD.  © 2021 Zhong Zhao, Haiming Tang, Xiaobin Zhang, Xingda Qu, Xinyao Hu, Jianping Lu.",Autism spectrum disorder; Eye tracking; Face-to-face interaction; Machine learning; Visual fixation,"Autism Spectrum Disorder; Autistic Disorder; Child; Eye-Tracking Technology; Fixation, Ocular; Humans; Machine Learning; Article; autism; child; clinical article; controlled study; conversation; decision tree; developmental delay; diagnostic accuracy; discriminant analysis; disease classification; eye tracking; feature selection; female; head movement; human; machine learning; male; random forest; support vector machine; autism; eye fixation",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85114021518,Movies / Media
Wittenberg T.; Stenzel A.; Wittenberg A.; Delius S.V.; Raithel M.; Eixelberger T.; Nowack S.,"Wittenberg, Thomas (6701619212); Stenzel, Antonia (57250117100); Wittenberg, Amelie (57249826400); Delius, Stefan Von (23970047500); Raithel, Martin (56251080400); Eixelberger, Thomas (57211116350); Nowack, Sebastian (56429487000)",6701619212; 57250117100; 57249826400; 23970047500; 56251080400; 57211116350; 56429487000,Initial experiments of eye-tracking during AIassisted polyp-detection in colonoscopy,2021,Current Directions in Biomedical Engineering,7,1,20211134,,,,1,10.1515/cdbme-2021-1031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114445000&doi=10.1515%2fcdbme-2021-1031&partnerID=40&md5=7c210051357422798fc24248a5e47ce7,"Currently, various AI-based systems for computerassisted adenoma- A nd polyp-detection during colonoscopy have been brought to the market and are under clinical investigation. With these systems available to be used during routine screening colonoscopy and first results published about experiments and findings, it has become of interest how and to which extend such systems are used during the examination. Specifically, similarly to automotive navigation, it is of interest of how much visual focus is put onto the augmented image of the above-mentioned devices, signalling possible hypothesis of adenomas or polyps, and how much time-of-attention remains on the original colonoscopic video data. Thus, within a study, N = 36 participants using a prototype of a polypdetection system have been observed with an eye-tracker-system, to capture and evaluate the relative time of attention with respect to the original and augmented video data and differentiate these values between various sub-groups based on experience, education and gender. T-tests were conducted to identify potential significant differences. Based on the obtained data, the augmented video data is used with a very high attention (up to 75%) depending on the regarded sub-group. Experienced as well as less-experienced users (with > 500 colonoscopies) both preferred looking at the original data. In contrast, gastroenterologists (in contrast to nurses, students, engineers) were more interested in the outcome of the novel AIsystem. The female group preferred looking at the unobstructed data, while the male group was highly interested in the AI-based data.  © 2021 by Walter de Gruyter Berlin/Boston.",Adenoma Detection; Artificial intelligence; Evaluation; Eye Tracking,Endoscopy; Tumors; Video recording; Adenoma detection; Automotives; Clinical investigation; Colonoscopy; Computer assisted; Evaluation; Eye-tracking; Polyp detection; Sub-groups; Video data; Eye tracking,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85114445000,Movies / Media
Williamson J.R.; Sturim D.; Vian T.; Lacirignola J.; Shenk T.E.; Yuditskaya S.; Rao H.M.; Talavage T.M.; Heaton K.J.; Quatieri T.F.,"Williamson, James R. (37076300900); Sturim, Doug (6507535735); Vian, Trina (56315524200); Lacirignola, Joseph (6504171095); Shenk, Trey E. (56337711600); Yuditskaya, Sophia (57192893749); Rao, Hrishikesh M. (57061830400); Talavage, Thomas M. (6701846437); Heaton, Kristin J. (7103392992); Quatieri, Thomas F. (7005856167)",37076300900; 6507535735; 56315524200; 6504171095; 56337711600; 57192893749; 57061830400; 6701846437; 7103392992; 7005856167,"Using Dynamics of Eye Movements, Speech Articulation and Brain Activity to Predict and Track mTBI Screening Outcomes",2021,Frontiers in Neurology,12,,665338,,,,0,10.3389/fneur.2021.665338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111012121&doi=10.3389%2ffneur.2021.665338&partnerID=40&md5=392a5ae5acd0fd5ceafe5a8138848746,"Repeated subconcussive blows to the head during sports or other contact activities may have a cumulative and long lasting effect on cognitive functioning. Unobtrusive measurement and tracking of cognitive functioning is needed to enable preventative interventions for people at elevated risk of concussive injury. The focus of the present study is to investigate the potential for using passive measurements of fine motor movements (smooth pursuit eye tracking and read speech) and resting state brain activity (measured using fMRI) to complement existing diagnostic tools, such as the Immediate Post-concussion Assessment and Cognitive Testing (ImPACT), that are used for this purpose. Thirty-one high school American football and soccer athletes were tracked through the course of a sports season. Hypotheses were that (1) measures of complexity of fine motor coordination and of resting state brain activity are predictive of cognitive functioning measured by the ImPACT test, and (2) within-subject changes in these measures over the course of a sports season are predictive of changes in ImPACT scores. The first principal component of the six ImPACT composite scores was used as a latent factor that represents cognitive functioning. This latent factor was positively correlated with four of the ImPACT composites: verbal memory, visual memory, visual motor speed and reaction speed. Strong correlations, ranging between r = 0.26 and r = 0.49, were found between this latent factor and complexity features derived from each sensor modality. Based on a regression model, the complexity features were combined across sensor modalities and used to predict the latent factor on out-of-sample subjects. The predictions correlated with the true latent factor with r = 0.71. Within-subject changes over time were predicted with r = 0.34. These results indicate the potential to predict cognitive performance from passive monitoring of fine motor movements and brain activity, offering initial support for future application in detection of performance deficits associated with subconcussive events. © Copyright © 2021 Williamson, Sturim, Vian, Lacirignola, Shenk, Yuditskaya, Rao, Talavage, Heaton and Quatieri.",eye tracking; fine motor coordination; fMRI; neurocognitive testing; resting state brain activity; speech,adult; Article; BOLD signal; cognition; concussion; controlled study; diagnostic test accuracy study; dynamics; electroencephalography; eye movement; eye tracking; female; functional magnetic resonance imaging; human; human experiment; image segmentation; impulse control disorder; machine learning; male; mathematical model; normal human; outcome assessment; post concussion assessment and cognitive testing; principal component analysis; receiver operating characteristic; screening test; signal noise ratio; speech analysis; speech articulation; time series analysis; verbal memory; visual attention; visual memory; working memory,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85111012121,Movies / Media
Skripkauskaite S.; Slade L.; Mayer J.,"Skripkauskaite, Simona (56534282200); Slade, Lance (7004189613); Mayer, Jennifer (56042766700)",56534282200; 7004189613; 56042766700,"Attentional shifting differences in autism: Domain general, domain specific or both?",2021,Autism,25,6,,1721,1733,12.0,5,10.1177/13623613211001619,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102789525&doi=10.1177%2f13623613211001619&partnerID=40&md5=ea85a0cfac2e7135cf556965efdb6386,"Atypical attention is considered to have an important role in the development of autism. Yet, it remains unclear whether these attentional difficulties are specific to the social domain. This study aimed to examine attentional orienting in autistic and non-autistic adults from and to non-social and social stimuli. We utilised a modified gap–overlap task with schematic images (Experiment 1: autistic = 27 and non-autistic = 26) and photographs (Experiment 2: autistic = 18 and non-autistic = 17). Eye-tracking data (i.e. saccadic latencies) were then compared across condition and type of stimulus (social or non-social) using multilevel modelling. Autistic adults exhibited mostly typical gap and overlap effects, as well as a bias towards social stimuli. Yet, autistic participants benefitted from exogenous disengagement when orienting to social information more than non-autistic participants. Neither a domain general nor social domain–specific account for attentional atypicalities in autism was supported separately. Yet, subtle combined domain differences were revealed in the gap condition. Lay abstract: Previous research has shown that autistic individuals look at other people less and orient to them more slowly than others. Yet, it is still unclear if this represents general visual differences (e.g. slower looking at any new information, social or not) or a uniquely social difference (e.g. only slower looking to humans but not objects). Here, we aimed to examine how quickly autistic and non-autistic adults look to and away from social (i.e. faces) and non-social information (i.e. squares and houses). We used an attentional shifting task with two images where sometimes the first image disappears before the new image appears (makes it easier to notice the new image) and other times it stays on the screen when the new image appears. In Experiment 1, we showed schematic faces and squares to 27 autistic and 26 non-autistic adults, and in Experiment 2, we showed photographs of faces and houses to 18 autistic and 17 non-autistic adults. In general, autistic adults looked at the new non-social or social images similarly to non-autistic adults. Yet, only autistic adults looked at new social information faster when the first image disappeared before the new image appeared. This shows that autistic individuals may find it easier to notice new social information if their attention is not already occupied. © The Author(s) 2021.",adults; autism; eye tracking; gap–overlap; saccadic latencies,Adult; Attention; Autism Spectrum Disorder; Autistic Disorder; Humans; adult; alexithymia; anxiety; Article; autism; clinical article; executive function; eye position; eye tracking; female; human; male; multilevel analysis; photography; quality of life; visual attention; attention,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85102789525,Movies / Media
Bovery M.; Dawson G.; Hashemi J.; Sapiro G.,"Bovery, Matthieu (57205304663); Dawson, Geraldine (7201539036); Hashemi, Jordan (55569154100); Sapiro, Guillermo (7005450011)",57205304663; 7201539036; 55569154100; 7005450011,A Scalable Off-the-Shelf Framework for Measuring Patterns of Attention in Young Children and Its Application in Autism Spectrum Disorder,2021,IEEE Transactions on Affective Computing,12,3,8598852,722,731,9.0,24,10.1109/TAFFC.2018.2890610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059480502&doi=10.1109%2fTAFFC.2018.2890610&partnerID=40&md5=15ade36bb825be906dad980825302869,"Autism spectrum disorder (ASD) is associated with deficits in the processing of social information and difficulties in social interaction, and individuals with ASD exhibit atypical attention and gaze. Traditionally, gaze studies have relied upon precise and constrained means of monitoring attention using expensive equipment in laboratories. In this work we develop a low-cost off-the-shelf alternative for measuring attention that can be used in natural settings. The head and iris positions of 104 16-31 months children, an age range appropriate for ASD screening and diagnosis, 22 of them diagnosed with ASD, were recorded using the front facing camera in an iPad while they watched on the device screen a movie displaying dynamic stimuli, social stimuli on the left and non-social stimuli on the right. The head and iris position were then automatically analyzed via computer vision algorithms to detect the direction of attention. We validate the proposed framework and computational tool showing that children in the ASD group paid less attention to the movie, showed less attention to the social as compared to the non-social stimuli, and often fixated their attention to one side of the screen. These results are expected from the ASD literature, here obtained with significantly simpler and less expensive attention tracking methods. The proposed method provides a low-cost means of monitoring attention to properly designed stimuli, demonstrating that the integration of stimuli design and automatic response analysis results in the opportunity to use off-the-shelf cameras to assess behavioral biomarkers.  © 2010-2012 IEEE.",attention; Autism spectrum disorder; computer vision; gaze-tracking; off-the-shelf cameras; stimuli design,Cameras; Cost benefit analysis; Costs; Diseases; Eye tracking; Monitoring; Motion pictures; Motion tracking; Pediatrics; Attention; Autism; Autism spectrum disorders; Gaze tracking; Tablet computer; Computer vision,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85059480502,Movies / Media
Kaliukhovich D.A.; Manyakov N.V.; Bangerter A.; Ness S.; Skalkin A.; Boice M.; Goodwin M.S.; Dawson G.; Hendren R.; Leventhal B.; Shic F.; Pandina G.,"Kaliukhovich, Dzmitry A. (35366457700); Manyakov, Nikolay V. (57193650166); Bangerter, Abigail (57193645588); Ness, Seth (7005910335); Skalkin, Andrew (57193651007); Boice, Matthew (57195928398); Goodwin, Matthew S. (7201733663); Dawson, Geraldine (59028708100); Hendren, Robert (57206412309); Leventhal, Bennett (57194074253); Shic, Frederick (6507802882); Pandina, Gahan (6507386347)",35366457700; 57193650166; 57193645588; 7005910335; 57193651007; 57195928398; 7201733663; 59028708100; 57206412309; 57194074253; 6507802882; 6507386347,Visual Preference for Biological Motion in Children and Adults with Autism Spectrum Disorder: An Eye-Tracking Study,2021,Journal of Autism and Developmental Disorders,51,7,,2369,2380,11.0,12,10.1007/s10803-020-04707-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091168803&doi=10.1007%2fs10803-020-04707-w&partnerID=40&md5=77d1e28c75c666defa91a8e0504e49a8,"Participants with autism spectrum disorder (ASD) (n = 121, mean [SD] age: 14.6 [8.0] years) and typically developing (TD) controls (n = 40, 16.4 [13.3] years) were presented with a series of videos representing biological motion on one side of a computer monitor screen and non-biological motion on the other, while their eye movements were recorded. As predicted, participants with ASD spent less overall time looking at presented stimuli than TD participants (P < 10–3) and showed less preference for biological motion (P < 10–5). Participants with ASD also had greater average latencies than TD participants of the first fixation on both biological (P < 0.01) and non-biological motion (P < 0.02). Findings suggest that individuals with ASD differ from TD individuals on multiple properties of eye movements and biological motion preference. © 2020, The Author(s).",Autism spectrum disorder; Biological motion; Biomarkers; Eye-tracking,"Adolescent; Adult; Attention; Autism Spectrum Disorder; Child; Eye Movements; Eye-Tracking Technology; Female; Fixation, Ocular; Humans; Male; Middle Aged; Motion Perception; Photic Stimulation; Prospective Studies; Task Performance and Analysis; Videotape Recording; Young Adult; adolescent; adult; Article; autism; behavior assessment; child; clinical assessment; clinical examination; controlled study; eye dominance; eye movement; eye tracking; female; head movement; human; latent period; major clinical study; male; middle aged; motion; symptom; videorecording; attention; autism; eye fixation; eye movement; movement perception; pathophysiology; photostimulation; physiology; prospective study; psychology; randomized controlled trial; task performance; young adult",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85091168803,Movies / Media
Castellotti S.; Francisci C.; Del Viva M.M.,"Castellotti, Serena (57205731708); Francisci, Carlo (57225035352); Del Viva, Maria Michela (8750278400)",57205731708; 57225035352; 8750278400,"Pupillary response to real, illusory, and implied motion",2021,PLoS ONE,16,7-Jul,e0254105,,,,12,10.1371/journal.pone.0254105,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109051301&doi=10.1371%2fjournal.pone.0254105&partnerID=40&md5=ad9bfcc1685e9f38aa0e6d71f6a04765,"The perception of moving objects (real motion) is a critical function for interacting with a dynamic environment. Motion perception can be also induced by particular structural features of static images (illusory motion) or by photographic images of subjects in motion (implied motion, IM). Many cortical areas are involved in motion processing, particularly the medial temporal cortical area (MT), dedicated to the processing of real, illusory, and implied motion. Recently, there has been a growing interest in the influence of high-level visual processes on pupillary responses. However, just a few studies have measured the effect of motion processing on the pupil, and not always with consistent results. Here we systematically investigate the effects of real, illusory, and implied motion on the pupil diameter for the first time, by showing different types of stimuli (movies, illusions, and photos) with the same average luminance to the same observers. We find different pupillary responses depending on the nature of motion. Real motion elicits a larger pupillary dilation than IM, which in turn induces more dilation than control photos representing static subjects (No-IM). The pupil response is sensitive even to the strength of IM, as photos with enhanced IM (blur, motion streaks, speed lines) induce larger dilation than simple freezed IM (subjects captured in the instant they are moving). Also, the subject represented in the stimulus matters: human figures are interpreted as more dynamic and induce larger dilation than objects/animals. Interestingly, illusory motion induces much less dilation than all the other motion categories, despite being seen as moving. Overall, pupil responses depend on the individual perception of dynamicity, confirming that the pupil is modulated by the subjective interpretation of complex stimuli. We argue that the different pupillary responses to real, illusory, and implied motion reflect the top-down modulations of different cortical areas involved in their processing. Copyright: © 2021 Castellotti et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Adult; Attention; Cognition; Eye Movements; Female; Humans; Illusions; Male; Motion Perception; Ocular Physiological Phenomena; Photic Stimulation; Pupil; Temporal Lobe; Vision, Ocular; Young Adult; Article; artifact; brain cortex; clinical article; cognition; controlled study; emotion; human; illusion; image analysis; luminance; mydriasis; perception; photoreceptor; pupil diameter; pupillometry; retina blood vessel; scanning laser ophthalmoscopy; sequence alignment; skin conductance; surgical training; task performance; thyroid nodule; vision; visual acuity; visual stimulation; adult; attention; diagnostic imaging; eye movement; female; male; movement perception; photostimulation; physiology; pupil; temporal lobe; visual system function; young adult",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85109051301,Movies / Media
Finn E.S.; Bandettini P.A.,"Finn, Emily S. (55761258200); Bandettini, Peter A. (7004212644)",55761258200; 7004212644,Movie-watching outperforms rest for functional connectivity-based prediction of behavior,2021,NeuroImage,235,,117963,,,,146,10.1016/j.neuroimage.2021.117963,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104307584&doi=10.1016%2fj.neuroimage.2021.117963&partnerID=40&md5=e5f04b91554171014625458c949e9ef7,"A major goal of human neuroscience is to relate differences in brain function to differences in behavior across people. Recent work has established that whole-brain functional connectivity patterns are relatively stable within individuals and unique across individuals, and that features of these patterns predict various traits. However, while functional connectivity is most often measured at rest, certain tasks may enhance individual signals and improve sensitivity to behavior differences. Here, we show that compared to the resting state, functional connectivity measured during naturalistic viewing—i.e., movie watching—yields more accurate predictions of trait-like phenotypes in the domains of both cognition and emotion. Traits could be predicted using less than three minutes of data from single video clips, and clips with highly social content gave the most accurate predictions. Results suggest that naturalistic stimuli amplify individual differences in behaviorally relevant brain networks. © 2021",,Adult; Auditory Perception; Cognitive Aging; Connectome; Emotions; Eye-Tracking Technology; Female; Humans; Individuality; Magnetic Resonance Imaging; Male; Motion Pictures; Nerve Net; Personality; Social Perception; Visual Perception; Young Adult; adult; Article; behavior assessment; brain function; brain region; cognition assessment; connectome; emotion; eye tracking; female; functional connectivity; functional magnetic resonance imaging; human; human experiment; image analysis; image processing; male; nerve cell network; normal human; prediction; recreation; resting state network; young adult; cognitive aging; connectome; diagnostic imaging; hearing; individuality; movie; nuclear magnetic resonance imaging; perception; personality; physiology; vision,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85104307584,Movies / Media
Sekiyama K.; Hisanaga S.; Mugitani R.,"Sekiyama, Kaoru (7005646701); Hisanaga, Satoko (56358459000); Mugitani, Ryoko (14018309100)",7005646701; 56358459000; 14018309100,Selective attention to the mouth of a talker in Japanese-learning infants and toddlers: Its relationship with vocabulary and compensation for noise,2021,Cortex,140,,,145,156,11.0,16,10.1016/j.cortex.2021.03.023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105569098&doi=10.1016%2fj.cortex.2021.03.023&partnerID=40&md5=09dbe31264d5b4f7336b9729d605b6a4,"Infants increasingly gaze at the mouth of talking faces during the latter half of the first postnatal year. This study investigated mouth-looking behavior of 120 full-term infants and toddlers (6 months–3 years) and 12 young adults (21–24 years) from Japanese monolingual families. The purpose of the study included: (1) Is such an attentional shift to the mouth in infancy similarly observed in Japanese environment where contribution of visual speech is known to be relatively weak? (2) Can noisy conditions increase mouth-looking behavior of Japanese young children? (3) Is the mouth-looking behavior related to language acquisition? To this end, movies of a talker speaking short phrases were presented while manipulating signal-to-noise ratio (SNR: Clear, SN+4, and SN-4). Expressive vocabulary of toddlers was obtained through their parents. The results indicated that Japanese infants initially have a strong preference for the eyes to mouth which is weakened toward 10 months, but the shift was later and in a milder fashion compared to known results for English-learning infants. Even after 10 months, no clear-cut preference for the mouth was observed even in linguistically challenging situations with strong noise until 3 years of age. In the Clear condition, there was a return of the gaze to the eyes as early as 3 years of age, where they showed increasing attention to the mouth with increasing noise level. In addition, multiple regression analyses revealed a tendency that 2- and 3-year-olds with larger vocabulary increasingly look at the eyes. Overall, the gaze of Japanese-learning infants and toddlers was more biased to the eyes in various aspects compared to known results of English-learning infants. The present findings shed new light on our understanding of the development of selective attention to the mouth in non-western populations. © 2021 Elsevier Ltd",Audiovisual speech comprehension; Eye tracking; Infant; Japanese; Toddler,"Child, Preschool; Face; Humans; Infant; Japan; Language Development; Mouth; Vocabulary; adult; Article; child; clinical article; English (language); eye position; eye tracking; facial expression; female; human; human experiment; infant; Japanese (people); language; language ability; male; mouth; noise; pitch; selective attention; signal noise ratio; speech; speech discrimination; toddler; vocabulary; face; Japan; language development; preschool child",Article,Final,,Scopus,2-s2.0-85105569098,Movies / Media
Levin D.T.; Salas J.A.; Wright A.M.; Seiffert A.E.; Carter K.E.; Little J.W.,"Levin, Daniel T. (7202969153); Salas, Jorge A. (57219433500); Wright, Anna M. (57224904540); Seiffert, Adrianne E. (6701667324); Carter, Kelly E. (57211023305); Little, Joshua W. (57222261549)",7202969153; 57219433500; 57224904540; 6701667324; 57211023305; 57222261549,The Incomplete Tyranny of Dynamic Stimuli: Gaze Similarity Predicts Response Similarity in Screen-Captured Instructional Videos,2021,Cognitive Science,45,6,e12984,,,,5,10.1111/cogs.12984,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108507706&doi=10.1111%2fcogs.12984&partnerID=40&md5=3527555829708911fca50ed0ed911338,"Although eye tracking has been used extensively to assess cognitions for static stimuli, recent research suggests that the link between gaze and cognition may be more tenuous for dynamic stimuli such as videos. Part of the difficulty in convincingly linking gaze with cognition is that in dynamic stimuli, gaze position is strongly influenced by exogenous cues such as object motion. However, tests of the gaze-cognition link in dynamic stimuli have been done on only a limited range of stimuli often characterized by highly organized motion. Also, analyses of cognitive contrasts between participants have been mostly been limited to categorical contrasts among small numbers of participants that may have limited the power to observe more subtle influences. We, therefore, tested for cognitive influences on gaze for screen-captured instructional videos, the contents of which participants were tested on. Between-participant scanpath similarity predicted between-participant similarity in responses on test questions, but with imperfect consistency across videos. We also observed that basic gaze parameters and measures of attention to centers of interest only inconsistently predicted learning, and that correlations between gaze and centers of interest defined by other-participant gaze and cursor movement did not predict learning. It, therefore, appears that the search for eye movement indices of cognition during dynamic naturalistic stimuli may be fruitful, but we also agree that the tyranny of dynamic stimuli is real, and that links between eye movements and cognition are highly dependent on task and stimulus properties. © 2021 Cognitive Science Society LLC",Attention; Eye movements; Learning; Media,"Cues; Eye Movements; Eye-Tracking Technology; Fixation, Ocular; Humans; Learning; association; eye fixation; eye movement; human; learning",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85108507706,Movies / Media
Patel G.H.; Arkin S.C.; Ruiz-Betancourt D.R.; Plaza F.I.; Mirza S.A.; Vieira D.J.; Strauss N.E.; Klim C.C.; Sanchez-Peña J.P.; Bartel L.P.; Grinband J.; Martinez A.; Berman R.A.; Ochsner K.N.; Leopold D.A.; Javitt D.C.,"Patel, Gaurav H. (12780150100); Arkin, Sophie C (57218294710); Ruiz-Betancourt, Daniel R (57218297535); Plaza, Fabiola I (57219810221); Mirza, Safia A (57219811503); Vieira, Daniel J (57219823625); Strauss, Nicole E (57218290910); Klim, Casimir C (56667598600); Sanchez-Peña, Juan P (57090403000); Bartel, Laura P (57219814424); Grinband, Jack (12647205500); Martinez, Antigona (57193212983); Berman, Rebecca A (7102017303); Ochsner, Kevin N (6603738607); Leopold, David A (7102017697); Javitt, Daniel C (7007040980)",12780150100; 57218294710; 57218297535; 57219810221; 57219811503; 57219823625; 57218290910; 56667598600; 57090403000; 57219814424; 12647205500; 57193212983; 7102017303; 6603738607; 7102017697; 7007040980,Failure to engage the temporoparietal junction/posterior superior temporal sulcus predicts impaired naturalistic social cognition in schizophrenia,2021,Brain,144,6,,1898,1910,12.0,18,10.1093/brain/awab081,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112863158&doi=10.1093%2fbrain%2fawab081&partnerID=40&md5=f9b28374aef10f8b1b561f6c22650f7f,"Schizophrenia is associated with marked impairments in social cognition. However, the neural correlates of these deficits remain unclear. Here we use naturalistic stimuli to examine the role of the right temporoparietal junction/posterior superior temporal sulcus (TPJ-pSTS) - an integrative hub for the cortical networks pertinent to the understanding complex social situations - in social inference, a key component of social cognition, in schizophrenia. Twenty-seven schizophrenia participants and 21 healthy control subjects watched a clip of the film The Good, the Bad and the Ugly while high resolution multiband functional MRI images were collected. We used inter-subject correlation to measure the evoked activity, which we then compared to social cognition as measured by The Awareness of Social Inference Test (TASIT). We also compared between groups the TPJ-pSTS blood oxygen level-dependent activity (i) relationship with the motion content in the film; (ii) synchronization with other cortical areas involved in the viewing of the movie; and (iii) relationship with the frequency of saccades made during the movie. Activation deficits were greatest in middle TPJ (TPJm) and correlated significantly with impaired TASIT performance across groups. Follow-up analyses of the TPJ-pSTS revealed decreased synchronization with other cortical areas, decreased correlation with the motion content of the movie, and decreased correlation with the saccades made during the movie. The functional impairment of the TPJm, a hub area in the middle of the TPJ-pSTS, predicts deficits in social inference in schizophrenia participants by disrupting the integration of visual motion processing into the TPJ. This disrupted integration then affects the use of the TPJ to guide saccades during the visual scanning of the movie clip. These findings suggest that the TPJ may be a treatment target for improving deficits in a key component of social cognition in schizophrenia participants. © 2021 The Author(s) (2021). Published by Oxford University Press on behalf of the Guarantors of Brain. All rights reserved.",attention; biological motion; functional MRI; hubs; visual scanning,Adult; Female; Humans; Magnetic Resonance Imaging; Male; Parietal Lobe; Schizophrenia; Social Cognition; Temporal Lobe; chlorpromazine; adult; Article; BOLD signal; clinical article; cognition assessment; computer vision; controlled study; evoked response; eye tracking; facial expression; female; follow up; functional disease; functional magnetic resonance imaging; human; image processing; male; medial prefrontal cortex; oxygen blood level; Positive and Negative Syndrome Scale; saccadic eye movement; schizophrenia; social cognition; superior temporal sulcus; temporoparietal junction; The Awareness of Social Inference Test; theory of mind; visual cortex; nuclear magnetic resonance imaging; parietal lobe; pathophysiology; schizophrenia; temporal lobe,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85112863158,Movies / Media
Van De Luecht M.-R.; Reed W.M.,"Van De Luecht, Monica-Rose (57221918979); Reed, Warren Michael (35192336200)",57221918979; 35192336200,The cognitive and perceptual processes that affect observer performance in lung cancer detection: a scoping review,2021,Journal of Medical Radiation Sciences,68,2,,175,185,10.0,5,10.1002/jmrs.456,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100522616&doi=10.1002%2fjmrs.456&partnerID=40&md5=ca9c540ef494aa7890b9bade0f404b7c,"Introduction: Early detection of malignant pulmonary nodules through screening has been shown to reduce lung cancer-related mortality by 20%. However, perceptual and cognitive factors that affect nodule detection are poorly understood. This review examines the cognitive and visual processes of various observers, with a particular focus on radiologists, during lung nodule detection. Methods: Four databases (Medline, Embase, Scopus and PubMed) were searched to extract studies on eye-tracking in pulmonary nodule detection. Studies were included if they used eye-tracking to assess the search and detection of lung nodules in computed tomography or 2D radiographic imaging. Data were charted according to identified themes and synthesised using a thematic narrative approach. Results: The literature search yielded 25 articles and five themes were discovered: 1 – functional visual field and satisfaction of search, 2 – expert search patterns, 3 – error classification through dwell time, 4 – the impact of the viewing environment and 5 – the effect of prevalence expectation on search. Functional visual field reduced to 2.7° in 3D imaging compared to 5° in 2D radiographs. Although greater visual coverage improved nodule detection, incomplete search was not responsible for missed nodules. Most radiological errors during lung nodule detection were decision-making errors (30%–45%). Dwell times associated with false-positive (FP) decisions informed feedback systems to improve diagnosis. Interruptions did not influence diagnostic performance; however, it increased viewing time by 8% and produced a 23.1% search continuation accuracy. Comparative scanning was found to increase the detection of low contrast nodules. Prevalence expectation did not directly affect diagnostic accuracy; however, decision-making time increased by 2.32 seconds with high prevalence expectations. Conclusion: Visual and cognitive factors influence pulmonary nodule detection. Insights gained from eye-tracking can inform advancements in lung screening. Further exploration of eye-tracking in lung screening, particularly with low-dose computed tomography (LDCT), will benefit the future of lung cancer screening. © 2020 The Authors. Journal of Medical Radiation Sciences published by John Wiley & Sons Australia, Ltd on behalf of Australian Society of Medical Imaging and Radiation Therapy and New Zealand Institute of Medical Radiation Technology",Cancer screening; eye-tracking; lung neoplasms; radiologic detection; visual perception,Cognition; Early Detection of Cancer; Humans; Lung; Lung Neoplasms; Solitary Pulmonary Nodule; bacterium identification; cancer diagnosis; cancer screening; chronic obstructive lung disease; cognition; computer assisted tomography; decision making; diagnostic value; dwell time; expectation; eye tracking; feedback system; human; image quality; lung cancer; lung nodule; mortality; non small cell lung cancer; observer performance; parasitemia; perception; prevalence; Review; sensitivity and specificity; three-dimensional imaging; visual field; cognition; diagnostic imaging; early cancer diagnosis; lung; lung nodule; lung tumor,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85100522616,Movies / Media
Abeles D.; Yuval-Greenberg S.,"Abeles, Dekel (57193995090); Yuval-Greenberg, Shlomit (15840895100)",57193995090; 15840895100,Active sensing and overt avoidance: Gaze shifts as a mechanism of predictive avoidance in vision,2021,Cognition,211,,104648,,,,1,10.1016/j.cognition.2021.104648,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102305057&doi=10.1016%2fj.cognition.2021.104648&partnerID=40&md5=c0075816fae7dd1dcf151afb81af474c,"Sensory organs are not only involved in passively transmitting sensory input, but are also involved in actively seeking it. Some sensory organs move dynamically to allow highly prioritized input to be detected by their most sensitive parts. Such ‘active sensing’ systems engage in pursuing relevant input, relying on attentional prioritizations. However, pursuing input may not always be advantageous. Task-irrelevant input may be distracting and interfere with task performance. We hypothesize that an efficient ‘active sensing’ mechanism should be able to not only pursue relevant input but also to predict irrelevant input and avoid it. Moreover, we hypothesize that this mechanism should be evident even when the task is non-visual and all visual information acts as a distractor. In this study, we demonstrate the existence of a predictive ‘overt avoidance’ mechanism in vision. In two experiments, participants were asked to perform a continuous mental-arithmetic task while occasionally being presented with task-irrelevant crowded displays limited to one quadrant of a screen. The locations of these visual stimuli were constant within a block but varied between blocks. Results show that gaze was consistently shifted away from the predicted location of distraction, even prior to its appearance, confirming the existence of a predictive ‘overt avoidance’ mechanism in vision. Based on these findings, we propose a conceptual model to explain how an ‘active sensing’ system, hardwired to explore, can overcome this drive when presented with distracting information. According to the model, distraction is handled through a dual mechanism of suppression and avoidance processes that are causally linked. This framework demonstrates how perception and motion work together to approach relevant information while avoiding irrelevant distraction. © 2021 Elsevier B.V.",Active sensing; Distraction avoidance; Eye movements; Gaze aversion; Overt avoidance,Attention; Humans; Task Performance and Analysis; Visual Perception; adult; article; aversion; avoidance behavior; conceptual model; eye movement; female; gaze; human; human experiment; male; mental arithmetic; task performance; vision; visual information; attention,Article,Final,,Scopus,2-s2.0-85102305057,Movies / Media
Hochhauser M.; Aran A.; Grynszpan O.,"Hochhauser, Michal (35362153200); Aran, Adi (57209543134); Grynszpan, Ouriel (22034481500)",35362153200; 57209543134; 22034481500,Investigating attention in young adults with autism spectrum disorder (ASD) using change blindness and eye tracking,2021,Research in Autism Spectrum Disorders,84,,101771,,,,8,10.1016/j.rasd.2021.101771,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103709899&doi=10.1016%2fj.rasd.2021.101771&partnerID=40&md5=8fd9f0d117abb47b0bd100f90f667a1b,"Background: Social interaction at its core entails allocating attention to relevant stimuli. As such, the perception of change requires attention, but studies have suggested that the social impairment in people with autism spectrum disorder (ASD) occurs at the attentual level of “on-line” social cognition. Method: Forty-four young adults—22 with autism spectrum disorder (ASD) and 22 with typical development (TD)—participated in two experiments. The first used a change blindness (CB) paradigm where attention was investigated through the detection of changed items with central and marginal levels of interest when viewing images of everyday scenarios. Eye-tracking was used to compare response times, first fixations and total fixation time on changes. The second used social films with eye tracking of gaze fixations. Results: Participants with ASD were slower in response time and first fixation than were participants with TD. Participants with TD showed longer fixation on items with marginal (compared to central) levels of interest. The social-film experiment showed that participants with ASD were slower to orient their gazes towards the characters’ faces and looked at speaking characters for less time than did the group with TD. This result correlates with less use of mental verbs in their narratives and less time spent looking at marginal items in the CB experiment. Conclusions: Results suggest reduced processing speed in young adults with ASD, which is associated with enhanced processing of local details. Clinically, these results imply that teaching strategies (e.g., cognitive cues) to process social context efficiently could benefit individuals with ASD. © 2021 Elsevier Ltd",Autism spectrum disorder; Change blindness; Eye tracking; Social interaction; Young adults,adult; Article; autism; change blindness; clinical article; controlled study; eye tracking; female; gaze; human; male; priority journal; processing speed; reaction time; social conflict; social environment; social interaction; videorecording; vignette; visual attention; young adult,Article,Final,,Scopus,2-s2.0-85103709899,Movies / Media
Murty D.V.P.S.; Manikandan K.; Kumar W.S.; Ramesh R.G.; Purokayastha S.; Nagendra B.; Abhishek M.L.; Balakrishnan A.; Javali M.; Rao N.P.; Ray S.,"Murty, Dinavahi VPS (57201200479); Manikandan, Keerthana (57216372282); Kumar, Wupadrasta Santosh (57216365866); Ramesh, Ranjini Garani (57216362825); Purokayastha, Simran (57200031119); Nagendra, Bhargavi (57205588968); Abhishek, M.L. (57221612715); Balakrishnan, Aditi (57221597017); Javali, Mahendra (57212029965); Rao, Naren Prahalada (16432624700); Ray, Supratim (57199001938)",57201200479; 57216372282; 57216365866; 57216362825; 57200031119; 57205588968; 57221612715; 57221597017; 57212029965; 16432624700; 57199001938,Stimulus-induced gamma rhythms are weaker in human elderly with mild cognitive impairment and alzheimer’s disease,2021,eLife,10,,e61666,,,,38,10.7554/eLife.61666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108875150&doi=10.7554%2feLife.61666&partnerID=40&md5=d60a00abcac348144ec3347b92a014d7,"Alzheimer’s disease (AD) in elderly adds substantially to socioeconomic burden necessitating early diagnosis. While recent studies in rodent models of AD have suggested diagnostic and therapeutic value for gamma rhythms in brain, the same has not been rigorously tested in humans. In this case-control study, we recruited a large population (N = 244; 106 females) of elderly (>49 years) subjects from the community, who viewed large gratings that induced strong gamma oscillations in their electroencephalogram (EEG). These subjects were classified as healthy (N = 227), mild cognitively impaired (MCI; N = 12), or AD (N = 5) based on clinical history and Clinical Dementia Rating scores. Surprisingly, stimulus-induced gamma rhythms, but not alpha or steady-state visually evoked responses, were significantly lower in MCI/AD subjects compared to their age-and gender-matched controls. This reduction was not due to differences in eye movements or baseline power. Our results suggest that gamma could be used as a potential screening tool for MCI/AD in humans. ©Murty et al.",,"Aged; Aged, 80 and over; Alzheimer Disease; Case-Control Studies; Cognitive Dysfunction; Evoked Potentials, Visual; Female; Gamma Rhythm; Humans; Male; Middle Aged; action potential; adult; aged; Alzheimer disease; Article; auditory stimulation; Clinical Dementia Rating; cognition; cohort analysis; controlled study; cortical thickness (brain); depression; early diagnosis; electroencephalogram; electroencephalography; encapsulation; eye movement; eye position; female; gamma rhythm; Hamilton Depression Rating Scale; human; longitudinal study; major clinical study; male; mentally disabled person; mild cognitive impairment; Mini Mental State Examination; steady state; task performance; very elderly; visual evoked potential; visual field; visual stimulation; Alzheimer disease; case control study; cognitive defect; gamma rhythm; middle aged; pathophysiology; physiology",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85108875150,Movies / Media
E. Bixler R.; K. D'Mello S.,"E. Bixler, Robert (57224465846); K. D'Mello, Sidney (14053463100)",57224465846; 14053463100,Crossed Eyes: Domain Adaptation for Gaze-Based Mind Wandering Models,2021,Eye Tracking Research and Applications Symposium (ETRA),PartF169256,,,,,,16,10.1145/3448017.3457386,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107639188&doi=10.1145%2f3448017.3457386&partnerID=40&md5=0d73baaacc7f138cdaa2bec044187030,"The effectiveness of user interfaces are limited by the tendency for the human mind to wander. Intelligent user interfaces can combat this by detecting when mind wandering occurs and attempting to regain user attention through a variety of intervention strategies. However, collecting data to build mind wandering detection models can be expensive, especially considering the variety of media available and potential differences in mind wandering across them. We explored the possibility of using eye gaze to build cross-domain models of mind wandering where models trained on data from users in one domain are used for different users in another domain. We built supervised classification models using a dataset of 132 users whose mind wandering reports were collected in response to thought-probes while they completed tasks from seven different domains for six minutes each (five domains are investigated here: Illustrated Text, Narrative Film, Video Lecture, Naturalistic Scene, and Reading Text). We used global eye gaze features to build within- and cross- domain models using 5-fold user-independent cross validation. The best performing within-domain models yielded AUROCs ranging from .57 to .72, which were comparable for the cross-domain models (AUROCs of .56 to .68). Models built from coarse-grained locality features capturing the spatial distribution of gaze resulted in slightly better transfer on average (transfer ratios of .61 vs .54 for global models) due to improved performance in certain domains. Instance-based and feature-level domain adaptation did not result in any improvements in transfer. We found that seven gaze features likely contributed to transfer as they were among the top ten features for at least four domains. Our results indicate that gaze features are suitable for domain adaptation from similar domains, but more research is needed to improve domain adaptation between more dissimilar domains.  © 2021 ACM.",Domain Adaptation; Eye Movements; Mind Wandering; User Modeling,Classification (of information); Text processing; User interfaces; Cross-domain models; Domain adaptation; Intelligent User Interfaces; Intervention strategy; Locality features; Potential difference; Supervised classification; User independents; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85107639188,Movies / Media
Melendrez-Ruiz J.; Goisbault I.; Charrier J.-C.; Pagnat K.; Dujourdy L.; Arvisenet G.; Chambaron S.,"Melendrez-Ruiz, Juliana (57209303637); Goisbault, Isabelle (57388874400); Charrier, Jean-Christophe (57388793700); Pagnat, Kevin (57388556400); Dujourdy, Laurence (7801514294); Arvisenet, Gaëlle (6506002466); Chambaron, Stéphanie (6506726216)",57209303637; 57388874400; 57388793700; 57388556400; 7801514294; 6506002466; 6506726216,An Exploratory Study Combining Eye-Tracking and Virtual Reality: Are Pulses Good “Eye-Catchers” in Virtual Supermarket Shelves?,2021,Frontiers in Virtual Reality,2,,655273,,,,11,10.3389/frvir.2021.655273,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138022221&doi=10.3389%2ffrvir.2021.655273&partnerID=40&md5=620f8498a6e5b3ff76f7f45d919b3b68,"Despite numerous health and environmental benefits, the consumption of pulses (i.e. lentils, chickpeas …) in France has decreased over the past few decades. One potential barrier to pulse consumption may be their shelf placement in French supermarkets. We studied gaze behavior toward pulses in a virtual supermarket. Products from four food categories (animal-based, pulses, starches, and vegetables) were randomly presented on four shelves (canned, dried, ready-to-eat, and refrigerated). Then, a composite super-shelf combined the canned, dried, and refrigerated shelves. Gaze behavior was recorded for the 108 participants in two screening phases: i) the four shelves one-by-one, ii) the super-shelf. Pulses were not strong “eye-catchers”: gaze behavior toward pulses varied from shelf to shelf. Similarly, visual attention was different for each food-group during super-shelf screening. These results could be used to implement specific strategies that should be developed in supermarkets to encourage the choice of pulses by consumers, and thus increase pulse consumption. Copyright © 2021 Melendrez-Ruiz, Goisbault, Charrier, Pagnat, Dujourdy, Arvisenet and Chambaron.",consumer; gaze behavior; immersive environment; implicit method; plant-based food,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85138022221,Movies / Media
Xu S.; Yan J.; Hu M.,"Xu, Shuning (57219228625); Yan, Junbing (59095772100); Hu, Menghan (55818700700)",57219228625; 59095772100; 55818700700,A new bio-inspired metric based on eye movement data for classifying ASD and typically developing children,2021,Signal Processing: Image Communication,94,,116171,,,,10,10.1016/j.image.2021.116171,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099248949&doi=10.1016%2fj.image.2021.116171&partnerID=40&md5=ea9a996528234d77821e354f6b9c14d7,"In this paper, we propose a new bio-inspired metric for classifying autism spectrum disorder (ASD) children and typically developed (TD) children. The model used in the Saliency4ASD Grand Challenge at ICME 2019 uses linear regression and prior probability to process distance and time data respectively. Unfortunately, this model performs unsatisfactorily because the visual attention characteristics of ASD and TD children are similar under certain circumstances. Therefore, we screen stimulus materials to select these with significant differences between eye movement distribution of ASD and TD children. We calculate the SSIM value of the ASD and TD data of each picture and conduct the subjective experiments to classify the stimulus materials into two categories: the images with the similar attention map for ASD and TD children; and the images with the dissimilar attention map for ASD and TD children. Owing to the biological property of eye, a viewing angle will be formed when people are observing a picture. Meanwhile, gazing at one point of longer time means more attention. Thus, we pick the point of the longest fixation time for each data group and extract the patch centered on this point. Three point-add strategies are afterward utilized to add points on this patch. Subsequently, a new bio-inspired metric based on graph theory is developed. Experimental results show that the new model outperforms our previous model with a classification accuracy of 72.3%. © 2021 Elsevier B.V.",Autism Spectrum Disorder (ASD); Curve similarity; Saliency model,Behavioral research; Biomimetics; Graph theory; Autism spectrum disorders; Biological properties; Classification accuracy; Eye movement datum; Prior probability; Stimulus materials; Subjective experiments; Visual Attention; Eye movements,Article,Final,,Scopus,2-s2.0-85099248949,Movies / Media
Eagle S.R.; Nindl B.C.; Johnson C.D.; Kontos A.P.; Connaboy C.,"Eagle, Shawn R. (57192279814); Nindl, Bradley C. (7004659155); Johnson, Caleb D. (57195300690); Kontos, Anthony P. (7004528698); Connaboy, Chris (26322353100)",57192279814; 7004659155; 57195300690; 7004528698; 26322353100,Does Concussion Affect Perception-Action Coupling Behavior? Action Boundary Perception as a Biomarker for Concussion,2021,Clinical Journal of Sport Medicine,31,3,,273,280,7.0,20,10.1097/JSM.0000000000000731,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105904386&doi=10.1097%2fJSM.0000000000000731&partnerID=40&md5=7d8b0fb978fd0407a2a57860fc67d4f8,"Background: After a concussion, athletes may be at increased risk of musculoskeletal injuries. Altered perception of action boundaries (ABP), or the limits of one's action capabilities, is one possible mechanism for this increase in injury risk after concussion. Objective: To evaluate differences in symptoms, neurocognitive, vestibular/oculomotor, and action boundary function between subjects with no concussion history (NoHx) and concussion history (ConcHX). Design: Cross-sectional study. Setting: Laboratory at the University of Pittsburgh. Participants: ConcHx (n 5 22; age: 21.8 6 3.0 years, height: 174.0 6 8.3 cm, and mass: 77.8 6 14.8 kg) and NoHx athletes (n 5 24; age: 21.6 6 2.0 years, height: 176.0 6 10.0 cm, and mass: 72.0 6 15.3 kg). Intervention: Immediate Postconcussion Assessment and Cognitive Testing (ImPACT) and Post-Concussion Symptom Scale (PCSS), Vestibular-Ocular Motor Screening (VOMS) tool, and the Perception-Action Coupling Task (PACT). The PACT measures the accuracy of ABP. Main OutcomeMeasures: Neurocognitive domain scores, PCSS, VOMS subdomain symptom gain, ABP accuracy, and actualization. Results: ConcHx reported 2.761.5 previous concussions occurring on average 263.86228.9 days prior. ConcHx was higher on several VOMS items including vertical/horizontal saccades (P 5 0.001; P 5 0.05), vertical/horizontal vestibular-ocular reflex (P,0.001; P50.04), and visual motion sensitivity (P,0.001). Average PACT movement time (P 5 0.01) and reaction time (P 5 0.01) were longer in ConcHx. Conclusions: These findings provide preliminary support for impaired vestibular/oculomotor function and ABP in ConcHx compared with NoHx. The current results may enhance our understanding of the mechanisms for increased musculoskeletal injury risk after concussion.  Copyright © 2019 Wolters Kluwer Health, Inc. All rights reserved.",Action boundary; Concussion; Perception,Adult; Athletic Injuries; Biomarkers; Brain Concussion; Cross-Sectional Studies; Humans; Neuropsychological Tests; Perception; Young Adult; biological marker; adult; Article; attention deficit disorder; binocular convergence; clinical article; concussion; controlled study; cross-sectional study; eye movement control; female; generalized anxiety disorder; human; immediate postconcussion assessment and cognitive testing; major depression; male; migraine; movement time; neurologic disease assessment; Patient Health Questionnaire 9; perception action coupling task; postconcussion syndrome; reaction time; saccadic eye movement; smooth pursuit eye movement; symptom; verbal memory; vestibular ocular motor screening; vestibuloocular reflex; visual memory; visual perception test; brain concussion; neuropsychological test; pathophysiology; perception; sport injury; young adult,Article,Final,,Scopus,2-s2.0-85105904386,Movies / Media
Huber-Huber C.; Steininger J.; Grüner M.; Ansorge U.,"Huber-Huber, Christoph (56507264000); Steininger, Julia (57222050774); Grüner, Markus (57194020328); Ansorge, Ulrich (6603919937)",56507264000; 57222050774; 57194020328; 6603919937,Psychophysical dual-task setups do not measure pre-saccadic attention but saccade-related strengthening of sensory representations,2021,Psychophysiology,58,5,e13787,,,,7,10.1111/psyp.13787,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101077871&doi=10.1111%2fpsyp.13787&partnerID=40&md5=274cc0bfbbcd453b9661e7401fd119d8,"Visual attention and saccadic eye movements are linked in a tight, yet flexible fashion. In humans, this link is typically studied with dual-task setups. Participants are instructed to execute a saccade to some target location, while a discrimination target is flashed on a screen before the saccade can be made. Participants are also instructed to report a specific feature of this discrimination target at the trial end. Discrimination performance is usually better if the discrimination target occurred at the same location as the saccade target compared to when it occurred at a different location, which is explained by the mandatory shift of attention to the saccade target location before saccade onset. This pre-saccadic shift of attention presumably enhances the perception of the discrimination target if it occurred at the same, but not if it occurred at a different location. It is, however, known that a dual-task setup can alter the primary process under investigation. Here, we directly compared pre-saccadic attention in single-task versus dual-task setups using concurrent electroencephalography (EEG) and eye-tracking. Our results corroborate the idea of a pre-saccadic shift of attention. They, however, question that this shift leads to the same-position discrimination advantage. The relation of saccade and discrimination target position affected the EEG signal only after saccade onset. Our results, thus, favor an alternative explanation based on the role of saccades for the consolidation of sensory and short-term memory. We conclude that studies with dual-task setups arrived at a valid conclusion despite not measuring exactly what they intended to measure. © 2021 The Authors. Psychophysiology published by Wiley Periodicals LLC on behalf of Society for Psychophysiological Research.",,Adult; Attention; Electroencephalography; Eye-Tracking Technology; Female; Humans; Male; Psychomotor Performance; Saccades; Visual Perception; Young Adult; adult; attention; electroencephalography; female; human; male; physiology; psychomotor performance; saccadic eye movement; vision; young adult,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85101077871,Movies / Media
Wambecke J.; Goguey A.; Nigay L.; Dargent L.; Hauret D.; Lafon S.; De Visme J.-S.L.,"Wambecke, Jérémy (57206894809); Goguey, Alix (55748694800); Nigay, Laurence (6602572073); Dargent, Lauren (57224318609); Hauret, Daniel (56316918400); Lafon, Stéphanie (57224314268); De Visme, Jean-Samuel Louis (57224306547)",57206894809; 55748694800; 6602572073; 57224318609; 56316918400; 57224314268; 57224306547,M[eye]cro: Eye-gaze+Microgestures for Multitasking and Interruptions,2021,Proceedings of the ACM on Human-Computer Interaction,5,EICS,210,,,,17,10.1145/3461732,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107340608&doi=10.1145%2f3461732&partnerID=40&md5=51325cf63b5c4313e512d3a38f3d74f8,"We present M[eye]cro an interaction technique to select on-screen objects and navigate menus through the synergistic use of eye-gaze and thumb-to-finger microgestures. Thumb-to-finger microgestures are gestures performed with the thumb of a hand onto the fingers of the same hand. The active body of research on microgestures highlights expected properties including speed, availability and eye-free interaction. Such properties make microgestures a good candidate for multitasking. However, while praised, the state-of-the-art hypothesis stating that microgestures could be beneficial for multitasking has never been quantitatively verified. We study and compare M[eye]cro to a baseline, i.e., a technique based on physical controllers, in a cockpit-based context. This context allows us to design a controlled experiment involving multitasking with low- and high-priority tasks in parallel. Our results show that performances of the two techniques are similar when participants only perform the selection task. However, M[eye]cro tends to yield better time performance when participants additionally need to treat high-priority tasks in parallel. Results also show that M[eye]cro induces less fatigue and is mostly preferred.  © 2021 ACM.",gesture; haptic; input techniques; pointing; touch; transportation,Human computer interaction; User interfaces; Controlled experiment; Eye-gaze; Interaction techniques; Physical controllers; Priority tasks; State of the art; Multitasking,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85107340608,Movies / Media
Atli D.; Yazici Ç.,"Atli, Dinçer (57116433500); Yazici, Çiğdem (57226185939)",57116433500; 57226185939,Philosophical perspectives on ethical issues in neuromarketing,2021,Paradigm Shifts within the Communication World,,,,255,273,18.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110814552&partnerID=40&md5=5667764dd014ae0a7e02a52b16c4ac18,"With the increase of multidisciplinary studies, interest in neuroscientific researches has also grown in many areas. At the intersection of neuroscience, consumer behavior, psychology and economics, neuromarketing appears to be a new discipline that uses neuroscientific methods to understand conscious and unconscious consumer reactions and to investigate basic marketing concepts such as persuasion and decision-making processes. With its interdisciplinary character, neuromarketing takes the attention of the business world. However, it also takes attention of many critical points of view with ethical reservations. These reservations stem mostly from ethical concerns about the potential negative consequences of neuromarketing for society, particularly for consumers. For example, the use of neuroscientific technologies, such as eye-tracking and screening neural movements in the brain, to only observe customers' choices, while customers do not have an equal level of information on producers and companies with transparency and reciprocity, creates an unbalanced and unequal relation among the customers, the producers, and the companies. In this chapter, we aim to discuss the possible ethical ideas of being good for the use of neuroscientific technologies in marketing with a philosophical perspective in terms of all participants: consumers, who are exposed to the effects of such studies, and companies, who conduct such studies. With this inquiry, we hope to define some preventative measures with ethical principles against the manipulative uses of neuroscience in marketing as well as in other applied areas without wasting its benefits. © 2021 Nova Science Publishers, Inc.",Business ethics; Ethics; Neuromarketing; Neuromarketing ethics,,Book chapter,Final,,Scopus,2-s2.0-85110814552,Movies / Media
Ye L.; Su H.; Zhao J.; Hang Y.,"Ye, Li (57200419696); Su, Hanjun (59629961300); Zhao, Jing (57116793100); Hang, Yongxin (57220177437)",57200419696; 59629961300; 57116793100; 57220177437,The Impact of Multimedia Effect on Art Learning: Eye Movement Evidence from Traditional Chinese Pattern Learning,2021,International Journal of Art and Design Education,40,2,,342,358,16.0,18,10.1111/jade.12347,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099833687&doi=10.1111%2fjade.12347&partnerID=40&md5=19755e8091232342e60f8550ee4fd60a,"At the beginning of 2020, the COVID-19 epidemic continued to spread and became a global pandemic. Affected by the epidemic, online teaching has become the new normal. As the main form of online education, multimedia learning has attracted more and more attention. The study of traditional patterns has always been a particularly important element of art study in China due to cultural heritage and precious resources. Chinese traditional patterns are an important object of learning because of the heritage. This study examines students’ understanding of the composition and evolution of traditional Chinese patterns in bronze mirrors by using different multimedia learning materials. A two by two factorial design is employed. The dependent variables includes (1) subjects’ post-test scores and (2) the data of subjects’ eye-movement behaviour. Data shows that students who use the animation with narration allocate a greater amount of visual attention than students who use animation with on-screen text. The students who use simulation with on-screen text demonstrated a greater amount of visual attention than students who use received simulation with narration. Furthermore, this empirical study confirmed a direct, positive correlation between the length of the subjects’ eye fixation behaviour and the depth of learning. This result also provides evidence to prove that the use of multimedia learning materials is helpful in art education, especially in the study of the various elements of traditional Chinese art. © 2021 NSEAD and John Wiley & Sons Ltd.",art education; eye movements; higher education; multimedia learning; traditional Chinese patterns,,Article,Final,,Scopus,2-s2.0-85099833687,Movies / Media
Koba C.; Notaro G.; Tamm S.; Nilsonne G.; Hasson U.,"Koba, Cemal (57216921089); Notaro, Giuseppe (57206697067); Tamm, Sandra (57188663821); Nilsonne, Gustav (14120128400); Hasson, Uri (6603086997)",57216921089; 57206697067; 57188663821; 14120128400; 6603086997,Spontaneous eye movements during eyes-open rest reduce resting-state-network modularity by increasing visual-sensorimotor connectivity,2021,Network Neuroscience,5,2,,451,476,25.0,11,10.1162/netn_a_00186,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108269394&doi=10.1162%2fnetn_a_00186&partnerID=40&md5=5be5900ccacb002f9aa920d25f236131,"During wakeful rest, individuals make small eye movements during fixation. We examined how these endogenously driven oculomotor patterns impact topography and topology of functional brain networks. We used a dataset consisting of eyes-open resting-state (RS) fMRI data with simultaneous eye tracking. The eye-tracking data indicated minor movements during rest, which correlated modestly with RS BOLD data. However, eye-tracking data correlated well with echo-planar imaging time series sampled from the area of the eye-orbit (EO-EPI), which is a signal previously used to identify eye movements during exogenous saccades and movie viewing. Further analyses showed that EO-EPI data were correlated with activity in an extensive motor and sensorimotor network, including components of the dorsal attention network and the frontal eye fields. Partialling out variance related to EO-EPI from RS data reduced connectivity, primarily between sensorimotor and visual areas. It also produced networks with higher modularity, lower mean connectivity strength, and lower mean clustering coefficient. Our results highlight new aspects of endogenous eye movement control during wakeful rest. They show that oculomotor-related contributions form an important component of RS network topology, and that those should be considered in interpreting differences in network structure between populations or as a function of different experimental conditions. © 2021 Massachusetts Institute of Technology Published under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.",Eye-movements; Eye-orbit; Modularity; Networks; Resting-state,Eye tracking; Topography; Topology; Brain networks; Clustering coefficient; Echo planar imaging; Experimental conditions; Eye movement control; Frontal eye fields; Network modularity; Network topology; adult; aged; Article; BOLD signal; controlled study; dorsal attention network; echo planar imaging; electroencephalogram; eye fixation; eye movement; eye movement control; eye tracking; frontal eye field; functional connectivity; functional magnetic resonance imaging; human; human experiment; normal human; resting state network; saccadic eye movement; sensorimotor network; time series analysis; young adult; Eye movements,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85108269394,Movies / Media
Jokinen J.P.P.; Acharya A.; Uzair M.,"Jokinen, Jussi P.P. (23035047100); Acharya, Aditya (57203783769); Uzair, Mohammad (56405404400)",23035047100; 57203783769; 56405404400,Touchscreen typing as optimal supervisory control,2021,Conference on Human Factors in Computing Systems - Proceedings,,,,,,,40,10.1145/3411764.3445483,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106736577&doi=10.1145%2f3411764.3445483&partnerID=40&md5=16319e34a25d156f2425b0c2a7d665a1,"Traditionally, touchscreen typing has been studied in terms of motor performance. However, recent research has exposed a decisive role of visual attention being shared between the keyboard and the text area. Strategies for this are known to adapt to the task, design, and user. In this paper, we propose a unifying account of touchscreen typing, regarding it as optimal supervisory control. Under this theory, rules for controlling visuo-motor resources are learned via exploration in pursuit of maximal typing performance. The paper outlines the control problem and explains how visual and motor limitations afect it. We then present a model, implemented via reinforcement learning, that simulates co-ordination of eye and fnger movements. Comparison with human data affrms that the model creates realistic fnger-and eye-movement patterns and shows human-like adaptation. We demonstrate the model's utility for interface development in evaluating touchscreen keyboard designs. © 2021 ACM.",Computational modelling; Rational adaptation; Touchscreen typing,Behavioral research; Computation theory; Human engineering; Reinforcement learning; Control problems; Eye movement patterns; Interface development; Motor performance; Optimal supervisory control; Recent researches; Touch-screen keyboards; Visual Attention; Eye movements,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85106736577,Movies / Media
De Vleeschhauwer J.; Broeder S.; Janssens L.; Heremans E.; Nieuwboer A.; Nackaerts E.,"De Vleeschhauwer, Joni (57222339226); Broeder, Sanne (56080333200); Janssens, Luc (57210966362); Heremans, Elke (10939424200); Nieuwboer, Alice (57206176479); Nackaerts, Evelien (39762495800)",57222339226; 56080333200; 57210966362; 10939424200; 57206176479; 39762495800,Impaired Touchscreen Skills in Parkinson's Disease and Effects of Medication,2021,Movement Disorders Clinical Practice,8,4,,546,554,8.0,10,10.1002/mdc3.13179,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102375195&doi=10.1002%2fmdc3.13179&partnerID=40&md5=4f006882453e4b83c86def96df7fdb3a,"Background: Deficits in fine motor skills may impair device manipulation including touchscreens in people with Parkinson's disease (PD). Objectives: To investigate the impact of PD and anti-parkinsonian medication on the ability to use touchscreens. Methods: Twelve PD patients (H&Y II-III), OFF and ON medication, and 12 healthy controls (HC) performed tapping, single and multi-direction sliding tasks on a touchscreen and a mobile phone task (MPT). Task performance was compared between patients (PD-OFF, PD-ON) and HC and between medication conditions. Results: Significant differences were found in touchscreen timing parameters, while accuracy was comparable between groups. PD-OFF needed more time than HC to perform single (P = 0.048) and multi-direction (P = 0.004) sliding tasks and to grab the dot before sliding (i.e., transition times) (P = 0.040; P = 0.004). For tapping, dopaminergic medication significantly increased performance times (P = 0.046) to comparable levels as those of HC. However, for the more complex multi-direction sliding, movement times remained slower in PD than HC irrespective of medication intake (P < 0.050 during ON and OFF). The transition times for the multi-direction sliding task was also higher in PD-ON than HC (P = 0.048). Touchscreen parameters significantly correlated with MPT performance, supporting the ecological validity of the touchscreen tool. Conclusions: PD patients show motor problems when manipulating touchscreens, even when optimally medicated. This hinders using mobile technology in daily life and has implications for developing adequate E-health applications for this group. Future work needs to establish whether touchscreen training is effective in PD. © 2021 International Parkinson and Movement Disorder Society",dopaminergic medication; Parkinson's disease; touchscreen skills; upper limb,dopamine receptor stimulating agent; adult; aged; anxiety; Article; cell phone use; clinical article; cognition; controlled clinical trial; controlled study; depression; disease severity; drug therapy; executive function; eye tracking; female; finger tapping test; hand function; human; male; motor performance; neuropsychological test; Parkinson disease; questionnaire; task performance; telehealth; upper limb,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85102375195,Movies / Media
Heck M.; Edinger J.; Bünemann J.; Becker C.,"Heck, Melanie (57205548572); Edinger, Janick (56178122500); Bünemann, Jonathan (57222469151); Becker, Christian (57225752577)",57205548572; 56178122500; 57222469151; 57225752577,The Subconscious Director: Dynamically Personalizing Videos Using Gaze Data,2021,"International Conference on Intelligent User Interfaces, Proceedings IUI",,,,98,108,10.0,4,10.1145/3397481.3450679,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104493818&doi=10.1145%2f3397481.3450679&partnerID=40&md5=c7a5a4e669f53dccf5cb949ead208b14,"Watching TV has become a side event rather than a deliberate pastime. Movie directors thus struggle to find new ways to sustain the attention of their audience. Interactive movies usually require the viewer to actively decide how the plot progresses, creating an experience more akin to video games than film. In this paper, we propose a system that analyses gaze data to personalize the plot of a video without the viewer's active intervention. User preferences are inferred from their gaze allocation to different elements in a scene. The subsequent scene is then dynamically tailored towards the user's predicted preference. In a user study (N = 175), we evaluate the effectiveness of the system with regard to user engagement. Our findings show that personalized videos have a positive effect on focused attention and involvement, whereas novelty perception is not significantly affected.  © 2021 ACM.",adaptive media; eye tracking; gaze-contingent systems; preference prediction.,Interactive movies; Personalized video; User engagement; User study; Video game; User interfaces,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85104493818,Movies / Media
Rheem H.; Vaughn Becker D.; Craig S.D.,"Rheem, Hansol (57208275267); Vaughn Becker, D. (8062327000); Craig, Scotty D. (7201656711)",57208275267; 8062327000; 7201656711,Assessing learning effort with hand motion tracking methods,2021,Applied Cognitive Psychology,35,3,,606,620,14.0,3,10.1002/acp.3784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099069519&doi=10.1002%2facp.3784&partnerID=40&md5=454fe19583396ee81fc10ac2b5643889,"Technology has enabled various alternative educational platforms, such as online courses. Compared to human instructors in traditional educational environments, alternative platforms often show a limited capacity to evaluate the learning progress of students and implement intervention strategies based on the evaluation. Here, we tested participants' hand motions, recorded using a computer mouse and a touchscreen, to determine if the data can predict learners' struggles. Hand motions of participants concurrently performing arithmetic and motor tasks were examined to investigate how the hand motions varied depending on the difficulty of the arithmetic task. The results indicated that working memory load affected both the temporal and spatial features of hand motions, which were predictive of participants' level of working memory load. These findings demonstrate that the assessment of struggles in learning may be achieved at relatively high accuracy with input devices commonly used by learners to access online education systems. © 2020 John Wiley & Sons, Ltd.",cognitive load assessment; evaluation methodologies; hand motion tracking; human-computer interface; working memory,adult; area under the curve; arithmetic; Article; child; clinical article; cognition; controlled study; e-learning; entropy; exercise; eye tracking; female; hand movement; heart rate; human; human experiment; imagery; Internet; learning; Likert scale; machine learning; male; measurement accuracy; middle aged; motion; skin conductance; task performance; trail making test; transcranial direct current stimulation; working memory,Article,Final,,Scopus,2-s2.0-85099069519,Movies / Media
de Milander M.; Schall R.; van der Vyver V.; Hattingh E.J.,"de Milander, M. (54410372500); Schall, R. (7006584039); van der Vyver, V. (57224936380); Hattingh, E.J. (57224919544)",54410372500; 7006584039; 57224936380; 57224919544,Association of attention deficit and hyperactivity disorder symptoms with visual functioning difficulties in grade 1 learners,2021,SAJCH South African Journal of Child Health,15,1,,3,7,4.0,1,10.7196/SAJCH.2021.v15i1.01705,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108593611&doi=10.7196%2fSAJCH.2021.v15i1.01705&partnerID=40&md5=96a3f4a28d987002c636abeee87333fe,"Background. Children with attention deficit and hyperactivity disorder (ADHD) can experience visual motor control difficulties. Therefore, early identification of such difficulties is important. Objective. To determine whether ADHD symptoms are associated with visual motor control difficulties in Grade 1 learners. Method. In total, 382 children participated in the study. To determine the presence of ADHD symptoms, the educators completed the Strength and Weaknesses of ADHD symptoms Normal behaviour scale (SWAN) for each learner after six months of observing their class behaviour. Two kinderkineticists applied two tests, namely the Pyfer Sensory Input Systems Screening test and one subtest of the Quick Neurological Screening Test-II (QNST-II). Fisher’s exact test was used to determine if ADHD symptoms were associated with visual functioning difficulties. Results. ADHD symptoms were found to be significantly associated with 10 out of 21 visual functioning difficulties. These skills included fixation with both eyes (p=0.0491), fixation with the right eye (p=0.0003), fixation with the left eye (p=0.0042), ocular alignment of the right eye (p=0.0029), visual tracking with both eyes on X shape (p=0.0284), visual tracking with the right eye (p=0.0301), and visual tacking with the left eye on a circle (p=0.0032). Furthermore, ADHD symptoms were significantly associated with the QNST-II tracking test normal range (p=0.0028), moderate discrepancy (p=0.0028) and severe discrepancy (p=0.0075). Conclusion. ADHD symptoms are significantly associated with approximately half of the tested visual functioning of Grade 1 learners. Appropriate interventions should be implemented by professionals to assist these learners. © 2021, Health and Medical Publishing Group. All rights reserved.",,Article; attention deficit disorder; behavior assessment; cognitive defect; controlled study; daily life activity; depth perception; dyslexia; eye fixation; eye movement; eye tracking; female; Hamilton Depression Rating Scale; human; major clinical study; male; mental deficiency; Mini Mental State Examination; motor control; questionnaire; sensory stimulation; visual acuity; visual impairment; visual memory; visual stimulation,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85108593611,Movies / Media
Reyes G.; Alles A.,"Reyes, Guillermo (57215871602); Alles, Alexandra (57220046487)",57215871602; 57220046487,Multi-modal Multi-scale Attention Guidance in Cyber-Physical Environments,2021,"International Conference on Intelligent User Interfaces, Proceedings IUI",,,,356,365,9.0,1,10.1145/3397481.3450678,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104541836&doi=10.1145%2f3397481.3450678&partnerID=40&md5=54b482f3f3b78b33c62fbb1f2dd4149b,"This work proposes a new method for guiding a user's attention towards objects of interest in a cyber-physical environment (CPE). CPEs are environments that contain several computing systems that interact with each other and with the physical world. These environments contain several sensors (cameras, eye trackers, etc.) and output devices (lamps, screens, speakers, etc.). These devices can be used to first track the user's position, orientation, and focus of attention to then find the most suitable output device to guide the user's attention towards a target object. We argue that the most suitable device in this context is the one that attracts attention closest to the target and is salient enough to capture the user's attention. The method is implemented as a function which estimates the ""closeness""and ""salience""of each visual and auditive output device in the environment. Some parameters of this method are then evaluated through a user study in the context of a virtual reality supermarket. The results show that multi-modal guidance can lead to better guiding performance. However, this depends on the set parameters.  © 2021 ACM.",Attention; Attention Guidance; Cyber-Physical Environments; Intelligent Environments; Multi-modal; Multi-scale,Cyber Physical System; Input output programs; Computing system; Cyber physicals; Eye trackers; Focus of Attention; Multi-modal; Output devices; Physical world; Target object; User interfaces,Conference paper,Final,,Scopus,2-s2.0-85104541836,Movies / Media
Liaqat S.; Wu C.; Duggirala P.R.; Cheung S.-C.S.; Chuah C.-N.; Ozonoff S.; Young G.,"Liaqat, Sidrah (59858672800); Wu, Chongruo (57210639542); Duggirala, Prashanth Reddy (57222178800); Cheung, Sen-ching Samson (34869344500); Chuah, Chen-Nee (7004251298); Ozonoff, Sally (7003652751); Young, Gregory (57225681104)",59858672800; 57210639542; 57222178800; 34869344500; 7004251298; 7003652751; 57225681104,Predicting ASD diagnosis in children with synthetic and image-based eye gaze data,2021,Signal Processing: Image Communication,94,,116198,,,,52,10.1016/j.image.2021.116198,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099252040&doi=10.1016%2fj.image.2021.116198&partnerID=40&md5=96a086cb9c784a893cb6b5ee17beefd0,"As early intervention is highly effective for young children with autism spectrum disorder (ASD), it is imperative to make accurate diagnosis as early as possible. ASD has often been associated with atypical visual attention and eye gaze data can be collected at a very early age. An automatic screening tool based on eye gaze data that could identify ASD risk offers the opportunity for intervention before the full set of symptoms is present. In this paper, we propose two machine learning methods, synthetic saccade approach and image based approach, to automatically classify ASD given children's eye gaze data collected from free-viewing tasks of natural images. The first approach uses a generative model of synthetic saccade patterns to represent the baseline scan-path from a typical non-ASD individual and combines it with the real scan-path as well as other auxiliary data as inputs to a deep learning classifier. The second approach adopts a more holistic image-based approach by feeding the input image and a sequence of fixation maps into a convolutional or recurrent neural network. Using a publicly-accessible collection of children's gaze data, our experiments indicate that the ASD prediction accuracy reaches 67.23% accuracy on the validation dataset and 62.13% accuracy on the test dataset. © 2021 Elsevier B.V.",Autism spectrum disorders; Deep learning; Eye gaze data,Behavioral research; Eye movements; Learning systems; Statistical tests; Automatic screening; Auxiliary data; Early intervention; Generative model; Learning classifiers; Prediction accuracy; Publicly accessible; Visual Attention; Recurrent neural networks,Article,Final,,Scopus,2-s2.0-85099252040,Movies / Media
Millet B.; Chattah J.; Ahn S.,"Millet, Barbara (35094362000); Chattah, Juan (57194579986); Ahn, Soyeon (55534685200)",35094362000; 57194579986; 55534685200,Soundtrack design: The impact of music on visual attention and affective responses,2021,Applied Ergonomics,93,,103301,,,,19,10.1016/j.apergo.2020.103301,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099780468&doi=10.1016%2fj.apergo.2020.103301&partnerID=40&md5=8c013da6915dbe688b324fb9b2cda7a1,"Through music, film composers attempt to affect the audience's emotions and visual attention; however, little empirical evidence exists characterizing the mechanisms whereby music affects viewers. We conducted a mixed-design experiment with 60 participants to explore the effect of music on viewers' visual attention and affective responses to a film. Music led to quicker first fixations on film objects and supplied emotional content, increasing positive sentiment for the film's story. However, music did not influence viewers' attitudes to filmed events. Within this context, music has limited impact on attitudes toward filmed events but can accentuate the saliency of film objects and supply emotional information altering viewers' sentiment towards the film. Understanding the mechanisms of music's physiological and behavioral effects can inform content delivery strategies. This study offers insights for composition and production of musical soundtracks for feature-length films, advertising videos, educational videos, and video games. © 2020 Elsevier Ltd",Emotional response; Eye tracking; Film music; Physiological measurement; Soundtrack; Visual attention,Attitude; Emotions; Humans; Music; Sound recording; Affective response; Behavioral effects; Content delivery; Design experiments; Educational videos; Emotional information; Video game; Visual Attention; adult; advertising; article; attitude; emotion; experimental design; eye tracking; female; human; human experiment; major clinical study; male; music; video game; visual attention; emotion; Behavioral research,Article,Final,,Scopus,2-s2.0-85099780468,Movies / Media
Seifer D.R.; McGrath K.; Scholl G.; Mohan V.; Gold J.A.,"Seifer, Daniel R. (57222731101); McGrath, Karess (57189989116); Scholl, Gretchen (55696981200); Mohan, Vishnu (38561933500); Gold, Jeffrey A. (7201492180)",57222731101; 57189989116; 55696981200; 38561933500; 7201492180,Sex differences in electronic health record navigation strategies: Secondary data analysis,2021,JMIR Human Factors,8,2,e25957,,,,2,10.2196/25957,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108837507&doi=10.2196%2f25957&partnerID=40&md5=6a1d3a8a72351afd9ec7d5d1b978377c,"Background: Use of electronic health records (EHRs) has increased dramatically over the past decade. Their widespread adoption has been plagued with numerous complaints about usability, with subsequent impacts on patient safety and provider well-being. Data in other fields suggest biological sex impacts basic patterns of navigation in electronic media. Objective: This study aimed to determine whether biological sex impacted physicians' navigational strategies while using EHRs. Methods: This is a secondary analysis of a prior study where physicians were given verbal and written signout, and then, while being monitored with an eye tracker, were asked to review a simulated record in our institution's EHR system, which contained 14 patient safety items. Afterward, the number of safety items recognized was recorded. Results: A total of 93 physicians (female: n=46, male: n=47) participated in the study. Two gaze patterns were identified: one characterized more so by saccadic (“scanning”) eye movements and the other characterized more so by longer fixations (“staring”). Female physicians were more likely to use the scanning pattern; they had a shorter mean fixation duration (P=.005), traveled more distance per minute of screen time (P=.03), had more saccades per minute of screen time (P=.02), and had longer periods of saccadic movement (P=.03). The average proportion of time spent staring compared to scanning (the Gaze Index [GI]) across all participants was approximately 3:1. Females were more likely than males to have a GI value <3.0 (P=.003). At the extremes, males were more likely to have a GI value >5, while females were more likely to have a GI value <1. Differences in navigational strategy had no impact on task performance. Conclusions: Females and males demonstrate fundamentally different navigational strategies while navigating the EHR. This has potentially significant impacts for usability testing in EHR training and design. Further studies are needed to determine if the detected differences in gaze patterns produce meaningful differences in cognitive load while using EHRs. © 2021 JMIR Human Factors.",Electronic health record; Eye tracking; Gaze; Sex differences; Usability,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85108837507,Movies / Media
Ausín J.M.; Bigne E.; Marín J.; Guixeres J.; Alcañiz M.,"Ausín, Jose M. (57190258689); Bigne, Enrique (55132662600); Marín, Javier (57994071000); Guixeres, Jaime (26423690300); Alcañiz, Mariano (36921902100)",57190258689; 55132662600; 57994071000; 26423690300; 36921902100,The background music-content congruence of TV advertisements: A neurophysiological study,2021,European Research on Management and Business Economics,27,2,100154,,,,12,10.1016/j.iedeen.2021.100154,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109357511&doi=10.1016%2fj.iedeen.2021.100154&partnerID=40&md5=16404e8eb83cde75158d7d8a9b09c52e,"Music affects viewers’ responses to advertisements. In this study we present the findings of an experiment that investigates the emotional and cognitive reactions of subjects’ brains during exposure to television advertisements with music congruent, and incongruent, with the advertisement content. We analyze the electroencephalography signals and eye-tracking behaviors of a group of 90 women watching six TV advertisements. The study's findings suggested that incongruent music generates higher levels of attention and advertisement recall. On the other hand, frontal asymmetry measured through electroencephalography was shown to be higher with congruent music. Similarly, cognitive workload was higher when the music was incongruent with the advertisement content. No significant differences were found in terms of advertisement likeability based on incongruent versus congruent music. The results demonstrated the validity of neurophysiological techniques for assessing the effects of levels of music congruence in advertisements. © 2021 The Authors",Advertising; Congruency; Effectiveness; Eye-tracking; JEL codes:; M37; Music; Neurophysiological measurement,,Article,Final,,Scopus,2-s2.0-85109357511,Movies / Media
Addleman D.A.; Legge G.E.; Jiang Y.V.,"Addleman, Douglas A. (57195384649); Legge, Gordon E. (7005064208); Jiang, Yuhong V. (35279609200)",57195384649; 7005064208; 35279609200,Simulated central vision loss impairs implicit location probability learning,2021,Cortex,138,,,241,252,11.0,11,10.1016/j.cortex.2021.02.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102424869&doi=10.1016%2fj.cortex.2021.02.009&partnerID=40&md5=a8891ce0a6ce3ab91f115aa658d7f527,"Some eye diseases, especially macular degeneration, can cause central vision loss (CVL), impairing goal-driven guidance of attention. Does CVL also affect implicit, experience-driven attention? We investigated how simulated central scotomas affected young adults' ability to prioritize locations frequently containing visual search targets (location probability learning). Participants searched among distractor letter ‘L's for a target ‘T’ that appeared more often in one screen quadrant than others. To dissociate potential impairments to statistical learning of target locations and attentional guidance, two experiments each included search with and without simulated scotomas. Experiment 1 successfully induced probability learning in a no-scotoma phase. When participants later searched both with and without simulated scotomas, they showed persistent, statistically equivalent spatial biases in both no-scotoma and scotoma search. Experiment 2 trained participants with a central scotoma. While Experiment 1's participants acquired probability learning regardless of their self-reported awareness of the target's location probability, in Experiment 2 only aware participants learned to bias attention to the high probability region. Similarly, learning with a scotoma affected search with no scotoma in aware but not unaware participants. Together, these results show that simulated central vision loss interferes with the acquisition of implicitly learned location probability learning, supporting a role of central vision in implicit spatial attentional biases. © 2021 Elsevier Ltd",Central vision loss; Location probability learning; Selection history; Visual attention; Visual search,Bias; Humans; Learning; Probability; Probability Learning; Scotoma; Young Adult; adult; Article; attentional bias; Bayes theorem; central scotoma; clinical article; female; follow up; human; male; probability learning; saccadic eye movement; young adult; learning; probability; scotoma; statistical bias,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85102424869,Movies / Media
De Groote E.; Bockstael A.; Botteldooren D.; Santens P.; De Letter M.,"De Groote, Evelien (57194015102); Bockstael, Annelies (23767099900); Botteldooren, Dick (6701666696); Santens, Patrick (7006128792); De Letter, Miet (6602734656)",57194015102; 23767099900; 6701666696; 7006128792; 6602734656,Evaluation of multi-feature auditory deviance detection in Parkinson’s disease: a mismatch negativity study,2021,Journal of Neural Transmission,128,5,,645,657,12.0,2,10.1007/s00702-021-02341-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105189752&doi=10.1007%2fs00702-021-02341-z&partnerID=40&md5=f8327fe8ba106c3986147ef0dbd50883,"Behavioral studies on auditory deviance detection in patients with Parkinson’s disease (PD) have reported contradictory results. The primary aim of this study was to investigate auditory deviance detection of multiple auditory features in patients with PD by means of objective and reliable electroencephalographic (EEG) measurements. Twelve patients with early-stage PD and twelve age- and gender-matched healthy controls (HCs) were included in this study. Patients with PD participated without their regular dopaminergic medication. All subjects underwent an audiometric screening and performed a passive multi-feature mismatch negativity (MMN) paradigm. Repeated-measures analysis of variance (ANOVA) demonstrated no significant differences between patients with PD and HCs regarding MMN mean amplitude and latency for frequency, duration and gap deviants. Nevertheless, a trend towards increased MMN mean amplitude and latency was found in response to intensity deviants in patients with PD compared to HCs. Increased intensity MMN amplitude may indicate that more neural resources are allocated to the processing of intensity deviances in patients with PD compared to HCs. The interpretation of this intensity-specific MMN alteration is further discussed in the context of a compensatory mechanism for auditory intensity processing and involuntary attention switching in PD. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.",Auditory deviance detection; Auditory event-related potentials (ERPs); Mismatch negativity (MMN); Parkinson’s disease (PD),Analysis of Variance; Attention; Auditory Perception; Electroencephalography; Humans; Parkinson Disease; antiparkinson agent; adult; aged; Article; auditory discrimination; auditory evoked potential; clinical article; controlled study; disease duration; disease severity; electroencephalography; eyelid reflex; female; hearing; human; male; mismatch negativity; Parkinson disease; priority journal; pure tone audiometry; saccadic eye movement; sensory memory; tympanometry; Unified Parkinson Disease Rating Scale; analysis of variance; attention; electroencephalography; hearing; Parkinson disease; pathophysiology,Article,Final,,Scopus,2-s2.0-85105189752,Movies / Media
Kaufmann B.C.; Cazzoli D.; Koenig-Bruhin M.; Müri R.M.; Nef T.; Nyffeler T.,"Kaufmann, Brigitte C. (57200416513); Cazzoli, Dario (23990403100); Koenig-Bruhin, Monica (8983670400); Müri, René M. (7003342964); Nef, Tobias (15726063900); Nyffeler, Thomas (6603229393)",57200416513; 23990403100; 8983670400; 7003342964; 15726063900; 6603229393,Video-Oculography During Free Visual Exploration to Detect Right Spatial Neglect in Left-Hemispheric Stroke Patients With Aphasia: A Feasibility Study,2021,Frontiers in Neuroscience,15,,640049,,,,6,10.3389/fnins.2021.640049,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104021318&doi=10.3389%2ffnins.2021.640049&partnerID=40&md5=bf257c886dae5b7de764e7f271c86110,"Spatial neglect has been shown to occur in 17–65% of patients after acute left-hemispheric stroke. One reason for this varying incidence values might be that left-hemispheric stroke is often accompanied by aphasia, which raises difficulties in assessing attention deficits with conventional neuropsychological tests entailing verbal instructions. Video-oculography during free visual exploration (FVE) requires only little understanding of simple non-verbal instruction and has been shown to be a sensitive and reliable tool to detect spatial neglect in patients with right-hemispheric stroke. In the present study, we aimed to investigate the feasibility of FVE to detect neglect in 10 left-hemispheric stroke patients with mild to severe aphasia as assessed by means of the Token Test, Boston Naming Test and Aachener Aphasie Test. The patient’s individual deviation between eye movement calibration and validation was recorded and compared to 20 age-matched healthy controls. Furthermore, typical FVE parameters such as the landing point of the first fixation, the mean gaze position (in ° of visual angle), the number and duration of visual fixations and the mean visual exploration area were compared between groups. In addition, to evaluate for neglect, the Bells cancellation test was performed and neglect severity in daily living was measured by means of the Catherine Bergego Scale (CBS). Our results showed that the deviation between calibration and validation did not differ between aphasia patients and healthy controls highlighting its feasibility. Furthermore, FVE revealed the typical neglect pattern with a significant leftward shift in visual exploration bahaviour, which highly correlated with neglect severity as assessed with CBS. The present study provides evidence that FVE has the potential to be used as a neglect screening tool in left-hemispheric stroke patients with aphasia in which compliance with verbal test instructions may be compromised by language deficits. © Copyright © 2021 Kaufmann, Cazzoli, Koenig-Bruhin, Müri, Nef and Nyffeler.",aphasia; free visual exploration; left-hemispheric stroke; mean gaze position; right spatial visual neglect; video-oculography; visual exploration behaviour,Aachener Aphasie Test; aged; aphasia; Article; Bells cancellation test; Boston naming test; calibration; Catherine Bergego Scale; cerebrovascular accident; clinical article; correlation analysis; daily life activity; disease severity; eye movement; eye tracking; feasibility study; female; free visual exploration; gaze; human; language disability; left hemisphere; male; mean gaze position; neurologic examination; neurological complication; right spatial visual neglect; screening test; stroke patient; token test; validation study; videooculography; vision; visual exploration area,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85104021318,Movies / Media
"Muthuswamy A.; Pardo I.D.; Rao D.B.; Switzer R.C., III; Sharma A.K.; Bolon B.","Muthuswamy, Anantharaman (57212352055); Pardo, Ingrid D. (7003651189); Rao, Deepa B. (55579723700); Switzer, Robert C. (7005872200); Sharma, Alok K. (56493613500); Bolon, Brad (7003438991)",57212352055; 7003651189; 55579723700; 7005872200; 56493613500; 7003438991,Neuroanatomy and Sampling of Central Projections for the Visual System in Mammals Used in Toxicity Testing,2021,Toxicologic Pathology,49,3,,455,471,16.0,6,10.1177/0192623320967279,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096834656&doi=10.1177%2f0192623320967279&partnerID=40&md5=326ca2959a3a3291fece2f586251b1ef,"Visual system toxicity may manifest anywhere in the visual system, from the eye proper to the visual brain. Therefore, effective screening for visual system toxicity must evaluate not only ocular structures (ie, eye and optic nerve) but also multiple key brain regions involved in vision (eg, optic tract, subcortical relay nuclei, and primary and secondary visual cortices). Despite a generally comparable pattern across species, the neuroanatomic organization and function of the visual brain in rodents and rabbits exhibit appreciable differences relative to nonrodents. Currently recognized sampling practices for general toxicity studies in animals, which are based on easily discerned external neuroanatomic landmarks and guided by extant stereotaxic brain atlases, typically will permit histopathologic evaluation of many brain centers involved in visual sensation (eg, optic chiasm, optic tract, dorsal lateral geniculate nucleus, primary and secondary visual cortices) and often some subcortical brain nuclei involved in light-modulated nonvisual activities needed for visual attention and orientation (eg, rostral colliculus in quadrupeds, termed the superior colliculus in bipeds; several cranial nerve nuclei). Pathologic findings induced by toxicants in the visual brain centers are similar to those that are produced in other brain regions. © The Author(s) 2020.",brain; eye; neuroanatomy; neuropathology; neurotoxicity; ocular toxicity; optic nerve; visual pathway,Animals; Brain; Geniculate Bodies; Mammals; Neuroanatomy; Rabbits; Retina; Superior Colliculi; Article; circadian rhythm; extraocular muscle; eye toxicity; human; lateral geniculate body; neuroanatomy; neurobiology; neuropathology; nonhuman; optic chiasm; optic nerve; optic tract; priority journal; saccadic eye movement; secondary visual cortex; sensory nerve; superior colliculus; toxicity testing; visual cortex; visual system; animal; brain; geniculate body; Leporidae; mammal; retina,Article,Final,,Scopus,2-s2.0-85096834656,Movies / Media
Lin J.-Y.; Zhang L.-Y.; Cao B.; Wei Q.-Q.; Ou R.-W.; Hou Y.-B.; Liu K.-C.; Xu X.-R.; Jiang Z.; Gu X.-J.; Liu J.; Shang H.-F.,"Lin, Jun-Yu (57218374578); Zhang, Ling-Yu (57192815567); Cao, Bei (55339132300); Wei, Qian-Qian (56946094500); Ou, Ru-Wei (56042716800); Hou, Yan-Bing (57189308206); Liu, Kun-Cheng (56604462500); Xu, Xin-Ran (57214875535); Jiang, Zheng (57212138655); Gu, Xiao-Jing (57194022246); Liu, Jiao (57215298135); Shang, Hui-Fang (55521148900)",57218374578; 57192815567; 55339132300; 56946094500; 56042716800; 57189308206; 56604462500; 57214875535; 57212138655; 57194022246; 57215298135; 55521148900,Sleep-related symptoms in multiple system atrophy: Determinants and impact on disease severity,2021,Chinese Medical Journal,134,6,,690,698,8.0,15,10.1097/CM9.0000000000001211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103226876&doi=10.1097%2fCM9.0000000000001211&partnerID=40&md5=85940b4a27a21719c05fb65159c1f1be,"Background:Sleep disorders are common but under-researched symptoms in patients with multiple system atrophy (MSA). We investigated the frequency and factors associated with sleep-related symptoms in patients with MSA and the impact of sleep disturbances on disease severity.Methods:This cross-sectional study involved 165 patients with MSA. Three sleep-related symptoms, namely Parkinson's disease (PD)-related sleep problems (PD-SP), excessive daytime sleepiness (EDS), and rapid eye movement sleep behavior disorder (RBD), were evaluated using the PD Sleep Scale-2 (PDSS-2), Epworth Sleepiness Scale (ESS), and RBD Screening Questionnaire (RBDSQ), respectively. Disease severity was evaluated using the Unified MSA Rating Scale (UMSARS).Results:The frequency of PD-SP (PDSS-2 score of ≥18), EDS (ESS score of ≥10), and RBD (RBDSQ score of ≥5) in patients with MSA was 18.8%, 27.3%, and 49.7%, respectively. The frequency of coexistence of all three sleep-related symptoms was 7.3%. Compared with the cerebellar subtype of MSA (MSA-C), the parkinsonism subtype of MSA (MSA-P) was associated with a higher frequency of PD-SP and EDS, but not of RBD. Binary logistic regression revealed that the MSA-P subtype, a higher total UMSARS score, and anxiety were associated with PD-SP; that male sex, a higher total UMSARS score, the MSA-P subtype, and fatigue were associated with EDS; and that male sex, a higher total UMSARS score, and autonomic onset were associated with RBD in patients with MSA. Stepwise linear regression showed that the number of sleep-related symptoms (PD-SP, EDS, and RBD), disease duration, depression, fatigue, and total Montreal Cognitive Assessment score were predictors of disease severity in patients with MSA.Conclusions:Sleep-related disorders were associated with both MSA subtypes and the severity of disease in patients with MSA, indicating that sleep disorders may reflect the distribution and degree of dopaminergic/non-dopaminergic neuron degeneration in MSA. © 2021 Lippincott Williams and Wilkins. All rights reserved.",Disease severity; Multiple system atrophy; Sleep disorders; Subtype,Cross-Sectional Studies; Humans; Male; Multiple System Atrophy; REM Sleep Behavior Disorder; Severity of Illness Index; Sleep; cross-sectional study; human; male; parasomnia; severity of illness index; Shy Drager syndrome; sleep,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85103226876,Movies / Media
Fu M.; Wang Y.; Chen Z.; Li J.; Xu F.; Liu X.; Hou F.,"Fu, Mingyu (57211462629); Wang, Yitian (57208908556); Chen, Zixin (57222492552); Li, Jin (37061426000); Xu, Fengguo (57201138399); Liu, Xinyu (57222905442); Hou, Fengzhen (55085874300)",57211462629; 57208908556; 57222492552; 37061426000; 57201138399; 57222905442; 55085874300,Deep Learning in Automatic Sleep Staging With a Single Channel Electroencephalography,2021,Frontiers in Physiology,12,,628502,,,,44,10.3389/fphys.2021.628502,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102880250&doi=10.3389%2ffphys.2021.628502&partnerID=40&md5=e1d5d2bac2b5f0b44c015f4741ceb452,"This study centers on automatic sleep staging with a single channel electroencephalography (EEG), with some significant findings for sleep staging. In this study, we proposed a deep learning-based network by integrating attention mechanism and bidirectional long short-term memory neural network (AT-BiLSTM) to classify wakefulness, rapid eye movement (REM) sleep and non-REM (NREM) sleep stages N1, N2 and N3. The AT-BiLSTM network outperformed five other networks and achieved an accuracy of 83.78%, a Cohen’s kappa coefficient of 0.766 and a macro F1-score of 82.14% on the PhysioNet Sleep-EDF Expanded dataset, and an accuracy of 81.72%, a Cohen’s kappa coefficient of 0.751 and a macro F1-score of 80.74% on the DREAMS Subjects dataset. The proposed AT-BiLSTM network even achieved a higher accuracy than the existing methods based on traditional feature extraction. Moreover, better performance was obtained by the AT-BiLSTM network with the frontal EEG derivations than with EEG channels located at the central, occipital or parietal lobe. As EEG signal can be easily acquired using dry electrodes on the forehead, our findings might provide a promising solution for automatic sleep scoring without feature extraction and may prove very useful for the screening of sleep disorders. © Copyright © 2021 Fu, Wang, Chen, Li, Xu, Liu and Hou.",attention mechanism; automatic sleep staging; bidirectional long short-term memory; deep learning; single channel electroencephalography,adult; aged; Article; convolutional neural network; deep learning; electroencephalography; feature extraction; female; human; long short term memory network; male; nonREM sleep; normal human; occipital lobe; parietal lobe; receiver operating characteristic; recurrent neural network; REM sleep; sleep stage; slow wave sleep; stage 1 sleep; stage 2 sleep; wakefulness,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85102880250,Movies / Media
Ford C.G.; Haliwa I.; Shook N.J.,"Ford, Cameron G. (57195260322); Haliwa, Ilana (57195351968); Shook, Natalie J. (7801574009)",57195260322; 57195351968; 7801574009,Mind your gaze: Examining the relation between trait mindfulness and visual attention to valenced images,2021,Behavioural Brain Research,401,,113063,,,,7,10.1016/j.bbr.2020.113063,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098135152&doi=10.1016%2fj.bbr.2020.113063&partnerID=40&md5=c82264da5d95d5aeae24099e16708d8b,"Trait mindfulness pertains to one's ability to non-judgmentally attend to experiences. While attention regulation represents a core component of mindfulness, the relation between trait mindfulness and visual attention is unclear. Further, despite established associations between mindfulness and emotion regulation, few studies have examined whether trait mindfulness may be related to attention to emotionally valenced content. Thus, the present study used an eye-tracking paradigm to assess relations between trait mindfulness, emotion regulation and selective visual attention to valenced stimuli. Participants (N = 123; 75.6 % female; 87 % Caucasian; Mage = 19.14 years) completed measures of trait mindfulness, emotion regulation, and engaged in an eye-tracking paradigm in which they viewed sad, threatening, neutral, and happy images simultaneously. Dwell times on images (all categories combined), black space on screen, and each image category were calculated. Bivariate correlations were assessed to determine the relations among mindfulness, emotion regulation, and visual attention, controlling for mood. Trait mindfulness was associated with longer dwell time on images overall, but specifically longer dwell time on threatening and happy images. Although trait mindfulness and emotion regulation were positively associated, emotion regulation was not significantly associated with visual attention. These results suggest that trait mindfulness is associated with visual attention to valenced stimuli, particularly happy and threatening images, and emotion regulation does not account for these relations. These findings add to our understanding of the cognitive mechanisms underlying trait mindfulness. © 2020 Elsevier B.V.",Dwell time; Emotion regulation; Eye-tracking; Mindfulness; Visual attention,"Adolescent; Adult; Affect; Attention; Emotional Regulation; Eye-Tracking Technology; Female; Humans; Male; Mindfulness; Pattern Recognition, Visual; Personality; Time Factors; Visual Perception; Young Adult; adult; article; Caucasian; controlled study; dwell time; emotion regulation; eye tracking; female; gaze; human; human experiment; major clinical study; male; mindfulness; mood; visual attention; adolescent; affect; attention; pattern recognition; personality; physiology; time factor; vision; young adult",Article,Final,,Scopus,2-s2.0-85098135152,Movies / Media
Zhang X.; Golomb J.D.,"Zhang, Xiaoli (58138267800); Golomb, Julie D. (57204279904)",58138267800; 57204279904,Neural representations of covert attention across saccades: Comparing pattern similarity to shifting and holding attention during fixation,2021,eNeuro,8,2,ENEURO.0186-20.2021,,,,2,10.1523/ENEURO.0186-20.2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103603910&doi=10.1523%2fENEURO.0186-20.2021&partnerID=40&md5=959a0899d7e585f9a519db5909e5a868,"We can focus visuospatial attention by covertly attending to relevant locations, moving our eyes, or both si-multaneously. How does shifting versus holding covert attention during fixation compare with maintaining covert attention across saccades? We acquired human fMRI data during a combined saccade and covert attention task. On Eyes-fixed trials, participants either held attention at the same initial location (“hold atten-tion”) or shifted attention to another location midway through the trial (“shift attention”). On Eyes-move trials, participants made a saccade midway through the trial, while maintaining attention in one of two reference frames: the “retinotopic attention” condition involved holding attention at a fixation-relative location but shifting to a different screen-centered location, whereas the “spatiotopic attention” condition involved holding attention on the same screen-centered location but shifting relative to fixation. We localized the brain network sen-sitive to attention shifts (shift > hold attention), and used multivoxel pattern time course (MVPTC) analyses to investigate the patterns of brain activity for spatiotopic and retinotopic attention across saccades. In the attention shift network, we found transient information about both whether covert shifts were made and whether saccades were executed. Moreover, in this network, both retinotopic and spatiotopic conditions were repre-sented more similarly to shifting than to holding covert attention. An exploratory searchlight analysis revealed additional regions where spatiotopic was relatively more similar to shifting and retinotopic more to holding. Thus, maintaining retinotopic and spatiotopic attention across saccades may involve different types of updating that vary in similarity to covert attention “hold” and “shift” signals across different regions. © 2021 Zhang and Golomb.",Covert attention shifts; FMRI; Reference frames; Representational similarity; Saccades,"Fixation, Ocular; Histological Techniques; Humans; Magnetic Resonance Imaging; Photic Stimulation; Retina; Saccades; adult; article; attention; controlled study; exploratory research; female; human; human experiment; male; nerve cell network; saccadic eye movement; eye fixation; histology; nuclear magnetic resonance imaging; photostimulation; retina",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85103603910,Movies / Media
Jones E.B.; Sharpe L.; Andrews S.; Colagiuri B.; Dudeney J.; Fox E.; Heathcote L.C.; Lau J.Y.F.; Todd J.; Van Damme S.; Van Ryckeghem D.M.L.; Vervoort T.,"Jones, Emma Blaisdale (56194762000); Sharpe, Louise (7102577510); Andrews, Sally (7202524925); Colagiuri, Ben (24511982300); Dudeney, Joanne (21833626300); Fox, Elaine (7202092877); Heathcote, Lauren C. (56099935400); Lau, Jennifer Y F (55241283500); Todd, Jemma (39262625200); Van Damme, Stefaan (6701787190); Van Ryckeghem, Dimitri M L (36446834400); Vervoort, Tine (14326439900)",56194762000; 7102577510; 7202524925; 24511982300; 21833626300; 7202092877; 56099935400; 55241283500; 39262625200; 6701787190; 36446834400; 14326439900,The time course of attentional biases in pain: a meta-analysis of eye-tracking studies,2021,Pain,162,3,,687,701,14.0,20,10.1097/j.pain.0000000000002083,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102153454&doi=10.1097%2fj.pain.0000000000002083&partnerID=40&md5=252f477d38ea182060c0a5ddff7a9b81,"ABSTRACT: Previous meta-analyses investigating attentional biases towards pain have used reaction time measures. Eye-tracking methods have been adopted to more directly and reliably assess biases, but this literature has not been synthesized in relation to pain. This meta-analysis aimed to investigate the nature and time course of attentional biases to pain-related stimuli in participants of all ages with and without chronic pain using eye-tracking studies and determine the role of task parameters and theoretically relevant moderators. After screening, 24 studies were included with a total sample of 1425 participants. Between-group analyses revealed no significant overall group differences for people with and without chronic pain on biases to pain-related stimuli. Results indicated significant attentional biases towards pain-related words or pictures across both groups on probability of first fixation (k = 21, g = 0.43, 95% confidence interval [CI] 0.15-0.71, P = 0.002), how long participants looked at each picture in the first 500 ms (500-ms epoch dwell: k = 5, g = 0.69, 95% CI 0.034-1.35, P = 0.039), and how long participants looked at each picture overall (total dwell time: k = 25, g = 0.44, 95% CI 0.15-0.72, P = 0.003). Follow-up analyses revealed significant attentional biases on probability of first fixation, latency to first fixation and dwell time for facial stimuli, and number of fixations for sensory word stimuli. Moderator analyses revealed substantial influence of task parameters and some influence of threat status and study quality. Findings support biases in both vigilance and attentional maintenance for pain-related stimuli but suggest attentional biases towards pain are ubiquitous and not related to pain status. Copyright © 2020 International Association for the Study of Pain.",,Attention; Attentional Bias; Chronic Pain; Eye-Tracking Technology; Humans; Reaction Time; attention; attentional bias; chronic pain; human; meta analysis; reaction time,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85102153454,Movies / Media
Kapp C.M.; Akulian J.A.; Yu D.H.; Chen A.; Cárdenas-García J.; Molena D.; Vachani A.; Wahidi M.M.; Maldonado F.; Fielding D.; Yarmus L.B.; Lee H.,"Kapp, Christopher M. (57217354866); Akulian, Jason A. (55123183100); Yu, Diana H. (57197872238); Chen, Alexander (55447277000); Cárdenas-García, José (55370058600); Molena, Daniela (6603350248); Vachani, Anil (8625677900); Wahidi, Momen M. (6603182033); Maldonado, Fabien (23012782200); Fielding, David (12773560800); Yarmus, Lonny B. (35182298600); Lee, Hans (35589967600)",57217354866; 55123183100; 57197872238; 55447277000; 55370058600; 6603350248; 8625677900; 6603182033; 23012782200; 12773560800; 35182298600; 35589967600,Cognitive Load in Electromagnetic Navigational and Robotic Bronchoscopy for Pulmonary Nodules,2021,ATS Scholar,2,1,,97,107,10.0,11,10.34197/ats-scholar.2020-0033OC,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136483934&doi=10.34197%2fats-scholar.2020-0033OC&partnerID=40&md5=66688f7ffa7b488d41e16a234a38a39f,"Background: Electromagnetic navigational bronchoscopy (ENB) and robotic-assisted bronchoscopy (RB) require a high degree of decision-making and psychomotor skill. Cognitive load theory is the overall effort expended by individuals in response to a task and is closely related to the usability of devices for medical procedures. High cognitive workload leads to poor surgical outcomes and represents a bottleneck for learning that affects performance. Objective: To analyze the cognitive load associated with ENB and RB in experienced ENB practitioners learning RB. Methods: Six experienced ENB bronchoscopists performed ENB and RB on a human cadaver model of peripheral pulmonary nodules. To assess cognitive load, we used the Surgery Task Load Index (SURG-TLX) and biometric changes. The SURG-TLX questionnaire was given to the provider after every peripheral pulmonary nodule biopsy with ENB and RB. Pupillary dilation and screen changes were continuously measured throughout the procedure for each biopsy attempt to collect biometric measures of cognitive load. Procedural time and biopsy outcome were also recorded. Results: Forty procedures (ENB and RB) were analyzed. Task complexity (23%) and mental demand (21.4%) were the highest contributors to cognitive load in ENB and RB. The cumulative SURG-TLX was significantly lower for the RB (69.25 vs. 101.25; P <0.01). Total procedure time was greater for ENB (6.7 min; SD 1.5) compared with RB (4.4 min; SD 1.5; P= 0.01). Pupillary diameter was similar across the modalities (RB vs. ENB), but the diameter was higher during the biopsy portion (4.25 mm) than the navigation portion (4.01 mm). Conclusion: The intrinsic cognitive load of RB was highly manageable by existing ENB practitioners, and in this study, RB appeared to be less mentally demanding. Future development and training should focus on task complexity and mental demand for RB. The biopsy portion, regardless of bronchoscopic modality, should be a focus for education and training.  Copyright © 2021 by the American Thoracic Society.",cognitive load; electromagnetic navigational bronchoscopy; ENB; procedural education; robotic bronchoscopy,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85136483934,Movies / Media
Melnyk R.; Campbell T.; Holler T.; Cameron K.; Saba P.; Witthaus M.W.; Joseph J.; Ghazi A.,"Melnyk, Rachel (57200043581); Campbell, Timothy (57200045924); Holler, Tyler (57222388541); Cameron, Katherine (57222391318); Saba, Patrick (57211646984); Witthaus, Michael W. (56703147500); Joseph, Jean (14031648400); Ghazi, Ahmed (26658992700)",57200043581; 57200045924; 57222388541; 57222391318; 57211646984; 56703147500; 14031648400; 26658992700,See like an Expert: Gaze-Augmented Training Enhances Skill Acquisition in a Virtual Reality Robotic Suturing Task,2021,Journal of Endourology,35,3,,376,382,6.0,13,10.1089/end.2020.0445,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102587834&doi=10.1089%2fend.2020.0445&partnerID=40&md5=45ba61918026f7ff364278fff286117f,"Introduction: The da Vinci Skills Simulator (DVSS) is an effective platform for robotic skills training. Novel training methods using expert gaze patterns to guide trainees have demonstrated superiority to traditional instruction. Portable head-mounted eye-trackers (HMET) offer the opportunity for eye tracking technology to enhance surgical robotic simulation training. Objective: To evaluate if training guided by expert gaze patterns can improve trainee performance over standard movement training techniques during robotic simulation. Methods: Medical students were recruited and randomized into gaze training (GT, n = 9) and movement training (MT, n = 8) groups. First, the participants reviewed an instructional video, with the GT group emulating expert gaze patterns and the MT group (n = 8) standard movement-based instruction. Training consisted of 10 repetitions of ""Suture Sponge 3""on the DVSS while wearing HMET; the first three repetitions were followed by group-appropriate video coaching (gaze vs movement feedback), while the remaining repetitions were without feedback. Finally, two multitasking repetitions with a secondary bell-counting task were completed. Primary outcomes included DVSS scores during training and multitasking. Secondary outcomes included metrics collected from the HMET (gaze patterns and gaze entropy). Results: Total score, efficiency, and penalties improved significantly over the training in both groups; the GT group achieved higher scores on every attempt. Total scores in the GT group were higher than the MT group postvideo review (20.3 ± 21.8 vs 3.0 ± 6.2, p = 0.047), after coaching repetitions (61.8 ± 18.8 vs 30.1 ± 26.2, p = 0.01), and at the last training attempt (73.0 ± 16.5 vs 63.1 ± 17.4, p = 0.247). During multitasking, the GT group maintained higher total scores (75 ± 10.1 vs 63.3 ± 15.3, p = 0.01), efficiency (86.3 ± 7.4 vs 77.4 ± 11.2, p = 0.009), and superior secondary task performance (error: 6.3% ± 0.06 vs 10.7% ± 0.11, p = 0.20). Gaze entropy (cognitive-load indicator) and gaze pattern analysis showed similar trends. Conclusion: Gaze-augmented training leads to more efficient movements through adoption of expert gaze patterns that withstand additional stressors. © Copyright 2021, Mary Ann Liebert, Inc., publishers 2021.",robotics; simulation,Clinical Competence; Computer Simulation; Humans; Robotic Surgical Procedures; Robotics; Simulation Training; Sutures; Virtual Reality; Article; feedback system; gaze; gaze training; human; medical education; medical student; movement training; priority journal; robot assisted surgery; scoring system; simulation training; task performance; videorecording; clinical competence; computer simulation; robotics; suture; virtual reality,Article,Final,,Scopus,2-s2.0-85102587834,Movies / Media
Schultheiß S.; Lewandowski D.,"Schultheiß, Sebastian (57193610111); Lewandowski, Dirk (56232434800)",57193610111; 56232434800,How users' knowledge of advertisements influences their viewing and selection behavior in search engines,2021,Journal of the Association for Information Science and Technology,72,3,,285,301,16.0,26,10.1002/asi.24410,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090432005&doi=10.1002%2fasi.24410&partnerID=40&md5=29482539ec8ffe407319ffc4eebe0dc6,"According to recent studies, search engine users have little knowledge of Google's business model. In addition, users cannot sufficiently distinguish organic results from advertisements, resulting in result selections under false assumptions. Following on from that, this study examines how users' understanding of search-based advertising influences their viewing and selection behavior on desktop computer and smartphone. To investigate this, we used a mixed methods approach (n = 100) consisting of a pre-study interview, an eye-tracking experiment, and a post-study questionnaire. We show that participants with a low level of knowledge on search advertising are more likely to click on ads than subjects with a high level of knowledge. Moreover, subjects with little knowledge show less willingness to scroll down to organic results. Regarding the device, there are significant differences in viewing behavior. These can be attributed to the influence of the direct visibility of search results on both devices tested: Ads that were ranked on top received significantly more visual attention on the small screen than the top ranked ads on the large screen. The results call for a clearer labeling of advertisements and for the promotion of users' information literacy. Future studies should investigate the motivations of searchers when clicking on ads. © 2020 The Authors. Journal of the Association for Information Science and Technology published by Wiley Periodicals LLC on behalf of Association for Information Science and Technology.",,Behavioral research; Eye tracking; Marketing; Surveys; Business modeling; Information literacy; Large screen; Mixed method; Organic results; Search-based; Small screens; Visual Attention; Search engines,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85090432005,Movies / Media
Schreiner S.J.; Imbach L.L.; Valko P.O.; Maric A.; Maqkaj R.; Werth E.; Baumann C.R.; Baumann-Vogel H.,"Schreiner, Simon J. (56109246300); Imbach, Lukas L. (6507251817); Valko, Philipp O. (24281992400); Maric, Angelina (55497364000); Maqkaj, Rina (57222313783); Werth, Esther (6602133517); Baumann, Christian R. (8510916500); Baumann-Vogel, Heide (55270317800)",56109246300; 6507251817; 24281992400; 55497364000; 57222313783; 6602133517; 8510916500; 55270317800,Reduced Regional NREM Sleep Slow-Wave Activity Is Associated With Cognitive Impairment in Parkinson Disease,2021,Frontiers in Neurology,12,,618101,,,,27,10.3389/fneur.2021.618101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102321786&doi=10.3389%2ffneur.2021.618101&partnerID=40&md5=b107b69b696a8c6d142c8108b80ffeb1,"Growing evidence implicates a distinct role of disturbed slow-wave sleep in neurodegenerative diseases. Reduced non-rapid eye movement (NREM) sleep slow-wave activity (SWA), a marker of slow-wave sleep intensity, has been linked with age-related cognitive impairment and Alzheimer disease pathology. However, it remains debated if SWA is associated with cognition in Parkinson disease (PD). Here, we investigated the relationship of regional SWA with cognitive performance in PD. In the present study, 140 non-demented PD patients underwent polysomnography and were administered the Montréal Cognitive Assessment (MoCA) to screen for cognitive impairment. We performed spectral analysis of frontal, central, and occipital sleep electroencephalography (EEG) derivations to measure SWA, and spectral power in other frequency bands, which we compared to cognition using linear mixed models. We found that worse MoCA performance was associated with reduced 1–4 Hz SWA in a region-dependent manner (F2, 687 =11.67, p < 0.001). This effect was driven by reduced regional SWA in the lower delta frequencies, with a strong association of worse MoCA performance with reduced 1–2 Hz SWA (F2, 687 =18.0, p < 0.001). The association of MoCA with 1–2 Hz SWA (and 1–4 Hz SWA) followed an antero-posterior gradient, with strongest, weaker, and absent associations over frontal (rho = 0.33, p < 0.001), central (rho = 0.28, p < 0.001), and occipital derivations, respectively. Our study shows that cognitive impairment in PD is associated with reduced NREM sleep SWA, predominantly in lower delta frequencies (1–2 Hz) and over frontal regions. This finding suggests a potential role of reduced frontal slow-wave sleep intensity in cognitive impairment in PD. © Copyright © 2021 Schreiner, Imbach, Valko, Maric, Maqkaj, Werth, Baumann and Baumann-Vogel.",cognition; cognitive impairment; EEG; Parkinson disease; polysomnography; sleep; slow-wave sleep; spectral analysis,antidepressant agent; benzodiazepine derivative; benzodiazepine receptor stimulating agent; cholinesterase inhibitor; clonazepam; dopamine receptor stimulating agent; levodopa; neuroleptic agent; adult; apnea hypopnea index; arousal index; Article; brain region; cognitive defect; controlled study; delta rhythm; depression; disease association; disease duration; education; electroencephalogram; female; frontal lobe; Hoehn and Yahr scale; human; linear mixed model; major clinical study; male; middle aged; Montreal cognitive assessment; nonREM sleep; occipital lobe; oscillation; parasomnia; Parkinson disease; performance; polysomnography; screening; slow wave sleep; spectral power; spectroscopy; statistical model,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85102321786,Movies / Media
Greening L.; Downing J.; Amiouny D.; Lekang L.; McBride S.,"Greening, Linda (55371389900); Downing, Josh (57221642819); Amiouny, Daniella (57221642863); Lekang, Line (57221642100); McBride, Sebastian (7005704924)",55371389900; 57221642819; 57221642863; 57221642100; 7005704924,The effect of altering routine husbandry factors on sleep duration and memory consolidation in the horse,2021,Applied Animal Behaviour Science,236,,105229,,,,19,10.1016/j.applanim.2021.105229,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099695026&doi=10.1016%2fj.applanim.2021.105229&partnerID=40&md5=9e8f2957c31eebbfb05e95af0f98212c,"Sleep is a critically important behaviour for all mammals due to its fundamental role within homeostatic/circadian systems and memory consolidation. As a large and vigilant prey species that is highly sensitive to stimuli at night, the horse sleeps less than other mammalian species. For this reason, the domestic environment has the potential to greatly affect the duration and quality of equine sleep. This study aimed to determine the effect of environmental factors on equine sleep stages, and whether this would influence cognitive performance during a spatial memory task. Ten riding school horses (mixed breed/ height/ sex; average age 14.9 + 2.4 years) were randomly assigned to two groups (n = 5) within a five-week crossover repeated measures design experiment. Each group experienced a combination of one of two light conditions (lights on = Treatment; lights off = Control), and one of two bedding depth treatments (15 cm bed = control; 5 cm bed = treatment) for six days. Duration of sleep stage behaviours (standing Non-Rapid Eye Movement [NREM]), sternal NREM, sternal Rapid Eye Movement [REM] and lateral REM) were measured continuously using CCTV infrared cameras. For the spatial memory task, latency, number of correct responses, and differences between these parameters during training and testing days were measured. A repeated measures general linear model assessed the effects of treatment conditions on duration of sleep stage, and changes in sleep stage over time (bedding and light set as within-subject factors). Wilcoxon Signed-Rank and paired t-tests determined differences in memory task parameters between treatments. Comparing Treatment Bedding with Control Bedding conditions, horses spent on average significantly less time in lateral REM (0.34 ± 0.12 versus 0.46 ± 0.13 h; p = 0.032) and sternal NREM (0.64 ± 0.10 versus 0.80 ± 0.12 h; p = 0.007), and significantly more time in standing NREM (3.69 ± 0.76 versus 3.17 ± 0.77; p = 0.024). Only sternal REM was significantly affected during the Treatment Light condition compared to control conditions (0.53 ± 0.07 versus 0.67 ± 0.11; p = 0.031). Interactions between day and treatment were apparent for specific sleep stage behaviours indicative of acclimatisation. No significant effects (p > 0.05) of Treatment Light or Bedding conditions were detected for performance during the spatial memory test. Overall, horses exposed to sub-optimal conditions tended to display significantly less time in recumbent sleep stages (NREM and REM) and increased time in a standing NREM stage. The impact of reduced sleep on equine cognition requires further study. © 2021 Elsevier B.V.",Bedding; Behaviour; Equine; Light; Nocturnal; Sleep,Equidae; Mammalia; animal husbandry; circadian rhythm; detection method; environmental factor; experimental design; homeostasis; horse; instrumentation; memory; sleep,Article,Final,,Scopus,2-s2.0-85099695026,Movies / Media
Sharma K.; Mangaroska K.; Berkel N.V.; Giannakos M.; Kostakos V.,"Sharma, Kshitij (55903734200); Mangaroska, Katerina (57189850061); Berkel, Niels van (56032304300); Giannakos, Michail (36462343600); Kostakos, Vassilis (6508135447)",55903734200; 57189850061; 56032304300; 36462343600; 6508135447,Information flow and cognition affect each other: Evidence from digital learning,2021,International Journal of Human Computer Studies,146,,102549,,,,17,10.1016/j.ijhcs.2020.102549,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092905211&doi=10.1016%2fj.ijhcs.2020.102549&partnerID=40&md5=bb0c0258a5d051836eaabda2c66ad5e9,"In the context of learning systems, identifying causal relationships among information presented to the user, their behavior and cognitive effort required/exerted to understand and perform a task is key to building effective learning experiences, and to maintain engagement in learning processes. An unexplored question is whether our interaction with presented information affects our cognitive effort (and behaviour), or vice-versa. We investigate causal relationship between information presented and cognitive effort (and behaviour) in the context of two separate studies (N = 40, N = 98), and study the effect of instruction (active/passive task). We utilize screen-recordings and eye-tracking data to investigate the relationship among these variables. To investigate the causal relationships among the different measurements, we use Granger's causality. Further, we propose a new method to combine two time-series from multiple participants for detecting causal relationships. Our results indicate that information presentation drives user focus size (behaviour), and that cognitive load (a measure of cognitive effort exerted) drives information presentation. This relationship is also moderated by instruction type and performance-level (high/low). We draw implications for design of educational material and learning technologies. © 2020 The Author(s)",Causality; E-Learning; Eye-Tracking; Massive open online courses; MOOC; Multimodal learning analytics,Behavioral research; Cognitive systems; Digital storage; E-learning; Eye tracking; Causal relationships; Cognitive efforts; Educational materials; Effective learning; Engagement in learning; Information flows; Information presentation; Learning technology; Learning systems,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85092905211,Movies / Media
Oakes L.M.; DeBolt M.C.; Beckner A.G.; Voss A.T.; Cantrell L.M.,"Oakes, Lisa M. (24587572100); DeBolt, Michaela C. (56644621500); Beckner, Aaron G. (57216131214); Voss, Annika T. (57225723280); Cantrell, Lisa M. (15519339200)",24587572100; 56644621500; 57216131214; 57225723280; 15519339200,Infant eye gaze while viewing dynamic faces,2021,Brain Sciences,11,2,231,1,37,36.0,7,10.3390/brainsci11020231,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101262961&doi=10.3390%2fbrainsci11020231&partnerID=40&md5=ac5599e1c00c66be06145ff02bbeba95,"Research using eye tracking methods has revealed that when viewing faces, between 6 to 10 months of age, infants begin to shift visual attention from the eye region to the mouth region. Moreover, this shift varies with stimulus characteristics and infants’ experience with faces and languages. The current study examined the eye movements of a racially diverse sample of 98 infants between 7.5 and 10.5 months of age as they viewed movies of White and Asian American women reciting a nursery rhyme (the auditory component of the movies was replaced with music to eliminate the influence of the speech on infants’ looking behavior). Using an analytic approach inspired by the multiverse analysis approach, several measures from infants’ eye gaze were examined to identify patterns that were robust across different analyses. Although in general infants preferred the lower regions of the faces, i.e., the region containing the mouth, this preference depended on the stimulus characteristics and was stronger for infants whose typical experience included faces of more races and for infants who were exposed to multiple languages. These results show how we can leverage the richness of eye tracking data with infants to add to our understanding of the factors that influence infants’ visual exploration of faces. © 2021 by the authors.",Eye movements; Eye tracking; Face processing; Face race; Infancy,Article; auditory stimulation; behavior; color blindness; dynamics; education; eye movement; eye tracking; facial expression; facial recognition; female; gaze; head movement; hearing impairment; human; infant; language ability; major clinical study; male; music; neurologic disease; pregnancy; questionnaire; signal noise ratio; speech; task performance; visual information; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85101262961,Movies / Media
Yamamoto M.; Konishi Y.; Kato I.; Koyano K.; Nakamura S.; Nishida T.; Kusaka T.,"Yamamoto, Mayumi (57195432028); Konishi, Yukihiko (37120632000); Kato, Ikuko (16316438700); Koyano, Kosuke (26658129800); Nakamura, Shinji (55461817700); Nishida, Tomoko (36194230200); Kusaka, Takashi (55774254200)",57195432028; 37120632000; 16316438700; 26658129800; 55461817700; 36194230200; 55774254200,Do low birth weight infants not see eyes? Face recognition in infancy,2021,Brain and Development,43,2,,186,191,5.0,3,10.1016/j.braindev.2020.09.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091603864&doi=10.1016%2fj.braindev.2020.09.002&partnerID=40&md5=fd21f45dfc0140b89f87c1e10feec60a,"Background: Progress in neonatal medicine has dramatically improved the survival rate of preterm births, but the evidence suggests that these low-birth weight infants (LBWIs) go on to develop pervasive development disorders and attention deficit hyperactivity disorder (ADHD) at greater rates than the general population. Children with neurodevelopmental disorders are known to suffer from deficits in visual cognition, such as in face perception and attentional functions, the characteristics of which already manifest in early infancy. Purpose: This study aimed to investigate visual cognition in LBWIs during infancy. Subjects: 20 LBWIs and 20 normal-birth-weight infants (NBWIs: control) of age 9–10 months (corrected age was used for LBWIs). Method: Children were held seated in front of an eye tracking system by a parent, and presented with facial photos as visual stimuli. During the familiarization phase, the child was presented with two images of the same human face (familiarization stimulus) on the left and right side of a display screen (5 × 10 s trials). Next, during the test phase, the child was presented with the same image on one side of the screen, and a photo of a different person's face (novel stimulus) on the other (2 × 5 s trials). Gaze behavior was assessed in terms of the total time spent looking at either facial stimulus, and specifically at the eyes of the stimuli, as well as the number of attentional shifts between stimuli, and novelty preference. Results/Discussion: LBWIs spent significant less time looking at facial stimuli overall, and less time at the eye region, than NBWIs. These findings seem to evidence developmental differences in functions related to visual cognition. © 2020 The Japanese Society of Child Neurology",Eye tracker; Facial recognition; Low birth weight infant,"Child Development; Cognition; Eye; Face; Facial Recognition; Female; Humans; Infant; Infant, Low Birth Weight; Male; Visual Perception; Article; attention; birth weight; clinical article; crying; eye movement; eye tracking; facial recognition; female; gaze; human; infancy; infant; low birth weight; male; vision; visual cognition; child development; cognition; eye; face; facial recognition; low birth weight; physiology; vision",Article,Final,,Scopus,2-s2.0-85091603864,Movies / Media
Iijima M.; Okuma Y.; Suzuki K.; Yoshii F.; Nogawa S.; Osada T.; Hirata K.; Kitagawa K.; Hattori N.,"Iijima, Mutsumi (7201773783); Okuma, Yasuyuki (7005444541); Suzuki, Keisuke (56879571700); Yoshii, Fumihito (7102975431); Nogawa, Shigeru (7003524387); Osada, Takashi (7103062339); Hirata, Koichi (57207219022); Kitagawa, Kazuo (7202183407); Hattori, Nobutaka (7201655756)",7201773783; 7005444541; 56879571700; 7102975431; 7003524387; 7103062339; 57207219022; 7202183407; 7201655756,"Associations between probable REM sleep behavior disorder, olfactory disturbance, and clinical symptoms in Parkinson's disease: A multicenter cross-sectional study",2021,PLoS ONE,16,2-Feb,e0247443,,,,13,10.1371/journal.pone.0247443,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101374155&doi=10.1371%2fjournal.pone.0247443&partnerID=40&md5=cd8bbb5934299a383e65a11fc89ad57a,"Background Rapid eye movement sleep behavior disorder (RBD) and olfactory dysfunction are useful for early diagnosis of Parkinson's disease (PD). RBD and severe olfactory dysfunction are also regarded as risk factors for cognitive impairment in PD. This study aimed to assess the associations between RBD, olfactory function, and clinical symptoms in patients with PD. Methods The participants were 404 patients with non-demented PD. Probable RBD (pRBD) was determined using the Japanese version of the RBD screening questionnaire (RBDSQ-J) and the RBD Single-Question Screen (RBD1Q). Olfactory function was evaluated using the odor identification test for Japanese. Clinical symptoms were evaluated using the Movement Disorder Society Revision of the Unified PD Rating Scale (MDS-UPDRS) parts I-IV. Results In total, 134 (33.2%) patients indicated a history of pRBD as determined by the RBD1Q and 136 (33.7%) by the RBDSQ-J based on a cutoff value of 6 points. Moreover, 101 patients were diagnosed as pRBD by both questionnaires, 35 by the RBDSQ-J only, and 33 by the RBD1Q only. The MDS-UPDRS parts I-III scores were significantly higher and disease duration significantly longer in the pRBD group. pRBD was significantly associated with male gender and the MDS-UPDRS part I score. The olfactory identification function was significantly reduced in the pRBD group. Conclusions About 33% of the patients with PD had pRBD based on the questionnaires, and both motor and non-motor functions were significantly decreased in these patients. These results suggest that more extensive degeneration occurred in patients with non-demented PD with RBD. Copyright: © 2021 Iijima et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Adult; Aged; Aged, 80 and over; Case-Control Studies; Cross-Sectional Studies; Female; Humans; Japan; Male; Middle Aged; Olfaction Disorders; Parkinson Disease; Prevalence; REM Sleep Behavior Disorder; Surveys and Questionnaires; adult; aged; anxiety; apathy; Article; cognitive defect; comparative study; constipation; cross-sectional study; daytime somnolence; depression; disease association; disease duration; disease severity; dizziness; fatigue; female; hallucination; human; Japanese (people); major clinical study; male; MDS-Unified Parkinson Disease Rating Scale; motor performance; odor recognition test; parasomnia; Parkinson disease; pathogenesis; sex difference; sleep disorder; smelling; smelling disorder; case control study; clinical trial; Japan; middle aged; multicenter study; parasomnia; Parkinson disease; prevalence; questionnaire; smelling disorder; very elderly",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85101374155,Movies / Media
Riechelmann E.; Raettig T.; Böckler A.; Huestegge L.,"Riechelmann, Eva (57196117800); Raettig, Tim (23135977900); Böckler, Anne (37002439500); Huestegge, Lynn (55934774700)",57196117800; 23135977900; 37002439500; 55934774700,Gaze interaction: anticipation-based control of the gaze of others,2021,Psychological Research,85,1,,302,321,19.0,8,10.1007/s00426-019-01257-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074590682&doi=10.1007%2fs00426-019-01257-4&partnerID=40&md5=3d5aa2ee4aa914fc93c195b4123fd34c,"Gaze control is an important component of social communication, e.g. to direct someone’s attention. While previous research on gaze interaction has mainly focused on the gaze recipient by asking how humans respond to perceived gaze (gaze cueing), we address the actor’s point of view by asking how actors control their own eye movements to trigger a gaze response in others. Specifically, we investigate whether gaze responses of a (virtual) interaction partner are anticipated and thereby affect oculomotor control. Building on a pre-established paradigm for addressing anticipation-based motor control in non-social contexts, participants were instructed to alternately look at two faces on the screen, which consistently responded to the participant’s gaze with either direct or averted gaze. We tested whether this gaze response of the targeted face is already anticipated prior to the participant’s eye movement by displaying a task-irrelevant visual stimulus (prior to the execution of the target saccade), which was either congruent, incongruent, or unrelated to the subsequently perceived gaze. In addition to schematic and photographic faces, we included conditions involving changes in non-social objects. Overall, we observed congruency effects (as an indicator of anticipation of the virtual other’s gaze response to one’s own gaze) for both social and non-social stimuli, but only when the perceived changes were sufficiently salient. Temporal dynamics of the congruency effects were comparable for social and non-social stimuli, suggesting that similar mechanisms underlie anticipation-based oculomotor control. The results support recent theoretical claims emphasizing the role of anticipation-based action control in social interaction. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",,"Adult; Attention; Communication; Cues; Eye Movements; Female; Fixation, Ocular; Humans; Male; Saccades; Social Interaction; Young Adult; adult; association; attention; eye fixation; eye movement; female; human; interpersonal communication; male; physiology; saccadic eye movement; social interaction; young adult",Article,Final,,Scopus,2-s2.0-85074590682,Movies / Media
Qu J.; Zhu S.; Wang W.; Li F.-Z.; Hu B.,"Qu, Jue (56970345900); Zhu, Shuai (57217524159); Wang, Wei (57192617530); Li, Fang-Zheng (57203344881); Hu, Bo (57208884981)",56970345900; 57217524159; 57192617530; 57203344881; 57208884981,Research on Visual Search Cognitive Characteristics of Adaptive Interface; [自适应界面视觉搜索认知特性研究],2021,Tien Tzu Hsueh Pao/Acta Electronica Sinica,49,2,,338,345,7.0,3,10.12236/DZXB.20190286,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103067316&doi=10.12236%2fDZXB.20190286&partnerID=40&md5=0bd4fd7f1ba938541a8be28e64c396a1,"In order to attract users' attention and improve the efficiency of interaction, adjusting the position and increasing the area of interface elements is very common in adaptive interface.In this paper, we studied the cognitive characteristics of people in the process of the change of regional location and the increase of regional area of the adaptive interface, which provides guidelines for the design of the adaptive interface.Ergonomics experiments were designed to make the interface adaptive items randomly switch between the middle position and other locations, as well as the original area interface and the enlarged area interface.The subjects were asked to complete the visual search task, and the reaction time and accuracy of the subjects were recorded.The results show that the direction (up, down, left and right), and the distance have significant effects on the reaction time.The eye movement heatmap shows that subjects are more sensitive to change in the direction of the up and down.Under the experimental conditions, the adaptive change distance of the interface items in the up and down directions can not exceed 12.5% of the screen size; the change distance cannot exceed 25% of the screen size in the direction of left and right.When the increase is greater than 125% of the original area, the dynamic switching factor has a significant effect on the reaction time, so the proportion of area increase can not exceed 100%. © 2021, Chinese Institute of Electronics. All right reserved.",Adaptive interface; Cognitive characteristic; Ergonomics; Eye-tracking,Screen printing; Adaptive interface; Cognitive characteristics; Dynamic switching; Experimental conditions; Interface elements; Regional areas; Regional locations; Visual search; Eye movements,Article,Final,,Scopus,2-s2.0-85103067316,Movies / Media
Holm S.K.; Olli K.; Häikiö T.; Kaakinen J.K.,"Holm, Suvi K. (57191613356); Olli, Konstantin (57355903800); Häikiö, Tuomo (9635019900); Kaakinen, Johanna K. (55917360500)",57191613356; 57355903800; 9635019900; 55917360500,Eye Movements during Dynamic Scene Viewing are Affected by Visual Attention Skills and Events of the Scene: Evidence from First-Person Shooter Gameplay Videos,2021,Journal of Eye Movement Research,14,2,,1,31,30.0,14,10.16910/jemr.14.2.3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120087136&doi=10.16910%2fjemr.14.2.3&partnerID=40&md5=08d4edd1dccf265636e7c47370407215,"The role of individual differences during dynamic scene viewing was explored. Participants (N=38) watched a gameplay video of a first-person shooter (FPS) videogame while their eye movements were recorded. In addition, the participants’ skills in three visual attention tasks (attentional blink, visual search, and multiple object tracking) were assessed. The results showed that individual differences in visual attention tasks were associated with eye movement patterns observed during viewing of the gameplay video. The differences were noted in four eye movement measures: number of fixations, fixation durations, saccade amplitudes and fixation distances from the center of the screen. The individual differences showed during specific events of the video as well as during the video as a whole. The results highlight that an unedited, fast-paced and cluttered dynamic scene can bring about individual differences in dynamic scene viewing. © 2021. This article is licensed under a Creative Commons Attribution 4.0 International license.",attention; dynamic scene; eSports; events; eye movement; eye tracking; gameplay video; individual differences; video game,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85120087136,Movies / Media
Shimizu Y.; Ohnishi A.; Terada T.; Tsukamoto M.,"Shimizu, Yusuke (57221873824); Ohnishi, Ayumi (57195073026); Terada, Tsutomu (7202850889); Tsukamoto, Masahiko (35399700000)",57221873824; 57195073026; 7202850889; 35399700000,Gaze-Adaptive Subtitles Considering the Balance among Vertical/Horizontal and Depth of Eye Movement,2021,"Proceedings - 2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct, ISMAR-Adjunct 2021",,,,127,132,5.0,4,10.1109/ISMAR-Adjunct54149.2021.00035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126341932&doi=10.1109%2fISMAR-Adjunct54149.2021.00035&partnerID=40&md5=2d29f76905a356bd0ab7d7be745ebd48,"Subtitles (captions displayed on the screen) are important in 3D content, such as virtual reality (VR) and 3D movies, to help users understand the content. However, an optimal displaying method and framework for subtitles have not been established for 3D content because 3D has a depth factor. To determine how to place text in 3D content, we propose four methods of moving subtitles dynamically considering the balance between the vertical/horizontal and depth of gaze shift. These methods are used to reduce the difference in depth or distance between the gaze position and subtitles. Additionally, we evaluate the readability of the text and participants' fatigue. The results show that aligning the text horizontally and vertically to eye movements improves visibility and readability. It is also shown that the eyestrain is related to the distance between the object and subtitles. This evaluation provides basic knowledge for presenting text in 3D content.  © 2021 IEEE.",Eye tracking; Sensing; Subtitles; Virtual reality,Eye movements; Eye tracking; User interfaces; 3D content; Eye-tracking; Gaze shifts; Subtitle; Virtual reality,Conference paper,Final,,Scopus,2-s2.0-85126341932,Movies / Media
Sethia D.; Parihar A.S.; Ghosh A.; Grover T.; Diwakar D.; Kumar S.; Tyagi U.,"Sethia, Divyashikha (35520212900); Parihar, Anil Singh (36998900100); Ghosh, Aheli (57210291116); Grover, Tanish (57210290972); Diwakar, Deep (57222259316); Kumar, Shivam (57218172910); Tyagi, Utkarsh (56974512300)",35520212900; 36998900100; 57210291116; 57210290972; 57222259316; 57218172910; 56974512300,MFlameGaze: Mobile-Based Flame Gazing for Improving Sustained Attention,2021,"2021 International Conference on COMmunication Systems and NETworkS, COMSNETS 2021",,,9352815,638,643,5.0,2,10.1109/COMSNETS51098.2021.9352815,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102065916&doi=10.1109%2fCOMSNETS51098.2021.9352815&partnerID=40&md5=a04b0b700cf3dc053f93f116bc87e0f5,"Yogic visual concentration techniques have proved to create a long term effect on mindfulness in adults. However, none of the existing gaze detection platforms actively monitor attention and provide feedback to the users. This paper presents a novel method to correlate and estimate the effect of a short-term candle gaze concentration technique on the sustained attention, by providing feedback to the participants and helping them keep track of their sustained attention. We present the prototype of an Android mobile-based flame gaze application known as mFlameGaze to perform the candle flame test (CFT). The app determines for how long the participants focus on the candle tip in their screens. It also detects the moment in time when the eyes first deflect from the flame. The proposed work uses this app to analyze the impact of candle gaze on sustained attention for a small group of normal, healthy children. The participants' sustained attention is measured before and after conducting the study using a letter cancellation test (LCT) as the benchmark. The results indicate an increase in the performance of participants in the LCT and also an increase in the focused gaze time, as measured by the mFlameGaze mobile app in a short duration of ten days. © 2021 IEEE.",,Information systems; Candle flame; Gaze detection; Keep track of; Long-term effects; Mobile app; Short durations; Short term; Sustained attention; Computer networks,Conference paper,Final,,Scopus,2-s2.0-85102065916,Movies / Media
Bochet A.; Franchini M.; Kojovic N.; Glaser B.; Schaer M.,"Bochet, Aurélie (57217983987); Franchini, Martina (55935541200); Kojovic, Nada (57201132662); Glaser, Bronwyn (7103024861); Schaer, Marie (57205783996)",57217983987; 55935541200; 57201132662; 7103024861; 57205783996,Emotional vs. Neutral Face Exploration and Habituation: An Eye-Tracking Study of Preschoolers With Autism Spectrum Disorders,2021,Frontiers in Psychiatry,11,,568997,,,,11,10.3389/fpsyt.2020.568997,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100051134&doi=10.3389%2ffpsyt.2020.568997&partnerID=40&md5=11eeb4b2f9e9a70bba2fd594a1489f39,"Diminished orienting to social stimuli, and particularly to faces, is a core feature of autism spectrum disorders (ASDs). Impaired face processing has been linked to atypical attention processes that trigger a cascade of pathological development contributing to impaired social communication. The aim of the present study is to explore the processing of emotional and neutral faces using an eye-tracking paradigm (the emotional faces task) with a group of 24 children with ASD aged 6 and under and a group of 22 age-matched typically developing (TD) children. We also measure habituation to faces in both groups based on the presentation of repeated facial expressions. Specifically, the task consists of 32 pairs of faces, a neutral face and an emotional face from the same identity, shown side by side on the screen. We observe differential exploration of emotional faces in preschoolers with ASD compared with TD. Participants with ASD make fewer fixations to emotional faces than their TD peers, and the duration of their first fixation on emotional faces is equivalent to their first fixation on neutral faces. These results suggest that emotional faces may be less interesting for children with ASD. We also observe a habituation process to neutral faces in both children with ASD and TD, who looked less at neutral faces during the last quarter of the task compared with the first quarter. By contrast, TD children show increased interest in emotional faces throughout the task, looking slightly more at emotional faces during the last quarter of the task than during the first quarter. Children with ASD demonstrate neither habituation nor increased interest in the changing emotional expressions over the course of the task, looking at the stimuli for equivalent time throughout the task. A lack of increased interest in emotional faces may suggest a lack of sensitivity to changes in expression in young children with ASD. © Copyright © 2020 Bochet, Franchini, Kojovic, Glaser and Schaer.",ASD; emotional faces; eye-tracking; face exploration; habituation; preschoolers,age distribution; Article; autism; child; clinical article; cognition assessment; controlled study; emotionality; eye fixation; eye tracking; facial expression; female; habituation; human; intelligence quotient; male; preschool child; sex difference; visual stimulation; Wechsler preschool and primary scale of intelligence,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85100051134,Movies / Media
Kanaan M.; Moacdieh N.M.,"Kanaan, Malk (57224308029); Moacdieh, Nadine Marie (55583410100)",57224308029; 55583410100,How do we react to cluttered displays? Evidence from the first seconds of visual search in websites,2021,Ergonomics,64,11,,1452,1464,12.0,3,10.1080/00140139.2021.1927200,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107343458&doi=10.1080%2f00140139.2021.1927200&partnerID=40&md5=5e66cb19301566ff7f48cf278194974a,"Display clutter is known to degrade search performance and lead to differences in eye movement measures in different contexts. The goal of this study was to determine whether these differences in eye movements could be detected in the first few seconds of a search task using a realistic display, both with or without time pressure. Participants were asked to search for image or word targets in 40 website screenshots. Time pressure was introduced for half the trials. Clutter algorithms were used to classify the websites as low- or high-clutter. Performance, subjective, and eye-tracking metrics were collected. Results showed that people’s attention allocation within the first 3 s of search is different when viewing high-clutter websites. In particular, people’s spread of attention was larger in high-clutter websites. The results can be used to detect whether a person is struggling with clutter early on after they view a display. Practitioner summary: Eye-tracking metrics showed that people react differently to a cluttered website in a variety of conditions. These differences were evident within the first 3 s of the search. The eye-tracking metrics identified can be used to detect people struggling with clutter as soon as they look at a website. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",Display clutter; eye tracking; interface design; visual search; websites,Algorithms; Attention; Eye Movements; Humans; Visual Perception; Clutter (information theory); Eye tracking; Radar clutter; Websites; Eye-movement measures; Screenshots; Search performance; Search tasks; Time pressures; Visual search; adult; algorithm; article; attention; eye tracking; female; human; human experiment; male; physician; algorithm; attention; eye movement; vision; Eye movements,Article,Final,,Scopus,2-s2.0-85107343458,Movies / Media
Jiang S.; Chen W.; Kang Y.,"Jiang, Shaoqi (57222386454); Chen, Weijiong (11139346400); Kang, Yutao (36998090200)",57222386454; 11139346400; 36998090200,Correlation Evaluation of Pilots' Situation Awareness in Bridge Simulations via Eye-Tracking Technology,2021,Computational Intelligence and Neuroscience,2021,,7122437,,,,17,10.1155/2021/7122437,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121576674&doi=10.1155%2f2021%2f7122437&partnerID=40&md5=d09f1fe5ec9c7566d68297a77ca56590,"To maintain situation awareness (SA) when exposed to emergencies during pilotage, a pilot needs to selectively allocate attentional resources to perceive critical status information about ships and environments. Although it is important to continuously monitor a pilot's SA, its relationship with attention is still not fully understood in ship pilotage. This study performs bridge simulation experiments that include vessel departure, navigation in the fairway, encounters, poor visibility, and anchoring scenes with 13 pilots (mean = 11.3 and standard deviation = 1.4 of experience). Individuals were divided into two SA group levels based on the Situation Awareness Rating Technology (SART-2) score (mean = 20.13 and standard deviation = 5.83) after the experiments. The visual patterns using different SA groups were examined using heat maps and scan paths based on pilots' fixations and saccade data. The preliminary visual analyses of the heat maps and scan paths indicate that the pilots' attentional distribution is modulated by the SA level. That is, the most concerning areas of interest (AOIs) for pilots in the high and low SA groups are outside the window (AOI-2) and electronic charts (AOI-1), respectively. Subsequently, permutation simulations were utilized to identify statistical differences between the pilots' eye-tracking metrics and SA. The results of the statistical analyses show that the fixation and saccade metrics are affected by the SA level in different AOIs across the five scenes, which confirms the findings of previous studies. In encounter scenes, the pilots' SA level is correlated with the fixation and saccade metrics: fixation count (p = 0.034 < 0.05 in AOI-1 and p = 0.032 < 0.05 in AOI-2), fixation duration (p = 0.043 < 0.05 in AOI-1 and p = 0.014 < 0.05 in AOI-2), and saccade count (p = 0.086 < 0.1 in AOI-1 and p = 0.054 < 0.1 in AOI-2). This was determined by the fixation count (p = 0.024 < 0.05 in AOI-1 and p = 0.034 < 0.05 in AOI-2), fixation duration (p = 0.036 < 0.05 in AOI-1 and p = 0.047 < 0.05 in AOI-2), and saccade duration (p = 0.05 ≤ 0.05 in AOI-1 and p = 0.042 < 0.05 in AOI-2) in poor-visibility scenes. In the remaining scenes, the SA could not be measured using eye movements alone. This study lays a foundation for the cognitive mechanism recognition of pilots based on SA via eye-tracking technology, which provides a reference to establish cognitive competency standards in preliminary pilot screenings. © 2021 Shaoqi Jiang et al.",,Awareness; Eye Movements; Eye-Tracking Technology; Humans; Pilots; Task Performance and Analysis; Eye tracking; Ships; Statistics; Area of interest; Correlation evaluations; Exposed to; Eye tracking technologies; Fixation duration; Heat maps; Poor visibility; Scan path; Situation awareness; Standard deviation; adult; article; awareness; controlled study; eye-tracking technology; female; heat; human; human experiment; male; saccadic eye movement; simulation; visibility; Eye movements,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85121576674,Movies / Media
Ettenhofer M.L.; Hungerford L.D.; Agtarap S.,"Ettenhofer, Mark L. (9740985500); Hungerford, Lars D. (56594719300); Agtarap, Stephanie (56311952100)",9740985500; 56594719300; 56311952100,Multimodal Neurocognitive Screening of Military Personnel with a History of Mild Traumatic Brain Injury Using the Bethesda Eye & Attention Measure,2021,Journal of Head Trauma Rehabilitation,36,6,,447,455,8.0,3,10.1097/HTR.0000000000000683,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107893052&doi=10.1097%2fHTR.0000000000000683&partnerID=40&md5=464302b603bb73a59c6444199ca254f4,"Objective: To evaluate a neurocognitive eye tracking task, the Bethesda Eye & Attention Measure (BEAM), for use in cognitive screening of patients with a history of mild traumatic brain injury (TBI). Setting: US military TBI rehabilitation clinic. Design/Participants: Cross-sectional study of 191 military personnel receiving outpatient services related to history of mild TBI. Main measures: BEAM; neuropsychological screening measures of attention, processing speed, executive function, and memory. Results: Medium effect sizes were found for partial correlations (controlling for age) between key BEAM metrics and neuropsychological screening tests. Linear regression analyses demonstrated that BEAM saccadic eye movements and manual (button press) metrics each provided complementary value in measurement of cognitive performance, above and beyond effects of demographic factors and clinical characteristics. Conclusion: This study provides initial support for the use of BEAM neurocognitive eye tracking in cognitive screening of adults with a history of mild TBI. BEAM saccadic metrics appear to be particularly well-suited for the assessment of visual attention. Study findings also highlight opportunities for greater cognitive sensitivity or testing efficiency that may be missed by tests measuring only one response modality at a time. © 2021 Lippincott Williams and Wilkins. All rights reserved.",cognitive assessment; concussion; eye tracking; mild traumatic brain injury; military; screening,Brain Concussion; Cross-Sectional Studies; Humans; Military Personnel; brain concussion; cross-sectional study; human; military personnel,Article,Final,,Scopus,2-s2.0-85107893052,Movies / Media
Feng Y.; Chen F.,"Feng, Yong (57191859436); Chen, Fei (57219004705)",57191859436; 57219004705,Investigation of Weighted Scales for Measuring Visual Fatigue in Screening Tasks,2021,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",2021-January,,,5768,5771,3.0,3,10.1109/EMBC46164.2021.9630334,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122533941&doi=10.1109%2fEMBC46164.2021.9630334&partnerID=40&md5=d7d60a872a3b50608e1fc313e45d2093,"The screening trend of modern society has been a progressively increasing burden on the human visual system, and visual fatigue problems are attracting growing attention. Nowadays, subjective testing is the most widely used measure for visual fatigue; however, the low accuracy of subjective testing has been hindering its further improvement. Motivated by the idea of weighted scoring, this study investigated the effects of two weighted scales for measuring visual fatigue in screening tasks. Specifically, a questionnaire with 10 items collected from the classic scales was performed with eye-tracking testing in two typical screen visual fatigue experiments, i.e., searching and watching. Then the subjective scores were factor-analyzed into three subscales before attempting linear regression analyses, which set the dependents to two previously validated eye-tracking parameters, i.e., fixation frequency and saccade amplitude. Finally, two weighted scales were obtained in assessing visual fatigue of varying levels, which demonstrated the potential to improve testing accuracy of visual fatigue with the calibration of objective measurement. © 2021 IEEE.",,Asthenopia; Attention; Humans; Mass Screening; Saccades; Surveys and Questionnaires; Eye tracking; Regression analysis; Eye-tracking; Fatigue experiments; Fatigue problems; Human Visual System; Linear regression analysis; Objective measurement; Testing accuracy; Visual fatigue; asthenopia; attention; human; mass screening; questionnaire; saccadic eye movement; Subjective testing,Conference paper,Final,,Scopus,2-s2.0-85122533941,Movies / Media
Szita K.; Rooney B.,"Szita, Kata (57222100780); Rooney, Brendan (55007994600)",57222100780; 55007994600,"The Effects of Smartphone Spectatorship on Attention, Arousal, Engagement, and Comprehension",2021,i-Perception,12,1,,,,,7,10.1177/2041669521993140,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101406629&doi=10.1177%2f2041669521993140&partnerID=40&md5=c12a48cd9b6f96b94932ce0a99afbbc7,"The popularity of watching movies and videos on handheld devices is rising, yet little attention has been paid to its impact on viewer behaviour. Smartphone spectatorship is characterized by the small handheld screen as well as the viewing environment where various unrelated stimuli can occur, providing possible distractions from viewing. Previous research suggests that screen size, handheld control, and external stimuli can affect viewing experience; however, no prior studies have combined these factors or applied them for the specific case of smartphones. In the present study, we compared smartphone and large-screen viewing of feature films in the presence and absence of external distractors. Using a combination of eye tracking, electrodermal activity measures, self-reports, and recollection accuracy tests, we measured smartphone-accustomed viewers’ attention, arousal, engagement, and comprehension. The results revealed the impact of viewing conditions on eye movements, gaze dispersion, electrodermal activity, self-reports of engagement, as well as comprehension. These findings show that smartphone viewing is more effective when there are no distractions, and smartphone viewers are more likely to be affected by external stimuli. In addition, watching large stationary screens in designated viewing environments increases engagement with a movie. © The Author(s) 2021.",attention; comprehension; electrodermal activity; eye movements; movie; presence; screen size; smartphones,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85101406629,Movies / Media
Patil U.; Lago S.,"Patil, Umesh (53464146500); Lago, Sol (56208708500)",53464146500; 56208708500,Prediction Advantage as Retrieval Interference: An ACT-R Model of Processing Possessive Pronouns,2021,Proceedings of ICCM 2021 - 19th International Conference on Cognitive Modelling,,,,213,219,6.0,4,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145198937&partnerID=40&md5=8bd544b711b0308bca61a3e33ec676fc,"We propose a retrieval interference-based explanation of a prediction advantage effect observed in Stone et al. (2021). They reported two dual-task eye-tracking experiments in which participants listened to instructions involving German possessive pronouns, e.g. ‘Click on his blue button’, and were asked to select the correct object from a set of objects displayed on screen. Participants’ eye movements showed predictive processing, such that the target object was fixated before its name was heard. Moreover, when the target and the antecedent of the pronoun matched in gender, predictions arose earlier than when the two genders mismatched — a prediction advantage. We propose that the prediction advantage arises due to similarity-based interference during antecedent retrieval, such that the overlap of gender features between the antecedent and possessum boosts the activation level of the latter and helps predict it faster. We report an ACT-R model supporting this hypothesis. Our model also provides a computational implementation of the idea that prediction can be thought of as memory retrieval. In addition, we provide a preliminary ACT-R model of how linguistic processes could drive changes in visual attention. © 2021 International Conference on Cognitive Modelling",ACT-R; possessive pronouns; prediction; pronoun resolution; retrieval interference,Behavioral research; Eye movements; Eye tracking; ACT-R; Activation level; Dual-tasks; Eye-tracking; Gender predictions; Possessive pronoun; Pronoun resolution; R models; Retrieval interference; Target object; Forecasting,Conference paper,Final,,Scopus,2-s2.0-85145198937,Movies / Media
Sun G.; Lin Y.; Ran L.; Meng Y.,"Sun, Guilei (15763867500); Lin, Yun (57219305953); Ran, Linghua (35103113700); Meng, Yanhua (57209320475)",15763867500; 57219305953; 35103113700; 57209320475,Effect of Red Blue 3D Videos on Visual Fatigue,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12767 LNAI,,,427,437,10.0,1,10.1007/978-3-030-77932-0_33,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112201972&doi=10.1007%2f978-3-030-77932-0_33&partnerID=40&md5=4a16e69aee19d343c1dbe5092fa90189,"In order to analyze the visual fatigue caused by Red Blue 3D videos, a combination of subjective questionnaire survey and objective experimental data was adopted. Questionnaire investigation for visual fatigue and eye movement data were collected in the process of viewing with human machine environment synchronous platform. Three segments of 0–15 min, 15–30 min and 30–45 min were intercepted, and the normality of physiological signal data was detected by SPSS 23.0. Kruskal-Wallis test and multiple tests were used to compare the differences between the groups. The results show that the fixation time of eyes on the screen decreases and the number of blinks increases gradually with the increase of watching time. And the pupil diameter gradually decreases while the right pupil diameter is larger than the left one. The subjects are more comfortable with blue lens than red one. © 2021, Springer Nature Switzerland AG.",Left pupil; Multiple test; Physiological signals; Pupil diameter; Red and blue 3D display,Ergonomics; Eye movements; Eye movement datum; Fixation time; Kruskal-Wallis tests; Multiple test; Physiological signals; Pupil diameter; Questionnaire surveys; Visual fatigue; Surveys,Conference paper,Final,,Scopus,2-s2.0-85112201972,Movies / Media
Xie X.; Song F.; Liu Y.; Wang S.; Yu D.,"Xie, Xiaojiao (57221868555); Song, Fanghao (36769159300); Liu, Yan (55313741600); Wang, Shurui (57221867195); Yu, Dong (57221860581)",57221868555; 36769159300; 55313741600; 57221867195; 57221860581,Study on the effects of display color mode and luminance contrast on visual fatigue,2021,IEEE Access,9,,9363189,35915,35923,8.0,50,10.1109/ACCESS.2021.3061770,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101765497&doi=10.1109%2fACCESS.2021.3061770&partnerID=40&md5=7e9c8b0aa1bc99347e37915d06ff037c,"Using electronic devices at night can easily cause visual fatigue. We investigated the conjoint effects of color mode and luminance contrast on visual fatigue and subjective preference when using electronic devices under low screen luminance and low ambient illumination at night. A multidimensional approach based on eye and subjective measures was used to test 2 color modes (dark mode, light mode) and 6 luminance contrast ratios (0.969, 0.935, 0.868, 0.855, 0.725, 0.469) in a 2 × 6 experimental design. We used eye movement tracking technology to collect blink rate and pupil diameters, and used the Likert scale to measure subjective visual fatigue scale and preference. Results showed that reading in the dark mode reduced visual fatigue, as reflected by an increase in blink rate and pupil accommodation. Lower subjective visual fatigue scale and higher preference were found in the light mode due to subjects' using habits of dark texts on a light background. There was a significant negative correlation between (text-background) luminance contrast and visual fatigue, and subjects preferred higher luminance contrast. We observed the lowest visual fatigue under the luminance contrast of 0.969 in the dark mode, and the lowest subjective preference when the luminance contrast was lower than 0.725. We suggest the users should choose the dark mode to reduce visual fatigue when using electronic devices at night. These findings also provide a reference for the design of interactive interfaces such as tablets and mobile phones, and have practical implications for reducing visual fatigue.  © 2013 IEEE.",color mode; electronic devices; Eye tracking; luminance contrast; visual fatigue,Color; Electronic equipment; Eye movements; Thermoelectric equipment; Ambient illumination; Electronic device; Eye-movement tracking; Interactive interfaces; Luminance contrast; Luminance contrast ratio; Multi-dimensional approach; Negative correlation; Luminance,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85101765497,Movies / Media
Armson M.J.; Diamond N.B.; Levesque L.; Ryan J.D.; Levine B.,"Armson, Michael J. (54419483700); Diamond, Nicholas B. (57192154392); Levesque, Laryssa (57216980011); Ryan, Jennifer D. (7404485411); Levine, Brian (7402296012)",54419483700; 57192154392; 57216980011; 7404485411; 7402296012,"Vividness of recollection is supported by eye movements in individuals with high, but not low trait autobiographical memory",2021,Cognition,206,,104487,,,,21,10.1016/j.cognition.2020.104487,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092943066&doi=10.1016%2fj.cognition.2020.104487&partnerID=40&md5=fe4a477effc8aba538c7c64a1876a765,"There are marked individual differences in the recollection of personal past events or autobiographical memory (AM). Theory concerning the relationship between mnemonic and visual systems suggests that eye movements promote retrieval of spatiotemporal details from memory, yet assessment of this prediction within naturalistic AM has been limited. We examined the relationship of eye movements to free recall of naturalistic AM and how this relationship is modulated by individual differences in AM capacity. Participants freely recalled past episodes while viewing a blank screen under free and fixed viewing conditions. Memory performance was quantified with the Autobiographical Interview, which separates internal (episodic) and external (non-episodic) details. In Study 1, as a proof of concept, fixation rate was predictive of the number of internal (but not external) details recalled across both free and fixed viewing. In Study 2, using an experimenter-controlled staged event (a museum-style tour) the effect of fixations on free recall of internal (but not external) details was again observed. In this second study, however, the fixation-recall relationship was modulated by individual differences in autobiographical memory, such that the coupling between fixations and internal details was greater for those endorsing higher than lower episodic AM. These results suggest that those with congenitally strong AM rely on the visual system to produce episodic details, whereas those with lower AM retrieve such details via other mechanisms. © 2020 Elsevier B.V.",,"Cognition; Eye Movements; Humans; Memory, Episodic; Mental Recall; adult; article; autobiographical memory; eye movement; female; human; human experiment; information center; interview; male; memory; proof of concept; visual system; cognition; episodic memory; eye movement; recall",Article,Final,,Scopus,2-s2.0-85092943066,Movies / Media
Suzuki K.,"Suzuki, Keisuke (56879571700)",56879571700,Current Update on Clinically Relevant Sleep Issues in Parkinson's Disease: A Narrative Review,2021,Journal of Parkinson's Disease,11,3,,971,992,21.0,30,10.3233/JPD-202425,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112209700&doi=10.3233%2fJPD-202425&partnerID=40&md5=b0217d98e38bf3ba534045f7ef9e9736,"Sleep disturbances are among the common nonmotor symptoms in patients with Parkinson's disease (PD). Sleep can be disrupted by nocturnal motor and nonmotor symptoms and other comorbid sleep disorders. Rapid eye movement sleep behavior disorder (RBD) causes sleep-related injury, has important clinical implications as a harbinger of PD and predicts a progressive clinical phenotype. Restless legs syndrome (RLS) and its related symptoms can impair sleep initiation. Excessive daytime sleepiness (EDS) is a refractory problem affecting patients' daytime activities. In particular, during the COVID-19 era, special attention should be paid to monitoring sleep problems, as infection-prevention procedures for COVID-19 can affect patients' motor symptoms, psychiatric symptoms and sleep. Therefore, screening for and managing sleep problems is important in clinical practice, and the maintenance of good sleep conditions may improve the quality of life of PD patients. This narrative review focused on the literature published in the past 10 years, providing a current update of various sleep disturbances in PD patients and their management, including RBD, RLS, EDS, sleep apnea and circadian abnormalities. © 2021 - The authors. Published by IOS Press.",excessive daytime sleepiness; Parkinson's disease; REM sleep behavior disorder; restless legs syndrome; sleep apnea syndrome; sleep disturbances,"COVID-19; Disorders of Excessive Somnolence; Humans; Parkinson Disease; REM Sleep Behavior Disorder; Restless Legs Syndrome; Sleep Apnea Syndromes; Sleep Disorders, Circadian Rhythm; circadian rhythm sleep disorder; complication; human; parasomnia; Parkinson disease; restless legs syndrome; sleep disordered breathing; somnolence",Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85112209700,Movies / Media
Ouyang X.; Zhou J.; Xiang H.,"Ouyang, Xiwen (57203130884); Zhou, Jia (36769895100); Xiang, Honglian (57218423493)",57203130884; 36769895100; 57218423493,Screen Mirroring is not as Easy as it Seems: A Closer Look at Older Adults’ Cross-Device Experience Through Touch Gestures,2021,International Journal of Human-Computer Interaction,37,12,,1173,1189,16.0,7,10.1080/10447318.2020.1870830,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100350066&doi=10.1080%2f10447318.2020.1870830&partnerID=40&md5=8cad86d2ed7ae045a87bf9258379cd05,"Screen mirroring might be a way to improve older adults’ user experience of smart televisions (STVs) through smartphones. To examine this possibility, two experiments were conducted. Experiment I examined older adults’ difficulties of screen mirroring (mirroring smartphone screens to STVs) through five common touch gestures (“Drag,” “Slide,” “Zoom,” “Draw,” and “Handwrite”), in comparison to younger adults. The results indicated that a major problem for older adults is the frequent attention switching between the STV and smartphone screens. Therefore, experiment II explored how to reduce the need of attention switching through the touch gestures (“Tap,” “Slide + Tap,” and “Slide + Release”) and the button sizes (8, 14, and 20 mm) for different input postures. Thirty older adults participated in this experiment and their eye movements were tracked. Four major findings were derived. First, the “Zoom,” “Draw,” and “Handwrite” gestures in screen mirroring were difficult for older adults with a task completion rate lower than 68%. Second, the problem of frequent attention switching between the STV and smartphone was predominant for tapping tasks. Third, the “Slide + Tap” and “Slide + Release” touch gestures helped to reduce attention switching in tapping tasks more than the “Tap” for older adults, while the “Slide + Release” received the worst subjective feedback. Fourth, increasing the button size from 8 mm to 14 mm on smartphones can improve the task completion rate and the task efficiency in screen mirroring when older adults used the one-handed posture to tap. © 2021 Taylor & Francis Group, LLC.",,Eye movements; Fasteners; Smartphones; Switching; User experience; Attention switching; Older adults; One-handed; Subjective feedback; Task efficiencies; Touch screens,Article,Final,,Scopus,2-s2.0-85100350066,Movies / Media
Cutting J.E.,"Cutting, James E. (7005410449)",7005410449,Three filmmaking practices that guide our attention to popular cinema,2021,Art and Perception,39,6,,1,26,25.0,5,10.1163/22134913-bja10032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121764868&doi=10.1163%2f22134913-bja10032&partnerID=40&md5=d5de77eceed87e43fb2371561296ae73,"Popular movies are constructed to control our attention and guide our eye movements across the screen. Estimates of fixation locations were made by manually moving a cursor and clicking over frames at the beginnings and ends of more than 30,000 shots in 24 English-language movies. Results provide evidence for three general filmmaking practices in screen composition. The first and overriding practice is that filmmakers generally put the most import content ‒ usually the center of a character’s face ‒ slightly above the center of the screen. The second concerns two-person conversations, which account for about half of popular movie content. Dialogue shots alternate views of the speakers involved, and filmmakers generally place the conversants slightly to opposite sides of the midline. The third concerns all other shots. For those, filmmakers generally follow important content in one shot by similar content in the next shot on the same side of the vertical midline. The horizontal aspect of the first practice seems to follow from the nature of our field of view and vertical aspect from the relationship of heads to bodies depicted. The second practice derives from social norms and an image composition norm called nose room, and the third from the consideration of continuity and the speed of re-engaging attention. © Koninklijke Brill NV, Leiden, 2021",Attention; Center bias; Conversations; Eye trace; Focal points; Gaze; Inward bias; Popular movies,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85121764868,Movies / Media
Zhong M.; Jiang X.; Zhu S.; Gu R.; Bai Y.; He H.; Pan Y.; Xu P.; Yan J.; Zhang L.,"Zhong, Min (57216615208); Jiang, Xu (57211860412); Zhu, Sha (57222572070); Gu, Ruxin (57222577408); Bai, Yu (57224502737); He, Hong (55243462400); Pan, Yang (56019815300); Xu, Pingyi (7202215735); Yan, Jun (57192161062); Zhang, Li (56282181400)",57216615208; 57211860412; 57222572070; 57222577408; 57224502737; 55243462400; 56019815300; 7202215735; 57192161062; 56282181400,Sleep disturbances and associated factors in drug-naïve patients with parkinson’s disease,2021,Neuropsychiatric Disease and Treatment,17,,,3499,3508,9.0,4,10.2147/NDT.S341782,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120582318&doi=10.2147%2fNDT.S341782&partnerID=40&md5=54c332db01463d8980e72b309e6af3e5,"Purpose: Sleep disturbance is one of the common symptoms in Parkinson’s disease (PD). The study of sleep disturbance used to concentrate on treated PD. This study aimed to investigate the factors that are associated with the sleep quality of drug-naïve patients with PD. Patients and Methods: All participants were interviewed using a standard questionnaire to collect basic information. PD severity, depression symptoms, anxiety symptoms, sleep quality, cognitive status, life quality, and the presence of rapid eye movement (REM) sleep behavior disorder (RBD) and minor hallucination were assessed using corresponding rating scales. The patients with a Pittsburgh Sleep Quality Index score ≤6 fell into the poor sleep group, and those with REM Sleep Behavior Disorder Screening Questionnaire score ≥5 were considered to have probable RBD. Results: Seventy drug-naive patients with PD and 30 healthy controls matched for age, sex, and education were recruited. Up to 41.4% of the patients suffered from sleep disturbance, and 24.3% of the patients had RBD. Poor sleepers were more likely to have left-side predominant motor symptoms. Compared with good sleepers, poor sleepers, particularly female patients, had more burden in the aspect of anxiety and depression. RBD was associated with more nonmotor symptoms, poor sleep quality, bad performance in cognition orientation domain, anxiety, depression, presence of minor hallucination, and poor life quality. Conclusion: Sleep disturbances are common in drug-naïve PD and require wide attention. Motor symptom laterality and gender difference in mood are associated with sleep quality. Depression, anxiety, and RBD are highly related to sleep disturbance. RBD has many comorbidities, which can influence the cognitive function and life quality of the patients. © 2021 Zhong et al.",Anxiety; Depression; Drug naïve; Parkinson’s disease; REM sleep behavior disorder; Sleep disturbance,adult; aged; anxiety; Article; cognition; cognitive defect; cohort analysis; controlled study; depression; disease severity; factor analysis; female; hallucination; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; hemispheric dominance; human; major clinical study; male; mood; motor dysfunction; parasomnia; Parkinson disease; Pittsburgh Sleep Quality Index; quality of life; questionnaire; REM Sleep Behavior Disorder Screening Questionnaire; sex difference; sleep disorder; sleep disorder assessment; sleep quality,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85120582318,Movies / Media
Doronina K.S.; Illarioshkin S.N.; Doronina O.B.,"Doronina, K.S. (57222602942); Illarioshkin, S.N. (7004025426); Doronina, O.B. (56712953400)",57222602942; 7004025426; 56712953400,The influence of parasomnia on clinical and functional characteristics of extrapyramidal disorders; [Vliyanie parasomnii na klinicheskie i funktsional'nye kharakteristiki ekstrapiramidnykh rasstroistv],2021,Zhurnal nevrologii i psikhiatrii imeni S.S. Korsakova,121,9,,13,18,5.0,1,10.17116/jnevro202112109113,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120662054&doi=10.17116%2fjnevro202112109113&partnerID=40&md5=0ed474b6e0929c0679d130c10456d046,"OBJECTIVE: To compare clinical and functional features of the essential tremor (ET) and Parkinson's disease (PD) with- or without rapid eye movement (REM) sleep behavior disorder (RBD). MATERIAL AND METHODS: Sixty patients with PD and 52 patients with ET were examined. Cognitive functions, anxiety, asthenia and depression, autonomic disorders and sleep disorders were assessed with scales and questionnaires. All patients underwent polysomnography (PSG). Based on the results of PSG, patients were divided by the presence or absence of parasomnia, known as REM sleep behavior disorder. RESULTS: Patients with PD and ET suffering from RBD were more likely to be overweight, more likely to develop cognitive impairment, obstructive sleep apnea, and emotional disorders. In addition, presence of RBD has adverse effects on the sleep structure. The profile of memory, attention, psychoemotional and sleep disorders in patients with PD and ET had common features, which suggests that it is RPBDH that affects the change in the clinical picture. CONCLUSION: Presence of RBD aggravates non-motor manifestations of such extrapyramidal diseases as PD and ET. On the one hand it helps to predict the course of the disease, on the other hand let us suspect RBD when we see non-motor symptoms worsening.; ЦЕЛЬ ИССЛЕДОВАНИЯ: Сравнить клинические и функциональные особенности клиники эссенциального тремора (ЭТ) и болезни Паркинсона (БП) у пациентов, страдающих и не страдающих расстройством поведения в фазе сна с быстрыми движениями глаз (РПБДГ). МАТЕРИАЛ И МЕТОДЫ: Были обследованы 60 пациентов с БП и 52 пациента с ЭТ. С помощью шкал и опросников были оценены когнитивные функции пациентов, уровни тревоги, астении и депрессии, тяжесть вегетативных нарушений и нарушений сна, проведено полисомнографическое обследование. На основании результатов полисомнографии пациенты были разделены на страдающих парасомнией, известной как РПБДГ и на не имеющих этого синдрома. РЕЗУЛЬТАТЫ: Установлено, что пациенты с БП и ЭТ, страдающие РПБДГ, чаще имели избыточную массу тела, были более склонны к развитию когнитивных нарушений, обструктивного апноэ сна и эмоциональных нарушений. Профиль нарушений памяти, внимания, психоэмоционального состояния и сна у пациентов с БП и ЭТ имел общие черты, что позволяет предположить, что именно РПБДГ влияет на изменение клинической картины. ЗАКЛЮЧЕНИЕ: Наличие РПБДГ отягощает немоторные проявления таких экстрапирамидных заболеваний, как БП и ЭТ, что, с одной стороны, дает возможность прогнозировать течение заболевания при своевременном обнаружении РПБДГ, с другой стороны — исключать РПБДГ при ухудшении немоторной симптоматики.",essential tremor; non-motor symptoms; Parkinson’s disease; polysomnography; REM sleep behavior disorder; sleep disorders,Humans; Parkinson Disease; Polysomnography; REM Sleep Behavior Disorder; Sleep Wake Disorders; Surveys and Questionnaires; complication; human; parasomnia; Parkinson disease; polysomnography; questionnaire; sleep disorder,Article,Final,,Scopus,2-s2.0-85120662054,Movies / Media
Herlambang M.B.; Cnossen F.; Taatgen N.A.,"Herlambang, Mega B. (57207359222); Cnossen, Fokie (6506450627); Taatgen, Niels A. (6602372660)",57207359222; 6506450627; 6602372660,The effects of intrinsic motivation on mental fatigue,2021,PLoS ONE,16,1-Jan,e0243754,,,,60,10.1371/journal.pone.0243754,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099332002&doi=10.1371%2fjournal.pone.0243754&partnerID=40&md5=21a6db0597f65dba2b2394d9bd61adfc,"There have been many studies attempting to disentangle the relation between motivation and mental fatigue. Mental fatigue occurs after performing a demanding task for a prolonged time, and many studies have suggested that motivation can counteract the negative effects of mental fatigue on task performance. To complicate matters, most mental fatigue studies looked exclusively at the effects of extrinsic motivation but not intrinsic motivation. Individuals are said to be extrinsically motivated when they perform a task to attain rewards and avoid punishments, while they are said to be intrinsically motivated when they do for the pleasure of doing the activity. To assess whether intrinsic motivation has similar effects as extrinsic motivation, we conducted an experiment using subjective, performance, and physiological measures (heart rate variability and pupillometry). In this experiment, 28 participants solved Sudoku puzzles on a computer for three hours, with a cat video playing in the corner of the screen. The experiment consisted of 14 blocks with two alternating conditions: low intrinsic motivation and high intrinsic motivation. The main results showed that irrespective of condition, participants reported becoming fatigued over time. They performed better, invested more mental effort physiologically, and were less distracted in high-level than in low-level motivation blocks. The results suggest that similarly to extrinsic motivation, time-on-task effects are modulated by the level of intrinsic motivation: With high intrinsic motivation, people can maintain their performance over time as they seem willing to invest more effort as time progresses than in low intrinsic motivation. Copyright: © 2021 Herlambang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Adult; Female; Humans; Male; Mental Fatigue; Motivation; Task Performance and Analysis; Young Adult; adult; amplitude modulation; Article; attention; blinking; controlled study; dysthymia; executive function; extrinsic motivation; female; frequency modulation; frustration; gaze; heart rate variability; human; intrinsic motivation; male; monetary reward; problem solving; pupillometry; reaction time; saccadic eye movement; task performance; visual analog scale; motivation; task performance; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85099332002,Movies / Media
Völter C.J.; Huber L.,"Völter, Christoph J. (55953494400); Huber, Ludwig (7102868913)",55953494400; 7102868913,Expectancy Violations about Physical Properties of Animated Objects in Dogs,2021,"Proceedings of the 43rd Annual Meeting of the Cognitive Science Society: Comparative Cognition: Animal Minds, CogSci 2021",,,,2602,2608,6.0,8,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118246789&partnerID=40&md5=05cea2170017efaa8d43009397385c7c,"Dogs are not particularly known for complex physical cognitive abilities. However, a number of recent violation-of-expectation studies have challenged this view. In the current eye-tracking study, we further investigated dogs’ (N=15) reaction to physically implausible events, particularly in the context of support, occlusion, and launching events. In Experiment 1, the dogs watched a rolling ball moving over a gap in a surface either falling down or hovering over the gap. In Experiment 2, the dogs saw a ball rolling behind a narrow pole either disappearing behind it or re-appearing on the other side. In Experiment 3, the dogs observed launching events either with or without contact between the balls. The dogs’ pupil dilation response and looking times suggest that they form implicit expectations about occlusion and launching events but not about gravity-related events at least in the context of animated objects on a screen. © Cognitive Science Society: Comparative Cognition: Animal Minds, CogSci 2021.All rights reserved.",canine cognition; contact causality; expectancy violation; eye tracking; object knowledge; physical cognition; pupillometry,Launching; 'current; Canine cognition; Cognitive ability; Contact causality; Expectancy violation; Eye-tracking; Eye-tracking studies; Object knowledge; Physical cognition; Pupillometry; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85118246789,Movies / Media
Yue J.; Lu Q.; Zhu D.; Min X.; Zhang X.-P.; Zhai G.,"Yue, Jiaomin (57466602000); Lu, Qiang (57221269151); Zhu, Dandan (57197848549); Min, Xiongkuo (56030205300); Zhang, Xiao-Ping (35214025100); Zhai, Guangtao (15847120000)",57466602000; 57221269151; 57197848549; 56030205300; 35214025100; 15847120000,Inter-Observer Visual Congruency in Video-Viewing,2021,"2021 International Conference on Visual Communications and Image Processing, VCIP 2021 - Proceedings",,,,,,,1,10.1109/VCIP53242.2021.9675428,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125245446&doi=10.1109%2fVCIP53242.2021.9675428&partnerID=40&md5=ab4038b6189cc33928c1b0b4b1892335,"There are individual differences in human visual attention between observers when viewing the same scene. Inter-observer visual congruency (IOVC) describes the dispersion between different people's visual attention areas when they observe the same stimulus. Research on the IOVC of video is interesting but lacking. In this paper, we first introduce the measurement to calculate the IOVC of video. and an eye-tracking experiment is conducted in a realistic movie-watching environment to establish a movie scene dataset. Then we propose a method to predict the IOVC of video, which employs a dual-channel network to extract and integrate content and optical flow features. The effectiveness of the proposed prediction model is validated on our dataset. and the correlation between inter-observer congruency and video emotion is analyzed. © 2021 IEEE.",Inter-observer visual congruency; Movie analysis; Neural network; Visual attention,Behavioral research; Motion pictures; Channel network; Dual channel; Eye-tracking; Human visual attention; Individual Differences; Inter-observer visual congruency; Movie analysis; Movie scenes; Neural-networks; Visual Attention; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85125245446,Movies / Media
Matar E.; McCarter S.J.; St Louis E.K.; Lewis S.J.G.,"Matar, E. (55606952600); McCarter, S.J. (54967103600); St Louis, E.K. (8730449800); Lewis, S.J.G. (7404041158)",55606952600; 54967103600; 8730449800; 7404041158,Current Concepts and Controversies in the Management of REM Sleep Behavior Disorder,2021,Neurotherapeutics,18,1,,107,123,16.0,27,10.1007/s13311-020-00983-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099032426&doi=10.1007%2fs13311-020-00983-7&partnerID=40&md5=31ae7e9a3c3a442b85cf0a30600a963b,"Rapid eye movement (REM) sleep behavior disorder (RBD) is characterized by dream enactment and the loss of muscle atonia during REM sleep, known as REM sleep without atonia (RSWA). RBD can result in significant injuries, prompting patients to seek medical attention. However, in others, it may present only as non-violent behaviors noted as an incidental finding during polysomnography (PSG). RBD typically occurs in the context of synuclein-based neurodegenerative disorders but can also be seen accompanying brain lesions and be exacerbated by medications, particularly antidepressants. There is also an increasing appreciation regarding isolated or idiopathic RBD (iRBD). Symptomatic treatment of RBD is a priority to prevent injurious complications, with usual choices being melatonin or clonazepam. The discovery that iRBD represents a prodromal stage of incurable synucleinopathies has galvanized the research community into delineating the pathophysiology of RBD and defining biomarkers of neurodegeneration that will facilitate future disease-modifying trials in iRBD. Despite many advances, there has been no progress in available symptomatic or neuroprotective therapies for RBD, with recent negative trials highlighting several challenges that need to be addressed to prepare for definitive therapeutic trials for patients with this disorder. These challenges relate to i) the diagnostic and screening strategies applied to RBD, ii) the limited evidence base for symptomatic therapies, (iii) the existence of possible subtypes of RBD, (iv) the relevance of triggering medications, (v) the absence of objective markers of severity, (vi) the optimal design of disease-modifying trials, and vii) the implications around disclosing the risk of future neurodegeneration in otherwise healthy individuals. Here, we review the current concepts in the therapeutics of RBD as it relates to the above challenges and identify pertinent research questions to be addressed by future work. © 2021, The American Society for Experimental NeuroTherapeutics, Inc.",disease-modifying; neurodegeneration; REM sleep behavior disorder; sleep; treatment,Central Nervous System Depressants; Humans; Melatonin; REM Sleep Behavior Disorder; Treatment Outcome; central depressant agent; melatonin; human; parasomnia; pathophysiology; treatment outcome,Review,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85099032426,Movies / Media
Alonso C.C.G.; Silva F.G.; Costa L.O.P.; Freitas S.M.S.F.,"Alonso, Cintia C. G. (57221541660); Silva, Fernanda G. (57192552720); Costa, Leonardo O. P. (9733149600); Freitas, Sandra M. S. F. (16174482800)",57221541660; 57192552720; 9733149600; 16174482800,Smell tests to distinguish Parkinson’s disease from other neurological disorders: a systematic review and meta-analysis,2021,Expert Review of Neurotherapeutics,21,3,,365,379,14.0,16,10.1080/14737175.2021.1886925,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102362864&doi=10.1080%2f14737175.2021.1886925&partnerID=40&md5=fb393b1176245257d89cd0eb91314832,"Introduction: Olfactory impairment has been considered for differential diagnosis in Parkinson’s disease (PD) patients. The authors aimed to identify the tests used to assess the olfactory function in PD patients and examine these tests’ ability to distinguish them from other neurological disorders. Areas covered: Cross-sectional studies published until May 2020 comparing the olfactory function of PD patients to other neurological disorders were searched on PubMed, PsycInfo, Cinahl, and Web of Science databases using search terms related to PD, olfactory function, and assessment. Five thousand three hundred and four studies were screened, and 35 were included in the systematic review. Six smell tests that evaluated a total of 1,544 PD patients were identified. Data of 1,144 patients included in the meta-analyses revealed worse smell performance than individuals with other neurological disorders, such as progressive supranuclear palsy and essential tremor, but not with idiopathic rapid eye movement sleep behavior disorder. Expert opinion: The University of Pennsylvania Smell Identification Test was the most used test to assess the olfactory function of PD. Smell loss was worse in PD than in some neurological disorders. The smell tests’ ability in differentiating PD from other neurological disorders still deserves more attention in future studies. Protocol register (PROSPERO/2018-CRD42018107009). © 2021 Informa UK Limited, trading as Taylor & Francis Group.",Non-motor symptom; olfactory dysfunction; Parkinson’s disease; smell clinical tests; systematic review,"Cross-Sectional Studies; Humans; Olfaction Disorders; Parkinson Disease; Smell; Supranuclear Palsy, Progressive; adult; aged; Alzheimer disease; Article; ataxia; corticobasal degeneration; differential diagnosis; diffuse Lewy body disease; drug induced disease; drug induced parkinsonism; essential tremor; female; human; Huntington chorea; male; meta analysis; multiple sclerosis; neurologic disease; odor recognition test; parasomnia; Parkinson disease; parkinsonism; progressive supranuclear palsy; pure autonomic failure; restless legs syndrome; Shy Drager syndrome; smelling; systematic review; task performance; traumatic brain injury; vascular parkinsonism; complication; cross-sectional study; odor; progressive supranuclear palsy; smelling disorder",Article,Final,,Scopus,2-s2.0-85102362864,Movies / Media
Segijn C.M.; Voorveld H.A.M.; Vakeel K.A.,"Segijn, Claire M. (56809451000); Voorveld, Hilde A. M. (35219387600); Vakeel, Khadija Ali (57170908000)",56809451000; 35219387600; 57170908000,The Role of Ad Sequence and Privacy Concerns in Personalized Advertising: An Eye-Tracking Study into Synced Advertising Effects,2021,Journal of Advertising,50,3,,320,329,9.0,35,10.1080/00913367.2020.1870586,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100748807&doi=10.1080%2f00913367.2020.1870586&partnerID=40&md5=969bb73143452b0dd56afcd4b9c56ecc,"Synced advertising is a relatively new strategy in which ads are personalized based on concurrent media usage. The aim of this study was to explore whether the sequence in which TV commercials and tablet ads were shown in synced advertising affected consumers’ memory and attention toward advertisements in both media. Because of public debate about privacy concerns related to personalized advertising, we examined the moderating role of consumers’ privacy concerns as a personal factor. An eye-tracking experiment (N = 118) showed that, overall, synchronizing ads across media results in the most favorable cognitive responses. The placement of a tablet ad simultaneous to (versus before or after) a TV commercial for the same brand resulted in the most attention toward both ads. However, consumers with higher (versus lower) privacy concerns paid less attention to the tablet ad when it was shown simultaneously with the TV commercial, compared to consumers with lower privacy concerns. The results show that synced advertising is a promising personalized advertising strategy for the industry but at the same time it might be less effective for people with higher privacy concerns. © 2021 The Author(s). Published with license by Taylor and Francis Group, LLC.",,,Note,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85100748807,Movies / Media
Han L.; Zhang H.; Xiang Z.; Shang J.; Anjani S.; Song Y.; Vink P.,"Han, Lu (57221534346); Zhang, Hechen (57219320340); Xiang, Zhongxia (7102139000); Shang, Jinze (57221531844); Anjani, Shabila (57222024405); Song, Yu (55494041400); Vink, Peter (7006242402)",57221534346; 57219320340; 7102139000; 57221531844; 57222024405; 55494041400; 7006242402,Desktop lighting for comfortable use of a computer screen,2021,Work,68,s1,,S209,S221,12.0,10,10.3233/WOR-208018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099374717&doi=10.3233%2fWOR-208018&partnerID=40&md5=e51ebbbe3616e68488e14c138b573ac4,"BACKGROUND: The contrast between a bright computer screen and a dark ambient environment may influence comfort of the users, especially on their eyes. OBJECTIVE: The objective of this research is to identify the optimal desktop lighting for the comfortable use of the computer screen in a dark environment. METHODS: An experiment was designed where seven illumination setups were introduced for the users to perform their leisure tasks on a computer screen. Fifteen healthy subjects participated in the experiments. During each session, durations of the eye blinks, fixations and saccades of the user were recorded by an eye tracker. His/her neck and trunk movements were recorded by a motion tracking system as well. The comfort/discomfort questionnaire, localized postural discomfort questionnaire, NASA task load index and computer user questionnaire were used to record the overall comfort/discomfort, the local perceived physical discomfort, the cognitive workload, and general/eye health problems, respectively. RESULTS: Subjective and objective measurement results indicated that users felt more comfortable with high intensity warm lights using a computer screen. We also identified that the eye fixation durations, as well as the scores of two questions in the computer user questionnaire, have significant negative correlations with comfort. On the other side, the durations of blinks and the scores of three questions in the computer user questionnaire, were significantly correlated with discomfort. CONCLUSION: The warm (3000K) and high intensity (1500 lux) light reduced the visual and cognitive fatigue of the user and therefore improve the comfort of the user during the use of a computer screen. © 2021 - The authors. Published by IOS Press.",design; eye tracking; Light,Cognition; Computer Terminals; Computers; Female; Humans; Lighting; Male; Movement; Workload; cognition; computer; computer terminal; female; human; illumination; male; movement (physiology); workload,Conference paper,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85099374717,Movies / Media
Berget G.; Fagernes S.,"Berget, Gerd (55204862100); Fagernes, Siri (24176517200)",55204862100; 24176517200,Reading experiences and reading efficiency among adults with dyslexia: An accessibility study,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12769 LNCS,,,221,240,19.0,4,10.1007/978-3-030-78095-1_17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117922348&doi=10.1007%2f978-3-030-78095-1_17&partnerID=40&md5=fd979de3938c5424e1a38875cfe1544c,"Dyslexia is a common reading disorder that typically affects reading, concentration and short-term memory. Consequently, for people with dyslexia, reading fictional books might be challenging. Several studies have addressed layout and typography of digital texts. Less attention has been directed towards printed books. It has been suggested that e-readers might be beneficial for some people in this cohort. In this study, however, all the participants preferred reading fictional books on paper. This study investigates whether different line lengths affect reading experiences and reading efficiency of people with dyslexia. The overall purpose is to get a better understanding of how to produce accessible books. The experiments involve 20 adults reading excerpts from three fictional books in four different conditions where line length is the only independent variable. A screening-test for dyslexia was applied, in addition to eye-tracking and interviews. The findings indicate that the participants do not prefer narrow line lengths. However, the results show no significant impact of line lengths on reading speed or comprehension. The main conclusion is that line lengths seem to affect reading motivation, but not performance. © Springer Nature Switzerland AG 2021.",Dyslexia; Line lengths; Reading,Efficiency; Condition; Digital text; Dyslexium; E-reader; Line length; Printed books; Reading; Reading disorders; Reading efficiencies; Short term memory; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85117922348,Movies / Media
Vergara A.; Siles I.; Castro A.C.; Chaves A.,"Vergara, Adrián (38261075500); Siles, Ignacio (50362167000); Castro, Ana Claudia (57218668510); Chaves, Alonso (57218675251)",38261075500; 50362167000; 57218668510; 57218675251,The Mechanisms of “Incidental News Consumption”: an Eye Tracking Study of News Interaction on Facebook,2021,Digital Journalism,9,2,,215,234,19.0,20,10.1080/21670811.2020.1813047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089970781&doi=10.1080%2f21670811.2020.1813047&partnerID=40&md5=99d1cc48e320acbfc7f9b9a1f3262f71,"This exploratory study examines how participants incidentally consumed news on social media through an eye tracking analysis of their visual interaction with posts on Facebook. By interaction, we refer to the attention participants gave to news (measured through the time devoted to looking at the content); how they read these news items (measured through ocular movements on the screen); and the way they engaged with this content (measured through forms of participation such as liking, commenting, or sharing news). The data were triangulated through interviews with Facebook users and an analysis of the metrics of posts from Costa Rican news organizations on Facebook from 2017 to 2020. We draw on scholarship in communication studies and multimodal discourse analysis. We argue for a more nuanced approach to what study participants did when they incidentally encountered news on social media that focuses on mechanisms, that is, the specific procedures and operations that shape user interaction with news on Facebook (such as visual fixations on parts of news posts; the visual entry points through which they begin to interact with the news; the sequences that characterize how they navigate content; and the time they spend assessing various multimodal elements). © 2020 Informa UK Limited, trading as Taylor & Francis Group.",Eye tracking measurement; Facebook; incidental news; Latin America; news consumption; social media,,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85089970781,Movies / Media
Cui Y.; Zheng B.,"Cui, Yixiao (57216853232); Zheng, Binghan (55512006100)",57216853232; 55512006100,"Consultation behaviour with online resources in English-Chinese translation: an eye-tracking, screen-recording and retrospective study",2021,Perspectives: Studies in Translation Theory and Practice,29,5,,740,760,20.0,16,10.1080/0907676X.2020.1760899,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085003875&doi=10.1080%2f0907676X.2020.1760899&partnerID=40&md5=d2e825d63831a1e7b37232721abc9aac,"This paper investigates the interaction between translators’ perceived translation problems and their online consultation behaviours, and how different consultation behaviours affect translation acceptability. Previous studies indicate that online consultation includes various types of complex information-searching behaviours which, to a great extent, depend on the personal preferences of the web users. In this study, 38 MA translation students translated two 100-word texts from English (L2) into Chinese (L1) using Translog II, with their translations and consultation processes being registered by a Tobii TX300 eye-tracker. The main findings are as follows: (1) an increase in perceived translation difficulty leads to an increase in both the time spent on online consultation and the complexity of the consultation, but does not lead to an increase in the cognitive load expended on consultation; (2) general translation problems, which involve more resource types and longer search times, require more consultation time than specific translation problems; (3) two sub-types of consultation behaviour, information-seeking and information relevance evaluation, are purpose-driven and (4) longer consultation time results in higher acceptability of individual translation solutions, while higher consultation complexity does not. © 2020 Informa UK Limited, trading as Taylor & Francis Group.",English-Chinese translation; eye-tracking; Information behaviour; online consultation; retrospection,,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85085003875,Movies / Media
Palmieri A.; Meconi F.; Vallesi A.; Capizzi M.; Pick E.; Marcato S.; Kleinbub J.R.; Sorarù G.; Sessa P.,"Palmieri, Arianna (25722808600); Meconi, Federica (56118712800); Vallesi, Antonino (10639787000); Capizzi, Mariagrazia (24471569300); Pick, Emanuele (57204058505); Marcato, Sonia (56422122900); Kleinbub, Johann R. (55425724900); Sorarù, Gianni (57222417541); Sessa, Paola (14023511500)",25722808600; 56118712800; 10639787000; 24471569300; 57204058505; 56422122900; 55425724900; 57222417541; 14023511500,Enhanced neural empathic responses in patients with spino-bulbar muscular atrophy: An electrophysiological study,2021,Brain Sciences,11,1,16,1,17,16.0,8,10.3390/brainsci11010016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098779473&doi=10.3390%2fbrainsci11010016&partnerID=40&md5=52685d0e0878312313576e00f246e7fb,"Background: Spino-bulbar muscular atrophy is a rare genetic X-linked disease caused by testosterone insensitivity. An inverse correlation has been described between testosterone levels and empathic responses. The present study explored the profile of neural empathic responding in spino-bulbar muscular atrophy patients. Methods: Eighteen patients with spino-bulbar muscular atrophy and eighteen healthy male controls were enrolled in the study. Their event-related potentials were recorded during an “Empathy Task” designed to distinguish neural responses linked with experience-sharing (early response) and mentalizing (late response) components of empathy. The task involved the presentation of contextual information (painful vs. neutral sentences) and facial expressions (painful vs. neutral). An explicit dispositional empathy-related questionnaire was also administered to all participants, who were screened via neuropsychological battery tests that did not reveal potential cognitive deficits. Due to electrophysiological artefacts, data from 12 patients and 17 controls were finally included in the analyses. Results: Although patients and controls did not differ in terms of dispositional, explicit empathic self-ratings, notably conservative event-related potentials analyses (i.e., spatio-temporal permutation cluster analyses) showed a significantly greater experience-sharing neural response in patients compared to healthy controls in the Empathy-task when both contextual information and facial expressions were painful. Conclusion: The present study contributes to the characterization of the psychological profile of patients with spino-bulbar muscular atrophy, highlighting the peculiarities in enhanced neural responses underlying empathic reactions. © 2020 by the authors. Li-censee MDPI, Basel, Switzerland.",Empathy; Event-related potentials; Experience-sharing; Mentalizing; Spino-bulbar muscular atrophy (SBMA),glutamic acid; hydrocortisone; testosterone; adult; adverse drug reaction; aged; Article; artifact; autism; behavior; case control study; clinical article; cluster analysis; cognition; cognitive defect; controlled study; depersonalization; electroencephalography; electrophysiology; emotionality; empathy; event related potential; eye tracking; facial expression; facial recognition; female; gynecomastia; heterozygote; human; human experiment; Kennedy disease; Likert scale; male; mentalization; middle aged; motor neuron disease; muscle atrophy; nerve potential; neurologic examination; questionnaire; reaction time; spectroscopy; sun exposure; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85098779473,Movies / Media
Sun G.; Zhang J.; Zheng K.; Fu X.,"Sun, Guangmin (8431278000); Zhang, Junjie (55755117900); Zheng, Kun (57072537200); Fu, Xiaohui (57221081174)",8431278000; 55755117900; 57072537200; 57221081174,Eye tracking and ROI detection within a computer screen using a monocular camera,2020,Journal of Web Engineering,19,8-Jul,,1117,1146,29.0,12,10.13052/jwe1540-9589.19789,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098231736&doi=10.13052%2fjwe1540-9589.19789&partnerID=40&md5=30114c8e6105816875f984b1b19eebb8,"The region of interest will change according to the task, even in the same situation. In the study, a method for region of interest detection within a computer screen using a monocular camera is proposed. In contrast to gaze tracking techniques that require particular devices (e.g., an eye tracker and RGB-D device) meanwhile complex calibration, a cheap and more convenient monocular camera is used in this study to solves the eye gaze tracking problem. Firstly, Human face is detected in a real-time video sequence using HoG features. Then, the landmarks around the eyes, which reflect the gaze position, are extracted. Next, the iris centers are detected in the eye region. In order to reduce the gaze error caused by head movement, a three-dimensional head model is proposed to estimate head pose. Finally, the eye region is tracked by calculating the eye vectors and head movement. Experiments were performed to evaluate the face detection, landmarks, iris detection, eye movement estimation, and head pose estimation on databases such as the Hong Kong, BioID, and Boston University head pose databases. Besides, experiments for gaze tracking were performed for a real-time video sequence. Deviation is calculated using Euclidean distance between the real and estimated points. The results show that the method achieves an average error of 1.85◦ with head fixed and 3.58◦ with head movement in the range of −45◦ and 45◦. The requirement is detecting the user's attention in the screen area. Our method can reach the same level to the other methods, even though the accuracy is not state-of-the-art. Meanwhile, as we all know not only a specific point is concerned but also a region area according to the characteristics of human eye imaging, thus the proposed method can meet the requirements of demand. © 2020 River Publishers",Gaze tracking; Iris detection; Monocular camera; ROI detection,,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85098231736,Movies / Media
Rose S.A.; Wass S.V.; Jankowski J.J.; Djukic A.,"Rose, Susan A. (7402127955); Wass, Sam V. (36169394400); Jankowski, Jeffery J. (7102760195); Djukic, Aleksandra (6507348992)",7402127955; 36169394400; 7102760195; 6507348992,Measures of Attention in Rett Syndrome: Internal Consistency Reliability,2021,Neuropsychology,35,6,,595,608,13.0,2,10.1037/neu0000744,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108974237&doi=10.1037%2fneu0000744&partnerID=40&md5=b71a84612001ca4806850d7049077f36,"Objective: Rett syndrome (RTT), an x-linked neurodevelopmental disorder caused by spontaneous mutations in the MECP2 gene, is characterized by profound impairments in expressive language and purposeful hand use. We have pioneered the use of gaze-based tasks to by-pass these limitations and developed measures suitable for clinical trials with RTT. Here we estimated internal consistency reliability for three aspects of attention that are key to cognitive growth and that we previously identified as impaired in RTT. Method: Using a sample of 66 children with RTT (2–19 years), we assessed Sustained Attention (butterfly task: Butterfly traverses the screen only when fixated and distractors are ignored); Disengaging/ Shifting Attention (“gap/overlap” task: Shifts of gaze from central to peripheral targets are compared in conditions where the central stimulus remains or disappears at the onset of the peripheral target); Selective Attention (search task: the target is embedded in arrays differing in size and distractor type). Results: Reliability was acceptable to excellent on almost all key measures from tasks assessing Sustained Attention and Disengaging/Shifting Attention, with split-half coefficients and Cronbach alphas ranging from.70 to.93. Reliability increased as more trials were aggregated, with acceptable levels often reached with as few as six to nine trials. Measures from Selective Attention showed only limited reliability. Conclusion: Finding that critical aspects of attention can be reliably assessed in RTT with gaze-based tasks constitutes a major advance in the development of cognitive measures appropriate for clinical and translational work. © 2021 American Psychological Association",Attention; Eye-tracking; Reliability; Rett syndrome,Attention; Child; Humans; Language; Mutation; Reproducibility of Results; Rett Syndrome; adolescent; adult; Article; attention; child; clinical feature; cognition; cognitive development; controlled study; disengaging attention; executive function; female; gaze; human; internal consistency; major clinical study; patient participation; Rett syndrome; school child; selective attention; sensory stimulation; shifting attention; sustained attention; attention; complication; genetics; language; mutation; reproducibility; Rett syndrome,Article,Final,,Scopus,2-s2.0-85108974237,Movies / Media
Riches S.; Pisani S.; Bird L.; Rus-Calafell M.; Garety P.; Valmaggia L.,"Riches, Simon (55872502500); Pisani, Sara (57220155903); Bird, Leanne (57214808066); Rus-Calafell, Mar (35094538900); Garety, Philippa (7004167371); Valmaggia, Lucia (23006795600)",55872502500; 57220155903; 57214808066; 35094538900; 7004167371; 23006795600,Virtual reality-based assessment and treatment of social functioning impairments in psychosis: a systematic review,2021,International Review of Psychiatry,33,3,,337,362,25.0,24,10.1080/09540261.2021.1918648,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107732692&doi=10.1080%2f09540261.2021.1918648&partnerID=40&md5=a7f754bec24ea1e1eb226760b2f6a3c2,"People with psychosis can experience social functioning impairments. Virtual reality (VR) has been used to assess and treat these difficulties. This systematic review (Prospero CRD42015026288) provides an evaluation of these VR applications. PsycINFO, MEDLINE, Embase, Web of Science, Cochrane Library, and Scopus were searched until May 2020. The Effective Public Health Practice Project (EPHPP) Quality Assessment Tool was used to assess studies. Database searching identified 3810 titles. Fifty-eight studies (published 2005–2020; N = 2,853), comprising twenty-six head-mounted display studies (20 assessment, 6 treatment) and thirty-two immersive 2D screen studies (23 assessment, 9 treatment), were included. There were forty-eight observational studies and ten randomised controlled trials, with 1570 participants (of which, 185 were at ultra-high risk of psychosis) in VR test groups. Nearly half the studies were published since 2016. Assessments targeted cognitive and behavioural indicators of social functioning, e.g. paranoia, eye gaze, or interpersonal distance. Treatments promoted cognitive-behavioural social skills or job interview training. Studies indicate feasibility, acceptability, and effectiveness of VR for social functioning impairments in psychosis. Limitations of studies include the narrow scope of social functioning, small sample sizes, and limited randomised controlled trials and standardised interventions. Findings suggest VR has potential to be integrated with existing psychological approaches. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",psychosis; schizophrenia; social functioning; systematic review; Virtual reality,Humans; Psychotic Disorders; Social Interaction; Virtual Reality; aripiprazole; risperidone; adult; behavior; bipolar disorder; clinical assessment; clinical effectiveness; Cochrane Library; cognition; Embase; female; functional magnetic resonance imaging; gaze; human; male; Medline; observational study; paranoia; patient safety; psychosis; PsycINFO; randomized controlled trial (topic); Review; schizophrenia; Scopus; social competence; social disability; social distance; social interaction; systematic review; virtual reality exposure therapy; Web of Science; psychology; psychosis; virtual reality,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85107732692,Movies / Media
McKay K.T.; Grainger S.A.; Coundouris S.P.; Skorich D.P.; Phillips L.H.; Henry J.D.,"McKay, Kate T. (57571711800); Grainger, Sarah A. (57194713728); Coundouris, Sarah P. (57194538859); Skorich, Daniel P. (55772392400); Phillips, Louise H. (58433682000); Henry, Julie D. (7403672085)",57571711800; 57194713728; 57194538859; 55772392400; 58433682000; 7403672085,Visual Attentional Orienting by Eye Gaze: A Meta-Analytic Review of the Gaze-Cueing Effect,2021,Psychological Bulletin,147,12,,1269,1289,20.0,79,10.1037/bul0000353,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127957685&doi=10.1037%2fbul0000353&partnerID=40&md5=3e1943fe600eeca3eb247ba2c1e6ef63,"Given limitations in the amount of visual information that a person can simultaneously process through to conscious perception, selective visual attention is necessary. Visual signals in the environment aid this selection process by triggering reflexive shifts of covert attention to locations of potential importance. One such signal appears to be others’ eye gaze. Indeed, a gaze-cueing effect, whereby healthy adults respond faster to targets that are presented at locations cued rather than miscued by eye gaze has been consistently observed in the empirical literature. Critically though, the influences of task and cue features on this effect are not well understood. To address this gap, we report a meta-analytic integration of 423 gaze-cueing effects using a multilevel approach. A gaze-cueing effect emerged across all levels of the assessed task and cue features, indicating that others’ eye gaze reliably directs observers’ attention. We found that the magnitude of the gaze-cueing effect was moderated by whether direct gaze cues preceded directional gaze cues or not; the cue-target stimulus onset asynchrony (SOA), whether participants had to detect, localize, or categorize targets; and the cue’s facial expression. Whether or not the gaze cue remained on screen after the target appeared, and whether schematic faces, computer-generated faces, or images of real faces were used as cues, did not appear to reliably function as moderators. The theoretical implications of these findings are discussed, particularly in relation to the social attention system © 2021. American Psychological Association",Emotional expression; Gaze-cueing; Social attention; Social perception; Visual attention,"Adult; Attention; Cues; Facial Expression; Fixation, Ocular; Humans; Reaction Time; adult; association; attention; eye fixation; facial expression; human; meta analysis; reaction time",Article,Final,,Scopus,2-s2.0-85127957685,Movies / Media
Hoydis J.,"Hoydis, Julia (57196052958)",57196052958,"Dialogues with the Machine, or Ruins of Closure and Control in Interactive Digital Narratives",2021,Open Library of Humanities,7,2,,1,24,23.0,3,10.16995/OLH.4695,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134511931&doi=10.16995%2fOLH.4695&partnerID=40&md5=b521942c4b1c09f14e19bd38fb5a8a64,"The interrelations between literary studies and posthumanism deserve attention beyond the focus on the representation of posthuman identities on the story level. To explore these, this article looks at examples of interactive digital narratives (IDN): Bandersnatch (2018), a ‘choose-your-own-adventure’-type instalment of Netflix’s dystopian Sci Fi-anthology series Black Mirror, the short film The Angry River (2017), which employs gaze-detection technology to determine what viewers get to see, and the serious multi-platform videogame The Climate Trail (2019), specifically designed to move players ‘into action’. Straddling the border between ludology and narrative to varying degrees, all offer the chance of ‘do-overs’ and the exploration of complex patterns and processes. They raise questions about the co-production of pre-scripted meanings, about authorial and reader agency, conceptions of control, closure, and narrative (un)reliability. Thus, this article argues, they challenge ideas about the potential of narratives in and beyond posthuman digital environments. © 2021. The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.",,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85134511931,Movies / Media
Indi C.S.; Pritham K.V.; Acharya V.; Prakasha K.,"Indi, Chirag S. (57223967428); Pritham, KCS Varun (57223958751); Acharya, Vasundhara (57220157427); Prakasha, Krishna (57204156598)",57223967428; 57223958751; 57220157427; 57204156598,Detection of Malpractice in E-exams by Head Pose and Gaze Estimation,2021,International Journal of Emerging Technologies in Learning,16,8,,47,60,13.0,26,10.3991/ijet.v16i08.15995,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106666043&doi=10.3991%2fijet.v16i08.15995&partnerID=40&md5=6bba1c097e5d4c02931c71aa987aba2b,"Examination malpractice is deliberate wrongdoing contrary to official examination rules designed to place a candidate at an unfair advantage or disadvantage. The proposed system depicts a new use of technology to identify malpractice in e-exams, which is essential due to online education growth. The current solutions for such a problem either require complete manual labor or have various vulnerabilities exploited by an examinee. The proposed application encompasses an end-to-end system that assists an examiner/evaluator in deciding whether a student passes an online exam without any probable attempts of malpractice or cheating in e-exams with the help of visual aids. The system works by categorizing the student’s VFOA (visual focus of attention) data by capturing the head pose estimates and eye gaze estimates using state-of-the-art machine learning (ML) techniques. The system only requires the student (test-taker) to have a functioning internet connection and a webcam to transmit the feed. The examiner is alerted when the student wavers in his VFOA from the screen greater than X, a predefined threshold of times. If this threshold X is crossed, the application will save the person’s data when his VFOA is off the screen and send it to the examiner to be manually checked and marked whether the student’s action was attempted malpractice or just a momentary lapse in concentration. The system uses a hybrid classifier approach where two different classifiers are used. One when gaze values are being read successfully. On failing this due to various reasons like transmission quality or glare from his spectacles, the model falls back to the default classifier, which only reads the head pose values to classify the attention metric. It is later used to map the student’s VFOA to check the likelihood of malpractice. The model has achieved an accuracy of 96.04 percent in classifying the attention metric. © 2021",Automated proctoring model; Gaze estimation; Head post estimation; Hybrid classifier; Machine learning; Malpractice detection; Online proctoring system; Visual focus of attention,Electronic assessment; Students; End-to-end systems; Gaze estimation; Hybrid classifier; Internet connection; On-line education; State of the art; Transmission quality; Visual focus of attentions; Education computing,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85106666043,Movies / Media
Smith K.G.; Bhutada A.M.,"Smith, Kimberly G. (57037492600); Bhutada, Ankita M. (57212508711)",57037492600; 57212508711,Detailed vision screening results from a cohort of individuals with aphasia,2021,Aphasiology,35,2,,186,199,13.0,3,10.1080/02687038.2019.1702918,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076886066&doi=10.1080%2f02687038.2019.1702918&partnerID=40&md5=a03f6e55aac1d6063bfa745ca3580f9a,"Background: Visual functioning is often affected in persons with aphasia following stroke and other brain injuries. Characterizing the visual functioning of persons with aphasia is imperative in both clinical and research domains; however, visual functioning of persons with aphasia is infrequently assessed or described in either domain. Aims: This study aims to examine the utility of various visual screening measures and document the results of the screening tools for a cohort of persons with aphasia. Methods & Procedures: Twenty-three individuals with chronic aphasia completed a detailed vision screening using a visual case history, the Visual Activities Questionnaire, the McDowell Vision Screening Kit, an Amsler grid, the line bisection task, and the National Institutes of Health Stroke Scale item 3-visual. Outcomes & Results: Two-thirds of the participants reported significant visual histories with only one participant reporting stroke-related visual deficits. On average, the group rated visual difficulty during daily activities as never or rarely occurring, with the least difficulty reported for color discrimination and the most difficulty with visual acuity and visual search, though still only occurring rarely. All participants passed the cover/uncover screening task measuring ocular alignment and motility, the color perception screening task, and several tasks measuring ocular function. Failing scores, however, were assigned for about half of the participants for distance visual acuity, and only three participants for near visual acuity. Visual fields were normal for about two-thirds of the participants and all participants presented with normal visual attention. Conclusions: The results suggest that visual deficits are common in persons with aphasia, but are not necessarily related to the stroke that the person experienced. The results highlight the need to screen the vision of persons with aphasia both for clinical purposes and research protocols to ensure visual deficits are treated, compensated for, or controlled. © 2019 Informa UK Limited, trading as Taylor & Francis Group.",Aphasia; screening; vision,adult; age related macular degeneration; amblyopia; aphasia; Article; binocular vision; cataract extraction; clinical article; color discrimination; color vision; daily life activity; depth perception; disease severity; eye disease; eye tracking; female; glare; human; low vision; male; McDowell Vision Screening Kit; medical history; middle aged; National Institutes of Health Stroke Scale; perception deafness; prevalence; quality of life; scoring system; screening; vision; vision test; visual Activities Questionnaire; visual acuity; visual attention; visual field; Wechsler adult intelligence scale,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85076886066,Movies / Media
Kratzke I.M.; Campbell A.; Yefimov M.N.; Mosaly P.R.; Adapa K.; Meltzer-Brody S.; Farrell T.M.; Mazur L.M.,"Kratzke, Ian M. (57211082689); Campbell, Alana (42461042900); Yefimov, Mae N. (57219422613); Mosaly, Prithima R. (35311368100); Adapa, Karthik (57190153566); Meltzer-Brody, Samantha (6603020320); Farrell, Timothy M. (34769803500); Mazur, Lukasz M. (23470089000)",57211082689; 42461042900; 57219422613; 35311368100; 57190153566; 6603020320; 34769803500; 23470089000,Pilot Study Using Neurofeedback as a Tool to Reduce Surgical Resident Burnout,2021,Journal of the American College of Surgeons,232,1,,74,80,6.0,15,10.1016/j.jamcollsurg.2020.08.762,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092641452&doi=10.1016%2fj.jamcollsurg.2020.08.762&partnerID=40&md5=dc7c6f48a58c97a9b7fa18576c4d71eb,"Background: Burnout is prevalent among surgical residents. Neurofeedback is a technique to train the brain in self-regulation skills. We aimed to assess the impact of neurofeedback on the cognitive workload and personal growth areas of surgery residents with burnout and depression. Study Design: Fifteen surgical residents with burnout (Maslach Burnout Inventory [MBI] score > 27) and depression (Patient Health Questionnaire–9 Depression Screen [PHQ-9] score >10), from 1 academic institution, were enrolled and participated in this institutional review board-approved prospective study. Ten residents with more severe burnout and depression scores were assigned to receive 8 weeks of neurofeedback treatments, and 5 others with less severe symptoms were treated as controls. Each participant's cognitive workload (or mental effort) was assessed initially, and again after treatment via electroencephalogram (EEG) while the subjects performed n-back working memory tasks. Analysis of variance (ANOVA) tested for significance between the degree of change in the treatment and control groups. Each subject was also asked to rate changes in growth areas, such as sleep and stress. Results: Both groups showed high cognitive workload in the pre-assessment. After the neurofeedback intervention, the treatment group showed a significant (p < 0.01) improvement in cognitive workload via EEG during the working memory task. These differences were not noted in the control group. There was significant correlation between time (NFB sessions) and average improvement in all growth areas (r = 0.98) Conclusions: Residents demonstrated high levels of burnout, correlating with EEG patterns indicative of post-traumatic stress disorder. There was a notable change in cognitive workload after the neurofeedback treatment, suggesting a return to a more efficient neural network. © 2020",,"Burnout, Professional; Electroencephalography; General Surgery; Humans; Internship and Residency; Neurofeedback; Occupational Stress; Pilot Projects; Surveys and Questionnaires; analysis of variance; burnout; clinical article; cognition; Conference Paper; controlled study; correlation analysis; data analysis software; depression; disease severity; electroencephalogram; human; Maslach Burnout Inventory; neurofeedback; Patient Health Questionnaire 9; pilot study; posttraumatic stress disorder; priority journal; prospective study; resident; sleep; software; stress; task performance; verbal feedback; visual feedback; working memory; burnout; diagnosis; education; electroencephalography; etiology; general surgery; job stress; medical education; neurofeedback; pathophysiology; prevention and control; procedures; psychology; questionnaire",Conference paper,Final,,Scopus,2-s2.0-85092641452,Movies / Media
Ramot M.; Walsh C.; Reimann G.E.; Martin A.,"Ramot, Michal (35311632200); Walsh, Catherine (57209703156); Reimann, Gabrielle Elise (57201975115); Martin, Alex (35446495000)",35311632200; 57209703156; 57201975115; 35446495000,Distinct neural mechanisms of social orienting and mentalizing revealed by independent measures of neural and eye movement typicality,2020,Communications Biology,3,1,48,,,,11,10.1038/s42003-020-0771-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078689481&doi=10.1038%2fs42003-020-0771-1&partnerID=40&md5=60d3ad53e0796a4ad3bde6c0f90fe0e6,"Extensive study of typically developing individuals and those on the autism spectrum has identified a large number of brain regions associated with our ability to navigate the social world. Although it is widely appreciated that this so-called “social brain” is composed of distinct, interacting systems, these component parts have yet to be clearly elucidated. Here we used measures of eye movement and neural typicality—based on the degree to which subjects deviated from the norm—while typically developing (N = 62) and individuals with autism (N = 36) watched a large battery of movies depicting social interactions. Our findings provide clear evidence for distinct, but overlapping, neural systems underpinning two major components of the “social brain,” social orienting, and inferring the mental state of others. © 2020, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.",,Adolescent; Adult; Attention; Autism Spectrum Disorder; Brain Mapping; Cognitive Neuroscience; Cohort Studies; Cues; Eye Movement Measurements; Eye Movements; Female; Humans; Magnetic Resonance Imaging; Male; Mentalization; Motion Pictures; Nerve Net; Social Behavior; Young Adult; adolescent; adult; association; attention; autism; brain mapping; cognitive neuroscience; cohort analysis; eye movement; female; human; male; movie; nerve cell network; nuclear magnetic resonance imaging; oculography; physiology; procedures; psychology; social behavior; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85078689481,Movies / Media
Caruana N.; Alhasan A.; Wagner K.; Kaplan D.M.; Woolgar A.; McArthur G.,"Caruana, Nathan (56251828400); Alhasan, Ayeh (57219895969); Wagner, Kirilee (57219892909); Kaplan, David M (40761453600); Woolgar, Alexandra (25636632200); McArthur, Genevieve (7005268526)",56251828400; 57219895969; 57219892909; 40761453600; 25636632200; 7005268526,The effect of non-communicative eye movements on joint attention,2020,Quarterly Journal of Experimental Psychology,73,12,,2389,2402,13.0,6,10.1177/1747021820945604,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095946924&doi=10.1177%2f1747021820945604&partnerID=40&md5=b78a6358039b672d5d599adf15347b05,"Eye movements provide important signals for joint attention. However, those eye movements that indicate bids for joint attention often occur among non-communicative eye movements. This study investigated the influence of these non-communicative eye movements on subsequent joint attention responsivity. Participants played an interactive game with an avatar which required both players to search for a visual target on a screen. The player who discovered the target used their eyes to initiate joint attention. We compared participants’ saccadic reaction times (SRTs) to the avatar’s joint attention bids when they were preceded by non-communicative eye movements that predicted the location of the target (Predictive Search), did not predict the location of the target (Random Search), and when there were no non-communicative eye gaze movements prior to joint attention (No Search). We also included a control condition in which participants completed the same task, but responded to a dynamic arrow stimulus instead of the avatar’s eye movements. For both eye and arrow conditions, participants had slower SRTs in Random Search trials than No Search and Predictive Search trials. However, these effects were smaller for eyes than for arrows. These data suggest that joint attention responsivity for eyes is relatively stable to the presence and predictability of spatial information conveyed by non-communicative gaze. Contrastingly, random sequences of dynamic arrows had a much more disruptive impact on subsequent responsivity compared with predictive arrow sequences. This may reflect specialised social mechanisms and expertise for selectively responding to communicative eye gaze cues during dynamic interactions, which is likely facilitated by the integration of ostensive eye contact cues. © Experimental Psychology Society 2020.",eye gaze; eye tracking; Joint attention; social cognition; social interaction,"Attention; Cues; Eye Movements; Fixation, Ocular; Humans; Reaction Time; association; attention; eye fixation; eye movement; human; reaction time",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85095946924,Movies / Media
Yang H.; Li J.; Han Y.; Hu M.,"Yang, Haoyu (57223692510); Li, Jiuwei (57223712266); Han, Yong (59786542300); Hu, Maorong (49663240600)",57223692510; 57223712266; 59786542300; 49663240600,Research on the application of new generation of Human-computer interaction in education,2020,"Proceedings - 2020 International Conference on Information Science and Education, ICISE-IE 2020",,,9418810,382,385,3.0,5,10.1109/ICISE51755.2020.00089,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105985932&doi=10.1109%2fICISE51755.2020.00089&partnerID=40&md5=df71145a9d76c8fae29c7f24fbeb0a9b,"Natural user interface is a new generation of human-computer interaction. It takes nature as the core and has speech recognition, gesture recognition, touch screen, touch, eye movement tracking and brain-computer interface. Natural user interfaces are suitable for education because they reduce cognitive load, improve learning immersion, and facilitate access to learning feedback. Based on the natural user interface, this paper explores the psychological theory foundation and application mode of human-computer interaction in teaching.  © 2020 IEEE.",Education application; Educational psychology; Human-computer interaction; Naturaluser interfaces,Brain computer interface; Eye movements; Gesture recognition; Speech recognition; Touch screens; User interfaces; Application modes; Cognitive loads; Eye-movement tracking; Human-computer interaction in educations; Natural user interfaces; Psychological theory; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85105985932,Movies / Media
Cohn N.; Foulsham T.,"Cohn, Neil (36015038400); Foulsham, Tom (8983741300)",36015038400; 8983741300,Zooming in on the cognitive neuroscience of visual narrative,2020,Brain and Cognition,146,,105634,,,,16,10.1016/j.bandc.2020.105634,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094976565&doi=10.1016%2fj.bandc.2020.105634&partnerID=40&md5=3ea4653e561b84e1126a2a5134f9bd3b,"Visual narratives like comics and films often shift between showing full scenes and close, zoomed-in viewpoints. These zooms are similar to the “spotlight of attention” cast across a visual scene in perception. We here measured ERPs to visual narratives (comic strips) that used zoomed-in and full-scene panels either throughout the whole sequence context or at specific critical panels. Zoomed-in panels were automatically generated on the basis of fixations from prior participants’ eye movements to the crucial content of panels (Foulsham & Cohn, 2020). We found that these fixation panels evoked a smaller N300 than full-scenes, indicative of reduced cost for object identification, but that they also evoked a slightly larger amplitude N400 response, suggesting a greater cost for accessing semantic memory with constrained content. Panels in sequences where fixation panels persisted across all positions of the sequence also evoked larger posterior P600s, implying that constrained views required more updating or revision processes throughout the sequence. Altogether, these findings suggest that constraining a visual scene to its crucial parts triggers various processes related not only to the density of its information but also to its integration into a sequential context. © 2020 The Author(s)",Comics; Film; N300; N400; P600; Visual language,Attention; Cognitive Neuroscience; Electroencephalography; Evoked Potentials; Female; Humans; Male; Narration; Visual Perception; adult; article; cognitive neuroscience; eye movement; female; human; human experiment; language; male; narrative; semantic memory; attention; electroencephalography; evoked response; verbal communication; vision,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85094976565,Movies / Media
Yeamkuan S.; Chamnongthai K.,"Yeamkuan, Suparat (57221865355); Chamnongthai, Kosin (57202765861)",57221865355; 57202765861,Fixational Feature-Based Gaze Pattern Recognition using Long Short-Term Memory,2020,"2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2020 - Proceedings",,,9306292,1103,1106,3.0,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100927127&partnerID=40&md5=a28b5c2eae2f9e33ac31f6015ce84987,"The pattern of eye gaze is increasingly powerful for human-computer interaction tasks. Understanding of gaze pattern can provide valuable information regarding to users' attention. Certainly, the patterns of eye gaze known as eye accessing cues are related to the cognitive processes of the human brain. In this paper we propose a method for gaze patterns recognition, where a gaze data was collected from eye tracker. Consequently, a gaze fixation feature and Long Short- Term Memory technique is employed in this work for the recognition. To evaluate the performance of the proposed method, we have an experiment with 7 examiners, in which they have to looked at 3 tasks of point, rotate and slide on screen. The experimental results show the proposed method offering favorable performance on a standard eye tracker, respectively.  © 2020 APSIPA.",,Brain; Human computer interaction; Long short-term memory; Pattern recognition; Cognitive process; Eye trackers; Eye-gaze; Feature-based; Human brain; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85100927127,Movies / Media
Völter C.J.; Karl S.; Huber L.,"Völter, Christoph J. (55953494400); Karl, Sabrina (57209974627); Huber, Ludwig (7102868913)",55953494400; 57209974627; 7102868913,Dogs accurately track a moving object on a screen and anticipate its destination,2020,Scientific Reports,10,1,19832,,,,16,10.1038/s41598-020-72506-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096071077&doi=10.1038%2fs41598-020-72506-5&partnerID=40&md5=e56c184b6e32243b5174e11ae998dd2f,"The prediction of upcoming events is of importance not only to humans and non-human primates but also to other animals that live in complex environments with lurking threats or moving prey. In this study, we examined motion tracking and anticipatory looking in dogs in two eye-tracking experiments. In Experiment 1, we presented pet dogs (N = 14) with a video depicting how two players threw a Frisbee back and forth multiple times. The horizontal movement of the Frisbee explained a substantial amount of variance of the dogs’ horizontal eye movements. With increasing duration of the video, the dogs looked at the catcher before the Frisbee arrived. In Experiment 2, we showed the dogs (N = 12) the same video recording. This time, however, we froze and rewound parts of the video to examine how the dogs would react to surprising events (i.e., the Frisbee hovering in midair and reversing its direction). The Frisbee again captured the dogs’ attention, particularly when the video was frozen and rewound for the first time. Additionally, the dogs looked faster at the catcher when the video moved forward compared to when it was rewound. We conclude that motion tracking and anticipatory looking paradigms provide promising tools for future cognitive research with canids. © 2020, The Author(s).",,"Animals; Anticipation, Psychological; Dogs; Eye; Eye Movements; Female; Humans; Male; Motion Perception; Play and Playthings; Video Recording; animal experiment; article; attention; dog; eye tracking; motion; nonhuman; videorecording; animal; anticipation; dog; eye; eye movement; female; human; male; movement perception; physiology; recreation",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85096071077,Movies / Media
Kreyenmeier P.; Deubel H.; Hanning N.M.,"Kreyenmeier, Philipp (57194799488); Deubel, Heiner (7004214070); Hanning, Nina M. (57131189700)",57194799488; 7004214070; 57131189700,Theory of visual attention (TVA) in action: Assessing premotor attention in simultaneous eye-hand movements,2020,Cortex,133,,,133,148,15.0,15,10.1016/j.cortex.2020.09.020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094205397&doi=10.1016%2fj.cortex.2020.09.020&partnerID=40&md5=5e4983c4f6a1305e0c2051d36359dd9b,"Attention shifts that precede goal-directed eye and hand movements are regarded as markers of motor target selection. Whether effectors compete for a single, shared attentional resource during simultaneous eye-hand movements or whether attentional resources can be allocated independently towards multiple target locations is controversially debated. Independent, effector-specific target selection mechanisms underlying parallel allocation of visuospatial attention to saccade and reach targets would predict an increase of the overall attention capacity with the number of active effectors. We test this hypothesis in a modified Theory of Visual Attention (TVA; Bundesen, 1990) paradigm. Participants reported briefly presented letters during eye, hand, or combined eye-hand movement preparation to centrally cued locations. Modeling the data according to TVA allowed us to assess both the overall attention capacity and the deployment of visual attention to individual locations in the visual work space. In two experiments, we show that attention is predominantly allocated to the motor targets–without pronounced competition between effectors. The parallel benefits at eye and hand targets, however, have concomitant costs at non-motor locations, and the overall attention capacity does not increase by the simultaneous recruitment of both effector systems. Moreover, premotor shifts of attention dominate over voluntary deployment of processing resources, yielding severe impairments of voluntary attention allocation. We conclude that attention shifts to multiple effector targets without mutual competition given that sufficient processing resources can be withdrawn from movement-irrelevant locations. © 2020 Elsevier Ltd",Attention capacity; Hand movements; Saccades; Selective attention; Theory of visual attention,adult; article; competition; hand movement; human; saccadic eye movement; selective attention; theoretical study; visual attention,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85094205397,Movies / Media
Wang G.; Gan Q.; Li Y.,"Wang, Gong (57268006800); Gan, Quan (57267365100); Li, Yubo (57267365200)",57268006800; 57267365100; 57267365200,Research on Attention-guiding Methods in Cinematic Virtual Reality Based on Eye Tracking Analysis,2020,"Proceedings - 2020 International Conference on Innovation Design and Digital Technology, ICIDDT 2020",,,,68,72,4.0,3,10.1109/ICIDDT52279.2020.00020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115430962&doi=10.1109%2fICIDDT52279.2020.00020&partnerID=40&md5=2c9cbaf48fc5aee06881fab006281e42,"Reproducing the virtual world is the development direction of film technology and film art. However, the current technology is not ready to build a true ""comprehensive cinema"". However, the current technology is not ready to construct a truly ""total cinema"". The viewer of a 360 degree virtual reality movie can choose viewing directions freely when watching a movie. Therefore, traditional language technique in filmmaking for guiding viewers' attention is less effective to a great extent. Viewers are no longer guided by directors or film editors in a passive way, but have almost complete freedom in choosing what they want to watch. This brings new challenges for story-telling. In Cinematic Virtual Reality (CVR), the viewing process is not decided by the filmmaker, instead viewers are guided to watch. Guiding viewers to catch the preset plots effectively and accurately within fixed time can ensure complete viewing experience. Based on eye tracking in CVR, this paper makes an experiment with different attention guiding methods, explores the differences of effects of these methods and attention patterns in watching VR movies, and provides new basis and references for narrative mode in VR movies from the perspective of eye tracking. © 2020 IEEE.",eye tracking; guiding methods; response speed; VR movie,Eye tracking; Virtual reality; Watches; Cinematics; Current technology; Development directions; Eye-tracking; Eye-tracking analysis; Film technology; Guiding method; Response speed; Virtual worlds; VR movie; Motion pictures,Conference paper,Final,,Scopus,2-s2.0-85115430962,Movies / Media
Clin E.; Maes P.; Stercq F.; Kissine M.,"Clin, Elise (57191646274); Maes, Pauline (57219946834); Stercq, Fanny (57015470200); Kissine, Mikhail (24067166300)",57191646274; 57219946834; 57015470200; 24067166300,No preference for direct versus averted gaze in autistic adults: a reinforced preferential looking paradigm,2020,Molecular Autism,11,1,91,,,,9,10.1186/s13229-020-00398-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096236327&doi=10.1186%2fs13229-020-00398-3&partnerID=40&md5=74a8d309e2ffd9bfb6ee92c535cc410e,"Background: With the overarching objective to gain better insights into social attention in autistic adults, the present study addresses three outstanding issues about face processing in autism. First, do autistic adults display a preference for mouths over eyes; second, do they avoid direct gaze; third, is atypical visual exploration of faces in autism mediated by gender, social anxiety or alexithymia? Methods: We used a novel reinforced preferential looking paradigm with a group of autistic adults (n = 43, 23 women) pairwise matched on age with neurotypical participants (n = 43, 21 women). Participants watched 28 different pairs of 5 s video recordings of a speaking person: the two videos, simultaneously displayed on the screen, were identical except that gaze was directed at the camera in one video and averted in the other. After a 680 ms transition phase, a short reinforcement animation appeared on the side that had displayed the direct gaze. Results: None of the groups showed a preference for mouths over eyes. However, neurotypical participants fixated significantly more the stimuli with direct gaze, while no such preference emerged in autistic participants. As the experiment progressed, neurotypical participants also increasingly anticipated the appearance of the reinforcement, based on the location of the stimulus with the direct gaze, while no such anticipation emerged in autistic participants. Limitations: Our autistic participants scored higher on the social anxiety and alexithymia questionnaires than neurotypicals. Future studies should match neurotypical and autistic participants on social anxiety and alexithymia and complement questionnaires with physiological measures of anxiety. Conclusions: The absence of preference for direct versus averted gaze in the autistic group is probably due to difficulties in distinguishing eye gaze direction, potentially linked to a reduced spontaneous exploration or avoidance of the eye region. Social attention and preference for direct versus averted gaze correlated with alexithymia and social anxiety scores, but not gender. © 2020, The Author(s).",Adults; Alexithymia; Autism; Eye gaze direction; Eye-tracking; Gender; Reinforced preferential looking paradigm; Social anxiety; Social attention,"Adult; Affective Symptoms; Anxiety; Autistic Disorder; Choice Behavior; Eye-Tracking Technology; Female; Fixation, Ocular; Humans; Male; Photic Stimulation; Reinforcement, Psychology; Social Behavior; adult; alexithymia; anticipation; Article; autism; averted gaze; clinical article; controlled study; direct gaze; eye tracking; female; gaze; groups by age; human; male; middle aged; patient participation; phase transition; priority journal; sex difference; social phobia; stimulus response; videorecording; anxiety; autism; complication; decision making; emotional disorder; eye fixation; pathophysiology; photostimulation; physiology; social behavior",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85096236327,Movies / Media
Wong C.L.; Rana T.; Leung Y.M.,"Wong, Cho Lee (57141327900); Rana, Tika (57208752803); Leung, Yan Ming (57220762816)",57141327900; 57208752803; 57220762816,Eye Tracking to Evaluate the Usability of an Online Pneumoconiosis Education Booklet in a Sample of South Asian Construction Workers,2020,CIN - Computers Informatics Nursing,38,12,,638,645,7.0,4,10.1097/CIN.0000000000000635,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094218955&doi=10.1097%2fCIN.0000000000000635&partnerID=40&md5=6f507ae62fc79e61be455ee67a466736,"Pneumoconiosis is an incurable disease. An online educational booklet for South Asian construction workers has been developed to provide them with knowledge of the disease and its preventive measures. As eye tracking has long been applied to assess users' preferences with regard to the content of commercial products, this approach would likely offer a promising opportunity for an objective assessment of the usability of the developed booklet. This was a mixed-methods study that combined eye tracking and interviews to explore the usability of the educational booklet among South Asian construction workers. Twelve construction workers were invited to read the booklet individually on a laptop computer. An eye-tracking device was placed under the computer screen to collect eye tracking data of the participants to measure their attention to the contents of the booklet. Afterward, the participants were invited to attend a semistructured interview to explore their acceptance of and satisfaction with the booklet. Results showed that participants gazed more often and for a longer duration at the working environment that increases pneumoconiosis risk and the preventive measures for pneumoconiosis, and they paid more attention to the pictures. The workers reported that the booklet was useful and informative, and they were satisfied with its design and layout.  © Lippincott Williams & Wilkins.",Booklet; Education; Eye tracking; Usability,Adult; Asia; Construction Industry; Eye-Tracking Technology; Humans; Internet; Interviews as Topic; Male; Pamphlets; Patient Education as Topic; Pneumoconiosis; Risk Factors; Surveys and Questionnaires; adult; Asia; building industry; human; Internet; interview; male; patient education; pneumoconiosis; publication; questionnaire; risk factor,Article,Final,,Scopus,2-s2.0-85094218955,Movies / Media
Ma X.; Zhuang X.; Ma G.,"Ma, Xueer (57261490400); Zhuang, Xiangling (48061545900); Ma, Guojie (55479565700)",57261490400; 48061545900; 55479565700,Transparent Windows on Food Packaging Do Not Always Capture Attention and Increase Purchase Intention,2020,Frontiers in Psychology,11,,593690,,,,14,10.3389/fpsyg.2020.593690,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096805611&doi=10.3389%2ffpsyg.2020.593690&partnerID=40&md5=0d0e098883708c6f39cfca8325db6684,"Transparent windows on food packaging can effectively highlight the actual food inside. The present study examined whether food packaging with transparent windows (relative to packaging with food‐ and non-food graphic windows in the same position and of the same size) has more advantages in capturing consumer attention and determining consumers’ willingness to purchase. In this study, college students were asked to evaluate prepackaged foods presented on a computer screen, and their eye movements were recorded. The results showed salience effects for both packaging with transparent and food-graphic windows, which were also regulated by food category. Both transparent and graphic packaging gained more viewing time than the non-food graphic baseline condition for all the three selected products (i.e., nuts, preserved fruits, and instant cereals). However, no significant difference was found between transparent and graphic window conditions. For preserved fruits, time to first fixations was shorter in transparent packaging than other conditions. For nuts, the willingness to purchase was higher in both transparent and graphic conditions than the baseline condition, while the packaging attractiveness played a key role in mediating consumers’ willingness to purchase. The implications for stakeholders and future research directions are discussed. © Copyright © 2020 Ma, Zhuang and Ma.",attractiveness; eye tracking; transparent packaging; visual attention; willingness to purchase,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85096805611,Movies / Media
Sprawson I.; Wood J.; Mantzios M.,"Sprawson, Isabella (57797598900); Wood, Jeffrey (55464328200); Mantzios, Michail (55948981700)",57797598900; 55464328200; 55948981700,“And Now Close Your Eyes or Lower Your Gaze”: Exploring Novice Meditators and Their Attentional Processes During Meditation,2020,Journal of Cognitive Enhancement,4,4,,369,378,9.0,3,10.1007/s41465-020-00175-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087423094&doi=10.1007%2fs41465-020-00175-3&partnerID=40&md5=3f39901304bafb32ea1684d98dee1694,"Brief mindfulness meditation practices are associated with a wealth of benefits; however, factors that may influence the success of meditation sessions have rarely been explored. The present study explored the effects of the visual environment as a factor of successful meditation. Eye-tracking techniques were employed to objectively measure attention within three attention-deviating conditions with basic meditation instructions, and the potential influence of personality traits as assessed through administering the HEXACO-60-PI, a self-report measure, to participants. Statistically significant results were uncovered regarding decreased fixation durations and increased state mindfulness scores of participants within the blank screen conditions over the two eyes-open conditions. No significant effect was found regarding fixation counts, which decreased within the blank screen condition. The findings regarding reduced state anxiety did not reach significance and there were no significant differences regarding the six personality types between conditions. The present study offers a step towards understanding how brief mindfulness meditation sessions can be optimised. © 2020, The Author(s).",Attention; Eye tracking; HEXACO; Mindfulness; Visual environment,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85087423094,Movies / Media
Ni L.; Hu Z.; Yang Q.; Liu Y.; Lin L.; Niu H.; Han Y.,"Ni, Lianghui (57215867247); Hu, Zhenyan (57221311737); Yang, Qin (57216922778); Liu, Yi (59851987900); Lin, Li (57216654203); Niu, Haijing (24721810700); Han, Ying (55369279900)",57215867247; 57221311737; 57216922778; 59851987900; 57216654203; 24721810700; 55369279900,Improvement of memory in healthy elderly subjects by Shentai Tea Polyphenols; [参肽茶多酚改善中老年人记忆功能的临床研究],2020,Chinese Journal of Neuromedicine,19,11,,1142,1148,6.0,2,10.3760/cma.j.cn115354-20201016-00816,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098756949&doi=10.3760%2fcma.j.cn115354-20201016-00816&partnerID=40&md5=8d97e79ddfc418df7f8266f994f4bd09,"Objective: To investigate the effect of Shentai Tea Polyphenols on memory and its underlying mechanism in healthy elderly adults. Methods: According to the randomized, double blind and placebo-controlled prospective experimental design, 240 healthy middle-aged or elderly subjects with normal objective cognition were recruited in our hospital from April to December 2019 through advertising, and they were randomly divided into an experimental group (n=120) and a control group (n=120). Oral administration of Shentai Tea Polyphenols or placebo capsules (lasting for 90 d, 2 times/d, 2 capsules/time) was given to subjects in the two groups. The neuropsychological scale scores and near-infrared brain imaging data of all subjects were collected before and after intervention, and the mean time from baseline data collection before intervention to follow-up data collection after medication was controlled within 6 months. Results: In patients from the experimental group, as compared with those before intervention, scores of delayed recall and recognition memory in the auditory verbal learning test (Huashan version) and Boston naming test, scores of Montreal cognitive assessment scale (basis version) were significantly higher, and scores of Hamilton anxiety scale, shape trails test A and rapid-eye-movement sleep behavior disorder screening questionnaire were significantly lower after intervention (P<0.05); however, only scores of delayed recall in the auditory verbal learning test (Huashan version) were significantly increased in the control group (P<0.05). A total of 23 pairs of differences of brain function connection before and after intervention in the experimental group were significantly higher than those in the control group (P<0.05), mainly involving the function connection of forehead peak network (FPN), and function connection of FPN-default network, function connection of FPN-somatosensory movement network, function connection of FPN-dorsal attention network and function connection of FPN-visual network, as well as the function connection of default network and somatosensory movement network. Conclusion: Shentai Tea Polyphenols can improve cognitive performances including memory, language and executive function, anxiety mood and sleep quality in healthy middle aged or elderly subjects by affecting the functional connections of the networks in the brain. Copyright © 2020 by the Chinese Medical Association.",Memory and mood; Near-infrared brain imaging; Non-pharmacological intervention; Shentai Tea Polyphenols,placebo; polyphenol; adult; aged; Article; behavior assessment; behavior disorder; Boston naming test; cognition; controlled study; double blind procedure; experimental design; follow up; Hamilton Anxiety Scale; human; human experiment; memory; middle aged; neuroimaging; neuropsychological assessment; priority journal; prospective study; questionnaire; randomized controlled trial; recognition; REM sleep; Rey auditory verbal learning test; tea; visual network,Article,Final,,Scopus,2-s2.0-85098756949,Movies / Media
Mao J.; Huang X.; Yu J.; Chen L.; Huang Y.; Tang B.; Guo J.,"Mao, Jingrong (57211798074); Huang, Xiurong (57219993480); Yu, Jiaming (59050135600); Chen, Lang (57218500819); Huang, Yuqian (57219994383); Tang, Beisha (55534015200); Guo, Jifeng (55709428800)",57211798074; 57219993480; 59050135600; 57218500819; 57219994383; 55534015200; 55709428800,Association Between REM Sleep Behavior Disorder and Cognitive Dysfunctions in Parkinson's Disease: A Systematic Review and Meta-Analysis of Observational Studies,2020,Frontiers in Neurology,11,,577874,,,,17,10.3389/fneur.2020.577874,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096445269&doi=10.3389%2ffneur.2020.577874&partnerID=40&md5=393ad2fd84219ecaa5814897bdedb370,"Background: Rapid eye movement sleep behavior disorder (RBD) is thought to be a prodromal symptom of Parkinson's disease (PD). RBD is also thought to be involved in cognitive decline and dementia in PD. In PD, although the relationship between RBD and cognitive dysfunctions was confirmed by considerable studies, whether RBD was associated with distinct types of cognitive defects is worth of study. Objectives: This systematic review summarizes the evidence relating to cognitive dysfunction in PD patients with RBD (PD-RBD) and those without and explores their specificity to cognitive domains. Methods: A meta-analysis using a random-effects model was performed for 16 different cognitive domains, including global cognitive function, memory (long-term verbal recall, long-term verbal recognition, long-term visual recall, short-term spatial recall, and short-term verbal recall), executive function (general, fluid reasoning, generativity, shifting, inhibition, and updating), language, processing speed/complex attention/working memory, visuospatial/constructional ability, and psychomotor ability. The cognitive difference between the groups of patients was measured as a standardized mean difference (SMD, Cohen's d). PD-RBD patients were classified into Confirmed-RBD (definite diagnosis with polysomnography, PSG) and Probable-RBD (without PSG re-confirmation). In some domains, RBD patients could not be analyzed separately due to the exiguity of primary studies; this analysis refers to such RBD patients as “Mixed-RBD.” Results: Thirty-nine studies with 6,695 PD subjects were finally included. Confirmed-RBD patients showed worse performance than those without in global cognitive function, long-term verbal recall, long-term verbal recognition, generativity, inhibition, shifting, language, and visuospatial/constructional ability; Probable-RBD, in global cognitive function and shifting; and Mixed-RBD, in long-term visual recall, short-term spatial recall, general executive function, and processing speed/complex attention/working memory. Conclusion: This meta-analysis strongly suggests a relationship between RBD, Confirmed-RBD in particular, and cognitive dysfunctions in PD patients. Early and routine screening by sensitive and targeted cognitive tasks is necessary for all PD-RBD patients because it may offer the therapeutic time window before they evolve to irreversible dementia. © Copyright © 2020 Mao, Huang, Yu, Chen, Huang, Tang and Guo.",cognitive dysfunction; dementia; meta-analysis; parkinson's disease (PD); rapid eye movement sleep behavior disorder (RBD),clonazepam; attention; cognitive defect; depth perception; disease association; executive function; human; language ability; long term memory; mental performance; parasomnia; Parkinson disease; polysomnography; processing speed; psychomotor activity; Review; short term memory; spatial memory; systematic review; verbal memory; visual memory; working memory,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85096445269,Movies / Media
Xu M.-W.; Jin L.-Z.; Tian X.-H.; Wei Y.-X.; Wang L.-J.,"Xu, Ming-Wei (57203977533); Jin, Long-Zhe (26659380500); Tian, Xing-Hua (57203985056); Wei, Yi-Xuan (57218797071); Wang, Li-Jun (57221119828)",57203977533; 26659380500; 57203985056; 57218797071; 57221119828,Visual fatigue of VDT operation under different illumination conditions in confined space; [受限空间不同照度环境下VDT作业视觉疲劳],2020,Gongcheng Kexue Xuebao/Chinese Journal of Engineering,42,12,,1605,1612,7.0,8,10.13374/j.issn2095-9389.2020.08.20.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098285849&doi=10.13374%2fj.issn2095-9389.2020.08.20.002&partnerID=40&md5=af7459b6ca5c3aedefa5d14c114dc0cc,"Using eyes with high concentration for long periods can cause visual fatigue. With the continuous development and progression of modern electronic devices, screens have become an integral part of many aspects of life. Watching a screen for a long time can cause extreme eye fatigue and accidents. A wireless monitoring system including multiple communication platforms is a new means of monitoring in confined spaces, which requires people to perform visual display terminal (VDT) operations in common operating places such as dispatch rooms, cabins, and shipyards. Visual fatigue in a confined space is one of the main causes of accidents. To explore the effect of lighting in a limited space on visual fatigue of VDT, 24 operators were selected to perform VDT typing in a confined space platform for 1 h, and seven light gradients were set within the range of 50-700 lx to collect pupil diameter data using an eye tracker. The collected data were normalized to reduce noise. Experimental results show that with an increase in illuminance, the pupil diameter generally decreases and the pupil-illuminance relationship conforms to the power function relationship. In high-illumination environments (400, 550, and 700 lx), the pupil diameter change rate fluctuates in the −12%-8% range, and with the increase in light intensity, the degree of visual fatigue of workers increases. Under low-illumination environments (50, 100, and 200 lx), the pupil diameter change rate fluctuates in the range of −8%−4%, and the degree of visual fatigue of the workers also increases with decreased intensity. This study proposes to use the windowed pupil diameter standard deviation,σ, to determine the time of visual fatigue. The peak value of σ under low illumination is earlier than that under high illumination; the peak value of σ under 300-lx illumination is the latest, weak illumination. The fatigue degree of vision caused by 50−300 lx is greater than that caused by strong illumination of 300−700 lx. © 2020, Science Press. All right reserved.",Confined space; Pupil diameter; Safety management; Visual display terminal task; Visual fatigue,Accidents; Lighting; Marine communication; Ships; Space platforms; Causes of accidents; Communication platforms; Continuous development; Illumination conditions; Low illuminations; Standard deviation; Visual display terminals; Wireless monitoring system; Eye tracking,Article,Final,,Scopus,2-s2.0-85098285849,Movies / Media
Swann L.; Popovic V.; Blackler A.; Thompson H.,"Swann, Levi (57207259144); Popovic, Vesna (7101831196); Blackler, Alethea (6602728477); Thompson, Helen (57203416789)",57207259144; 7101831196; 6602728477; 57203416789,Airport Security Screener Problem-Solving Knowledge and Implications,2020,Human Factors,62,8,,1265,1285,20.0,12,10.1177/0018720819874169,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074031037&doi=10.1177%2f0018720819874169&partnerID=40&md5=a6a58cfef0e870ff5d6e59ab4992b508,"Objective: This research investigates security screeners’ knowledge and the effect that differences in knowledge have on the performance of problem-solving activities. We argue that the development of problem-solving knowledge enables security screeners to perform effective problem-solving activity, which assists search and decision-making processes. Background: Airport security screening research has investigated the many variables that affect security screeners’ search and decision making during simulated threat-detection tasks. Although search and decision making are essential aspects of security screening, few studies have investigated the problem-solving knowledge and activities that support security screening task performance. Method: Sixteen more-experienced and 24 less-experienced security screeners were observed as they performed x-ray screening in the field at an Australian international airport’s departure security checkpoint. Participants wore eye-tracking glasses and delivered concurrent verbal protocol. Results: When interacting with other security screeners, more-experienced screeners demonstrated situational knowledge more than less-experienced screeners, whereas less-experienced screeners experienced more insufficient knowledge. Lag-sequential analysis using combined data from both screener groups showed that situational knowledge facilitated effective problem-solving activity to support search and decision making. Insufficient knowledge led screeners to seek assistance and defer decision making. Conclusion: This study expands current understandings of airport security screening. It demonstrates that security screeners develop knowledge that is specific to problem solving. This knowledge assists effective problem-solving activity to support search and decision making, and to mitigate uncertainty during the x-ray screening task. Application: Findings can inform future security screening processes, screener training, and technology support tools. Furthermore, findings are potentially transferable to other domains. © 2019, Human Factors and Ergonomics Society.",cognition; experience; expert–novice differences; knowledge elicitation; skilled performance,Airports; Australia; Humans; Problem Solving; Security Measures; Task Performance and Analysis; Airports; Decision making; Eye tracking; Knowledge acquisition; X ray screens; X rays; Airport security screeners; cognition; Decision making process; experience; International airport; Security checkpoint; Sequential analysis; skilled performance; airport; Australia; human; organization and management; problem solving; task performance; Airport security,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85074031037,Movies / Media
Bill G.; Whyte E.; Griffin J.W.; Scherf K.S.,"Bill, Gordon (57217864598); Whyte, Elisabeth (56053310000); Griffin, Jason W. (57213343803); Scherf, K. Suzanne (55664600900)",57217864598; 56053310000; 57213343803; 55664600900,Measuring sensitivity to eye gaze cues in naturalistic scenes: Presenting the eye gaze FoCuS database,2020,International Journal of Methods in Psychiatric Research,29,4,,1,9,8.0,7,10.1002/mpr.1833,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087788711&doi=10.1002%2fmpr.1833&partnerID=40&md5=2b71a216d7780bf0ef83bb411dd93a76,"Objectives: The ability to process information about eye gaze and its use for nonverbal communication is foundational to human social interactions. We developed and validated a database of stimuli that are optimized to investigate the perception and referential understanding of shifts in eye gaze. Methods: The 245 Gaze Perception stimuli are digital photographs that test the ability to estimate and interpret eye gaze trajectory. The 82 Gaze Following stimuli are digital videos that measure the ability to follow and interpret eye gaze shifts online. Both stimuli were designed for a 4-alternative forced choice paradigm (4AFC) in which the participant identifies the gazed-at object. Results: Each stimulus was validated by independent raters and only included if the endorsement of the correct item was ≥75%. Finally, we provided timestamps for 19 40-second video segments from adolescent-oriented entertainment movies that are matched on several factors. These segments involve social interactions with eye gaze shifts and can be used to measure visual social attention. Conclusions: This database will be an excellent resource for researchers interested in studying the developmental, behavioral, and/or neural mechanisms supporting the perception and interpretation of eye gaze cues. © 2020 The Authors. International Journal of Methods in Psychiatric Research Published by John Wiley & Sons Ltd.",autism; face; gaze following; gaze perception; social anxiety,"Adolescent; Attention; Cues; Databases, Factual; Fixation, Ocular; Humans; Nonverbal Communication; adolescent; association; attention; eye fixation; factual database; human; nonverbal communication",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85087788711,Movies / Media
Mori T.; Otomo T.; Ishii E.; Hoshino Y.; Yamada M.,"Mori, Taiga (57207823738); Otomo, Takahide (57211111359); Ishii, Eriko (57205999750); Hoshino, Yuko (55555640800); Yamada, Mitsuho (7405745700)",57207823738; 57211111359; 57205999750; 55555640800; 7405745700,Proposal of an interest word presentation system when browsing the web using eye movements: Demo abstract,2020,SenSys 2020 - Proceedings of the 2020 18th ACM Conference on Embedded Networked Sensor Systems,,,,631,632,1.0,0,10.1145/3384419.3430420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097557131&doi=10.1145%2f3384419.3430420&partnerID=40&md5=84d34d58492128802c9103b3b6b5cf1f,"In recent years, eye tracking technology has received a lot of attention. This time, as a basic study of interaction that can extract user's interest information, we tried to develop a user interaction system using a low-cost, non-contact eye-gaze input device. Our system uses the user's gaze point and gaze time when browsing a web page to extract words that the user may be interested in and display the information on the screen. © 2020 ACM.",gaze; interaction system; web,Embedded systems; Eye movements; Websites; Eye tracking technologies; Gaze point; Input devices; Non-contact; System use; User interaction; User's interest; Word presentation; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85097557131,Movies / Media
Mengoudi K.; Ravi D.; Yong K.X.X.; Primativo S.; Pavisic I.M.; Brotherhood E.; Lu K.; Schott J.M.; Crutch S.J.; Alexander D.C.,"Mengoudi, Kyriaki (57210202731); Ravi, Daniele (57201696886); Yong, Keir X. X. (55650633000); Primativo, Silvia (55831755300); Pavisic, Ivanna M. (57195351982); Brotherhood, Emilie (56079056500); Lu, Kirsty (57205113051); Schott, Jonathan M. (7103177641); Crutch, Sebastian J. (6602191607); Alexander, Daniel C. (7402830766)",57210202731; 57201696886; 55650633000; 55831755300; 57195351982; 56079056500; 57205113051; 7103177641; 6602191607; 7402830766,Augmenting dementia cognitive assessment with instruction-less eye-tracking tests,2020,IEEE Journal of Biomedical and Health Informatics,24,11,9124654,3066,3075,9.0,39,10.1109/JBHI.2020.3004686,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095799060&doi=10.1109%2fJBHI.2020.3004686&partnerID=40&md5=ff169d1227903ea0592bdbe2a2893704,"Eye-tracking technology is an innovative tool that holds promise for enhancing dementia screening. In this work, we introduce a novel way of extracting salient features directly from the raw eye-tracking data of a mixed sample of dementia patients during a novel instruction-less cognitive test. Our approach is based on self-supervised representation learning where, by training initially a deep neural network to solve a pretext task using well-defined available labels (e.g. recognising distinct cognitive activities in healthy individuals), the network encodes high-level semantic information which is useful for solving other problems of interest (e.g. dementia classification). Inspired by previous work in explainable AI, we use the Layer-wise Relevance Propagation (LRP) technique to describe our network's decisions in differentiating between the distinct cognitive activities. The extent to which eye-tracking features of dementia patients deviate from healthy behaviour is then explored, followed by a comparison between self-supervised and handcrafted representations on discriminating between participants with and without dementia. Our findings not only reveal novel self-supervised learning features that are more sensitive than handcrafted features in detecting performance differences between participants with and without dementia across a variety of tasks, but also validate that instruction-less eye-tracking tests can detect oculomotor biomarkers of dementia-related cognitive dysfunction. This work highlights the contribution of self-supervised representation learning techniques in biomedical applications where the small number of patients, the non-homogenous presentations of the disease and the complexity of the setting can be a challenge using state-of-the-art feature extraction methods. © 2013 IEEE.",cognition; deep-learning; dementia; Eye-tracking; representation learning,Cognition; Cognitive Dysfunction; Dementia; Eye-Tracking Technology; Humans; Neuropsychological Tests; Backpropagation; Classification (of information); Deep learning; Deep neural networks; Diagnosis; Feature extraction; Learning systems; Medical applications; Network coding; Neurodegenerative diseases; Semantics; biological marker; Biomedical applications; Cognitive activities; Cognitive assessments; Dementia screenings; Eye tracking technologies; Feature extraction methods; High level semantics; Learning techniques; adult; aged; Article; behavior change; body weight loss; classification algorithm; clinical article; cognitive defect; computer assisted tomography; controlled study; deep learning; deep neural network; dementia; dementia assessment; electroencephalography; emotionality; episodic memory; eye tracking; feature extraction; female; frontal variant frontotemporal dementia; functional magnetic resonance imaging; human; human experiment; human tissue; image quality; learning algorithm; machine learning; male; memory disorder; middle aged; mild cognitive impairment; Mini Mental State Examination; social cognition; social interaction test; stimulus; support vector machine; task performance; very elderly; visual field; visual stimulation; cognition; cognitive defect; dementia; neuropsychological test; Eye tracking,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85095799060,Movies / Media
Assogna M.; Casula E.P.; Borghi I.; Bonnì S.; Samà D.; Motta C.; Di Lorenzo F.; D'Acunto A.; Porrazzini F.; Minei M.; Caltagirone C.; Martorana A.; Koch G.,"Assogna, Martina (57205577218); Casula, Elias Paolo (55613454600); Borghi, Ilaria (57218654046); Bonnì, Sonia (26533986400); Samà, Domenico (57193964342); Motta, Caterina (36461399500); Di Lorenzo, Francesco (6603888625); D'Acunto, Alessia (57211785698); Porrazzini, Francesco (57211781866); Minei, Marilena (57218654201); Caltagirone, Carlo (35228717800); Martorana, Alessandro (7005822633); Koch, Giacomo (36866518200)",57205577218; 55613454600; 57218654046; 26533986400; 57193964342; 36461399500; 6603888625; 57211785698; 57211781866; 57218654201; 35228717800; 7005822633; 36866518200,"Effects of Palmitoylethanolamide Combined with Luteoline on Frontal Lobe Functions, High Frequency Oscillations, and GABAergic Transmission in Patients with Frontotemporal Dementia",2020,Journal of Alzheimer's Disease,76,4,,1297,1308,11.0,41,10.3233/JAD-200426,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089922320&doi=10.3233%2fJAD-200426&partnerID=40&md5=5c8e67fe8a72d282cce936ca7110dcc6,"Frontotemporal dementia (FTD) is a presenile neurodegenerative disease for which there is no effective pharmacological treatment. Recently, a link has been proposed between neuroinflammation and FTD. Objective: Here, we aim to investigate the effects of palmitoylethanolamide (PEA) combined with luteoline (PEA-LUT), an endocannabinoid with anti-inflammatory and neuroprotective effects, on behavior, cognition, and cortical activity in a sample of FTD patients. Methods: Seventeen patients with a diagnosis of probable FTD were enrolled. Cognitive and neurophysiological evaluations were performed at baseline and after 4 weeks of PEA-LUT 700mg×2/day. Cognitive effects were assessed by Neuropsychiatric Inventory (NPI), Mini-Mental State Examination, Frontal Assessment Battery (FAB), Screening for Aphasia in Neurodegeneration, Activities of Daily Living-Instrumental Activities of Daily Living, and Frontotemporal Lobar Degeneration-modified Clinical Dementia Rating scale. To investigate in vivo neurophysiological effects of PEA-LUT, we used repetitive and paired-pulse transcranial magnetic stimulation (TMS) protocols assessing LTP-like cortical plasticity, short-interval intracortical inhibition, long-interval intracortical inhibition (LICI), and short-latency afferent inhibition. Moreover, we used TMS combined with EEG to evaluate the effects on frontal lobe cortical oscillatory activity. Results: Treatment with PEA-LUT was associated with an improvement in NPI and FAB scores. Neurophysiological evaluation showed a restoration of LICI, in particular at ISI 100ms, suggesting a modulation of GABA(B) activity. TMS-EEG showed a remarkable increase of TMS-evoked frontal lobe activity and of high-frequency oscillations in the beta/gamma range. Conclusion: PEA-LUT could reduce behavioral disturbances and improve frontal lobe functions in FTD patients through the modulation of cortical oscillatory activity and GABA(B)ergic transmission.  © 2020 - IOS Press and the authors. All rights reserved.",behavioral symptoms; Brain inflammation; EEG; executive functions; frontotemporal dementia; GABA activity; transcranial magnetic stimulation,"Activities of Daily Living; Aged; Amides; Cognition; Ethanolamines; Evoked Potentials, Motor; Female; Frontotemporal Dementia; Humans; Luteolin; Male; Middle Aged; Neural Inhibition; Neurodegenerative Diseases; Palmitic Acids; Transcranial Magnetic Stimulation; luteolin; palmidrol; amide; ethanolamine derivative; luteolin; palmidrol; palmitic acid derivative; adult; antiinflammatory activity; Article; clinical article; Clinical Dementia Rating; cognition; daily life activity; electroencephalogram; eye movement; female; frontal lobe; frontotemporal dementia; GABAergic transmission; high frequency oscillation; human; in vivo study; male; middle aged; Mini Mental State Examination; nerve cell excitability; nerve cell plasticity; neuroprotection; neuropsychiatric inventory; neurotransmission; patient compliance; primary progressive aphasia; priority journal; transcranial magnetic stimulation; aged; degenerative disease; drug effect; frontotemporal dementia; motor evoked potential; nerve cell inhibition; physiology; procedures",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85089922320,Movies / Media
Ballenghein U.; Kaakinen J.K.; Tissier G.; Baccino T.,"Ballenghein, Ugo (57200412292); Kaakinen, Johanna K (55917360500); Tissier, Geoffrey (56027572700); Baccino, Thierry (6506451570)",57200412292; 55917360500; 56027572700; 6506451570,Cognitive engagement during reading on digital tablet: Evidence from concurrent recordings of postural and eye movements,2020,Quarterly Journal of Experimental Psychology,73,11,,1820,1829,9.0,13,10.1177/1747021820931830,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091010849&doi=10.1177%2f1747021820931830&partnerID=40&md5=3a7c5413f713f9bc1d2ced8a7f518776,"The present study utilised a novel combination of eye movement and motion capture recordings to examine cognitive engagement during reading on a hand-held tablet computer. Participants read a multiple-page text with a specific task in mind and after reading recalled the main contents of text from memory. The results showed that head distance from screen was slightly shorter, and readers spent longer time reading task-relevant than irrelevant segments of text and had better memory for task-relevant than irrelevant text information, indicating that there are task-induced momentary changes in engagement during reading. Moreover, head motion and individual fixation durations decreased during the course of reading of relevant segments, and even though there was an overall increase in table motion during reading, the slope of this increase was steeper for irrelevant than relevant text segments. These results suggest that readers become more engaged with relevant and less engaged with irrelevant text segments across the text. The novel methodological combination of eye and postural movements seems to provide valuable information about cognitive engagement during reading in digital environments. The cumulation of evidence from this and previous studies suggests that reading on a tablet affords different interactions between the reader and the text than reading on a computer screen. Reading on a tablet might be more similar to reading on paper, and this may impact the attentional processes during reading. © Experimental Psychology Society 2020.",Cognitive engagement; digital reading; eye movements; hand-held device; postural movements; reading,"Attention; Cognition; Computers, Handheld; Eye Movements; Female; Head; Humans; Male; Memory; Posture; Reading; Young Adult; attention; body position; cognition; eye movement; female; head; human; male; memory; personal digital assistant; reading; young adult",Article,Final,,Scopus,2-s2.0-85091010849,Movies / Media
David E.; Beitner J.; Võ M.L.-H.,"David, Erwan (57202111778); Beitner, Julia (57203870149); Võ, Melissa Le-Hoa (9634349400)",57202111778; 57203870149; 9634349400,Effects of transient loss of vision on head and eye movements during visual search in a virtual environment,2020,Brain Sciences,10,11,841,1,26,25.0,26,10.3390/brainsci10110841,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095995234&doi=10.3390%2fbrainsci10110841&partnerID=40&md5=2ba85748a2dc9beeeb7a622d24f7ff47,"Central and peripheral fields of view extract information of different quality and serve different roles during visual tasks. Past research has studied this dichotomy on-screen in conditions remote from natural situations where the scene would be omnidirectional and the entire field of view could be of use. In this study, we had participants looking for objects in simulated everyday rooms in virtual reality. By implementing a gaze-contingent protocol we masked central or peripheral vision (masks of 6 deg. of radius) during trials. We analyzed the impact of vision loss on visuo-motor variables related to fixation (duration) and saccades (amplitude and relative directions). An important novelty is that we segregated eye, head and the general gaze movements in our analyses. Additionally, we studied these measures after separating trials into two search phases (scanning and verification). Our results generally replicate past on-screen literature and teach about the role of eye and head movements. We showed that the scanning phase is dominated by short fixations and long saccades to explore, and the verification phase by long fixations and short saccades to analyze. One finding indicates that eye movements are strongly driven by visual stimulation, while head movements serve a higher behavioral goal of exploring omnidirectional scenes. Moreover, losing central vision has a smaller impact than reported on-screen, hinting at the importance of peripheral scene processing for visual search with an extended field of view. Our findings provide more information concerning how knowledge gathered on-screen may transfer to more natural conditions, and attest to the experimental usefulness of eye tracking in virtual reality. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Gaze-contingent protocol; Virtual reality; Visual attention; Visual field loss; Visual search,adult; Article; cardboard test; cognition; depth perception; experimental test; eye movement; eye tracking; female; gaze; head movement; human; human experiment; interpupillary distance; male; normal human; peripheral vision; saccadic eye movement; simulation; thumb test; validation process; virtual reality; vision; visual acuity; visual attention; visual impairment; visual information; visual stimulation; visual system parameters; visuomotor coordination,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85095995234,Movies / Media
Haensel J.X.; Ishikawa M.; Itakura S.; Smith T.J.; Senju A.,"Haensel, Jennifer X. (56492963100); Ishikawa, Mitsuhiko (57193431831); Itakura, Shoji (7006345646); Smith, Tim J. (55568512084); Senju, Atsushi (6507202951)",56492963100; 57193431831; 7006345646; 55568512084; 6507202951,Cultural influences on face scanning are consistent across infancy and adulthood,2020,Infant Behavior and Development,61,,101503,,,,12,10.1016/j.infbeh.2020.101503,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096227533&doi=10.1016%2fj.infbeh.2020.101503&partnerID=40&md5=7f69e56e61c64276c4db6c67c60db068,"The emergence of cultural differences in face scanning is thought to be shaped by social experience. However, previous studies mainly investigated eye movements of adults and little is known about early development. The current study recorded eye movements of British and Japanese infants (aged 10 and 16 months) and adults, who were presented with static and dynamic faces on screen. Cultural differences were observed across all age groups, with British participants exhibiting more mouth scanning, and Japanese individuals showing increased central face (nose) scanning for dynamic stimuli. Age-related influences independent of culture were also revealed, with a shift from eye to mouth scanning between 10 and 16 months, while adults distributed their gaze more flexibly. Against our prediction, no age-related increases in cultural differences were observed, suggesting the possibility that cultural differences are largely manifest by 10 months of age. Overall, the findings suggest that individuals adopt visual strategies in line with their cultural background from early in infancy, pointing to the development of a highly adaptive face processing system that is shaped by early sociocultural experience. © 2020",Cultural differences; Dynamic faces; Eye tracking; Face perception; Face scanning; Social development,Adult; Asian Continental Ancestry Group; Child Development; Cross-Sectional Studies; Culture; Ethnic Groups; European Continental Ancestry Group; Facial Recognition; Female; Humans; Infant; Male; Social Cognition; adult; adulthood; article; British citizen; eye tracking; facial recognition; female; gaze; groups by age; human; human experiment; infancy; Japanese (people); male; mouth; nose; prediction; social evolution; Asian continental ancestry group; Caucasian; child development; cross-sectional study; cultural anthropology; ethnic group; ethnology; facial recognition; infant; physiology; psychology; social cognition,Article,Final,,Scopus,2-s2.0-85096227533,Movies / Media
Ouyang J.; Huang L.; Jiang J.,"Ouyang, Jinghui (57191617586); Huang, Lingshan (57218632076); Jiang, Jingyang (56051717900)",57191617586; 57218632076; 56051717900,The effects of glossing on incidental vocabulary learning during second language reading: based on an eye-tracking study,2020,Journal of Research in Reading,43,4,,496,515,19.0,18,10.1111/1467-9817.12326,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089868623&doi=10.1111%2f1467-9817.12326&partnerID=40&md5=11c89f6d5829786161a1f1a981fc53a2,"Providing glosses that explain the meanings of unknown words is a common method of promoting learners' learning of new words. Numerous studies have shown that compared with no-gloss condition, glosses benefit the learning of the meaning of new words. This study combines both online (i.e., eye-tracking) and offline (i.e., immediate vocabulary tests) measures to investigate the influences of glosses on incidental vocabulary learning and evaluating the degree to which glossing influences reading behaviour during second language (L2) reading. The eye movements of 45 high-intermediate adult learners of English were recorded when they read a text presented on-screen. Two different text versions (both with 17 new words) were presented to two different groups of participants: first language (L1) textual glossed and no-glossed. After reading, unannounced vocabulary tests were administered to gauge learners' recall and recognition of vocabulary meaning. Learners performed better in meaning recall and meaning recognition tests under L1-glossed condition. Eye-tracking measures of the target words were significantly different in two conditions. Eye-tracking measures of new words and their glosses in L1-glossed condition were significantly correlated with learners' scores of vocabulary tests. L1 glosses promote the learning of the meaning of new words in an incidental condition. The attention allocated to the new words is different in L1-glossed and no-glossed conditions. More importantly, there is a relationship between the online reading behaviour and the vocabulary test performance in gloss condition. © 2020 UKLA",attention; eye movements; glosses; incidental vocabulary learning; L2 reading,,Article,Final,,Scopus,2-s2.0-85089868623,Movies / Media
Xu K.; Ji B.; Wang Z.; Liu J.; Liu H.,"Xu, Kai (56411423800); Ji, Bin (57212017927); Wang, Zhiyong (57205198429); Liu, Jingjing (57211670942); Liu, Honghai (54958434200)",56411423800; 57212017927; 57205198429; 57211670942; 54958434200,An Auxiliary Screening System for Autism Spectrum Disorder Based on Emotion and Attention Analysis,2020,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",2020-October,,9283365,2299,2304,5.0,3,10.1109/SMC42975.2020.9283365,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098846870&doi=10.1109%2fSMC42975.2020.9283365&partnerID=40&md5=702ec06600ca635bd2553f5e91c0b45d,"The screening and diagnosis of Autism Spectrum Disorder(ASD) suffer from great challenges due to insufficient professional clinicians and complex procedures. It is urgent to introduce an effective auxiliary system in the diagnosis and treatment process to assist in the completion of pathological information collection tasks, consequently simplifying the screening method and improving the accuracy of screening. We propose a computer vision-based early screening system for ASD to characterize the facial expressions and eye gaze attention which are considered to remarkable indicators for early screening of autism. The system provides the subjects with three different virtual interaction modes: video, picture, and virtual interactive game. During the interaction between the subject and the computer, the system extracts and analyzes the quantitative information of the subject's performance. Then, through computer vision-based emotion analysis and attention analysis methods, the subject's emotions and attention features in the three interaction modes are automatically calculated to assist in the early screening of autism. Finally, the accuracy and feasibility of the system are verified through experiments on both the publicly available dataset and the data collected from 10 ASD children. © 2020 IEEE.",attention analysis; autism; computer vision; emotion analysis,Diseases; Autism spectrum disorders; Facial Expressions; Information collections; Interaction modes; Interactive games; Quantitative information; Screening methods; Virtual interactions; Computer vision,Conference paper,Final,,Scopus,2-s2.0-85098846870,Movies / Media
Evans-Harvey K.; Erridge S.; Karamchandani U.; Abdalla S.; Beatty J.W.; Darzi A.; Purkayastha S.; Sodergren M.H.,"Evans-Harvey, Keane (57218824883); Erridge, Simon (56989487600); Karamchandani, Urvi (57200624244); Abdalla, Sala (57220475350); Beatty, Jasmine Winter (57218175251); Darzi, Ara (14633357600); Purkayastha, Sanjay (36151052000); Sodergren, Mikael H. (25929707800)",57218824883; 56989487600; 57200624244; 57220475350; 57218175251; 14633357600; 36151052000; 25929707800,Comparison of surgeon gaze behaviour against objective skill assessment in laparoscopic cholecystectomy-a prospective cohort study,2020,International Journal of Surgery,82,,,149,155,6.0,14,10.1016/j.ijsu.2020.08.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090353999&doi=10.1016%2fj.ijsu.2020.08.006&partnerID=40&md5=fab24acbb4a492e6058a6fb7fa623bd4,"Background: Eye tracking technology may provide the basis of a novel, objective technical skill assessment in surgery. Past research has showed differences in the gaze patterns between expert and novice surgeons. The aim of this study was to investigate the relationship between gaze behaviors and technical skill during laparoscopic cholecystectomy as determined by objective assessment scores. Methods: Gaze behaviors of surgeons performing laparoscopic cholecystectomies were mapped using wearable eye tracking apparatus. Two impartial surgeons retrospectively analyzed video footage of the procedure to perform Objective Structured Assessment of Technical Skill (OSATS) assessments. Primary endpoints were correlation between gaze behaviours (dwell time (%) and fixation frequency (count/s)) and OSATS scores. Dwell time was defined as the percentage of time spent fixating on particular visual areas of interest (AOI). Pearson's correlation coefficient was used to estimate the relationship between primary endpoints and AOIs. Statistical significance was set at p < 0.05. Results: 13 procedures were analyzed. Throughout all operative segments, a negative correlation was present between operating theatre dwell time and OSATS scores (p < 0.05). During dissection of Calot's triangle, there was a strong positive correlation between laparoscopic screen dwell time and OSATS scoring [r = 0.655, p < 0.05]. Scrub nurse dwell time during dissection of Calot's triangle showed a strong negative correlation with OSATS scoring [r = −0.619, p < 0.05]. During dissection of gallbladder fossa, operating theatre fixation frequency negatively correlated against OSATS scores [r = −0.566, p < 0.05]. Conclusion: The results suggest a greater focus on significant visual stimuli alongside a lack of attention to non-essential stimuli during critical stages of the operative period is associated with greater technical skill. This aids the validation of eye tracking as an adjunct high-stakes technical skill assessment. © 2020",Assessment; Eye-tracking; Laparoscopic cholecystectomy,"Cholecystectomy, Laparoscopic; Clinical Competence; Eye Movements; Female; Humans; Male; Prospective Studies; Retrospective Studies; Surgeons; Article; assessment of humans; clinical competence; cohort analysis; comparative study; correlation coefficient; dwell time; eye fixation; eye tracking; female; human; interrater reliability; laparoscopic cholecystectomy; male; Objective Structured Assessment of Technical Skill; observational study; priority journal; prospective study; skill; surgeon; clinical competence; eye movement; laparoscopic cholecystectomy; psychology; retrospective study; surgeon",Article,Final,,Scopus,2-s2.0-85090353999,Movies / Media
Venni J.; Bétrancourt M.,"Venni, Julien (57221462320); Bétrancourt, Mireille (6602857958)",57221462320; 6602857958,Aesthetics in hypermedia: Impact of colour harmony on implicit memory and user experience,2020,ICMI 2020 Companion - Companion Publication of the 2020 International Conference on Multimodal Interaction,,,,215,219,4.0,4,10.1145/3395035.3425324,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099234578&doi=10.1145%2f3395035.3425324&partnerID=40&md5=7e1943a44ff11b0518bd7edeab2b8ed9,"According to recent perspectives on human-computer interactions, subjective aspects (emotion or visual attractiveness) have to be considered to provide optimal multimedia material. However, the research investigating the impact of aesthetics or emotional design has yielded varying conclusions regarding the use of interfaces and the resulting learning outcomes. Possible reasons include implementation of the aesthetics variable which varies from one study to another. On this base, an experimental study was conducted to assess the influence of a specific feature of aesthetics, colour harmony, on the use and subjective evaluation of a website. The study involved 34 participants browsing on two versions of the same website about science-fiction movies, with harmonious vs. disharmonious colours as the between-subject factor. After conducting six information search tasks, participants answered to questionnaires assessing usability, user experience, non-instrumental and instrumental qualities. Measures of actual usability of the website, navigation, eye movements and implicit memory performance were collected. Results showed that disharmonious colours caused lower subjective ratings for pragmatic qualities, appeared to distract visual attention but, surprisingly, lead to higher memory performances. On the other hand, colour harmony did not impact the navigation and perceived usability of the system, the perception of the aesthetics (apart from colour), hedonic qualities as well as the experience of use. These findings comfort the hypothesis that aesthetic features affect users' behavior and perception, but not on all dimensions of user experience. Based on the findings, a model for future research in the field is suggested. © 2020 ACM.",Aesthetics; Colour harmony; Emotional design; User experience,Behavioral research; Color; Eye movements; Human computer interaction; Interactive computer systems; Surveys; Websites; Actual usabilities; Aesthetic features; Information search; Multimedia materials; Perceived usability; Pragmatic qualities; Subjective aspects; Subjective evaluations; User experience,Conference paper,Final,,Scopus,2-s2.0-85099234578,Movies / Media
Porcu S.; Floris A.; Anedda M.; Popescu V.; Fadda M.; Atzori L.,"Porcu, Simone (57202321753); Floris, Alessandro (55414506600); Anedda, Matteo (49961024300); Popescu, Vlad (35103143500); Fadda, Mauro (54968905900); Atzori, Luigi (57208011473)",57202321753; 55414506600; 49961024300; 35103143500; 54968905900; 57208011473,Quality of experience eye gaze analysis on HbbTV smart home notification system,2020,"IEEE International Symposium on Broadband Multimedia Systems and Broadcasting, BMSB",2020-October,,9379794,,,,2,10.1109/BMSB49480.2020.9379794,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103468265&doi=10.1109%2fBMSB49480.2020.9379794&partnerID=40&md5=65cc0342bf62309a91ff5e3e2a897850,"Recent studies have started to consider the HbbTV as the central hub to handle notifications regarding the smart home devices. The HbbTV integrates into the multimedia TV contents the notifications coming from various smart home devices such as the smartphone, video door-phone, sensors, washing machine, etc. Therefore, there is a need to evaluate the impact on-screen notifications would have on the user's perceived Quality of Experience (QoE). In some cases, notifications may annoy the user and negatively impact the QoE perceived for the watched video contents. For these reasons, a subjective quality assessment is presented in order to evaluate the impact of onscreen notifications while users are watching TV video contents. Test participants were recorded while watching the video because, using the eye's gaze direction, the attention of the participants towards notifications was measured.  © 2020 IEEE.",Future broadcasting services; Multimedia service deployments; Performance evaluation techniques; Quality of experience; Subjective evaluation techniques.,Ambient intelligence; Automation; Broadband networks; Multimedia systems; Quality control; Video recording; Eye-gaze; Gaze direction; Notification systems; Perceived quality; Quality of experience (QoE); Smart homes; Subjective quality assessments; Video contents; Quality of service,Conference paper,Final,,Scopus,2-s2.0-85103468265,Movies / Media
Ansani A.; Marini M.; D’Errico F.; Poggi I.,"Ansani, Alessandro (57195280946); Marini, Marco (57207346101); D’Errico, Francesca (56441548900); Poggi, Isabella (6603703752)",57195280946; 57207346101; 56441548900; 6603703752,"How Soundtracks Shape What We See: Analyzing the Influence of Music on Visual Scenes Through Self-Assessment, Eye Tracking, and Pupillometry",2020,Frontiers in Psychology,11,,2242,,,,26,10.3389/fpsyg.2020.02242,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094167414&doi=10.3389%2ffpsyg.2020.02242&partnerID=40&md5=0c3a2c496aa65f787e9f46573527e18e,"This article presents two studies that deepen the theme of how soundtracks shape our interpretation of audiovisuals. Embracing a multivariate perspective, Study 1 (N = 118) demonstrated, through an online between-subjects experiment, that two different music scores (melancholic vs. anxious) deeply affected the interpretations of an unknown movie scene in terms of empathy felt toward the main character, impressions of his personality, plot anticipations, and perception of the environment of the scene. With the melancholic music, participants felt empathy toward the character, viewing him as more agreeable and introverted, more oriented to memories than to decisions, while perceiving the environment as cozier. An almost opposite pattern emerged with the anxious music. In Study 2 (N = 92), we replicated the experiment in our lab but with the addition of eye-tracking and pupillometric measurements. Results of Study 1 were largely replicated; moreover, we proved that the anxious score, by increasing the participants’ vigilance and state of alert (wider pupil dilation), favored greater attention to minor details, as in the case of another character who was very hard to be noticed (more time spent on his figure). Results highlight the pervasive nature of the influence of music within the process of interpretation of visual scenes. © Copyright © 2020 Ansani, Marini, D’Errico and Poggi.",audiovisual; empathy; environment perception; eye tracking; film music; interpretation; pupillometry; soundtrack,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85094167414,Movies / Media
,,,Proceedings - SUI 2020: ACM Symposium on Spatial User Interaction,2020,Proceedings - SUI 2020: ACM Symposium on Spatial User Interaction,,,,,,195.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096617426&partnerID=40&md5=239c49a78142fe056d2c362e8a17cee5,The proceedings contain 34 papers. The topics discussed include: rotational self-motion cues improve spatial learning when teleporting in virtual environments; eye gaze-based object rotation for head-mounted displays; exploring the limitations of environment lighting on optical see-through head-mounted displays; RayGraphy: aerial volumetric graphics rendered using lasers in fog; methods for evaluating depth perception in a large-screen immersive display; evaluating interaction cue purpose and timing for learning and retaining virtual reality training; the effect of spatial reference on visual attention and workload during viewpoint guidance in augmented reality; and hand with sensing sphere: body-centered spatial interactions with a hand-worn spherical camera.,,,Conference review,Final,,Scopus,2-s2.0-85096617426,Movies / Media
Riffo B.; Guerra E.; Rojas C.; Novoa A.; Veliz M.,"Riffo, Bernardo (22954160900); Guerra, Ernesto (56377117400); Rojas, Carlos (57217865478); Novoa, Abraham (57217866202); Veliz, Mónica (25655603200)",22954160900; 56377117400; 57217865478; 57217866202; 25655603200,Strategic Spatial Anchoring as Cognitive Compensation During Word Categorization in Parkinson’s Disease: Evidence from Eye Movements,2020,Journal of Psycholinguistic Research,49,5,,823,836,13.0,6,10.1007/s10936-020-09718-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087769484&doi=10.1007%2fs10936-020-09718-3&partnerID=40&md5=66dd8e093f5e71cf10ba7fbff8801d7d,"The association between a word and typical location (e.g., cloud—up) appears to modulate healthy individuals’ response times and visual attention. This study examined whether similar effects can be observed in a clinical population characterized by difficulties in both spatial representation and lexical processing. In an eye-tracking experiment, participants categorized spoken words as either up-associated or down-associated. Parkinson’s disease patients exhibited a tendency to maintain their visual attention in the upper half of the screen, however, this tendency was significantly lower when participants categorized concepts as down-associated. Instead, the control group showed no preference for either the upper or lower half of the screen. We argue that Parkinson’s disease patients present an over-reliance on space during word categorization as a form of cognitive compensation. Such compensation reveals that this clinical population may use spatial anchoring when categorizing words with a spatial association, even in the absence of explicit spatial cues. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.",Blank-screen paradigm; Eye tracking; Parkinson’s disease; Spatial representation; Word categorization,Adult; Attention; Cognition; Cues; Eye Movements; Female; Humans; Language; Male; Parkinson Disease; adult; association; attention; cognition; eye movement; female; human; language; male; Parkinson disease; pathophysiology; physiology,Article,Final,,Scopus,2-s2.0-85087769484,Movies / Media
Liu W.; Ma Z.; Zhang H.; Tian Y.; Liao Z.; Liu Z.; Gong J.; Li C.,"Liu, Wei (56795972400); Ma, Zhenyu (35223623000); Zhang, Heng (57205703274); Tian, Yongji (16643955500); Liao, Zhiyi (57205704105); Liu, Zhiming (57218795550); Gong, Jian (15057870600); Li, Chunde (8428468200)",56795972400; 35223623000; 57205703274; 16643955500; 57205704105; 57218795550; 15057870600; 8428468200,Clinical features and treatment strategy of pediatric tectal gliomas; [儿童顶盖胶质瘤的临床特征及治疗策略],2020,Chinese Journal of Neurosurgery,36,9,,874,879,5.0,1,10.3760/cma.j.cn112050-20200520-00300,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092577843&doi=10.3760%2fcma.j.cn112050-20200520-00300&partnerID=40&md5=6b1120523f9db9ff0d78573a53d301cf,"Objective: To explore the clinical features and treatment strategy of pediatric tectal gliomas (TGs). Methods: The clinical data of patients with the diagnosis of TGs (age ≤ 18 years old) admitted to Neurosurgery Department of Beijing Tiantan Hospital, Capital Medical University from January 1996 to December 2019 were retrospectively analyzed. Eighty-four patients first underwent treatment of hydrocephalus. Among them, 42 patients underwent ventriculoperitoneal shunt (VPs) and 42 underwent endoscopic third ventriculostomy (ETV). A total of 24 patients eventually underwent tumor resection by transcallosal interforniceal/transchoroidal approach (n=11), supracerebellar infratentorial/trans-fourth ventricular approach (n=10) and sub-occipital transtentorial approach (n=3). According to MRI at follow-up, the recovery of hydrocephalus, tumor resection and progression were evaluated. Results: Of the 88 patients, the median age was 9.3 years (range: 6 months to 18 years). The obstructive hydrocephalus with intracranial hypertension due to tumor compression was the primary presentation at diagnosis and reported in 45 patients (51.1%). Of 42 cases with failure of VPs, 14 (33.3%) received additional revisions. Only 6 out of 42 cases (14.3%) in the ETV group required additional VPs and the successful rate of ETV was 85.7% (36/42). Synchronous tissue biopsy during ETV was performed in 9 patients. Among the 24 cases(27 procedures) who underwent craniotomy, total resection was achieved in 7 procedures, near total resection 14, and partial resection in 6. After hydrocephalus treatment, 58 cases were followed up without undergoing craniotomy or biopsy and histological examination was conducted in the remaining 30 cases. Among them, 25 patients had low grade glioma, 3 patients had high grade gliomas, and gliosis was reported in 2. The median follow-up duration of 88 children was 39.5 months (4-288 months). Among the 76 children who did not undergo early craniotomy, the follow-up indicated tumor progression in 24 patients (31.6%), 2 patients (8.3%) underwent a second resection due to tumor recurrence and 2 (2.3%) deaths were documented. The remaining 86 cases kept a normal life. There were 4 cases of transient memory impairment, 3 cases of eye movement disorder and 20 cases of recurrence of hydrocephalus. Conclusions: Pediatric TGs are generally low-grade gliomas and obstructive hydrocephalus is its mainly manifestation. ETV should be the first choice and an alternative to shunt placement for hydrocephalus treatment. Resection surgery is required in only some cases. In most cases, general recommendation for treatment is close observation after management of hydrocephalus, while attention should be paid to the tumor progression. Copyright © 2020 by the Chinese Medical Association.",Child; Glioma; Hydrocephalus; Midbrain tectum; Treatment protocol,adolescent; adult; Article; brain histology; brain ventricle peritoneum shunt; cancer grading; cancer mortality; cancer surgery; cancer therapy; child; clinical evaluation; clinical feature; controlled study; craniotomy; endoscopic surgery; eye movement disorder; follow up; glioma; gliosis; hospital admission; human; human tissue; infant; intracranial hypertension; major clinical study; memory disorder; neuroimaging; nuclear magnetic resonance imaging; obstructive hydrocephalus; postoperative complication; priority journal; recurrent disease; reoperation; retrospective study; tectum; third ventriculostomy; treatment failure; tumor biopsy; tumor growth; tumor recurrence; young adult,Article,Final,,Scopus,2-s2.0-85092577843,Movies / Media
Ponce H.R.; Mayer R.E.; Sitthiworachart J.; López M.J.,"Ponce, Héctor R. (36751744900); Mayer, Richard E. (7403065717); Sitthiworachart, Jirarat (6508298124); López, Mario J. (57189495226)",36751744900; 7403065717; 6508298124; 57189495226,Effects on response time and accuracy of technology-enhanced cloze tests: an eye-tracking study,2020,Educational Technology Research and Development,68,5,,2033,2053,20.0,8,10.1007/s11423-020-09740-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078089632&doi=10.1007%2fs11423-020-09740-1&partnerID=40&md5=acdcdd5e0321939f1b7e02f66d7c09ff,"The transition from paper-based tests to corresponding computer-administered tests allows for the incorporation of improved interfaces that support response making. The main research question is whether innovative interfaces affect test response time and/or response accuracy. This study compared performance on banked cloze tests using a conventional interface (based on paper-based formats for responding by writing a number in a box) versus cloze tests with improved interfaces (based on computer-based affordances such as dragging and dropping responses to fill in a blank). In a banked cloze test, the left side of the page shows a text with words deleted and replaced with blanks that are numbered, and the right side shows the word list with a space to write in the corresponding number. In Experiment 1, 56 fourth graders in the conventional group responded more slowly but just as accurately, and spent more time looking at the word list on the right of the screen but spent equivalent time looking at the text as compared to a group that took the test with an improved interface. In Experiment 2, the same pattern of results was replicated with 148 sixth graders and for each of three versions of improved interfaces as compared to the conventional interface. Results support the idea that the improved interface affected the response execution phase but not the response development phase of performance on the cloze test. © 2020, Association for Educational Communications and Technology.",Cloze test; Cognitive load; Computer-administered test; Drag-and-drop interface; Technology-enhanced items,,Article,Final,,Scopus,2-s2.0-85078089632,Movies / Media
Wolfe J.M.,"Wolfe, Jeremy M. (14036406400)",14036406400,Visual Search: How Do We Find What We Are Looking For?,2020,Annual Review of Vision Science,6,,,539,562,23.0,138,10.1146/annurev-vision-091718-015048,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091191619&doi=10.1146%2fannurev-vision-091718-015048&partnerID=40&md5=eb495eac5aa782b24bd0659a544660f3,"In visual search tasks, observers look for targets among distractors. In the lab, this often takes the form of multiple searches for a simple shape that may or may not be present among other items scattered at random on a computer screen (e.g., Find a red T among other letters that are either black or red.). In the real world, observers may search for multiple classes of target in complex scenes that occur only once (e.g., As I emerge from the subway, can I find lunch, my friend, and a street sign in the scene before me?). This article reviews work on how search is guided intelligently. I ask how serial and parallel processes collaborate in visual search, describe the distinction between search templates in working memory and target templates in long-term memory, and consider how searches are terminated. © 2020 Annual Reviews Inc.. All rights reserved.",foraging; parallel processing; serial processing; visual attention; visual search; working memory,"Color Perception; Eye Movements; Humans; Memory, Short-Term; Pattern Recognition, Visual; color vision; eye movement; human; pattern recognition; physiology; short term memory",Review,Final,,Scopus,2-s2.0-85091191619,Movies / Media
Purple R.J.; Cosgrave J.; Vyazovskiy V.; Foster R.G.; Porcheret K.; Wulff K.,"Purple, R.J. (57190858109); Cosgrave, J. (56585657000); Vyazovskiy, V. (8245395400); Foster, R.G. (7402462300); Porcheret, K. (32367763700); Wulff, K. (7005365870)",57190858109; 56585657000; 8245395400; 7402462300; 32367763700; 7005365870,Sleep-related memory consolidation in the psychosis spectrum phenotype,2020,Neurobiology of Learning and Memory,174,,107273,,,,5,10.1016/j.nlm.2020.107273,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089069806&doi=10.1016%2fj.nlm.2020.107273&partnerID=40&md5=021d26f5740125d2e38b34ab0e895a1e,"Sleep and memory processing impairments range from mild to severe in the psychosis spectrum. Relationships between memory processing and sleep characteristics have been described for schizophrenia, including unaffected first-degree relatives, but they are less clear across other high-risk groups within the psychosis spectrum. In this study, we investigated high-risk individuals with accumulated risk-factors for psychosis and subthreshold symptoms. Out of 1898 screened individuals, 44 age- and sex-matched participants were sub-grouped into those with substantial environmental risk factors for psychosis and subthreshold psychotic symptoms (high-risk group) and those without these phenotypes (low-risk controls). Four groups (high/low risk, morning/evening training) were trained and tested in the laboratory for sustained attention, motor skill memory (finger-tapping task) and declarative memory (word-pair learning task) immediately after training, again after a night of EEG-recorded sleep at home or a period of daytime wakefulness, and again after 24 h from training. No differences in sustained attention or in memory consolidation of declarative and motor skill memory were found between groups for any time period tested. However, a group difference was found for rapid-eye movement (REM) sleep in relation to motor skill memory: the longer the total sleep time, particularly longer REM sleep, the greater the performance gain, which occurred only in high-risk individuals. In conclusion, our results suggest a gain in motor skill performance with sufficient sleep opportunity for longer REM sleep in high-risk individuals with subthreshold psychotic symptoms. Declarative memory did not benefit from sleep consolidation above or beyond that of the control group. © 2020 The Authors",Declarative; Memory consolidation; Motor skill; Psychosis; Risk factors; Sleep,Adolescent; Adult; Attention; Electroencephalography; Female; Humans; Male; Memory Consolidation; Motor Skills; Phenotype; Polysomnography; Psychomotor Performance; Psychotic Disorders; Sleep; Young Adult; adult; alertness; Article; attention; controlled study; declarative memory; electroencephalography; female; high risk population; human; low risk population; male; memory; memory consolidation; motor skill memory; psychosis; REM sleep; risk factor; sleep; sleep time; task performance; adolescent; motor performance; pathophysiology; phenotype; polysomnography; psychology; psychomotor performance; psychosis; young adult,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85089069806,Movies / Media
Picó A.; Espert R.; Gadea M.,"Picó, Alfonso (57204960932); Espert, Raul (6603079132); Gadea, Marien (6601966868)",57204960932; 6603079132; 6601966868,How Our Gaze Reacts to Another Person’s Tears? Experimental Insights Into Eye Tracking Technology,2020,Frontiers in Psychology,11,,2134,,,,10,10.3389/fpsyg.2020.02134,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091026870&doi=10.3389%2ffpsyg.2020.02134&partnerID=40&md5=0f00fafcd2af86994c06de076216b8bb,"Crying is an ubiquitous human behavior through which an emotion is expressed on the face together with visible tears and constitutes a slippery riddle for researchers. To provide an answer to the question “How our gaze reacts to another person’s tears?,” we made use of eye tracking technology to study a series of visual stimuli. By presenting an illustrative example through an experimental setting specifically designed to study the “tearing effect,” the present work aims to offer methodological insight on how to use eye-tracking technology to study non-verbal cues. A sample of 30 healthy young women with normal visual acuity performed a within-subjects task in which they evaluated images of real faces with and without tears while their eye movements were tracked. Tears were found to be a magnet for visual attention in the task of facial attribution, facilitating a greater perception of emotional intensity. Moreover, the inspection pattern changed qualitatively and quantitatively, with our participants becoming fully focused on the tears when they were visible. The mere presence of a single tear running down a cheek was associated with an increased emotional inference and greater perception of sincerity. Using normalized and validated tools (Reading the Eyes in the Mind Test and the SALAMANCA screening test for personality disorders), we measured the influence of certain characteristics of the participants on their performance of the experimental task. On the one hand, a higher level of cognitive empathy helped to classify tearful faces with higher emotional intensity and tearless faces with less emotional intensity. On the other hand, we observed that less sincerity was attributed to the tearful faces as the SALAMANCA test scores rose in clusters A (strange and extravagant) and B (immature and emotionally unstable) of our sample. The present findings highlight the advantages of using eye tracking technology to study non-verbal cues and draw attention to methodological issues that should be taken into account. Further exploration of the relationship between empathy and tear perception could be a fruitful avenue of future research using eye tracking. © Copyright © 2020 Picó, Espert and Gadea.",crying; empathy; eye tracking; gaze; tears,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85091026870,Movies / Media
Howell D.R.; Brilliant A.N.; Master C.L.; Meehan W.P.,"Howell, David R. (55536489400); Brilliant, Anna N. (57198420973); Master, Christina L. (8685818700); Meehan, William P. (8891930200)",55536489400; 57198420973; 8685818700; 8891930200,Reliability of Objective Eye-Tracking Measures among Healthy Adolescent Athletes,2020,Clinical Journal of Sport Medicine,30,5,,444,450,6.0,17,10.1097/JSM.0000000000000630,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090546185&doi=10.1097%2fJSM.0000000000000630&partnerID=40&md5=73ba777dd972a1ac0162439ca60085df,"Objective:To determine the test-retest correlation of an objective eye-Tracking device among uninjured youth athletes.Design:Repeated-measures study.Setting:Sports-medicine clinic.Participants:Healthy youth athletes (mean age = 14.6 ± 2.2 years; 39% women) completed a brief, automated, and objective eye-Tracking assessment.Independent variables:Participants completed the eye-Tracking assessment at 2 different testing sessions.Main outcome measures:During the assessment, participants watched a 220-second video clip while it moved around a computer monitor in a clockwise direction as an eye tracker recorded eye movements. We obtained 13 eye movement outcome variables and assessed correlations between the assessments made at the 2 time points using Spearman's Rho (rs).Results:Thirty-one participants completed the eye-Tracking evaluation at 2 time points [median = 7 (interquartile range = 6-9) days between tests]. No significant differences in outcomes were found between the 2 testing times. Several eye movement variables demonstrated moderate to moderately high test-retest reliability. Combined eye conjugacy metric (BOX score, rs= 0.529, P = 0.008), the variance of the ratio for both eye movements in the horizontal (rs= 0.497, P = 0.013) and vertical (rs= 0.446; P = 0.029) movement planes along the top/bottom of the computer screen, and the variance of the left and right eye movement along the bottom segment of the computer screen (rs= 0.565; P = 0.004) each demonstrated moderate between-Test correlations.Conclusions:Automated and quantitative eye movement and conjugacy metrics provide relatively stable measurements among a group of healthy youth athletes. Thus, their inclusion as a visual tracking metric may be complementary to other visual examination techniques when monitoring concussion recovery across time. © 2020 Lippincott Williams and Wilkins. All rights reserved.",concussion; disconjugacy; eye tracking; vision,"Adolescent; Athletes; Attention Deficit Disorder with Hyperactivity; Brain Concussion; Child; Eye Movements; Eye-Tracking Technology; Female; Humans; Male; Outcome Assessment, Health Care; Prospective Studies; Reproducibility of Results; Statistics, Nonparametric; Time Factors; adolescent; athlete; attention deficit disorder; brain concussion; child; devices; eye movement; female; human; male; nonparametric test; pathophysiology; physiology; prospective study; reproducibility; time factor",Article,Final,,Scopus,2-s2.0-85090546185,Movies / Media
Gomez A.; Huron C.,"Gomez, Alice (7202716539); Huron, Caroline (6603087412)",7202716539; 6603087412,Subitizing and counting impairments in children with developmental coordination disorder,2020,Research in Developmental Disabilities,104,,103717,,,,9,10.1016/j.ridd.2020.103717,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086723018&doi=10.1016%2fj.ridd.2020.103717&partnerID=40&md5=d42de8d836f3144912e9dc0640881264,"Developmental coordination disorder (DCD) interferes with academic achievement and daily life, and is associated with persistent academic difficulties, in particular within mathematical learning. In the present study, we aimed to study numerical cognition using an approach that taps very basic numerical processes such as subitizing and counting abilities in DCD. We used a counting task and a subitizing task in forty 7–10 years-old children with or without DCD. In both tasks, children were presented with arrays of one to eight dots and asked to name aloud the number of dots as accurately and quickly as possible. In the subitizing task, dots were presented during 250 ms whereas in the counting task they stayed on the screen until the participants gave a verbal response. The results showed that children with DCD were less accurate and slower in the two enumeration tasks (with and without a time limit), providing evidence that DCD impairs both counting and subitizing. These impairments might have a deleterious impact on the ability to improve the acuity of the Approximate Number System through counting, and thus could play a role in the underachievement of children with DCD in mathematics. © 2020 Elsevier Ltd",Approximate number system; Counting; Developmental Coordination Disorder; Eyetracking; Subitizing,Child; Cognition; Educational Status; Humans; Mathematics; Motor Skills Disorders; academic underachievement; analytical error; Article; child; clinical article; cognition; controlled study; developmental coordination disorder; eye tracking; female; human; image display; intellectual impairment; male; mathematical computing; mathematics; reaction time; school child; task performance; verbal behavior; educational status; psychomotor disorder,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85086723018,Movies / Media
Tabone A.; Bonnici A.; Cristina S.,"Tabone, André (57216269962); Bonnici, Alexandra (35748631300); Cristina, Stefania (49963155000)",57216269962; 35748631300; 49963155000,Automated Page Turner for Musicians,2020,Frontiers in Artificial Intelligence,3,,57,,,,6,10.3389/frai.2020.00057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117283728&doi=10.3389%2ffrai.2020.00057&partnerID=40&md5=ca5293bc3923ad1545ee178c918fea55,"An increasing number of musicians are opting to use tablet devices instead of traditional print media for their music sheets since the digital medium offers the benefit of storing a lot of music in a compact space. The limited screen size of the tablet devices makes the music difficult to read and musicians often opt to display part of the music page at a time. With fewer music lines on display, the musician will then have to resort to scrolling through the music to read the entire score. This scrolling is annoying since the musicians will need to remove their hands from the instrument to interact with the tablet, causing a break in the music if this is not done quickly enough, or if the tablet is not sufficiently responsive. In this paper, we describe an alternative page turning system which automates the page turning event of the musician. By actively monitoring the musician's on-screen point of regard, the system retains the musician in the loop and thus, the page turns are attuned to the musician's position on the score. By analysing the way the musician's gaze changes between attention to the score and the instrument as well as the way musicians fixate on different parts of the score, we note that musicians often look away from the score and toward their hands, or elsewhere, when playing the instrument. As a result, the eye regions fall outside the field-of-view of the eye-gaze tracker, giving rise to erratic page-turns. To counteract this problem, we create a gaze prediction model that uses Kalman filtering to predict where the musician would be looking on the score. We evaluate our hands-free page turning system using 15 different piano songs containing different levels of difficulty, various repeats, and which also required playing in different registers on the piano, thus, evaluating the applicability of the page-turner under different conditions. Performance of the page-turner was quantified through the number of correct page turns, the number of delayed page turns, and the number of mistaken page turns. Of the 289 page turns involved in the experiment, 98.3% were successfully executed, 1.7% were delayed, while no mistaken page turns were observed. © Copyright © 2020 Tabone, Bonnici and Cristina.",eye-gaze tracking; eye-hand span; half-page turns; Kalman filter; page-turning,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85117283728,Movies / Media
Pagnotta M.; Laland K.N.; Coco M.I.,"Pagnotta, Murillo (56144652500); Laland, Kevin N. (7003969474); Coco, Moreno I. (35093644900)",56144652500; 7003969474; 35093644900,Attentional coordination in demonstrator-observer dyads facilitates learning and predicts performance in a novel manual task,2020,Cognition,201,,104314,,,,12,10.1016/j.cognition.2020.104314,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084958934&doi=10.1016%2fj.cognition.2020.104314&partnerID=40&md5=a89ae9658236715c952f8b2986262598,"Observational learning is a form of social learning in which a demonstrator performs a target task in the company of an observer, who may as a consequence learn something about it. In this study, we approach social learning in terms of the dynamics of coordination rather than the more common perspective of transmission of information. We hypothesised that observers must continuously adjust their visual attention relative to the demonstrator's time-evolving behaviour to benefit from it. We eye-tracked observers repeatedly watching videos showing a demonstrator solving one of three manipulative puzzles before attempting at the task. The presence of the demonstrator's face and the availability of his verbal instruction in the videos were manipulated. We then used recurrence quantification analysis to measure the dynamics of coordination between the overt attention of the observers and the demonstrator's manipulative actions. Bayesian hierarchical logistic regression was applied to examine (1) whether the observers' performance was predicted by such indexes of coordination, (2) how performance changed as they accumulated experience, and (3) if the availability of speech and intentional gaze of the demonstrator mediated it. Results showed that learners better able to coordinate their eye movements with the manipulative actions of the demonstrator had an increasingly higher probability of success in solving the task. The availability of speech was beneficial to learning, whereas the presence of the demonstrator's face was not. We argue that focusing on the dynamics of coordination between individuals may greatly improve understanding of the cognitive processes underlying social learning. © 2020 Elsevier B.V.",Attentional synchronisation; Bayesian regression; Eye tracking; Observational learning; Recurrence quantification analysis,Bayes Theorem; Humans; Learning; Social Learning; Speech; Videotape Recording; adult; article; eye tracking; gaze; human; human experiment; male; probability; social learning; speech; videorecording; visual attention; Bayes theorem; learning,Article,Final,,Scopus,2-s2.0-85084958934,Movies / Media
Kittler P.M.; Kim S.-Y.; Flory M.J.; Phan H.T.T.; Karmel B.Z.; Gardner J.M.,"Kittler, P.M. (6602156701); Kim, S.-Y. (57216792041); Flory, M.J. (6603816747); Phan, H.T.T. (35366932400); Karmel, B.Z. (7003390740); Gardner, J.M. (7403050498)",6602156701; 57216792041; 6603816747; 35366932400; 7003390740; 7403050498,Effects of motion and audio-visual redundancy on upright and inverted face and feature preferences in 4-13-month old pre- and full-term NICU graduates,2020,Infant Behavior and Development,60,,101439,,,,2,10.1016/j.infbeh.2020.101439,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084671675&doi=10.1016%2fj.infbeh.2020.101439&partnerID=40&md5=a8ce341176e5baf1b1858ac8fb4fa639,"NICU infants are reported to have diminished social orientation and increased risk of socio-communicative disorders. In this eye tracking study, we used a preference for upright compared to inverted faces as a gauge of social interest in high medical risk full- and pre-term NICU infants. We examined the effects of facial motion and audio-visual redundancy on face and eye/mouth preferences across the first year. Upright and inverted baby faces were simultaneously presented in a paired-preference paradigm with motion and synchronized vocalization varied. NICU risk factors including birth weight, sex, and degree of CNS injury were examined. Overall, infants preferred the more socially salient upright faces, making this the first report, to our knowledge, of an upright compared to inverted face preference among high medical risk NICU infants. Infants with abnormalities on cranial ultrasound displayed lower social interest, i.e. less of a preferential interest in upright faces, when viewing static faces. However, motion selectively increased their upright face looking time to a level equal that of infants in other CNS injury groups. We also observed an age-related sex effect suggesting higher risk in NICU males. Females increased their attention to the mouth in upright faces across the first year, especially between 7–10 months, but males did not. Although vocalization increased diffuse attention toward the screen, contrary to our predictions, there was no evidence that the audio-visual redundancy embodied in a vocalizing face focused additional attention on upright faces or mouths. This unexpected result may suggest a vulnerability in response to talking faces among NICU infants that could potentially affect later verbal and socio-communicative development. © 2020 Elsevier Inc.",Audio-visual redundancy; Eye tracking; Face inversion; Pre/full-term NICU graduates; Talking face,"Acoustic Stimulation; Eye Movements; Facial Recognition; Female; Humans; Infant; Infant, Newborn; Infant, Premature; Intensive Care Units, Neonatal; Longitudinal Studies; Male; Motion Perception; Orientation, Spatial; Photic Stimulation; Article; attention test; audiovisual recording; birth weight; central nervous system; child; controlled study; eye tracking; face profile; facial expression; female; groups by age and sex; high risk infant; human; infant; longitudinal study; male; neonatal intensive care unit; prediction; prematurity; preschool child; priority journal; redundancy analysis; social evolution; speech development; ultrasound; vocalization; auditory stimulation; eye movement; facial recognition; movement perception; newborn; photostimulation; physiology; prematurity; procedures; psychology; spatial orientation",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85084671675,Movies / Media
Zhou B.; Lin L.,"Zhou, Bin (57218589666); Lin, Li (56963059800)",57218589666; 56963059800,Research on cognitive matching of biological morphological features and images for profiling design,2020,E3S Web of Conferences,179,,1015,,,,0,10.1051/e3sconf/202017901015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089692575&doi=10.1051%2fe3sconf%2f202017901015&partnerID=40&md5=9689c173dba7e8eb6a5e4ca4a4a89bde,"To obtain high-quality bionic design scheme of product form, this paper explores the matching relationship between users' biological form features and their images from the level of implicit cognition, providing objective basis for effective selection of ideographic biological form features in bionic design of product form. The eye movement experiment was used to screen the biomorphic feature group that was focused on. Questionnaire survey and cluster analysis were used to obtain the main image phrases of the morphological feature group. The two collected materials were combined with implicit cognitive measurement (IAT) to obtain the response time data of the subjects in the classification task. According to Greenwald's method to verify the effectiveness of the data as a whole, the response time of the combination of various features and images in the compatibility group is sorted to obtain the design guidance conclusion. Taking the white shouldered eagle as an example, the experimental data showed high validity by t-test, and the implicit effect value of the compatibility group was 0.68. According to the analysis of the data, the main image that most matches the head shape characteristics of the white shouldered eagle is ""Ferocious"", and the main image that most matches the wing shape characteristics is ""Lightsome"", and there is no difference in the implicit cognitive attitude between men and women. The designer takes this as the design reference to improve the effectiveness of the design output. This study can provide more objective suggestions for the bionic design of the related product shape. © The Authors, published by EDP Sciences, 2020.",,Bionics; Cluster analysis; Eye movements; Image analysis; Surveys; Water resources; Classification tasks; Cognitive attitudes; Cognitive measurement; Design guidance; Morphological features; Questionnaire surveys; Related products; Shape characteristics; Product design,Conference paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85089692575,Movies / Media
Tao L.; Wang Q.; Liu D.; Wang J.; Zhu Z.; Feng L.,"Tao, Ling (57215665559); Wang, Quan (56145277600); Liu, Ding (8543105200); Wang, Jing (57204397284); Zhu, Ziqing (57215666899); Feng, Li (56965973100)",57215665559; 56145277600; 8543105200; 57204397284; 57215666899; 56965973100,Eye tracking metrics to screen and assess cognitive impairment in patients with neurological disorders,2020,Neurological Sciences,41,7,,1697,1704,7.0,88,10.1007/s10072-020-04310-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081572162&doi=10.1007%2fs10072-020-04310-y&partnerID=40&md5=93e7d8f865063047c76cb3a41bf1ced1,"Purpose of review: Eye tracking is a powerful method to investigate the relationship between behavior and neural mechanisms. In recent years, eye movement analysis has been used in patients with neurological disorders to assess cognitive function. In this review, we explore the latest eye tracking researches in neurological disorders that are commonly associated with cognitive deficits, specifically, amyotrophic lateral sclerosis (ALS), Alzheimer’s disease (AD), Parkinson’s disease (PD), multiple sclerosis (MS), and epilepsy. We focus on the application of ocular measures in these disorders, with the goal of understanding how eye tracking technology can be used in the clinical setting. Findings: Eye tracking tasks (especially saccadic tasks) are often used as an adjunct to traditional scales for cognitive assessment. Eye tracking data confirmed that executive dysfunction is common in PD and ALS, whereas AD and MS are characterized by attention deficits. Research in evaluating cognitive function in epilepsy using eye tracking is still in its early stages, but this approach has shown advantages as a sensitive quantitative method with high temporal and spatial resolution. Summary: Eye tracking technology can facilitate the assessment of cognitive impairment with higher temporal resolution and finer granularity than traditional cognitive assessment. Oculomotor data collected during cognitive tasks can provide insight into biological processes. Eye tracking provides a nonverbal and less cognitively demanding method of measuring disease progression in cognitively impaired patients. © 2020, Fondazione Società Italiana di Neurologia.",Alzheimer’s disease; Amyotrophic lateral sclerosis; Cognition; Epilepsy; Eye tracking; Multiple sclerosis; Neurology; Parkinson’s disease,Amyotrophic Lateral Sclerosis; Benchmarking; Cognition Disorders; Cognitive Dysfunction; Eye-Tracking Technology; Humans; Neuropsychological Tests; attention deficit disorder; cognition; cognitive defect; disease exacerbation; disease severity; epilepsy; eye tracking; human; interrater reliability; neurologic disease; Review; systematic review; amyotrophic lateral sclerosis; benchmarking; cognitive defect; neuropsychological test,Review,Final,,Scopus,2-s2.0-85081572162,Movies / Media
Wang J.; Zhu Y.; Chen Y.; Mamat A.; Yu M.; Zhang J.; Dang J.,"Wang, Jianrong (55885983000); Zhu, Yumeng (57218198418); Chen, Yu (57188765772); Mamat, Abdilbar (57218200391); Yu, Mei (56479650300); Zhang, Ju (55868128700); Dang, Jianwu (7006574053)",55885983000; 57218198418; 57188765772; 57218200391; 56479650300; 55868128700; 7006574053,An eye-tracking study on audiovisual speech perception strategies adopted by normal-hearing and deaf adults under different language familiarities,2020,"Journal of Speech, Language, and Hearing Research",63,7,,2245,2254,9.0,8,10.1044/2020_JSLHR-19-00223,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088235765&doi=10.1044%2f2020_JSLHR-19-00223&partnerID=40&md5=c6434dc1715894f21b4924c4bf8cc68b,"Purpose: The primary purpose of this study was to explore the audiovisual speech perception strategies.80.23.47 adopted by normal-hearing and deaf people in processing familiar and unfamiliar languages. Our primary hypothesis was that they would adopt different perception strategies due to different sensory experiences at an early age, limitations of the physical device, and the developmental gap of language, and others. Method: Thirty normal-hearing adults and 33 prelingually deaf adults participated in the study. They were asked to perform judgment and listening tasks while watching videos of a Uygur–Mandarin bilingual speaker in a familiar language (Standard Chinese) or an unfamiliar language (Modern Uygur) while their eye movements were recorded by eye-tracking technology. Explore Results: Task had a slight influence on the distribution of selective attention, whereas subject and language had significant influences. To be specific, the normal-hearing and the d10eaf participants mainly gazed at the speaker’s eyes and mouth, respectively, in the experiment; moreover, while the normal-hearing participants had to stare longer at the speaker’s mouth when they confronted with the unfamiliar language Modern Uygur, the deaf participant did not change their attention allocation pattern when perceiving the two languages. Conclusions: Normal-hearing and deaf adults adopt different audiovisual speech perception strategies: Normal-hearing adults mainly look at the eyes, and deaf adults mainly look at the mouth. Additionally, language and task can also modulate the speech perception strategy. © 2020 American Speech-Language-Hearing Association.",,adult; clinical article; decision making; eye tracking; female; hearing impaired person; human; human experiment; language; male; mandarin; mouth; nonhuman; note; selective attention; speech perception; videorecording; article,Note,Final,,Scopus,2-s2.0-85088235765,Movies / Media
Nie J.; Qiu Q.; Phillips M.; Sun L.; Yan F.; Lin X.; Xiao S.; Li X.,"Nie, Jing (57206130349); Qiu, Qi (58954668400); Phillips, Michael (57202563610); Sun, Lin (56442960200); Yan, Feng (57220819328); Lin, Xiang (57207007083); Xiao, Shifu (7402022817); Li, Xia (43561619700)",57206130349; 58954668400; 57202563610; 56442960200; 57220819328; 57207007083; 7402022817; 43561619700,Early Diagnosis of Mild Cognitive Impairment Based on Eye Movement Parameters in an Aging Chinese Population,2020,Frontiers in Aging Neuroscience,12,,221,,,,28,10.3389/fnagi.2020.00221,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089411776&doi=10.3389%2ffnagi.2020.00221&partnerID=40&md5=852a29896ee5ad2a9997abba3fef0559,"Background: The pathogenesis of dementia often starts several years prior to clinical onset during which the individual is asymptomatic. Existing strategies for the accurate diagnosis of early dementia are limited by high cost and the invasive nature of the procedures. Eye movement parameters associated with cognitive functions may be helpful in the early identification of dementia and in the development and evaluation of preventive and therapeutic strategies. Objective: We aimed to assess differences in eye movement parameters between healthy elderly individuals and patients with mild cognitive impairment (MCI). Furthermore, we examined the correlations between eye movement parameters with cognitive functions and specific hemispheric region and neural structures in individuals with MCI. Method: Eighty individuals with MCI without dementia (based on DSM-IV criteria) identified by community screening and 170 healthy controls were administered Chinese versions of MoCA and NTB, and a long (20 min) or short (5 min) version of a visual paired comparison (VPC) task. Two weeks later, 44 MCI patients and 107 healthy controls completed a retest of the VPC task, 44 MCI patients and 43 healthy controls among them administered a MRI. At the end of 1-year follow-up, a subset of 26 individuals with MCI and 57 healthy controls were administered the long version of VPC task and MoCA test again. Eye movement parameters and the relationship of eye movement parameters with cognitive functions and with changes in neural structures were compared between groups. Results: Patients with MCI were older, had less education, and had lower scores on cognitive tests than healthy controls. After adjustment for age and level of education, patients with MCI had lower novelty preference scores on the VPC than healthy controls. Using the logistic regression model, the amount of time that subjects focused on these novel images could predict MCI patients from normal elderly with an out of sample area under the receiver operator characteristic curve of 0.62. Furthermore, the cognition score of subjects whose novelty preference score was low decreased more remarkably in 1 year. For both the patient and control groups, VPC novelty preference was significantly correlated with verbal fluency and delayed and short-term memory function. Novelty preference score was also significantly correlated with the cortical thickness of several structures in the right hemisphere. Conclusion: Eye movement parameters are stable indicators to distinguish patients with MCI and cognitively normal subjects and are not affected by different testing versions and numbers. Additionally, the patients’ cognitive deficits and eye movement indices were correlated. Future longitudinal studies should further explore the clinical utility of eye movement parameters as early markers of MCI. © Copyright © 2020 Nie, Qiu, Phillips, Sun, Yan, Lin, Xiao and Li.",dementia; eye-tracking assessment; magnetic resonance imaging; mild cognitive impairment; preclinical diagnosis,age distribution; aged; aging; Article; brain dysfunction; brain region; case control study; Chinese; cognitive function test; cohort analysis; community care; controlled study; cortical thickness (brain); diagnostic accuracy; diagnostic test accuracy study; DSM-IV; early diagnosis; educational status; eye movement; eye tracking; female; follow up; geriatric patient; human; logistic regression analysis; longitudinal study; major clinical study; male; mild cognitive impairment; Montreal cognitive assessment; neuroimaging; novelty preference score; nuclear magnetic resonance imaging; population research; predictive value; receiver operating characteristic; right hemisphere; screening test; sensitivity and specificity; short term memory; task performance; verbalization; very elderly; visual paired comparison; visual system parameters,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85089411776,Movies / Media
Aivaliotis P.-E.; Grivokostopoulou F.; Perikos I.; Daramouskas I.; Hatziligeroudis I.,"Aivaliotis, Panteleimon-Evangelos (57221474593); Grivokostopoulou, Foteini (54412205200); Perikos, Isidoros (27667764000); Daramouskas, Ioannis (57207760262); Hatziligeroudis, Ioannis (25924984600)",57221474593; 54412205200; 27667764000; 57207760262; 25924984600,Eye Gaze Analysis of Students in Educational Systems,2020,"11th International Conference on Information, Intelligence, Systems and Applications, IISA 2020",,,9284374,,,,2,10.1109/IISA50023.2020.9284374,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099188196&doi=10.1109%2fIISA50023.2020.9284374&partnerID=40&md5=de1597d3eb866d829d1ebc98e54e95b9,"Eye gaze provides indicative information about the status and the behavior of a person and can be very assistive in human-computer interaction. Eye-gaze analysis is very helpful in a variety of applications in order to understand the interest of the users, their behavior or even to unveil distractions. However, the accurate eye-gaze estimation is a very challenging process. In this paper, we present an eye gaze estimation work that relies on convolutional neural networks which imitate the LeNet's architecture. They analyze eye gaze and provide a 2D vector that concerns the coordinates of the specific pixel inside the 2D screen's space, in which the user is looking at. Also, a system capable of working under various real-world conditions such as light, angle and distance differentiations was designed and developed. An evaluation study was performed and the results are quite promising pointing out that the system is scalable and accurate in estimating the eye gaze of the users. © 2020 IEEE.",Convolutional Neural Networks; Deep Learning; Eye Gaze estimation; Human-Computer Interaction,Convolutional neural networks; Vector spaces; Assistive; Educational systems; Evaluation study; Eye-gaze; Real-world; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85099188196,Movies / Media
Kaufmann B.C.; Cazzoli D.; Pflugshaupt T.; Bohlhalter S.; Vanbellingen T.; Müri R.M.; Nef T.; Nyffeler T.,"Kaufmann, Brigitte C. (57200416513); Cazzoli, Dario (23990403100); Pflugshaupt, Tobias (7801655988); Bohlhalter, Stephan (6506324427); Vanbellingen, Tim (25723852900); Müri, René M. (7003342964); Nef, Tobias (15726063900); Nyffeler, Thomas (6603229393)",57200416513; 23990403100; 7801655988; 6506324427; 25723852900; 7003342964; 15726063900; 6603229393,Eyetracking during free visual exploration detects neglect more reliably than paper-pencil tests,2020,Cortex,129,,,223,235,12.0,45,10.1016/j.cortex.2020.04.021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085881859&doi=10.1016%2fj.cortex.2020.04.021&partnerID=40&md5=610e01326f480f8b33b04b650dc46b8a,"Neglect after stroke is most accurately diagnosed by a systematic, ecological observation during everyday behaviour using the Catherine Bergego Scale (CBS). However, the CBS is time-consuming and often omitted in clinical settings, especially stroke units. In this study, we aimed to explore if video-oculography during free visual exploration (FVE), which can be performed in few minutes, is sensitive in mirroring neglect in everyday behaviour and whether it is more sensitive than conventional neuropsychological paper-pencil tests. In this retrospective, observational, multicentre study, we identified 78 patients in our database with subacute right-hemispheric stroke, with and without neglect in everyday behaviour, diagnosed by the CBS, who also performed FVE. 40 age-matched healthy participants served as controls. The sensitivity to detect neglect was compared between FVE (i.e., mean gaze position on the horizontal axis) and conventional neuropsychological paper-pencil tests, i.e., Random Shape Cancellation, Line Bisection, Two-Part Picture, Bells, Star Cancellation, Letter Cancellation, Sensitive Neglect, and Five-Point. FVE correctly identified neglect in 85%of patients, with an AUC-value of .922 in ROC-analysis. Conventional neuropsychological paper-pencil tests, considered alone or in combination, showed heterogeneous results, and identified neglect significantly less often (21.74%–68.75%). Moreover, there was a significant correlation between mean gaze position and CBS scores, providing evidence for the relationship between FVE and neglect in everyday behaviour. Furthermore, VLSM analyses suggested that the absence of a pathological rightward bias in FVE might depend on the integrity of the second branch of the right Superior Longitudinal Fascicle (SLF II), a white-matter tract connecting cortical areas critical for visual attention. Video-oculography during FVE has a high sensitivity and specificity to diagnose neglect after stroke and it is more sensitive than conventional neuropsychological paper-pencil tests. It can be performed in short time and has the potential to be used as a fast and accurate screening tool that allows the initiation of comprehensive neuropsychological diagnostics and therapy from early on. © 2020 The Authors",Neglect; Right-hemispheric stroke; ROC analyses; Sensitivity; Video-oculography,adult; Article; bells test; brain hemorrhage; cancellation test; Catherine Bergego Scale; cerebrovascular accident; controlled study; exploratory behavior test; eye tracking; female; five point test; free visual exploration test; gaze; hemianopia; human; letter cancellation test; line bisection test; major clinical study; male; middle aged; multicenter study; neurologic disease assessment; neuropsychological test; nuclear magnetic resonance imaging; observational study; paper pencil test; predictive value; random shape cancellation test; receiver operating characteristic; retrospective study; right hemisphere; sensitive neglect test; sensitivity and specificity; star cancellation test; stroke patient; stroke unit; superior longitudinal fasciculus; two part picture test; videooculography; visual attention; visual deprivation; visual field defect; visual orientation; white matter,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85085881859,Movies / Media
McColeman C.; Thompson J.; Anvari N.; Azmand S.J.; Barnes J.; Barrett R.C.A.; Byliris R.; Chen Y.; Dolguikh K.; Fischler K.; Harrison S.; Hayre R.S.; Poe R.; Swanson L.; Tracey T.; Volkanov A.; Woodruff C.; Zhang R.; Blair M.,"McColeman, Caitlyn (55882781700); Thompson, Joe (56327680200); Anvari, Neda (57216630328); Azmand, Somaya Judi (57216631208); Barnes, Jordan (56154411900); Barrett, Robin C. A. (57195065710); Byliris, Romanos (57216634942); Chen, Yue (57216638641); Dolguikh, Katerina (57216634971); Fischler, Kayla (57216634052); Harrison, Scott (57216633401); Hayre, Rajan S. (57204568851); Poe, Rollin (57216635915); Swanson, Lief (57216631450); Tracey, Tyrus (57216638325); Volkanov, Alex (57216633153); Woodruff, Calvert (57216632526); Zhang, Ruilin (57216635351); Blair, Mark (7102440319)",55882781700; 56327680200; 57216630328; 57216631208; 56154411900; 57195065710; 57216634942; 57216638641; 57216634971; 57216634052; 57216633401; 57204568851; 57216635915; 57216631450; 57216638325; 57216633153; 57216632526; 57216635351; 7102440319,Digit eyes: Learning-related changes in information access in a computer game parallel those of oculomotor attention in laboratory studies,2020,"Attention, Perception, and Psychophysics",82,5,,2434,2447,13.0,4,10.3758/s13414-020-02019-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084118985&doi=10.3758%2fs13414-020-02019-w&partnerID=40&md5=24d3af192797098684ab0446c8442981,"Active sensing theory is founded upon the dynamic relationship between information sampling and an observer’s evolving goals. Oculomotor activity is a well studied method of sampling; a mouse or a keyboard can also be used to access information past the current screen. We examine information access patterns of StarCraft 2 players at multiple skill levels. The first measures are analogous to existing eye-movement studies: fixation frequency, fixation targets, and fixation duration all change as a function of skill, and are commensurate with known properties of eye movements in learning. Actions that require visual attention at moderate skill levels are eventually performed with little visual attention at all. This (a) confirms the generalizability of laboratory studies of attention and learning using eye movements to digital interface use, and (b) suggests that a wide variety of information access behaviors may be considered as a unified set of phenomena. © 2020, The Psychonomic Society, Inc.",Attention in learning; Eye movements and visual attention; Perception and action,"Attention; Eye Movements; Fixation, Ocular; Humans; Learning; Saccades; Video Games; Visual Perception; attention; eye fixation; eye movement; human; learning; saccadic eye movement; video game; vision",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85084118985,Movies / Media
Manoach D.S.; Mylonas D.; Baxter B.,"Manoach, Dara S. (7003820011); Mylonas, Dimitrios (55647163842); Baxter, Bryan (56102825900)",7003820011; 55647163842; 56102825900,Targeting sleep oscillations to improve memory in schizophrenia,2020,Schizophrenia Research,221,,,63,70,7.0,32,10.1016/j.schres.2020.01.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078854215&doi=10.1016%2fj.schres.2020.01.010&partnerID=40&md5=1ed8a3db7d57acc678790f32712716ce,"Although schizophrenia is defined by waking phenomena, a growing literature documents a deficit in sleep spindles, a defining oscillation of stage 2 non-rapid eye movement sleep. Compelling evidence supports an important role for spindles in cognition, and particularly memory. In schizophrenia, although the spindle deficit correlates with impaired sleep-dependent memory consolidation, recent clinical trials find that increasing spindles does not improve memory. This may reflect that sleep-dependent memory consolidation relies not on spindles alone, but also on their precise temporal coordination with cortical slow oscillations and hippocampal sharp-wave ripples. Consequently, interventions to improve memory in schizophrenia must not only increase spindles, but also preserve or enhance slow oscillations, hippocampal ripples and their temporal relations. Because hippocampal ripples and the activity of the thalamic spindle generator are difficult to measure noninvasively, screening potential interventions requires complementary animal and human studies. In this review we (i) propose that sleep oscillations are novel pathophysiological targets for therapy to improve cognition in schizophrenia; (ii) summarize our understanding of how these oscillations interact to consolidate memory; (iii) suggest that a systems neuroscience strategy is essential to selecting and evaluating effective treatments, and illustrate this with findings from clinical trials; and (iv) selectively review the interventional literature relevant to sleep and cognition, covering both pharmacological and noninvasive brain stimulation approaches. We conclude that coordinated sleep oscillations are promising targets for improving cognition in schizophrenia and that effective therapies will need to preserve or enhance sleep oscillatory dynamics and restore function at the network level. © 2020 Elsevier B.V.",Brain stimulation; Hippocampal ripples; Memory; Schizophrenia; Sleep spindles; Slow oscillations,Animals; Electroencephalography; Hippocampus; Humans; Memory; Memory Consolidation; Schizophrenia; Sleep; Sleep Stages; eszopiclone; placebo; zolpidem tartrate; Article; CACNA1I gene; cognitive defect; declarative memory; executive function; gene; genetic risk; human; intelligence quotient; memory consolidation; nonhuman; nonREM sleep; priority journal; procedural memory; PTCHD1 gene; schizophrenia; sleep; sleep oscillation; sleep spindle; thalamus reticular nucleus; transcranial alternating current stimulation; transcranial direct current stimulation; verbal memory; working memory; animal; complication; electroencephalography; hippocampus; memory; sleep; sleep stage,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85078854215,Movies / Media
Valiyamattam G.J.; Katti H.; Chaganti V.K.; O’Haire M.E.; Sachdeva V.,"Valiyamattam, Georgitta J. (57217389513); Katti, Harish (25421611300); Chaganti, Vinay K. (56600511600); O’Haire, Marguerite E. (36473660500); Sachdeva, Virender (24529154100)",57217389513; 25421611300; 56600511600; 36473660500; 24529154100,Do Animals Engage Greater Social Attention in Autism? An Eye Tracking Analysis,2020,Frontiers in Psychology,11,,727,,,,20,10.3389/fpsyg.2020.00727,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087154764&doi=10.3389%2ffpsyg.2020.00727&partnerID=40&md5=827dd1a89905e20d4ce73dcc377eb457,"Background: Visual atypicalities in autism spectrum disorder (ASD) are a well documented phenomenon, beginning as early as 2–6 months of age and manifesting in a significantly decreased attention to the eyes, direct gaze and socially salient information. Early emerging neurobiological deficits in perceiving social stimuli as rewarding or its active avoidance due to the anxiety it entails have been widely purported as potential reasons for this atypicality. Parallel research evidence also points to the significant benefits of animal presence for reducing social anxiety and enhancing social interaction in children with autism. While atypicality in social attention in ASD has been widely substantiated, whether this atypicality persists equally across species types or is confined to humans has not been a key focus of research insofar. Methods: We attempted a comprehensive examination of the differences in visual attention to static images of human and animal faces (40 images; 20 human faces and 20 animal faces) among children with ASD using an eye tracking paradigm. 44 children (ASD n = 21; TD n = 23) participated in the study (10,362 valid observations) across five regions of interest (left eye, right eye, eye region, face and screen). Results: Results obtained revealed significantly greater social attention across human and animal stimuli in typical controls when compared to children with ASD. However in children with ASD, a significantly greater attention allocation was seen to animal faces and eye region and lesser attention to the animal mouth when compared to human faces, indicative of a clear attentional preference to socially salient regions of animal stimuli. The positive attentional bias toward animals was also seen in terms of a significantly greater visual attention to direct gaze in animal images. Conclusion: Our results suggest the possibility that atypicalities in social attention in ASD may not be uniform across species. It adds to the current neural and biomarker evidence base of the potentially greater social reward processing and lesser social anxiety underlying animal stimuli as compared to human stimuli in children with ASD. © Copyright © 2020 Valiyamattam, Katti, Chaganti, O’Haire and Sachdeva.",animals; autism (ASD); eye tracking; human animal interaction (HAI); neurobiomarker; social attention; visual attention,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85087154764,Movies / Media
Brandtner A.; Pekal J.; Brand M.,"Brandtner, Annika (57209460577); Pekal, Jaro (56309889900); Brand, Matthias (7202584047)",57209460577; 56309889900; 7202584047,Investigating properties of imagery-induced flash-forwards and the effect of eye movements on the experience of desire and craving in gamers,2020,Addictive Behaviors,105,,106347,,,,11,10.1016/j.addbeh.2020.106347,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079385726&doi=10.1016%2fj.addbeh.2020.106347&partnerID=40&md5=1049915dcae5bfd38a026355b37c4d83,"Vivid and emotionally laden imagery is a symptom across a wide range of psychiatric disorders. Flash-forwards describe the mental simulation of anticipated future events which might also be relevant in the context of gaming disorder. The aim of this laboratory study was to investigate flash-forwards and the experience of desires and craving in gamers, and to examine the effect of eye movements on their vividness and related desires. A sample of 77 gamers formed a mental picture of themselves gaming in the future and rated the vividness and emotionality of this imagination, and their current desire and craving for gaming. Thereafter, one half of the gamers conducted a dual task (i.e., horizontal eye movements while retrieving the picture), whereas the other half let their eyes rest on the middle of the computer screen while retrieving the picture (non-dual task). Vividness of the flash-forward and intensity of desire and craving were again measured after the dual or non-dual task. In the overall sample, more imagery-related desire correlated positively with associated positive affect and vividness of flash-forwards. However, in a subsample of problematic gamers, flash-forwards are experienced less vivid and less pleasurable with increasing symptom severity. Eye movements while retrieving the flash-forwards led to significantly decreased ratings of imagery-related desire intensity, which was not the case for the non-dual condition. Results suggest different properties of flash-forwards between recreational and problematic gamers. Moreover, an attention-demanding task taxing the working memory seems beneficial for reducing desires related to imagery-induced flash-forwards. © 2020 Elsevier Ltd",Craving; Desire; Eye movements; Flash-forwards; Gaming disorder; Mental imagery,"Adolescent; Adult; Craving; Emotions; Eye Movements; Female; Humans; Imagination; Internet Addiction Disorder; Male; Memory, Short-Term; Middle Aged; Young Adult; adult; Article; controlled study; correlation analysis; craving; disease severity; emotionality; eye movement; female; flash forward; game; game addiction; human; imagery; imagination; male; task performance; adolescent; emotion; internet addiction; middle aged; psychology; short term memory; young adult",Article,Final,,Scopus,2-s2.0-85079385726,Movies / Media
Fujioka T.; Fujisawa T.X.; Inohara K.; Okamoto Y.; Matsumura Y.; Tsuchiya K.J.; Katayama T.; Munesue T.; Tomoda A.; Wada Y.; Kosaka H.,"Fujioka, T. (56684203000); Fujisawa, T.X. (35388223900); Inohara, K. (55598433500); Okamoto, Y. (55567687400); Matsumura, Y. (36164244500); Tsuchiya, K.J. (8567495200); Katayama, T. (7401478639); Munesue, T. (6506045275); Tomoda, A. (55680967100); Wada, Y. (35411983900); Kosaka, H. (7103002548)",56684203000; 35388223900; 55598433500; 55567687400; 36164244500; 8567495200; 7401478639; 6506045275; 55680967100; 35411983900; 7103002548,Attenuated relationship between salivary oxytocin levels and attention to social information in adolescents and adults with autism spectrum disorder: A comparative study,2020,Annals of General Psychiatry,19,1,38,,,,14,10.1186/s12991-020-00287-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086396037&doi=10.1186%2fs12991-020-00287-2&partnerID=40&md5=fd89d5525d3899002e111cc6cc4993e7,"Background: Previous research studies have assessed the relationship between attention to social information and peripheral (e.g., plasma and salivary) oxytocin (OT) levels in typically developing (TD) children and children with autism spectrum disorder (ASD). A relationship between them was observed in TD children, but not in children with ASD. However, this relationship remains unexamined in other age groups. To clarify whether this lack of association is maintained throughout development in individuals with ASD, we aimed to assess the relationship between salivary OT levels and attention to social information in adolescents and adults with and without ASD. Methods: We recruited male adolescents and adults with ASD (n = 17) and TD participants (n = 24). Using the all-in-one eye-tracking system Gazefinder, we measured the percentage fixation time allocated to social information. We also measured the salivary OT levels and Autism Spectrum Quotient (AQ) of participants. Subsequently, we confirmed group differences and conducted a correlation analysis to investigate the relationships between these three measures. Results: Salivary OT levels did not show any significant difference between the ASD and TD groups and were negatively correlated with the AQ in the whole-group analysis, but not in within-group analysis. Individuals with ASD had significantly lower percentage fixation times than did TD individuals for eye regions in human faces with/without mouth motion, for upright biological motion, and for people regions in the people and geometry movies. The percentage of fixation for geometric shapes in the people and geometry movies was significantly higher in the ASD than in the TD group. In the TD group, salivary OT levels were positively correlated with percentage fixation times for upright biological motion and people and negatively correlated with inverted biological motion and geometry. However, no significant correlations were found in the ASD group. Conclusions: Our exploratory results suggest that salivary OT levels in adolescents and adults with ASD are less indicative of attention to social stimuli than they are in TD adolescents and adults. It is suggested that their association is slightly weaker in adolescents and adults with ASD and that this attenuated relationship appears to be maintained throughout development. © 2020 The Author(s).",Adolescents; Adult; Autism spectrum disorder; Eye-tracking; Oxytocin; Social information,oxytocin; adolescent; adult; Article; attention; autism; clinical article; comparative study; controlled study; correlation analysis; eye fixation; human; information; male; saliva level; social information,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85086396037,Movies / Media
Hedeshy R.H.; Kumar C.; Menges R.; Staab S.,"Hedeshy, Ramin Hedeshy (57217114976); Kumar, Chandan (57192105487); Menges, Raphael (57192103839); Staab, Steffen (7004053291)",57217114976; 57192105487; 57192103839; 7004053291,GIUPlayer: A Gaze Immersive YouTube Player Enabling Eye Control and Attention Analysis,2020,Eye Tracking Research and Applications Symposium (ETRA),,,3391984,,,,1,10.1145/3379157.3391984,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086313096&doi=10.1145%2f3379157.3391984&partnerID=40&md5=b152eb9cfe392cad96414c3dca3c9998,"We developed a gaze immersive YouTube player, called GIUPlayer, with two objectives: First to enable eye-controlled interaction with video content, to support people with motor disabilities. Second to enable the prospect of quantifying attention when users view video content, which can be used to estimate natural viewing behaviour. In this paper, we illustrate the functionality and design of GIUPlayer, and the visualization of video viewing pattern. The long-term perspective of this work could lead to the realization of eye control and attention based recommendations in online video platforms and smart TV applications that record eye tracking data. © 2020 Owner/Author.",eye tracking; Video player; Web accessibility,Video recording; Eye control; Immersive; Long-term perspective; Motor disability; Online video; Smart-TV; Video contents; YouTube; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85086313096,Movies / Media
Wang H.; An R.; Chen Y.; Mu X.; Yang B.; Zhao Q.; Huang H.; Ning P.; Shen Q.; Xie D.; Lu H.; Zhou J.; Xu Y.,"Wang, Hui (59076176700); An, Ran (55847412700); Chen, Yalan (56968250900); Mu, Xin (57208060499); Yang, Baiyuan (57193719013); Zhao, Quanzhen (56739625600); Huang, Hongyan (57193222246); Ning, Pingping (57193260041); Shen, Qiuyan (57202923010); Xie, Dan (57209368423); Lu, Haitao (57209363261); Zhou, Junying (55213363900); Xu, Yanming (57207020913)",59076176700; 55847412700; 56968250900; 57208060499; 57193719013; 56739625600; 57193222246; 57193260041; 57202923010; 57209368423; 57209363261; 55213363900; 57207020913,Clinical features of multiple system atrophy with or without rapid eye movement behavior disorder: a cross-sectional study in southwest China,2020,Clinical Autonomic Research,30,3,,239,245,6.0,4,10.1007/s10286-019-00651-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076602793&doi=10.1007%2fs10286-019-00651-7&partnerID=40&md5=eb2c55a80da83a13e0267f704e7fddaf,"Objective: The aim of this study was to investigate the prevalence of rapid eye movement behavior disorder (RBD) in Chinese patients with multiple system atrophy (MSA) and to compare motor and non-motor symptoms and sleep disturbance of MSA patients with and without RBD. Methods: A total of 55 patients who were consecutively admitted to West China Hospital of Sichuan University from 2016 to 2019 and subsequently diagnosed with probable MSA were enrolled in this cross-sectional study. The diagnosis of RBD was based on the results of video polysomnography (PSG) and a history of abnormal sleep-related behaviors. The patients were divided into two groups: those with RBD and those without. These two groups were then compared in terms of severity of motor symptoms (Unified Multiple System Arophy Rating Scale) and non-motor symptoms (Non-Motor Symptoms Scale, Mini-Mental State Examination score, Epworth Sleepiness Scale, Fatigue Severity Scale, Pittsburgh Sleep Quality Index, REM Sleep Behavior Disorder Screening Questionnaire, Hamilton Depression Rating Scale, Hamilton Anxiety Rating Scale) and sleep parameters as recorded on PSG. Results: Of the 55 patients (35 males), 18 (33%, 13 males) were diagnosed with RBD. Patients with or without RBD did not differ in demographic characteristics, clinical features, or sleep parameters based on PSG. Conclusion: There was no difference in motor and non-motor symptoms between MSA patients with or without RBD, indicating that the presence of RBD may not be significantly associated with the severity of motor or non-motor dysfunction in MSA. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Clinical features; Multiple system atrophy; Polysomnography; Prevalence; Rapid eye movement behavior disorder,"China; Cross-Sectional Studies; Humans; Male; Multiple System Atrophy; REM Sleep Behavior Disorder; Sleep, REM; China; complication; cross-sectional study; human; male; parasomnia; REM sleep; Shy Drager syndrome",Article,Final,,Scopus,2-s2.0-85076602793,Movies / Media
Avni I.; Meiri G.; Bar-Sinai A.; Reboh D.; Manelis L.; Flusser H.; Michaelovski A.; Menashe I.; Dinstein I.,"Avni, Inbar (57211622769); Meiri, Gal (7801433301); Bar-Sinai, Asif (57194589336); Reboh, Doron (57209107291); Manelis, Liora (57194585236); Flusser, Hagit (15065350600); Michaelovski, Analya (57201374867); Menashe, Idan (57220360596); Dinstein, Ilan (21742041100)",57211622769; 7801433301; 57194589336; 57209107291; 57194585236; 15065350600; 57201374867; 57220360596; 21742041100,Children with autism observe social interactions in an idiosyncratic manner,2020,Autism Research,13,6,,935,946,11.0,22,10.1002/aur.2234,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074628557&doi=10.1002%2faur.2234&partnerID=40&md5=25020029f700f62625c20b26e37b67a3,"Previous eye-tracking studies have reported that children with autism spectrum disorders (ASD) fixate less on faces in comparison to controls. To properly understand social interactions, however, children must gaze not only at faces but also at actions, gestures, body movements, contextual details, and objects, thereby creating specific gaze patterns when observing specific social interactions. We presented three different movies with social interactions to 111 children (71 with ASD) who watched each of the movies twice. Typically developing children viewed the movies in a remarkably predictable and reproducible manner, exhibiting gaze patterns that were similar to the mean gaze pattern of other controls, with strong correlations across individuals (intersubject correlations) and across movie presentations (intra-subject correlations). In contrast, children with ASD exhibited significantly more variable/idiosyncratic gaze patterns that differed from the mean gaze pattern of controls and were weakly correlated across individuals and presentations. Most importantly, quantification of gaze idiosyncrasy in individual children enabled separation of ASD and control children with higher sensitivity and specificity than traditional measures such as time gazing at faces. Individual magnitudes of gaze idiosyncrasy were also significantly correlated with ASD severity and cognitive scores and were significantly correlated across movies and movie presentations, demonstrating clinical sensitivity and reliability. These results suggest that gaze idiosyncrasy is a potent behavioral abnormality that characterizes a considerable number of children with ASD and may contribute to their impaired development. Quantification of gaze idiosyncrasy in individual children may aid in assessing symptom severity and their change in response to treatments. Autism Res 2020, 13: 935-946. © 2019 International Society for Autism Research, Wiley Periodicals, Inc. Lay Summary: Typically, developing children watch movies of social interactions in a reliable and predictable manner, attending faces, gestures, actions, body movements, and objects that are relevant to the social interaction and its narrative. Here, we demonstrate that children with ASD watch such movies with significantly more variable/idiosyncratic gaze patterns that differ across individuals and across movie presentations. We demonstrate that quantifying this gaze variability may aid in identifying children with ASD and in determining the severity of their symptoms. © 2019 International Society for Autism Research, Wiley Periodicals, Inc.",ecological; eye position; eye tracking; gaze; idiosyncrasy; movies; naturalistic; outcome measure; social; symptom severity; variability,"Attention; Autism Spectrum Disorder; Child, Preschool; Female; Fixation, Ocular; Humans; Male; Motion Pictures; Reproducibility of Results; Social Interaction; Article; autism; child; child behavior; cognition; controlled study; disease severity; eye tracking; female; gaze; human; major clinical study; male; prediction; priority journal; reliability; reproducibility; sensitivity and specificity; social interaction; vision; attention; autism; eye fixation; movie; pathophysiology; preschool child; psychology",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85074628557,Movies / Media
Chou W.-Y.S.; Trivedi N.; Peterson E.; Gaysynsky A.; Krakow M.; Vraga E.,"Chou, Wen-ying Sylvia (35268092900); Trivedi, Neha (57210580850); Peterson, Emily (55286410400); Gaysynsky, Anna (56344415100); Krakow, Mindy (55966212900); Vraga, Emily (35369308400)",35268092900; 57210580850; 55286410400; 56344415100; 55966212900; 35369308400,How do social media users process cancer prevention messages on Facebook? An eye-tracking study,2020,Patient Education and Counseling,103,6,,1161,1167,6.0,29,10.1016/j.pec.2020.01.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079074559&doi=10.1016%2fj.pec.2020.01.013&partnerID=40&md5=9ed299325115b52d14b2c6e96e8c4dd1,"Objective: The quality of cancer-related information on social media (SM) is mixed, and exposure to inaccurate information may negatively affect knowledge, attitudes, and behaviors. This study examines SM users’ attention to simulated Facebook posts related to cancer and identifies message features associated with increased attention. Methods: SM users (N = 53) participated in a mixed methods experimental study using eye-tracking technology, whereby participants’ dwell time on message components was measured. Stimuli conditions included message format (narrative/non-narrative), information veracity, source (organization/individual), and cancer topic (HPV vaccine and sunscreen safety). Results: Pixel-size adjusted analyses revealed that average dwell time was longer on posts attributed to individuals and on narrative-based posts. The source of the message received nearly the same amount of dwell time as the text. Dwell time on other message components did not significantly differ by condition. Conclusion: This study found that the source of a message attracted substantial attention, whereas other features were not associated with attention. The study illustrates how communication research can help us understand the processing of ubiquitous cancer-related messages on SM. Practical Implications: Health communication practitioners should consider message features that garner attention when developing efforts to facilitate the exchange of evidence-based information and to mitigate the harms of misinformation. © 2020",Cancer communication; Eye tracking; HPV vaccine; Misinformation; Social media; Sun safety,Eye-Tracking Technology; Health Communication; Humans; Narration; Neoplasms; Social Media; sunscreen; Wart virus vaccine; adult; Article; attention; cancer prevention; drug safety; dwell time; experimental study; eye tracking; female; human; human experiment; individualization; information processing; male; medical information system; narrative; normal human; organization; pilot study; priority journal; public health message; social media; medical information; neoplasm; verbal communication,Article,Final,,Scopus,2-s2.0-85079074559,Movies / Media
Gkalitsiou Z.; Byrd C.; Griffin Z.,"Gkalitsiou, Zoi (56524675700); Byrd, Courtney (16232527900); Griffin, Zenzi (6603685074)",56524675700; 16232527900; 6603685074,Executive control in adults who stutter: The antisaccade task,2020,"Journal of Speech, Language, and Hearing Research",63,6,,1688,1699,11.0,5,10.1044/2020_JSLHR-19-00045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086792734&doi=10.1044%2f2020_JSLHR-19-00045&partnerID=40&md5=e3c587af12f4cba64f4d20dddc30011d,"Purpose: The purpose of this study was to investigate executive control in adults who stutter (AWS) and adults who do not stutter (AWNS) via a nonspeech paradigm, wherein eye movements were monitored (i.e., antisaccade task). Processes involved in an antisaccade task include working memory, attention, and voluntary motor control, but the task primarily provides insight into inhibitory control. Method: Seventeen AWS (14 men, three women; M = 23.41 years) and 17 AWNS (M = 23.29 years) were presented with a combination of prosaccade (i.e., looking toward a target) and antisaccade (i.e., suppress a reflexive saccade toward the target and look in the opposite direction) trials. The distance of the target from the center of the screen was also manipulated (i.e., 5.5o = short distance and 10.8o = long distance). Data for accuracy and reaction time of the first accurate saccade were collected and analyzed. Results: No difference was found between AWS and AWNS in accuracy or in reaction time. Both groups were more accurate in the prosaccade than the antisaccade trials and in the long compared to the short distance trials. Furthermore, both groups demonstrated longer saccade latencies for long compared to short distances and for antisaccade compared to prosaccade trials. Conclusions: Preliminary results do not support deficits in inhibition in AWS during a motorically simple, non– speech-related oculomotor task, but additional research is warranted. © 2020 American Speech-Language-Hearing Association.",,,Article,Final,,Scopus,2-s2.0-85086792734,Movies / Media
Maraver M.J.; Steenbergen L.; Hossein R.; Actis-Grosso R.; Ricciardelli P.; Hommel B.; Colzato L.S.,"Maraver, Maria J. (57192005702); Steenbergen, Laura (55966140800); Hossein, Romina (57216436945); Actis-Grosso, Rossana (6506511259); Ricciardelli, Paola (6602880233); Hommel, Bernhard (7005738313); Colzato, Lorenza S. (6507926993)",57192005702; 55966140800; 57216436945; 6506511259; 6602880233; 7005738313; 6507926993,Transcutaneous vagus nerve stimulation modulates attentional resource deployment towards social cues,2020,Neuropsychologia,143,,107465,,,,25,10.1016/j.neuropsychologia.2020.107465,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083508821&doi=10.1016%2fj.neuropsychologia.2020.107465&partnerID=40&md5=481fa3771b39e54cbbee6a5609bfdbf2,"Transcutaneous vagus nerve stimulation (tVNS) has been shown to promote inferences of emotional states based on eye-related information provided by facial expressions of emotions. Eye gaze direction can influence the allocation of attentional sources when processing facial emotional stimuli. Here we sought for further evidence indicating whether tVNS effects would be specific to emotional expressions or to gaze - both socially relevant stimuli - and whether they reflect the enhancement of attention. In two separate sessions receiving either active or sham tVNS, forty-three healthy young volunteers completed a Rapid Serial Visual Presentation task in which participants identified the gender of a target face (T1) with direct (salient social cue) or averted gaze (subtler social cue) with different emotional expressions or a neutral expression, and then judged the orientation of a landscape (T2) that appeared at different temporal lags after T1. Active tVNS, compared to sham stimulation, enhanced conditional T2 accuracy for both neutral and emotional faces and independently of the temporal lag, but only when gaze was directed at the participant. This suggests that tVNS modulates attention to a direct gaze (salient social cue) irrespective of the expressed emotion. We interpret that the effects of tVNS seem to reflect enhanced perception of gaze direction, which in turn attracts attention, making the observer more sensitive and increasing the impact of the socially relevant facial cue. We conclude that tVNS is a promising technique for enhancing social information processing in healthy humans. © 2020 Elsevier Ltd",Facial emotion recognition; Gaze direction; Perception; Social cues; Transcutaneous vagus nerve stimulation,"Cues; Emotions; Facial Expression; Fixation, Ocular; Humans; Vagus Nerve Stimulation; adult; article; attention; clinical article; controlled study; face; female; gaze; gender; human; human experiment; male; perception; vagus nerve stimulation; association; emotion; eye fixation; facial expression",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85083508821,Movies / Media
Chiu P.-Y.; Hung G.-U.; Wei C.-Y.; Tzeng R.-C.; Pai M.-C.,"Chiu, Pai-Yi (7103182590); Hung, Guang-Uei (57192368259); Wei, Cheng-Yu (41862617200); Tzeng, Ray-Chang (57204006471); Pai, Ming-Chyi (56506470700)",7103182590; 57192368259; 41862617200; 57204006471; 56506470700,Freezing of Speech Single Questionnaire as a Screening Tool for Cognitive Dysfunction in Patients With Dementia With Lewy Bodies,2020,Frontiers in Aging Neuroscience,12,,65,,,,7,10.3389/fnagi.2020.00065,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084576377&doi=10.3389%2ffnagi.2020.00065&partnerID=40&md5=0e8b89656b754a0e1c9a7a9416a2258f,"Introduction: Freezing phenomenon is a striking feature of Parkinson’s disease. However, it has never been studied in people with dementia with Lewy bodies (DLB). We designed a freezing of speech single questionnaire (FOSSQ) and investigated the frequency and association of freezing of speech (FOS) in patients with DLB and other types of dementia. Methods: This is a retrospective analysis of data from the project of history-based artificial intelligent computerized dementia diagnostic system. We compared the frequencies of FOS among non-demented (ND) participants, patients with Alzheimer’s disease (AD), vascular dementia (VaD), and DLB. Further, we explored the association factors of FOS in all the participants. Results: We enrolled 666 individuals with the following disease distribution: 190, ND; 230, AD; 183, VaD; and 63, DLB. Compared to individuals with ND (2.1%), patients with AD (6.1%), or VaD (18.0%), DLB (54.0%) showed a significantly higher frequency of positive FOS (all p < 0.001). The association factors of FOS were older age, more severe dementia, more severe motor dysfunction, fluctuating cognition, visual hallucinations, parkinsonism, rapid eye movement sleep behavior disorder, attention, mental manipulation, and language. Conclusion: Our study showed that the informant-based FOSSQ may be a practical screening tool for discriminating DLB from individuals with ND or other forms of dementia. The FOSSQ can be applied in clinical practice as well as on the artificial intelligent platform. © Copyright © 2020 Chiu, Hung, Wei, Tzeng and Pai.",Alzheimer’s disease; dementia with Lewy bodies; fluctuating cognition; freezing of speech; vascular dementia,age; aged; Alzheimer disease; Article; artificial intelligence; attention; cognition; cognitive defect; controlled study; diffuse Lewy body disease; disease association; disease severity; female; freezing of speech single questionnaire; human; language; machiavellianism; major clinical study; male; motor dysfunction; multiinfarct dementia; parasomnia; parkinsonism; questionnaire; retrospective study; very elderly; visual hallucination,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85084576377,Movies / Media
Pentus K.; Ploom K.; Mehine T.; Koiv M.; Tempel A.; Kuusik A.,"Pentus, Kristian (57201258159); Ploom, Kerli (16402824500); Mehine, Tanel (57201261808); Koiv, Madli (57214899151); Tempel, Age (57214896774); Kuusik, Andres (25960966100)",57201258159; 16402824500; 57201261808; 57214899151; 57214896774; 25960966100,Mobile and stationary eye tracking comparison – package design and in-store results,2020,Journal of Consumer Marketing,37,3,,259,269,10.0,14,10.1108/JCM-04-2019-3190,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079448317&doi=10.1108%2fJCM-04-2019-3190&partnerID=40&md5=5bea8e9dbc29a16408a8a945fcad83fb,"Purpose: This paper aims to test the similarity of the results of on-screen eye tracking compared to mobile eye tracking in the context of first fixation location on stimuli. Design/methodology/approach: Three studies were conducted altogether with 117 participants, where the authors compared both methods: stationary eye tracking (Tobii Pro X2-60) and mobile eye tracking (Tobii Pro Glasses 2). Findings: The studies revealed that the reported average first fixation locations from stationary and mobile eye tracking are different. Stationary eye tracking is more affected by a centre fixation bias. Based on the research, it can be concluded that stationary eye tracking is not always suitable for studying consumer perception and behaviour because of the centre viewing bias. Research limitations/implications: When interpreting the results, researchers should take into account that stationary eye tracking results are affected by a centre fixation bias. Previous stationary eye tracking research should be interpreted with the centre fixation bias in mind. Some of this previous work should be retested using mobile eye tracking. If possible small-scale pilot studies should be included in papers to show that the more appropriate method, less affected by attention biases, was chosen. Practical implications: Managers should trust research where the ability of package design to attract attention on a shelf is tested using mobile eye tracking. The authors suggest using mobile eye tracking to optimise store shelf planograms, point-of-purchase materials, and shelf layouts. In package design, interpretations of research using stationary eye tracking should consider its centre fixation bias. Managers should also be cautious when interpreting previous stationary eye tracking research (both applied and scientific), knowing that stationary eye tracking is more prone to a centre fixation bias. Originality/value: While eye tracking research has become more and more popular as a marketing research method, the limitations of the method have not been fully understood by the field. This paper shows that the chosen eye tracking method can influence the results. No such comparative paper about mobile and stationary eye tracking research has been done in the marketing field. © 2020, Emerald Publishing Limited.",Consumer behaviour; Eye fixation; Eye tracking; First fixation location; In-store testing; Package design; Packaging design; Perception; Shopping research,,Article,Final,,Scopus,2-s2.0-85079448317,Movies / Media
Byeon H.,"Byeon, Haewon (36452769600)",36452769600,Application of machine learning technique to distinguish parkinson’s disease dementia and alzheimer’s dementia: Predictive power of parkinson’s disease-related non-motor symptoms and neuropsychological profile,2020,Journal of Personalized Medicine,10,2,31,,,,13,10.3390/jpm10020031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084849335&doi=10.3390%2fjpm10020031&partnerID=40&md5=7612c22bea59b5942b32aced91daa461,"In order to develop a predictive model that can distinguish Parkinson's disease dementia (PDD) from other dementia types, such as Alzheimer's dementia (AD), it is necessary to evaluate and identify the predictive accuracy of the cognitive profile while considering the non-motor symptoms, such as depression and rapid eye movement (REM) sleep behavior disorders. This study compared Parkinson's disease (PD)’s non-motor symptoms and the diagnostic predictive power of cognitive profiles that distinguish AD and PD using machine learning. This study analyzed 118 patients with AD and 110 patients with PDD, and all subjects were 60 years or older. In order to develop the PDD prediction model, the dataset was divided into training data (70%) and test data (30%). The prediction accuracy of the model was calculated by the recognition rate. The results of this study show that Parkinson-related non-motor symptoms, such as REM sleep behavior disorders, and cognitive screening tests, such as Korean version of Montreal Cognitive Assessment, were highly accurate factors for predicting PDD. It is required to develop customized screening tests that can detect PDD in the early stage based on these results. Furthermore, it is believed that including biomarkers such as brain images or cerebrospinal fluid as input variables will be more useful for developing PDD prediction models in the future. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Alzheimer’s dementia; Cognitive function; MoCA; Neuropsychological profile; Parkinson’s disease dementia; Random forest,biological marker; adult; aged; Alzheimer disease; Article; atrial fibrillation; Clinical Dementia Rating; cognition; cognitive defect; computer assisted tomography; cross-sectional study; daily life activity; decision tree; dementia; depression; diabetes mellitus; eye movement; female; Geriatric Depression Scale; human; hyperlipidemia; hypertension; ICD-10; machine learning; major clinical study; male; middle aged; Mini Mental State Examination; Montreal cognitive assessment; neuropsychological test; nuclear magnetic resonance imaging; Parkinson disease; prevalence; quality control; random forest; REM sleep; support vector machine,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85084849335,Movies / Media
Lange D.; Stratmann T.C.; Gruenefeld U.; Boll S.,"Lange, Daniel (57203053012); Stratmann, Tim Claudius (55838339500); Gruenefeld, Uwe (56426574900); Boll, Susanne (14522025600)",57203053012; 55838339500; 56426574900; 14522025600,HiveFive: Immersion Preserving Attention Guidance in Virtual Reality,2020,Conference on Human Factors in Computing Systems - Proceedings,,,3376803,,,,46,10.1145/3313831.3376803,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089992658&doi=10.1145%2f3313831.3376803&partnerID=40&md5=dfa99fa7015ddf0e9690ffcc433d0c3a,"Recent advances in Virtual Reality (VR) technology, such as larger fields of view, have made VR increasingly immersive. However, a larger field of view often results in a user focusing on certain directions and missing relevant content presented elsewhere on the screen. With HiveFive, we propose a technique that uses swarm motion to guide user attention in VR. The goal is to seamlessly integrate directional cues into the scene without losing immersiveness. We evaluate HiveFive in two studies. First, we compare biological motion (from a prerecorded swarm) with non-biological motion (from an algorithm), finding further evidence that humans can distinguish between these motion types and that, contrary to our hypothesis, non-biological swarm motion results in significantly faster response times. Second, we compare HiveFive to four other techniques and show that it not only results in fast response times but also has the smallest negative effect on immersion. © 2020 ACM.",attention guidance; eye-tracking; immersion; particle swarms; user studies; virtual reality,Bioinformatics; Human engineering; Response time (computer systems); Biological motion; Biological swarms; Fast response; Immersive; Immersiveness; Larger fields; User attention; Virtual reality,Conference paper,Final,,Scopus,2-s2.0-85089992658,Movies / Media
Jiang X.; Li Y.; Jokinen J.P.P.; Hirvola V.B.; Oulasvirta A.; Ren X.,"Jiang, Xinhui (57219108898); Li, Yang (57277053100); Jokinen, Jussi P.P. (23035047100); Hirvola, Viet Ba (57209300784); Oulasvirta, Antti (13006124600); Ren, Xiangshi (7401875870)",57219108898; 57277053100; 23035047100; 57209300784; 13006124600; 7401875870,How We Type: Eye and Finger Movement Strategies in Mobile Typing,2020,Conference on Human Factors in Computing Systems - Proceedings,,,3376711,,,,27,10.1145/3313831.3376711,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091281459&doi=10.1145%2f3313831.3376711&partnerID=40&md5=e2e0df1daae805ca92c16ec26d660b4f,"Relatively little is known about eye and finger movement in typing with mobile devices. Most prior studies of mobile typing rely on log data, while data on finger and eye movements in typing come from studies with physical keyboards. This paper presents new findings from a transcription task with mobile touchscreen devices. Movement strategies were found to emerge in response to sharing of visual attention: attention is needed for guiding finger movements and detecting typing errors. In contrast to typing on physical keyboards, visual attention is kept mostly on the virtual keyboard, and glances at the text display are associated with performance. When typing with two fingers, although users make more errors, they manage to detect and correct them more quickly. This explains part of the known superiority of two-thumb typing over one-finger typing. We release the extensive dataset on everyday typing on smartphones. © 2020 ACM.",eye movement; eye-hand coordination; finger movement; mobile device; text input,Behavioral research; Human engineering; Finger movements; Log data; Typing errors; Virtual Keyboards; Visual Attention; Eye movements,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85091281459,Movies / Media
Cao R.; Chen X.; Xing F.; Xie C.; Hu P.; Wang K.,"Cao, R. (57215718871); Chen, X. (35204582200); Xing, F. (57215718931); Xie, C. (57192997017); Hu, P. (36165563300); Wang, K. (56959592900)",57215718871; 35204582200; 57215718931; 57192997017; 36165563300; 56959592900,Cross-sectional and longitudinal associations between probable rapid eye movement sleep behavior disorder and impulse control disorders in Parkinson’s disease,2020,European Journal of Neurology,27,5,,757,763,6.0,7,10.1111/ene.14177,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081755247&doi=10.1111%2fene.14177&partnerID=40&md5=3147dba90fc42f9d488c65ddc309fbaa,"Background and purpose: The aim was to investigate whether probable rapid eye movement sleep behavior disorder (pRBD) is associated with impulse control disorders (ICDs) in drug-naïve patients with Parkinson’s disease (PD) and whether baseline pRBD is associated with a higher incidence of ICDs during follow-up. Methods: The Parkinson’s Progression Markers Initiative is an international, multicenter, prospective cohort study to identify biomarkers of PD progression. In all, 423 drug-naïve patients with early-stage PD were included in the cross-sectional analysis, and 320 patients who screened negative for any ICDs or related behaviors at baseline were included in the longitudinal analysis. Results: In the cross-sectional analysis, a significant correlation was found between pRBD and ICDs in drug-naïve patients whilst controlling for potential confounders [odds ratio 2.56, 95% confidence interval (CI) 1.38–4.76, P = 0.003]. In the longitudinal analysis, baseline pRBD was an independent predictor of ICD development over time [hazard ratio (HR) 1.648, 95% CI 1.054–2.576; P = 0.028]. Other significant predictors of ICDs included younger age of onset (HR = 0.973, 95% CI = 0.950–0.997; P = 0.026) and greater State-Trait Anxiety Inventory score (HR = 1.040, 95% CI = 1.020–1.061; P < 0.001). Conclusion: Our data suggest that identifying baseline pRBD in early-stage PD may help clinicians to choose a better therapeutic strategy so as to prevent or limit neuropsychiatric complications. © 2020 European Academy of Neurology",drug-naïve; impulse control disorders; Parkinson’s disease; prospective; RBD; REM sleep behavior disorder,"Cross-Sectional Studies; Disruptive, Impulse Control, and Conduct Disorders; Female; Humans; Longitudinal Studies; Male; Middle Aged; Parkinson Disease; Prospective Studies; REM Sleep Behavior Disorder; adult; anxiety disorder; Article; clinical evaluation; cognition; cohort analysis; cross-sectional study; depression; disease association; disease duration; disease severity; female; follow up; human; impulse control disorder; incidence; longitudinal study; major clinical study; male; middle aged; neuropsychological test; onset age; Parkinson disease; priority journal; prospective study; REM sleep; sleep disorder; State Trait Anxiety Inventory; Unified Parkinson Disease Rating Scale; verbal memory; clinical trial; complication; impulse control disorder; multicenter study; parasomnia; Parkinson disease",Article,Final,,Scopus,2-s2.0-85081755247,Movies / Media
Wegner-Clemens K.; Rennig J.; Beauchamp M.S.,"Wegner-Clemens, Kira (57205332278); Rennig, Johannes (37003264400); Beauchamp, Michael S. (35518650400)",57205332278; 37003264400; 35518650400,A relationship between autism-spectrum quotient and face viewing behavior in 98 participants,2020,PLoS ONE,15,4,e0230866,,,,8,10.1371/journal.pone.0230866,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084277266&doi=10.1371%2fjournal.pone.0230866&partnerID=40&md5=98b94a2ce7a5b1b90e5e0a852bf9b7d4,"Faces are one of the most important stimuli that we encounter, but humans vary dramatically in their behavior when viewing a face: some individuals preferentially fixate the eyes, others fixate the mouth, and still others show an intermediate pattern. The determinants of these large individual differences are unknown. However, individuals with Autism Spectrum Disorder (ASD) spend less time fixating the eyes of a viewed face than controls, suggesting the hypothesis that autistic traits in healthy adults might explain individual differences in face viewing behavior. Autistic traits were measured in 98 healthy adults recruited from an academic setting using the Autism-Spectrum Quotient, a validated 50-statement questionnaire. Fixations were measured using a video-based eye tracker while participants viewed two different types of audiovisual movies: short videos of talker speaking single syllables and longer videos of talkers speaking sentences in a social context. For both types of movies, there was a positive correlation between Autism-Spectrum Quotient score and percent of time fixating the lower half of the face that explained from 4% to 10% of the variance in individual face viewing behavior. This effect suggests that in healthy adults, autistic traits are one of many factors that contribute to individual differences in face viewing behavior. © 2020 Wegner-Clemens et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Adolescent; Adult; Attention; Autism Spectrum Disorder; Eye Movements; Face; Female; Humans; Male; Middle Aged; Young Adult; adult; Article; autism; autism assessment; brain depth stimulation; controlled study; eye movement; face; female; human; major clinical study; male; personality; social interaction; task performance; adolescent; attention; autism; middle aged; psychology; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85084277266,Movies / Media
Natsuhara T.; Kato T.; Nakayama M.; Yoshida T.; Sasaki R.; Matsutake T.; Asai T.,"Natsuhara, Takayuki (57200324869); Kato, Takaaki (55483079400); Nakayama, Masao (36617539600); Yoshida, Takuya (55700678200); Sasaki, Ryota (56246511800); Matsutake, Takahiro (57200321773); Asai, Takeshi (23395810600)",57200324869; 55483079400; 36617539600; 55700678200; 56246511800; 57200321773; 23395810600,Decision-Making While Passing and Visual Search Strategy During Ball Receiving in Team Sport Play,2020,Perceptual and Motor Skills,127,2,,468,489,21.0,31,10.1177/0031512519900057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078110487&doi=10.1177%2f0031512519900057&partnerID=40&md5=cbeaaa7b05e0b14aee21d30a6cb9b9db,"In many team sports, in which environmental change is constant, athletes selectively allocate attention between the approaching ball and other players, and constantly consistently making decisions regarding whom to pass the ball to. Few previous studies on decision-making in team sports such as soccer have included the ball reception phase. This study examined players’ visual search strategies during pass decisions. Using five-on-four soccer-specific film simulations from previously recorded real scenes, high-level players (HLPs) and middle-level players (MLPs) reacted to life-sized soccer scenes. We measured their visual search strategies in decision-making tasks involving ball reception and pass execution and collected their verbal reports. We employed a novel system wherein the ball is ejected toward participants according to the video clips in order to maintain perception–action coupling during the task. We found skill-based differences in decision-making accuracy, eye movement data, and verbal reports. HLPs demonstrated better decision-making than MLPs, and, in eye movement data, HLPs allocated more attention to nonmarked attackers ([M] = 14.1, [SD] = 4.8%, p <.001, η2 = 0.39), the teammate receiving the pass (M = 18.4, SD = 4.3%, p <.05, η2 = 0.15), and opponents (M = 14.6, SD = 6.3%, p <.05, η2 = 0.17) than did MLPs. Furthermore, according to verbal reports, HLPs tended to attend to information on opponent players. Thus, visual search strategies during ball reception suggest that the position and situation of teammates and opponents are the most important information sources for accurate and consistent pass decisions. © The Author(s) 2020.",attention; eye movements; pass receive; soccer; verbal report,Adult; Athletic Performance; Decision Making; Executive Function; Humans; Male; Psychomotor Performance; Space Perception; Sports; Visual Perception; Young Adult; adult; article; attention; decision making; eye movement; female; human; human experiment; male; perception; simulation; skill; soccer; team sport; verbal behavior; videorecording; athletic performance; decision making; depth perception; executive function; physiology; psychomotor performance; sport; vision; young adult,Article,Final,,Scopus,2-s2.0-85078110487,Movies / Media
Ettenhofer M.L.; Gimbel S.I.; Cordero E.,"Ettenhofer, Mark L. (9740985500); Gimbel, Sarah I. (36927092300); Cordero, Evelyn (57210212034)",9740985500; 36927092300; 57210212034,Clinical validation of an optimized multimodal neurocognitive assessment of chronic mild TBI,2020,Annals of Clinical and Translational Neurology,7,4,,507,516,9.0,6,10.1002/acn3.51020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082139486&doi=10.1002%2facn3.51020&partnerID=40&md5=0e9826a3aa286994d3ea6402ffd1a4ab,"Objective: Previous laboratory-based studies have shown that neurocognitive eye-tracking metrics are sensitive to chronic effects of mild traumatic brain injury (mTBI), even in individuals with normal performance on traditional neuropsychological measures. In this study, we sought to replicate and extend these findings in a military medical environment. We expected that metrics from the multimodal Fusion n-Back test would successfully distinguish chronic mTBI participants from controls, particularly eye movement metrics from the more cognitively challenging “1-Back” subtest. Methods: We compared performance of participants with chronic mTBI (n = 46) and controls (n = 33) on the Fusion n-Back test and a battery of conventional neuropsychological tests. Additionally, we examined test reliability and the impact of potential confounds to neurocognitive assessment. Results: Our results supported hypotheses; Fusion 1-Back metrics were successful in multimodal (saccadic and manual) classification of chronic mTBI versus control. In contrast, conventional neuropsychological measures could not distinguish these groups. Additional findings demonstrated the reliability of Fusion n-Back test metrics and provided evidence that saccadic metrics are resistant to confounding influences of age, intelligence, and psychiatric symptoms. Interpretation: The Fusion n-Back test could provide advantages in differential diagnosis for complex brain injury populations. Additionally, the rapid administration of this test could be valuable for screening patients in clinical settings where longer test batteries are not feasible. Published 2020. This article is a U.S. Government work and is in the public domain in the USA. Annals of Clinical and Translational Neurology published by Wiley Periodicals, Inc. on behalf of American Neurological Association",,Adult; Brain Concussion; Chronic Disease; Eye Movement Measurements; Female; Humans; Male; Military Personnel; Neuropsychological Tests; Veterans; Young Adult; adult; Article; cognition; cognitive defect; cognitive function test; controlled study; Cronbach alpha coefficient; educational status; female; fusion n back test; human; intelligence quotient; major clinical study; male; military personnel; neurocognitive assessment; neurologic disease assessment; neuropsychological test; priority journal; psychometry; traumatic brain injury; working memory; brain concussion; chronic disease; oculography; pathophysiology; veteran; young adult,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85082139486,Movies / Media
Bender S.; Sung B.,"Bender, Stuart (57193687678); Sung, Billy (55597980000)",57193687678; 55597980000,Data-driven creativity for screen production students: developing and testing learning materials involving audience biometrics,2020,Digital Creativity,31,2,,98,113,15.0,2,10.1080/14626268.2020.1767654,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086125434&doi=10.1080%2f14626268.2020.1767654&partnerID=40&md5=bb90918df9c4a751c14feaa3f744f5d8,"This article presents the Data-Driven Creativity Project (DDCP) materials designed to enhance screen students’ understandings of how aesthetic choices impact the audience. The project first collected data on audience attention (eye-tracking), arousal (skin conductance level) and emotion (using facial expression). This data was then used in pedagogical materials delivered to two student cohorts in both lecture format and as an e-learning package. Self-reported survey data on the student experience indicates significant increase in Learning Interest toward the concepts of the DDCP, as well as strong ratings of the material’s Useability and Application to Knowledge. We also report on focus group discussions of the strengths and weaknesses of the DDCP. We show that the DDCP offers an innovative and novel intervention into contemporary screen creativity pedagogy, forging a valuable teaching-research nexus between the findings of the research field of cognitive media theory and their application in the field of student production. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.",audience studies; biometrics; data analysis; flipped learning; media education; Screen production,Eye tracking; Facial Expressions; Focus groups; Learning materials; Research fields; Screen production; Skin conductance; Student experiences; Teaching researches; Students,Article,Final,,Scopus,2-s2.0-85086125434,Movies / Media
Nag A.; Haber N.; Voss C.; Tamura S.; Daniels J.; Ma J.; Chiang B.; Ramachandran S.; Schwartz J.; Winograd T.; Feinstein C.; Wall D.P.,"Nag, Anish (57216603664); Haber, Nick (56353182800); Voss, Catalin (57190141053); Tamura, Serena (57203685649); Daniels, Jena (56145159000); Ma, Jeffrey (57216605883); Chiang, Bryan (57216603814); Ramachandran, Shasta (58067925500); Schwartz, Jessey (57196152141); Winograd, Terry (7003633896); Feinstein, Carl (7005771772); Wall, Dennis P. (7202196193)",57216603664; 56353182800; 57190141053; 57203685649; 56145159000; 57216605883; 57216603814; 58067925500; 57196152141; 7003633896; 7005771772; 7202196193,Toward continuous social phenotyping: Analyzing gaze patterns in an emotion recognition task for children with autism through wearable smart glasses,2020,Journal of Medical Internet Research,22,4,e13810,,,,37,10.2196/13810,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084027983&doi=10.2196%2f13810&partnerID=40&md5=a3d603aca33037cdf2b82406682f13d8,"Background: Several studies have shown that facial attention differs in children with autism. Measuring eye gaze and emotion recognition in children with autism is challenging, as standard clinical assessments must be delivered in clinical settings by a trained clinician. Wearable technologies may be able to bring eye gaze and emotion recognition into natural social interactions and settings. Objective: This study aimed to test: (1) the feasibility of tracking gaze using wearable smart glasses during a facial expression recognition task and (2) the ability of these gaze-tracking data, together with facial expression recognition responses, to distinguish children with autism from neurotypical controls (NCs). Methods: We compared the eye gaze and emotion recognition patterns of 16 children with autism spectrum disorder (ASD) and 17 children without ASD via wearable smart glasses fitted with a custom eye tracker. Children identified static facial expressions of images presented on a computer screen along with nonsocial distractors while wearing Google Glass and the eye tracker. Faces were presented in three trials, during one of which children received feedback in the form of the correct classification. We employed hybrid human-labeling and computer vision-enabled methods for pupil tracking and world-gaze translation calibration. We analyzed the impact of gaze and emotion recognition features in a prediction task aiming to distinguish children with ASD from NC participants. Results: Gaze and emotion recognition patterns enabled the training of a classifier that distinguished ASD and NC groups. However, it was unable to significantly outperform other classifiers that used only age and gender features, suggesting that further work is necessary to disentangle these effects. Conclusions: Although wearable smart glasses show promise in identifying subtle differences in gaze tracking and emotion recognition patterns in children with and without ASD, the present form factor and data do not allow for these differences to be reliably exploited by machine learning systems. Resolving these challenges will be an important step toward continuous tracking of the ASD phenotype. © 2020 Journal of Medical Internet Research. All rights reserved.",Artificial intelligence; Autism spectrum disorder; Digital therapy; Eye tracking; MAchine learning; Precision health; Translational medicine; Wearable technologies,Adolescent; Autism Spectrum Disorder; Child; Emotions; Female; Humans; Male; Phenotype; Smart Glasses; Wearable Electronic Devices; argipressin; aripiprazole; carbamazepine; dexmethylphenidate; guanfacine; methylphenidate; sertraline; adolescent; Article; autism; child; clinical article; computer vision; controlled study; emotion; eye tracking; facial expression; facial recognition; feedback system; female; gaze; human; machine learning; male; autism; electronic device; emotion; phenotype; physiology,Article,Final,,Scopus,2-s2.0-85084027983,Movies / Media
Kerr-Gaffney J.; Mason L.; Jones E.; Hayward H.; Ahmad J.; Harrison A.; Loth E.; Murphy D.; Tchanturia K.,"Kerr-Gaffney, Jess (57188561881); Mason, Luke (55783092600); Jones, Emily (13408335100); Hayward, Hannah (55322832100); Ahmad, Jumana (57194605107); Harrison, Amy (35179313900); Loth, Eva (23766871300); Murphy, Declan (7404062227); Tchanturia, Kate (8384655900)",57188561881; 55783092600; 13408335100; 55322832100; 57194605107; 35179313900; 23766871300; 7404062227; 8384655900,Emotion recognition abilities in adults with anorexia nervosa are associated with autistic traits,2020,Journal of Clinical Medicine,9,4,1057,,,,24,10.3390/jcm9041057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090793406&doi=10.3390%2fjcm9041057&partnerID=40&md5=fbf9c6cf841f4cf8ce5a105745bc6735,"Difficulties in socio-emotional functioning are proposed to contribute to the development and maintenance of anorexia nervosa (AN). This study aimed to examine emotion recognition abilities in individuals in the acute and recovered stages of AN compared to healthy controls (HCs). A second aim was to examine whether attention to faces and comorbid psychopathology predicted emotion recognition abilities. The films expressions task was administered to 148 participants (46 AN, 51 recovered AN, 51 HC) to assess emotion recognition, during which attention to faces was recorded using eye-tracking. Comorbid psychopathology was assessed using self-report questionnaires and the Autism Diagnostic Observation Schedule-2nd edition (ADOS-2). No significant differences in emotion recognition abilities or attention to faces were found between groups. However, individuals with a lifetime history of AN who scored above the clinical cut-off on the ADOS-2 displayed poorer emotion recognition performance than those scoring below cut-off and HCs. ADOS-2 scores significantly predicted emotion recognition abilities while controlling for group membership and intelligence. Difficulties in emotion recognition appear to be associated with high autism spectrum disorder (ASD) traits, rather than a feature of AN. Whether individuals with AN and high ASD traits may require different treatment strategies or adaptations is a question for future research. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Anorexia nervosa; Asd; Attention; Comorbidity; Emotion recognition,adult; anorexia nervosa; Article; autism; Autism Diagnostic Observation Schedule; body mass; controlled study; DSM-5; Eating Disorder Examination Questionnaire; emotion; eye tracking; facial recognition; female; Hospital Anxiety and Depression Scale; human; intelligence; Liebowitz Social Anxiety Scale; major clinical study; male; measurement accuracy; middle aged; reaction time; scoring system; social adaptation; task performance; Toronto Alexithymia scale; Wechsler intelligence scale; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85090793406,Movies / Media
Bacon E.C.; Moore A.; Lee Q.; Carter Barnes C.; Courchesne E.; Pierce K.,"Bacon, Elizabeth C (57192273734); Moore, Adrienne (23397582700); Lee, Quimby (58824934800); Carter Barnes, Cynthia (56681214600); Courchesne, Eric (7006350638); Pierce, Karen (7101864147)",57192273734; 23397582700; 58824934800; 56681214600; 7006350638; 7101864147,Identifying prognostic markers in autism spectrum disorder using eye tracking,2020,Autism,24,3,,658,669,11.0,37,10.1177/1362361319878578,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074502121&doi=10.1177%2f1362361319878578&partnerID=40&md5=5ad2c553f6a48f26490b2b2b29d0dee9,"While many children with autism spectrum disorder are now detected at young ages given the rise in screening and general awareness, little is known regarding the prognosis of early detected children. The brain is shaped by experience-dependent mechanisms; thus, what a child pays attention to plays a pivotal role in shaping brain development. Eye tracking can provide an index of a child’s visual attention and, as such, holds promise as a technology for revealing prognostic markers. In this, 49 children aged 1–3 years with autism spectrum disorder participated in an eye-tracking test, the GeoPref Test, that revealed preference for social versus nonsocial images. Next, children participated in a comprehensive test battery 5–9 years following the initial GeoPref Test. Statistical tests examined whether early age eye tracking predicted later school-age outcomes in symptom severity, social functioning, adaptive behavior, joint attention, and IQ. Results indicated that toddlers with higher preference for geometric images demonstrated greater symptom severity and fewer gaze shifts at school age. This relationship was not found in relation to IQ or adaptive behavior. Overall, the GeoPref Test holds promise as a symptom severity prognostic tool; further development of eye-tracking paradigms may enhance prognostic power and prove valuable in validating treatment progress. © The Author(s) 2019.",autism spectrum disorders; development; diagnosis; school-age children,"Autism Spectrum Disorder; Biomarkers; Child, Preschool; Eye-Tracking Technology; Female; Humans; Infant; Male; Prognosis; biological marker; Article; autism; Autism Diagnostic Observation Schedule; behavior assessment; child; clinical article; cognition assessment; communication skill; comprehension; eye tracking; female; gaze; Geometric Preference Test; human; human experiment; intelligence quotient; male; motor performance; preschool child; priority journal; prognosis; psychometry; school child; scoring system; social behavior; social interaction; Social Responsiveness Scale; stimulus response; task performance; Vineland Adaptive Behavior Scale; visual attention; visual memory; visual stimulation; Wechsler intelligence scale for children; autism; infant; pathophysiology; prognosis",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85074502121,Movies / Media
Aufegger L.; Serou N.; Chen S.; Franklin B.D.,"Aufegger, Lisa (55911133200); Serou, Naresh (57216292319); Chen, Shiping (57216293751); Franklin, Bryony Dean (57194222242)",55911133200; 57216292319; 57216293751; 57194222242,Evaluating users' experiences of electronic prescribing systems in relation to patient safety: A mixed methods study,2020,BMC Medical Informatics and Decision Making,20,1,62,,,,7,10.1186/s12911-020-1080-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083042177&doi=10.1186%2fs12911-020-1080-9&partnerID=40&md5=4cb426289a374896745cd2a6dc2a012e,"Background: User interface (UI) design features such as screen layout, density of information, and use of colour may affect the usability of electronic prescribing (EP) systems, with usability problems previously associated with medication errors. To identify how to improve existing systems, our aim was to explore prescribers' perspectives of UI features of a commercially available EP system, and how these may affect patient safety. Methods: Two studies were conducted, each including ten participants prescribing a penicillin for a test patient with a penicillin allergy. In study 1, eye-gaze tracking was used as a means to explore visual attention and behaviour during prescribing, followed by a self-reported EP system usability scale. In study 2, a think-aloud method and semi-structured interview were applied to explore participants' thoughts and views on prescribing, with a focus on UI design and patient safety. Results: Study 1 showed high visual attention toward information on allergies and patient information, allergy pop-up alerts, and medication order review and confirmation, with less visual attention on adding medication. The system's usability was rated 'below average'. In study 2, participants highlighted EP design features and workflow, including screen layout and information overload as being important for patient safety, benefits of EP systems such as keeping a record of relevant information, and suggestions for improvement in relation to system design (colour, fonts, customization) and patient interaction. Conclusions: Specific UI design factors were identified that may improve the usability and/or safety of EP systems. It is suggested that eye-gaze tracking and think-aloud methods are used in future experimental research in this area. Limitations include the small sample size; further work should include similar studies on other EP systems. © 2020 The Author(s).",Electronic prescribing system; Eye-tracking; Think-aloud method; User experience; User interface,Electronic Prescribing; Humans; Medication Errors; Patient Safety; Patients; User-Computer Interface; computer interface; electronic prescribing; human; medication error; patient; patient safety,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85083042177,Movies / Media
Mesfin G.; Hussain N.; Kani-Zabihi E.; Covaci A.; Saleme E.B.; Ghinea G.,"Mesfin, Gebremariam (56342202500); Hussain, Nadia (57205121889); Kani-Zabihi, Elahe (14419967300); Covaci, Alexandra (56419559200); Saleme, Estêvão B. (56695376600); Ghinea, Gheorghita (35616295700)",56342202500; 57205121889; 14419967300; 56419559200; 56695376600; 35616295700,QoE of cross-modally mapped Mulsemedia: an assessment using eye gaze and heart rate,2020,Multimedia Tools and Applications,79,12-Nov,,7987,8009,22.0,8,10.1007/s11042-019-08473-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077557935&doi=10.1007%2fs11042-019-08473-5&partnerID=40&md5=233b33012ee000a5b4a052dfd2a0acb1,"A great deal of research effort has been put in exploring crossmodal correspondences in the field of cognitive science which refer to the systematic associations frequently made between different sensory modalities (e.g. high pitch is matched with angular shapes). However, the possibilities cross-modality opens in the digital world have been relatively unexplored. Therefore, we consider that studying the plasticity and the effects of crossmodal correspondences in a mulsemedia setup can bring novel insights about improving the human-computer dialogue and experience. Mulsemedia refers to the combination of three or more senses to create immersive experiences. In our experiments, users were shown six video clips associated with certain visual features based on color, brightness, and shape. We examined if the pairing with crossmodal matching sound and the corresponding auto-generated haptic effect, and smell would lead to an enhanced user QoE. For this, we used an eye-tracking device as well as a heart rate monitor wristband to capture users’ eye gaze and heart rate whilst they were experiencing mulsemedia. After each video clip, we asked the users to complete an on-screen questionnaire with a set of questions related to smell, sound and haptic effects targeting their enjoyment and perception of the experiment. Accordingly, the eye gaze and heart rate results showed significant influence of the cross-modally mapped multisensorial effects on the users’ QoE. Our results highlight that when the olfactory content is crossmodally congruent with the visual content, the visual attention of the users seems shifted towards the correspondent visual feature. Crosmodally matched media is also shown to result in an enhanced QoE compared to a video only condition. © 2020, The Author(s).",Crossmodal correspondence; Gaze tracking; Heart rate; Mulsemedia; Quality of experience,Behavioral research; Heart; Human computer interaction; Patient monitoring; Quality of service; User interfaces; Video cameras; Cross-modal; Gaze tracking; Heart rates; Mulsemedia; Quality of experience (QoE); Eye tracking,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85077557935,Movies / Media
Arca K.N.; Starling A.J.; Acierno M.D.; Demaerschalk B.M.; Marks L.; O'Carroll C.B.,"Arca, Karissa N. (57202589380); Starling, Amaal J. (55889768300); Acierno, Marie D. (6602405499); Demaerschalk, Bart M. (6602774113); Marks, Lisa (57191623751); O'Carroll, Cumara B. (37031696700)",57202589380; 55889768300; 6602405499; 6602774113; 57191623751; 37031696700,"Is King-Devick Testing, Compared with Other Sideline Screening Tests, Superior for the Assessment of Sports-related Concussion?: A Critically Appraised Topic",2020,Neurologist,25,2,,33,37,4.0,6,10.1097/NRL.0000000000000268,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081407349&doi=10.1097%2fNRL.0000000000000268&partnerID=40&md5=4440e2ac60091a71c6a9b5a5c6e625f9,"Background:Concussion affects almost 4 million individuals annually. There are many sideline screening tools available to assist in the detection of sports-related concussion. The King-Devick (K-D) test in association with Mayo Clinic utilizes rapid number naming to test saccadic eye movements in order to screen for concussion. An ideal screening tool for concussion would correctly identify all athletes with active concussion. The accuracy of K-D testing compared with other sideline screening tools is undetermined.Objective:To critically assess current evidence regarding the utility of K-D testing as a sideline screening tool for acute concussion and compare K-D testing to other sideline concussion assessments.Methods:The objective was addressed through the development of a critically appraised topic that included a clinical scenario, structured question, literature search strategy, critical appraisal, assessment of results, evidence summary, commentary, and bottom-line conclusions. Participants included consultant and resident neurologists, a medical librarian, clinical epidemiologists, and content experts in the field of concussion neurology and neuro-ophthalmology.Results:A recent meta-analysis was selected for critical appraisal. Cohorts analyzing athletes with sports-related concussion were selected, and utilized K-D testing as the main baseline and sideline assessment of concussion. K-D testing was found to have a high sensitivity and specificity for detecting concussion when there was worsening from baseline.Conclusion:K-D testing has high sensitivity and specificity for detecting sideline concussion. Compared with other sideline screening tools that do not include vision testing, it has greater accuracy. Screening for concussion is optimized when multiple testing modalities are used in conjunction. © 2020 Lippincott Williams and Wilkins. All rights reserved.",concussion; critically appraised topic; evidence-based medicine; King-Devick test; mild traumatic brain injury; sideline,"Brain Concussion; Female; Humans; Male; Neuropsychological Tests; Sensitivity and Specificity; Sports; Vision, Ocular; adolescent; Article; athlete; case report; clinical article; cohort analysis; concussion; diagnostic accuracy; diagnostic test accuracy study; disease assessment; dizziness; drowsiness; fatigue; head injury; headache; human; ice hockey; king devick testing; male; Post Concussion Symptom Scale score; priority journal; scoring system; screening test; sensitivity and specificity; social participation; sport injury; Standardized Assessment of Concussion score; structured questionnaire; visual disorder; brain concussion; comparative study; female; neuropsychological test; physiology; sport; vision",Article,Final,,Scopus,2-s2.0-85081407349,Movies / Media
Sjerps M.J.; Decuyper C.; Meyer A.S.,"Sjerps, Matthias J (35387040700); Decuyper, Caitlin (57201582700); Meyer, Antje S (7401839760)",35387040700; 57201582700; 7401839760,Initiation of utterance planning in response to pre-recorded and “live” utterances,2020,Quarterly Journal of Experimental Psychology,73,3,,357,374,17.0,10,10.1177/1747021819881265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079203054&doi=10.1177%2f1747021819881265&partnerID=40&md5=2363574550c38dd500b87991957fa280,"In everyday conversation, interlocutors often plan their utterances while listening to their conversational partners, thereby achieving short gaps between their turns. Important issues for current psycholinguistics are how interlocutors distribute their attention between listening and speech planning and how speech planning is timed relative to listening. Laboratory studies addressing these issues have used a variety of paradigms, some of which have involved using recorded speech to which participants responded, whereas others have involved interactions with confederates. This study investigated how this variation in the speech input affected the participants’ timing of speech planning. In Experiment 1, participants responded to utterances produced by a confederate, who sat next to them and looked at the same screen. In Experiment 2, they responded to recorded utterances of the same confederate. Analyses of the participants’ speech, their eye movements, and their performance in a concurrent tapping task showed that, compared with recorded speech, the presence of the confederate increased the processing load for the participants, but did not alter their global sentence planning strategy. These results have implications for the design of psycholinguistic experiments and theories of listening and speaking in dyadic settings. © Experimental Psychology Society 2019.",Conversation; turn-taking; utterance planning,Adult; Eye Movement Measurements; Female; Humans; Male; Psycholinguistics; Psychomotor Performance; Social Interaction; Speech; Speech Perception; Young Adult; adult; female; human; male; oculography; physiology; psycholinguistics; psychomotor performance; social interaction; speech; speech perception; young adult,Article,Final,,Scopus,2-s2.0-85079203054,Movies / Media
Valko Y.; Werth E.; Imbach L.L.; Valko P.O.; Weber K.P.,"Valko, Yulia (36169426900); Werth, Esther (6602133517); Imbach, Lukas L. (6507251817); Valko, Philipp O. (24281992400); Weber, Konrad P. (7402657086)",36169426900; 6602133517; 6507251817; 24281992400; 7402657086,The eyes wake up: Screening for benign paroxysmal positional vertigo with polysomnography,2020,Clinical Neurophysiology,131,3,,616,624,8.0,0,10.1016/j.clinph.2019.12.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078510061&doi=10.1016%2fj.clinph.2019.12.002&partnerID=40&md5=57837760fe7c3ad2d46df02cae7ea2d0,"Objective: While positional nystagmus of benign paroxysmal positional vertigo (BPPV) has been shown to be detectable in electrooculography (EOG) tracings of polysomnography (PSG), the frequency of undiagnosed BPPV in patients referred for sleep-wake examination has never been investigated. Methods: Prospective evaluation of positional nystagmus in 129 patients, referred to a neurological sleep laboratory for sleep-wake examination with PSG. Both in the evening and morning, patients had diagnostic positioning maneuvers under ongoing EOG-PSG registration, followed by visual inspection of EOG for positional nystagmus. Results: In 19 patients (14.7%), we found patterns of positional nystagmus, typically appearing few seconds after changes in head position. In 9 of these patients (47%), the nystagmus was also provoked by the positioning maneuvers. Nystagmus only occurred during wakefulness, not during sleep. In a patient with severe cupulolithiasis, we observed disappearance of nystagmus while entering N1 sleep stage. Nocturnal positional nystagmus was independently associated with positive positioning maneuvers. Conclusions: Inspection of EOG-PSG demonstrated that positional nystagmus is common, occurring only when wake, and independently associated with positive positioning maneuvers. Significance: By routinely searching for positional nystagmus in PSG, sleep physicians may substantially contribute to the identification of patients with so-far undiagnosed BPPV. © 2019 International Federation of Clinical Neurophysiology",Benign paroxysmal positional vertigo; Polysomnography; Positional nystagmus; Positional nystagmus suppression in NREM1 sleep; Sleep,"Adult; Aged; Benign Paroxysmal Positional Vertigo; Electrooculography; Female; Humans; Male; Middle Aged; Nystagmus, Pathologic; Patient Positioning; Polysomnography; Prospective Studies; Sleep; adult; apnea hypopnea index; Article; benign paroxysmal positional vertigo; body mass; body position; comorbidity; controlled study; cupulolithiasis; dizziness; dystonia; electrooculography; Epworth sleepiness scale; essential tremor; eye movement; Fatigue Severity Scale; female; head position; human; major clinical study; male; middle aged; migraine; neurologic disease; optokinetic nystagmus; Parkinson disease; periodic limb movement disorder; polysomnography; priority journal; prospective study; REM sleep; semicircular canal; sleep time; sleep waking cycle; slow wave sleep; stage 1 sleep; stage 2 sleep; traumatic brain injury; aged; benign paroxysmal positional vertigo; nystagmus; pathophysiology; patient positioning; physiology; sleep",Article,Final,,Scopus,2-s2.0-85078510061,Movies / Media
Alblas M.C.; Mollen S.; Fransen M.L.; van den Putte B.,"Alblas, Monique C. (57073614200); Mollen, Saar (35812299300); Fransen, Marieke L. (24554017000); van den Putte, Bas (8607145700)",57073614200; 35812299300; 24554017000; 8607145700,Food at first sight: Visual attention to palatable food cues on TV and subsequent unhealthy food intake in unsuccessful restrained eaters,2020,Appetite,147,,104574,,,,17,10.1016/j.appet.2019.104574,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078508081&doi=10.1016%2fj.appet.2019.104574&partnerID=40&md5=0470bfb8e04b7dacd224e5bf13878860,"Background: This study investigated whether unsuccessful dieters show heightened visual attention to food cues in TV content and how visual attention influences subsequent unhealthy food intake. This study adds to prior literature by investigating the influence of visual attention to food cues on food intake with actual media content (i.e., instead of isolated food cues such as pictures or words) and by differentiating between chronic dieters (i.e., restrained eaters) who vary in dieting success (i.e., perceived self-regulatory success [PSRS]). To get a more detailed insight into different processes of visual attention, two measures of attention (i.e., initial orientation and attention duration) were examined. Methods: Unrestrained (n = 34) and restrained eaters (n = 28) varying in PSRS watched a talk show containing subtly depicted, palatable food cues. While watching, their visual attention to the food cues was measured with an eye-tracker. Unhealthy food intake was assessed afterwards in a taste test. Results: A two-way interaction between eating restraint and PSRS on initial visual orientation was found: unsuccessful restrained eaters’ initial orientation to food cues was faster compared to that of successful restrained eaters. There were no significant findings on attention duration. Furthermore, visual attention did not predict unhealthy food intake. Discussion: Unsuccessful restrained eaters’ fast initial orientation, but no longer attention duration, suggests that self-regulation may be important at early stages of visual attention. Future research on this topic should continue to differentiate between initial orientation and attention duration, as well as between more and less successful restrained eaters. The lack of findings on unhealthy food intake suggest that food cues embedded in actual media content might have less influence on eating behavior compared to isolated food cues. © 2019 Elsevier Ltd",Eating restraint; Food cues; Food intake; Media effects; Self-regulation; Visual attention,"Adult; Attention; Cues; Diet, Healthy; Diet, Reducing; Eating; Feeding Behavior; Female; Food; Humans; Linear Models; Television; adult; Article; controlled study; eating; female; food intake; human; human experiment; male; palatability; television viewing; visual attention; visual orientation; association; attention; eating; feeding behavior; food; low calorie diet; psychology; statistical model; television",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85078508081,Movies / Media
Cohen P.E.; Sufrinko A.; Elbin R.J.; Collins M.W.; Sinnott A.M.; Kontos A.P.,"Cohen, Paul E. (57194038285); Sufrinko, Alicia (56582218000); Elbin, Robert J. (24066225800); Collins, Michael W. (35557667100); Sinnott, Aaron M. (57201902362); Kontos, Anthony P. (7004528698)",57194038285; 56582218000; 24066225800; 35557667100; 57201902362; 7004528698,Do Initial Symptom Factor Scores Predict Subsequent Impairment Following Concussion?,2020,Clinical journal of sport medicine : official journal of the Canadian Academy of Sport Medicine,30,,,S61,S68,7.0,8,10.1097/JSM.0000000000000581,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081413113&doi=10.1097%2fJSM.0000000000000581&partnerID=40&md5=4d777886077e7ad57beb2ca6ae5af8af,"OBJECTIVE: Symptom factors present during the first week following concussion may predict subsequent concussion outcomes and recovery duration. We hypothesized that a high loading on cognitive-fatigue-migraine and somatic factors would be predictive of neurocognitive impairment following concussion. We also hypothesized that the affective factor would be related to vestibular symptoms and impairment. DESIGN: Prospective repeated measures. SETTING: Concussion specialty clinic. PARTICIPANTS: Athletes aged 13 to 20 years diagnosed with a concussion within the past 7 days. INDEPENDENT VARIABLE: Symptom factors at the initial visit 1 to 7 days after injury. MAIN OUTCOME MEASURE: Symptom factor score, neurocognitive testing, and vestibular/ocular motor assessment at the second visit (2-4 weeks after injury). RESULTS: The somatic symptom factor from the initial visit was significant (P < 0.05) in all vestibular/ocular screening components (P < 0.05) but not neurocognitive test performance (P > 0.05) at the second visit. The cognitive-migraine-fatigue and affective symptom factors predicted symptom burden at the second visit (P < 0.001) but did not predict recovery time (P = 0.200). CONCLUSIONS: The somatic symptom factor during the first week after injury predicted symptom provocation during vestibular/ocular screening at 2 to 4 weeks after injury. Specifically, higher scores on somatic symptom factor at the initial visit predicted worse symptom reporting for all vestibular/ocular screening components at the second visit. Patients with higher scores on the cognitive-migraine-fatigue and affective symptom factors at the initial visit predicted total symptom burden at the second visit.",,"Adolescent; Athletes; Athletic Injuries; Brain Concussion; Cognition Disorders; Fatigue; Female; Humans; Male; Migraine Disorders; Neurocognitive Disorders; Post-Concussion Syndrome; Prospective Studies; Pursuit, Smooth; Recovery of Function; Saccades; Symptom Assessment; Time Factors; Vestibular Diseases; Young Adult; adolescent; athlete; brain concussion; cognitive defect; complication; convalescence; disorders of higher cerebral function; fatigue; female; human; male; migraine; pathophysiology; physiology; postconcussion syndrome; prospective study; saccadic eye movement; smooth pursuit eye movement; sport injury; symptom assessment; time factor; vestibular disorder; young adult",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85081413113,Movies / Media
Son J.; Ai L.; Lim R.; Xu T.; Colcombe S.; Franco A.R.; Cloud J.; Laconte S.; Lisinski J.; Klein A.; Craddock R.C.; Milham M.,"Son, Jake (57203128162); Ai, Lei (57194759560); Lim, Ryan (57216293611); Xu, Ting (35996035600); Colcombe, Stanley (6602567116); Franco, Alexandre Rosa (19640049400); Cloud, Jessica (57216292946); Laconte, Stephen (6603207526); Lisinski, Jonathan (35748685100); Klein, Arno (8937780100); Craddock, R. Cameron (36909040100); Milham, Michael (6701672014)",57203128162; 57194759560; 57216293611; 35996035600; 6602567116; 19640049400; 57216292946; 6603207526; 35748685100; 8937780100; 36909040100; 6701672014,Evaluating fMRI-Based Estimation of Eye Gaze during Naturalistic Viewing,2020,Cerebral Cortex,30,3,,1171,1184,13.0,26,10.1093/cercor/bhz157,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083042337&doi=10.1093%2fcercor%2fbhz157&partnerID=40&md5=097ccedf6eada3384d5688a4560ec0e6,"The collection of eye gaze information during functional magnetic resonance imaging (fMRI) is important for monitoring variations in attention and task compliance, particularly for naturalistic viewing paradigms (e.g., movies). However, the complexity and setup requirements of current in-scanner eye tracking solutions can preclude many researchers from accessing such information. Predictive eye estimation regression (PEER) is a previously developed support vector regression-based method for retrospectively estimating eye gaze from the fMRI signal in the eye's orbit using a 1.5-min calibration scan. Here, we provide confirmatory validation of the PEER method's ability to infer eye gaze on a TR-by-TR basis during movie viewing, using simultaneously acquired eye tracking data in five individuals (median angular deviation < 2°). Then, we examine variations in the predictive validity of PEER models across individuals in a subset of data (n = 448) from the Child Mind Institute Healthy Brain Network Biobank, identifying head motion as a primary determinant. Finally, we accurately classify which of the two movies is being watched based on the predicted eye gaze patterns (area under the curve = 0.90 ± 0.02) and map the neural correlates of eye movements derived from PEER. PEER is a freely available and easy-to-use tool for determining eye fixations during naturalistic viewing. © 2019 The Author(s) 2019. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.",eye tracking; functional magnetic resonance imaging; naturalistic viewing,"Adult; Brain; Brain Mapping; Eye Movement Measurements; Female; Fixation, Ocular; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Middle Aged; Photic Stimulation; Regression Analysis; Article; eye fixation; eye movement; eye tracking; functional magnetic resonance imaging; gaze; head movement; human; image processing; information processing; predictive validity; priority journal; reproducibility; support vector machine; vision; adult; brain; brain mapping; female; male; middle aged; nuclear magnetic resonance imaging; oculography; photostimulation; physiology; regression analysis",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85083042337,Movies / Media
Kanari K.,"Kanari, Kei (56450606800)",56450606800,Pupil response is modulated by attention shift in optokinetic nystagmus,2020,"Journal of the Optical Society of America A: Optics and Image Science, and Vision",37,3,,361,367,6.0,2,10.1364/JOSAA.379598,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081129142&doi=10.1364%2fJOSAA.379598&partnerID=40&md5=491a60e173fe4400cdbbfe517b9f8c63,"Pupil size is modulated not only by the luminance at the eye position but also by that at the attended location. This study aims to examine whether pupil changes also correspond to the luminance at the spatial location to which the attention is shifted in optokinetic nystagmus. The test stimulus consisted of randomly positioned dots that moved to the left or to the right on a display screen that was bright on one side of the centerline and dark on the other. The results show that pupil size changes in accordance with the luminance at the location to which participants' attention shifts as a result of optokinetic nystagmus (i.e., eye movements in the direction opposite to that of the motion stimulus). This study suggests that pupil size is modulated by the luminance at the location to which attention shifts through unidirectional field motion. © 2020 Optical Society of America",,"Adolescent; Attention; Female; Humans; Male; Nystagmus, Optokinetic; Pupil; Young Adult; Eye movements; Location; Occupational diseases; Attention shifts; Centerlines; Display screen; Eye position; Optokinetic nystagmus; Pupil response; Pupil size; Spatial location; adolescent; attention; female; human; male; optokinetic nystagmus; physiology; pupil; young adult; Luminance",Article,Final,,Scopus,2-s2.0-85081129142,Movies / Media
Wang J.; Antonenko P.; Dawson K.,"Wang, Jiahui (57191491117); Antonenko, Pavlo (23090326200); Dawson, Kara (16238356400)",57191491117; 23090326200; 16238356400,Does visual attention to the instructor in online video affect learning and learner perceptions? An eye-tracking analysis,2020,Computers and Education,146,,103779,,,,128,10.1016/j.compedu.2019.103779,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076034624&doi=10.1016%2fj.compedu.2019.103779&partnerID=40&md5=c44a8377d4fa3b37dbe5e832d4e55f61,"An increasing number of instructional videos online integrate a real instructor on the video screen. So far, the empirical evidence from previous studies has been limited and conflicting, and none of the studies have explored how learners' allocation of visual attention to the on-screen instructor influences learning and learner perceptions. Therefore, this study aimed to disentangle a) how instructor presence in online videos affects learning, learner perceptions (i.e., cognitive load, judgment of learning, satisfaction, situational interest), and visual attention distribution and b) to what extent visual attention patterns in instructor-present videos predict learning and learner perceptions. Sixty college students each watched two videos on Statistics, one on an easy topic and the other one on a difficult topic, with each in one of the two video formats: instructor-present or instructor-absent. Their eye movements were simultaneously registered using a desktop-mounted eye tracker. Afterwards, participants self-reported their cognitive load, judgment of learning, satisfaction, and situational interest for both videos, and feelings toward seeing the instructor for the instructor-present videos. Learning from the two videos was measured using retention and transfer questions. Findings indicated instructor presence a) improved transfer performance for the difficult topic, b) reduced cognitive load for the difficult topic, c) increased judgment of learning for the difficult topic, and d) enhanced satisfaction and situational interest for both topics. Most participants expressed a positive feeling toward the instructor. Results also showed the instructor attracted a considerable amount of overt visual attention in both videos, and the amount of attention allocated to the instructor positively predicted participants’ satisfaction level for both topics. © 2019 Elsevier Ltd",,Behavioral research; Eye movements; Eye tracking; Students; College students; Eye-tracking analysis; Instructional videos; Learner perceptions; Overt visual attentions; Positive feelings; Transfer performance; Visual Attention; E-learning,Article,Final,,Scopus,2-s2.0-85076034624,Movies / Media
Schmitz A.; Macquarrie A.; Julier S.; Binetti N.; Steed A.,"Schmitz, Anastasia (57212747599); Macquarrie, Andrew (57148269700); Julier, Simon (7003972937); Binetti, Nicola (56380384400); Steed, Anthony (18435050200)",57212747599; 57148269700; 7003972937; 56380384400; 18435050200,Directing versus Attracting Attention: Exploring the Effectiveness of Central and Peripheral Cues in Panoramic Videos,2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,,9089479,63,72,9.0,30,10.1109/VR46266.2020.1581102716289,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085506737&doi=10.1109%2fVR46266.2020.1581102716289&partnerID=40&md5=21817fcf9a0f4b65fc3461b2e04f5135,"Filmmakers of panoramic videos frequently struggle to guide attention to Regions of Interest (ROIs) due to consumers' freedom to explore. Some researchers hypothesize that peripheral cues attract reflexive/involuntary attention whereas cues within central vision engage and direct voluntary attention. This mixed-methods study evaluated the effectiveness of using central arrows and peripheral flickers to guide and focus attention in panoramic videos. Twenty-five adults wore a head-mounted display with an eye tracker and were guided to 14 ROIs in two panoramic videos. No significant differences emerged in regard to the number of followed cues, the time taken to reach and observe ROIs, ROI-related memory and user engagement. However, participants' gaze travelled a significantly greater distance toward ROIs within the first 500 ms after flicker-onsets compared to arrow-onsets. Nevertheless, most users preferred the arrow and perceived it as significantly more rewarding than the flicker. The findings imply that traditional attention paradigms are not entirely applicable to panoramic videos, as peripheral cues appear to engage both involuntary and voluntary attention. Theoretical and practical implications as well as limitations are discussed. © 2020 IEEE.",360° video; Cinematic Virtual Reality; eye-tracking; guiding attention; head-mounted display; memory,Eye tracking; Helmet mounted displays; Motion pictures; User interfaces; Central vision; Eye trackers; Head mounted displays; Mixed method; Panoramic video; Regions of interest; User engagement; Virtual reality,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85085506737,Movies / Media
Walper D.; Kassau J.; Methfessel P.; Pronold T.; Einhäuser W.,"Walper, Daniel (55984748200); Kassau, Julia (57217013187); Methfessel, Philipp (57193508254); Pronold, Timo (57217013863); Einhäuser, Wolfgang (8701678900)",55984748200; 57217013187; 57193508254; 57217013863; 8701678900,Optimizing user interfaces in food production: Gaze tracking is more sensitive for A-B-testing than behavioral data alone,2020,Eye Tracking Research and Applications Symposium (ETRA),,,17,,,,4,10.1145/3379156.3391351,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085735952&doi=10.1145%2f3379156.3391351&partnerID=40&md5=bd180a2e079f1f3fe33641d04794a1e7,"Eye-tracking data often provide access to information about users' strategies and preferences that extend beyond purely behavioral data. Thanks to modern eye-tracking technology, gaze can be tracked rather unobtrusively in real-world settings. Here we examine the usefulness of gaze tracking with a mobile eye-tracker for interface design in an industrial setting, specifically the operation of a food production line. We use a mock task that is similar in its interface usage to the actual production task in routine machine operation. We compare two interface designs to each other as well as two levels of user expertise. We do not find any effects of experience or interface type in the behavioral data-in particular, both user groups needed the same time to complete the task on average. However, gaze data reveals different strategies: users with high experience in using the interface spend significantly less time looking at the screen-that is, actually interacting with the interface-in absolute terms as well as expressed as fraction of the total time needed to complete the task. This exemplifies how gaze tracking can be utilized to uncover different user-dependent strategies that would not be accessible through behavioral data alone. © 2020 ACM.",Attention; Eye tracking; Human-machine interaction; Interface design; Usability,User experience; User interfaces; Behavioral data; Eye tracking technologies; Food production; Industrial settings; Interface designs; Machine operation; Real world setting; User-dependent; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85085735952,Movies / Media
Al Ghalayini M.; Antoun J.; Moacdieh N.M.,"Al Ghalayini, Maher (57205154266); Antoun, Jumana (27667529600); Moacdieh, Nadine Marie (55583410100)",57205154266; 27667529600; 55583410100,Too much or too little? Investigating the usability of high and low data displays of the same electronic medical record,2020,Health Informatics Journal,26,1,,88,103,15.0,12,10.1177/1460458218813725,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058862893&doi=10.1177%2f1460458218813725&partnerID=40&md5=8f4f27063133a817b8aab6e74ad288bf,"The high data density on electronic medical record screens is touted as a major usability issue. However, it may not be a problem if the data is relevant and well-organized. Our objective was to test this assumption using a comprehensive set of measures that assess the three pillars of usability: efficiency (both physical and cognitive), effectiveness, and satisfaction. Physicians were asked to go through a series of tasks using two versions of the same electronic medical record: one where all the display items were separated into tabs (the original display), and one where important display items were grouped logically in one tab (the redesigned display). Results supported the hypothesis that combining relevant data in organized fashion into a smaller location would improve usability. The findings highlight the role of good display organization to mitigate the effects of high data density, as well as the importance of assessing cognitive load as part of usability studies. © The Author(s) 2018.",cognitive load; electronic medical records; eye tracking; GOMS; usability,Data Display; Efficiency; Electronic Health Records; Humans; Physicians; User-Computer Interface; article; electronic medical record; eye tracking; human; human experiment; physician; satisfaction; computer interface; electronic health record; information processing; organization and management; productivity,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85058862893,Movies / Media
Yang B.; Shoo Z.,"Yang, Bokai (57908789000); Shoo, Zhenhua (57215602326)",57908789000; 57215602326,Relationship between industrial product design and behavioural psychology,2020,Revista Argentina de Clinica Psicologica,29,2,,136,141,5.0,0,10.24205/03276716.2020.215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081380035&doi=10.24205%2f03276716.2020.215&partnerID=40&md5=6a853dc14367dd129741729ab6737681,"The design of industrial products is affected by the behavioural psychology of both designers and consumers. This paper attempts to identify the relationship between industrial product design and behavioural psychology The industrial product design was evaluated both based on the theory of behavioural psychology, and through actual application of behavioural psychology in the design. For the theoretical analysis, the elements of industrial product design were analysed, before setting up an evaluation system for the design. For the actual application, the behavioural psychology was applied to the design of mobile phone screen, and the effects were evaluated through eye movement test. The results show that the design of industrial products mainly focuses on product modelling, functional analysis, structural solution determination, product materials, process selection and large-scale production; the behavioural psychology of designers and consumers has an in-depth impact throughout the design process; the elements of behavioural psychology that affect the design include feeling, perception, judgment decision, and reaction execution, attention, long-term memory and short-term memory. The research findings provide a theoretical basis for the application of behavioural psychology in industrial product design. © 2020 Fundacion Aigle.",Behavioural psychology; Industrial product design; Judgment decision; Process selection,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85081380035,Movies / Media
Şendurur E.; Doğusoy B.; Yondemir Çalişkan N.,"Şendurur, Emine (41961558200); Doğusoy, Berrin (23396786100); Yondemir Çalişkan, Neslihan (57203876224)",41961558200; 23396786100; 57203876224,Investigation of non-native learners’ informal learning processes from cognitive-load theory perspective,2020,Interactive Learning Environments,28,1,,95,106,11.0,4,10.1080/10494820.2018.1517096,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053352133&doi=10.1080%2f10494820.2018.1517096&partnerID=40&md5=6ddd6ea3a337a4f2b79fce66c9fc3d31,"This study aims to investigate the effectiveness of the subtitles embedded into either declarative or procedural video on non-native Turkish speakers’ understandings of the content. In addition, their perceived difficulties about and eye behaviors during watching the two videos were explored. There were 40 volunteer international students from various departments. Two experiments were designed to observe how participants’ retention performance changed according to the content given in the videos. As participants individually watching the videos, their eye behavior was recorded for more objective observations about their fixations on either subtitle or main areas of the screen. In this way, their eye behaviors and their retention performance were compared. The findings showed that there were no significant differences in participants’ scores of retention and perceived difficulty regardless of both the video type (declarative vs. procedural) and subtitle existence (subtitled vs. non-subtitled). Moreover, the declarative video was perceived as difficult despite being easy-to-follow. The eye movement data analysis showed that in both the video types, the number of fixations on the subtitle AOI and main AOI were high in a parallel way, but when the participants experienced with procedural video, the percentage of fixations on subtitle area increased. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.",,,Article,Final,,Scopus,2-s2.0-85053352133,Movies / Media
Zheng Y.; Mao J.; Liu Y.; Sanderson M.; Zhang M.; Ma S.,"Zheng, Yukun (57195628755); Mao, Jiaxin (56125702100); Liu, Yiqun (35327597400); Sanderson, Mark (7202315611); Zhang, Min (57043667600); Ma, Shaoping (7403725163)",57195628755; 56125702100; 35327597400; 7202315611; 57043667600; 7403725163,Investigating examination behavior in mobile search,2020,WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining,,,,771,779,8.0,7,10.1145/3336191.3371797,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079529231&doi=10.1145%2f3336191.3371797&partnerID=40&md5=f226e973031f0c7a7a59d16427cb63fc,"Examination is one of the most important user interactions in Web search. A number of works studied examination behavior in Web search and helped researchers better understand how users allocate their attention on search engine result pages (SERPs). Compared to desktop search, mobile search has a number of differences such as fewer results on the screen. These differences bring in mobile-specific factors affecting users’ examination behavior. However, there still lacks research on users’ attention allocation mechanism via viewports in mobile search. Therefore, we design a lab-based study to collect user’s rich interaction behavior in mobile search. Based on the collected data, we first analyze how users examine SERPs and allocate their attention to heterogeneous results. Then we investigate the effect of mobile-specific factors and other common factors on users allocating attention. Finally, we apply the findings of user attention allocation from the user study into click model construction efforts, which significantly improves the state-of-the-art click model. Our work brings insights into a better understanding of users’ interaction patterns in mobile search and may benefit other mobile search-related research. © 2020 Association for Computing Machinery.",Examination behavior; Eye tracking; Mobile search; Mobile viewport,Eye tracking; Information retrieval; Search engines; Websites; Allocation mechanism; Examination behavior; Interaction behavior; Interaction pattern; Mobile search; Mobile viewport; Model construction; Search engine results; Data mining,Conference paper,Final,,Scopus,2-s2.0-85079529231,Movies / Media
Korbach A.; Ginns P.; Brünken R.; Park B.,"Korbach, Andreas (56976342300); Ginns, Paul (6602415322); Brünken, Roland (7003356739); Park, Babette (36458908500)",56976342300; 6602415322; 7003356739; 36458908500,Should learners use their hands for learning? Results from an eye-tracking study,2020,Journal of Computer Assisted Learning,36,1,,102,113,11.0,44,10.1111/jcal.12396,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074816116&doi=10.1111%2fjcal.12396&partnerID=40&md5=bfb4202c5acf7ab27f6f0a0c6ff1bb58,"Given the widespread use of touch screen devices, the effect of the users' fingers on information processing and learning is of growing interest. The present study drew on cognitive load theory and embodied cognition perspectives to investigate the effects of pointing and tracing gestures on the surface of a multimedia learning instruction. Learning performance, cognitive load and visual attention were examined in a one-factorial experimental design with the between-subject factor pointing and tracing gestures. The pointing and tracing group were instructed to use their fingers during the learning phase to make connections between corresponding text and picture information, whereas the control group was instructed not to use their hands for learning. The results showed a beneficial effect of pointing and tracing gestures on learning performance, a significant shift in visual attention and deeper processing of information by the pointing and tracing group, but no effect on subjective ratings of cognitive load. Implications for future research and practice are discussed. © 2020, Blackwell Publishing Ltd. All rights reserved.",cognitive load theory; embodied cognition; eye-tracking; tracing gestures,,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85074816116,Movies / Media
Faber M.; Krasich K.; Bixler R.E.; Brockmole J.R.; D'Mello S.K.,"Faber, Myrthe (56411660500); Krasich, Kristina (56536941600); Bixler, Robert E. (55789867400); Brockmole, James R. (6603687579); D'Mello, Sidney K. (14053463100)",56411660500; 56536941600; 55789867400; 6603687579; 14053463100,The Eye-Mind Wandering Link: Identifying Gaze Indices of Mind Wandering Across Tasks,2020,Journal of Experimental Psychology: Human Perception and Performance,,,,,,,63,10.1037/xhp0000743,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089137006&doi=10.1037%2fxhp0000743&partnerID=40&md5=7a7e5b3e8e286836d1f6befbe1efb8d3,"During mind wandering, visual processing of external information is attenuated. Accordingly, mind wandering is associated with changes in gaze behaviors, albeit findings are inconsistent in the literature. This heterogeneity obfuscates a complete view of the moment-to-moment processing priorities of the visual system during mind wandering. We hypothesize that this observed heterogeneity is an effect of idiosyncrasy across tasks with varying spatial allocation demands, visual processing demands, and discourse processing demands and reflects a strategic, compensatory shift in how the visual system operates during mind wandering. We recorded eye movements and mind wandering (via thought-probes) as 132 college-aged adults completed a battery of 7 short (6 min) tasks with different visual demands. We found that for tasks requiring extensive sampling of the visual field, there were fewer fixations, and, depending on the specific task, fixations were longer and/or more dispersed. This suggests that visual sampling is sparser and potentially slower and more dispersed to compensate for the decreased sampling rate during mind wandering. For tasks that demand centrally focused gaze, mind wandering was accompanied by more exploratory eye movements, such as shorter and more dispersed fixations as well as larger saccades. Gaze behaviors were not reliably associated with mind wandering during a film comprehension task. These findings provide insight into how the visual system prioritizes external information when attention is focused inward and indicates the importance of task demands when assessing the relationship between eye movements, visual processing, and mind wandering. © 2020 American Psychological Association.",Cognitive processing; Eye movements; Mind wandering; Visual processing,"Adult; Attention; Eye-Tracking Technology; Female; Fixation, Ocular; Humans; Male; Pattern Recognition, Visual; Reading; Speech Perception; Young Adult; adult; attention; eye fixation; female; human; male; pattern recognition; physiology; reading; speech perception; young adult",Article,Article in press,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85089137006,Movies / Media
Souza A.S.; Czoschke S.; Lange E.B.,"Souza, Alessandra S. (55436300200); Czoschke, Stefan (57194646490); Lange, Elke B. (8632495100)",55436300200; 57194646490; 8632495100,Gaze-Based and Attention-Based Rehearsal in Spatial Working Memory,2020,Journal of Experimental Psychology: Learning Memory and Cognition,46,5,,980,1003,23.0,20,10.1037/xlm0000771,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073099352&doi=10.1037%2fxlm0000771&partnerID=40&md5=709782a58acc3a943ff13004ec8b91d0,"How do we maintain information about spatial configurations in mind? Many working memory (WM) models assume that rehearsal processes are used to counteract forgetting in WM. Here, we investigated the contributions of gaze-based and attention-based rehearsal for protecting spatial representations from time-based forgetting. Participants memorized 6 locations selected from a grid of 30 scattered dots. Memory was tested after 1.5 or 4.5 s, and this interval was either blank or the grid remained onscreen (which is assumed to provide rehearsal support). In 2 experiments, we monitored eye movements during the retention phase, or asked participants to fixate the screen center. In 3 subsequent experiments, we tested spatial WM under dual-task conditions inhibiting shifts of visuospatial attention or central attention to the memoranda. Memory was better and more resistant to time-based forgetting in the grid than blank condition. Recording of fixations showed more frequent and efficient gaze-based rehearsal in the presence of the grid. Fixations toward distractor locations occurred at a similar frequency in the blank and grid conditions, and it did not predict incorrect recalls. Inhibition of eye-movements or shifts of visuospatial attention impaired memory overall, but it did not change the grid benefit nor the rate of time-based forgetting. In contrast, distracting central attention increased time-based forgetting regardless of grid presence. These results indicate that (a) the grid benefit is only partially explained by rehearsal; (b) gaze-errors (i.e., distractor fixations) do not lead to more forgetting; and (c) the maintenance of spatial representations over time depends on central processing. © 2019 American Psychological Association",central attention; eye-movements; rehearsal; spatial working memory; visuospatial attention,"Attention; Eye Movement Measurements; Eye Movements; Humans; Memory, Short-Term; Mental Recall; Psychological Tests; Psychological Theory; Spatial Memory; Young Adult; attention; eye movement; human; oculography; psychologic test; psychological theory; recall; short term memory; spatial memory; young adult",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85073099352,Movies / Media
Wakeford L.J.; Murray W.S.,"Wakeford, Laura J. (57209716196); Murray, Wayne S. (7201983332)",57209716196; 7201983332,The lexical access of multiple words during a single fixation: overlapping access processes?,2020,"Language, Cognition and Neuroscience",,,,1435,1444,9.0,0,10.1080/23273798.2020.1792952,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088018808&doi=10.1080%2f23273798.2020.1792952&partnerID=40&md5=64af8b4d00fc86d9383dfabfd16333bd,"Since it has become increasingly difficult to tease apart the predictions of serial and parallel models of eye movement control during reading, we return to the underlying theoretical question of whether parallel lexical processing of two words is, at the very least, psychologically plausible. Two horizontally aligned letter strings were presented simultaneously on a screen, the task being to decide whether they were physically identical or not. Even with presentation durations short enough to prohibit serial inspection of each word, the results show clear lexical effects: high frequency word pairs were responded to faster and with fewer errors than low frequency words. Effects of lexicality, orthography and scanning direction were also found. The results suggest that two words can be processed at a lexical level in an overlapping fashion. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.",attention; models of eye movement control; parallel lexical processing; same-different matching; Word recognition,article; attention; eye movement control; word recognition,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85088018808,Movies / Media
Hashim S.; Stewart L.; Küssner M.B.,"Hashim, Sarah (57299857300); Stewart, Lauren (7202187064); Küssner, Mats B. (55761584700)",57299857300; 7202187064; 55761584700,Saccadic Eye-Movements Suppress Visual Mental Imagery and Partly Reduce Emotional Response During Music Listening,2020,Music and Science,3,,,,,,15,10.1177/2059204320959580,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112669287&doi=10.1177%2f2059204320959580&partnerID=40&md5=4fbc76179cf4e7f7e6d93b7d0c530428,"Visual mental imagery has been proposed to be an underlying mechanism of music-induced emotion, yet very little is known about the phenomenon due to its ephemeral nature. The present study utilised a saccadic eye-movement task designed to suppress visual imagery during music listening. Thirty-five participants took part in Distractor (eye-movement) and Control (blank screen) conditions, and reported the prevalence, control, and vividness of their visual imagery, and felt emotion ratings using the GEMS-9 in response to short excerpts of film music. The results show that the eye-movement task was highly effective in reducing ratings for prevalence and vividness of visual imagery, and for one GEMS item, Nostalgia, but was not successful in reducing control of imagery or the remaining GEMS items in response to the music. This represents a novel approach to understanding the potentially causal role of visual imagery on music-induced emotion, on which future research can build by considering the attentional mechanisms that a distraction task may pose during music-induced visual imagery formation. © The Author(s) 2020.",emotion induction; music listening; suppression of imagery; visual imagery,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85112669287,Movies / Media
Klein P.; Lichtenberger A.; Küchemann S.; Becker S.; Kekule M.; Viiri J.; Baadte C.; Vaterlaus A.; Kuhn J.,"Klein, P. (56374702400); Lichtenberger, A. (26023484600); Küchemann, S. (36240700600); Becker, S. (57191904903); Kekule, M. (57193379453); Viiri, J. (15520193600); Baadte, C. (14621609200); Vaterlaus, A. (6603715705); Kuhn, J. (55984409000)",56374702400; 26023484600; 36240700600; 57191904903; 57193379453; 15520193600; 14621609200; 6603715705; 55984409000,Visual attention while solving the test of understanding graphs in kinematics: An eye-tracking analysis,2020,European Journal of Physics,41,2,25701,,,,28,10.1088/1361-6404/ab5f51,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081979554&doi=10.1088%2f1361-6404%2fab5f51&partnerID=40&md5=b029ca3be5d37e67dd751bde21150dc5,"This study used eye-tracking to capture students' visual attention while taking a test of understanding graphs in kinematics (TUG-K). A total of N = 115 upper-secondary-level students from Germany and Switzerland took the 26-item multiple-choice instrument after learning about kinematics graphs in the regular classroom. Besides choosing the correct alternative among research-based distractors, the students were required to judge their response confidence for each question. The items were presented sequentially on a computer screen equipped with a remote eye tracker, resulting in a set of approx. 3000 paired responses (accuracy and confidence) and about 40 h of eye-movement data (approx. 500 000 fixations). The analysis of students' visual attention related to the item stems (questions), and the item options reveal that high response confidence is correlated with shorter visit duration on both elements of the items. While the students' response accuracy and their response confidence are highly correlated on the score level, r(115) = 0.63, p < 0.001, the eye-tracking measures do not sufficiently discriminate between correct and incorrect responses. However, a more fine-grained analysis of visual attention based on different answer options reveals a significant discrimination between correct and incorrect answers in terms of an interaction effect: incorrect responses are associated with longer visit durations on strong distractors and less time spent on correct options while correct responses show the opposite trend. Outcomes of this study provide new insights into the validation of concept inventories based on the students' behavioural level. © 2020 European Physical Society.",Eye-tracking; graph understanding; kinematics; test validation; visual attention,Behavioral research; Eye movements; Eye tracking; Students; Computer screens; Eye trackers; Eye-tracking; Eye-tracking analysis; Graph understanding; Multiple choice; Secondary level students; Switzerland; Test validation; Visual Attention; Kinematics,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85081979554,Movies / Media
Pereira M.L.G.D.F.; Camargo M.V.Z.D.A.; Bellan A.F.R.; Tahira A.C.; Dos Santos B.; Dos Santos J.; Machado-Lima A.; Nunes F.L.S.; Forlenza O.V.,"Pereira, Marta Luísa Gonçalves De Freitas (57215149602); Camargo, Marina Von Zuben De Arruda (57126850900); Bellan, Ariella Fornachari Ribeiro (57216803024); Tahira, Ana Carolina (54407554500); Dos Santos, Bernardo (55339980900); Dos Santos, Jéssica (54685132200); Machado-Lima, Ariane (57195959173); Nunes, Fátima L.S. (7102392843); Forlenza, Orestes Vicente (6603840032)",57215149602; 57126850900; 57216803024; 54407554500; 55339980900; 54685132200; 57195959173; 7102392843; 6603840032,Visual Search Efficiency in Mild Cognitive Impairment and Alzheimer's Disease: An Eye Movement Study,2020,Journal of Alzheimer's Disease,75,1,,261,275,14.0,33,10.3233/jad-190690,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084721449&doi=10.3233%2fjad-190690&partnerID=40&md5=67e87971c92ccd01c3a4da3886c370ba,"Background: Visual search abilities are essential to everyday life activities and are known to be affected in Alzheimer's disease (AD). However, little is known about visual search efficiency in mild cognitive impairment (MCI), a transitive state between normal aging and dementia. Eye movement studies and machine learning methods have been recently used to detect oculomotor impairments in individuals with dementia. Objective: The aim of the present study is to investigate the association between eye movement metrics and visual search impairment in MCI and AD. Methods: 127 participants were tested: 43 healthy controls, 51 with MCI, and 33 with AD. They completed an eyetracking visual search task where they had to find a previously seen target stimulus among distractors. Results: Both patient groups made more fixations on the screen when searching for a target, with longer duration than controls. MCI and AD fixated the distractors more often and for a longer period of time than the target. Healthy controls were quicker and made less fixations when scanning the stimuli for the first time. Machine-learning methods were able to distinguish between controls and AD subjects and to identify MCI subjects with a similar oculomotor profile to AD with a good accuracy. Conclusion: Results showed that eye movement metrics are useful for identifying visual search impairments in MCI and AD, with possible implications in the early identification of individuals with high-risk of developing AD. © 2020 - IOS Press and the authors. All rights reserved.",Alzheimer's disease; eye movements; eyetracking; machine learning; mild cognitive impairment; visual attention; visual impairments; visual search,Aged; Alzheimer Disease; Attention; Cognitive Dysfunction; Disease Progression; Eye Movements; Female; Humans; Machine Learning; Male; Middle Aged; Visual Perception; aged; Alzheimer disease; Article; case control study; controlled study; dementia; diagnostic test accuracy study; disease association; eye fixation; eye movement; eye tracking; female; human; machine learning; major clinical study; male; measurement accuracy; mild cognitive impairment; oculomotor system; optometry; priority journal; radial basis function; receiver operating characteristic; stimulus; support vector machine; task performance; visual impairment; visual search; visual system; Alzheimer disease; attention; cognitive defect; disease exacerbation; eye movement; middle aged; pathophysiology; physiology; vision,Article,Final,,Scopus,2-s2.0-85084721449,Movies / Media
Wei Y.; Wan Y.; Tanenhaus M.K.,"Wei, Yipu (57209341339); Wan, Yingjia (57203788955); Tanenhaus, Michael K. (7003537050)",57209341339; 57203788955; 7003537050,Effects of Coordination on Perspective-taking: Evidence from Eye-tracking,2020,"Proceedings for the 42nd Annual Meeting of the Cognitive Science Society: Developing a Mind: Learning in Humans, Animals, and Machines, CogSci 2020",,,,2767,2773,6.0,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139514498&partnerID=40&md5=bc50460c7c2355af303243915e6f1c00,"We investigated whether fine-grained coordination in a screen-based puzzle task with a (virtual) partner would influence online perspective-taking. Participants played a screen-based puzzle game with a computer player. In the high-coordination condition, the player presented participants with puzzle pieces that could be placed near their partner's last piece. In the low-coordination condition, pieces could only be placed further away from their partner's last piece. Participant's eye movements were then measured in a referential communication task, with the partner giving the instructions, and whether possible competitor referents were in shared or privileged ground. The results demonstrate clear effects of ground and coordination. Participants in both coordination groups were sensitive to the perspective of the interlocutor. In addition, participants in the high-level coordination condition were more sensitive to statistical regularities in the input and their comprehension was more time-locked to the utterance of the speaker. © 2020 The Author(s). This work is licensed under a Creative Commons Attribution 4.0 International License (CC BY)",coordination; joint action; online comprehension; perspective-taking; social cognition,Computer games; Eye tracking; Condition; Coordination; Creative Commons; Eye-tracking; Fine grained; Joint actions; Online comprehension; Perspective taking; Puzzle games; Social cognition; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85139514498,Movies / Media
Sridhar S.; Kwon Y.; Cho Y.; Kim I.,"Sridhar, Smriti (57216397734); Kwon, Younghoon (59437091400); Cho, Yeilim (57195755625); Kim, Inki (56576840500)",57216397734; 59437091400; 57195755625; 56576840500,An adaptive fuzzy modeling of visual attention in real-world interaction with health information system,2020,Proceedings of the Human Factors and Ergonomics Society,64,1,,249,253,4.0,0,10.1177/1071181320641059,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199483120&doi=10.1177%2f1071181320641059&partnerID=40&md5=5ba1298b85315f9f6e64e9a3c5b7ff49,"Bottom-up and top-down processes are the two mechanisms of visual attention allocation, which allow people to efficiently spot task-relevant stimuli from cluttered and noisy environments, while staying alert to abnormalities within the visual field of view. This paper presents a preliminary study of the physicians’ real-life interaction with Information Communication Technology (ICT) in their own offices, along with extensively analyzing one case of an hour-long interaction of a physician, in which one performs a daily routine of reviewing patient electronic health records (EHRs) and writing diagnostic notes to the system interface. The physician interactions were captured in a time series data by recording display screen, keystrokes and mouse movements, also by simultaneously tracking eye movements. Then, a fuzzy-based model that can distinguish bottom-up and top-down processes were defined by using statistical random variables in terms of eye-movement patterns. The shift between those two attentional processes was detected by tracking the parametric changes of gaze behaviors as input: Significant shift of fixation, sustained gazing, and fixation trajectory over time. Based on those gaze metrics, a random variable was assigned to the discrete probability of low (0), medium (0.5), or high (1.0), for a quantified fuzzy output, which was further machine-learned into an Adaptive Neuro-Fuzzy Inference System (ANFIS) model in order to judge how a physician is likely to be dominated by a bottom-up or top-down processes in performing a task at that instance in time. On training the ANFIS model with three different types of fuzzy membership functions (Gaussian, triangular and trapezoidal), the model performed best with the Gaussian function (after 100 iterations, the predicted root mean-square error (RMSE) converged at 0.07%, yielding a smooth linear curve). For a proof-of concept, the model was implemented by using one physician’s gaze behaviors, of which the average, machine-learned fuzzy output probability indicated that the physician was veering toward bottom-up visual attention. This individualized, task-specific pattern of visual attention has implications for the designs of intelligent interface in ICT. Our ANFIS model can scale up to different physicians and tasks to predict the likelihood of bottom-up or top-down information processing based on real-world gaze behaviors. © 2020 by Human Factors and Ergonomics Society. All rights reserved.",,Behavioral research; Eye movements; Fuzzy inference; Fuzzy neural networks; Fuzzy systems; Mammals; Membership functions; Random variables; Adaptive neuro-fuzzy inference; Bottom-up and top-down; Fuzzy output; Gaze behaviours; Information communication technology; Neuro-fuzzy inference systems; Real-world; System models; Top-down process; Visual Attention; Mean square error,Conference paper,Final,,Scopus,2-s2.0-85199483120,Movies / Media
Wu M.-D.; Chen H.-J.; Hu J.-F.,"Wu, Ming-Da (56861471200); Chen, Hsi-Jen (56403960100); Hu, Jon-Fan (23090663300)",56861471200; 56403960100; 23090663300,Visual Features of the Touchscreen Keyboard Guide Attention and Text Entry Behavior: An Eye-Tracking Study,2020,Advances in Intelligent Systems and Computing,1256 AISC,,,430,439,9.0,1,10.1007/978-981-15-7801-4_45,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090099328&doi=10.1007%2f978-981-15-7801-4_45&partnerID=40&md5=0d197cd31bf7dc4fac8f8226d4f5c2a8,"Text entry via the smartphone touchscreen is an increasingly important means of communication. However, there is an offset between the intended landing location and the actual touch location, which reduces the accuracy of text entry. The present study found that at least two visual features of the soft smartphone keyboards in the market may have an effect on touch behavior. Therefore, this study aims to investigate whether symbol shape and key border affect the distribution of attention and user’s touch behavior. Four soft keyboards were designed to record the touch location while simultaneously using the eye tracker to capture the gaze data. The results show that the usability score of bordered keys is better than that of borderless keys, but the touch accuracy of bordered keys is poorer than that of borderless keys. In addition, the center of attention is not consistent with the touch location. The results of this research can be used as a reference for the design of the soft keyboard interface to reduce the error of text entry on the smartphone. © 2020, Springer Nature Singapore Pte Ltd.",Eye movement; Interface design; Smartphone,Location; Smartphones; Eye trackers; Eye-tracking studies; Landing locations; Soft keyboard; Text entry; Touch-screen keyboards; Visual feature; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85090099328,Movies / Media
Kadooka K.; Franchak J.M.,"Kadooka, Kellan (57218878091); Franchak, John M. (36096593400)",57218878091; 36096593400,Developmental changes in infants’ and children’s attention to faces and salient regions vary across and within video stimuli.,2020,Developmental Psychology,56,11,,2065,2079,14.0,14,10.1037/dev0001073,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090601572&doi=10.1037%2fdev0001073&partnerID=40&md5=2b4eb54de38eda60b7f1b579d69bafe9,"Visual attention in complex, dynamic scenes is attracted to locations that contain socially relevant features, such as faces, and to areas that are visually salient. Previous work suggests that there is a global shift over development such that observers increasingly attend to faces with age. However, no prior work has tested whether this shift is truly global, that is, consistent across and within stimuli despite variations in content. To test the global shift hypothesis, we recorded eye movements of 89 children (6 months to 10 years) and adults while they viewed 7 video clips. We measured the extent to which each participant attended to faces and to salient areas for each video. There was no evidence of global age-related changes in attention: Neither feature showed consistent increases or decreases with age. Moreover, windowed analyses within each stimulus video revealed significant moment-to-moment variations in the relation between age and each visual feature (via a bootstrapping analysis). For some time windows, adults looked more often at both feature types compared to infants and children. However, for other time windows, the pattern was reversed—younger participants looked more at faces and salient locations. Lack of consistent directional effects provides strong evidence against the global shift hypothesis. We suggest an alternative explanation: Over development, observers increasingly prioritize when and where to look by learning to track which features are relevant within a scene. Implications for the development of visual attention and children’s understanding of screen-based media are discussed. (PsycInfo Database Record (c) 2020 APA, all rights reserved) © 2020 American Psychological Association",eye movements; faces; media; saliency; visual attention,Adult; Child; Eye Movements; Humans; Infant; adult; child; eye movement; human; infant,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85090601572,Movies / Media
Loschky L.C.; Larson A.M.; Smith T.J.; Magliano J.P.,"Loschky, Lester C. (6602946442); Larson, Adam M. (36786715600); Smith, Tim J. (55568512084); Magliano, Joseph P. (6701369755)",6602946442; 36786715600; 55568512084; 6701369755,The Scene Perception & Event Comprehension Theory (SPECT) Applied to Visual Narratives,2020,Topics in Cognitive Science,12,1,,311,351,40.0,90,10.1111/tops.12455,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064069095&doi=10.1111%2ftops.12455&partnerID=40&md5=b1ea13d5926ad4a22eaf72573ddf620e,"Understanding how people comprehend visual narratives (including picture stories, comics, and film) requires the combination of traditionally separate theories that span the initial sensory and perceptual processing of complex visual scenes, the perception of events over time, and comprehension of narratives. Existing piecemeal approaches fail to capture the interplay between these levels of processing. Here, we propose the Scene Perception & Event Comprehension Theory (SPECT), as applied to visual narratives, which distinguishes between front-end and back-end cognitive processes. Front-end processes occur during single eye fixations and are comprised of attentional selection and information extraction. Back-end processes occur across multiple fixations and support the construction of event models, which reflect understanding of what is happening now in a narrative (stored in working memory) and over the course of the entire narrative (stored in long-term episodic memory). We describe relationships between front- and back-end processes, and medium-specific differences that likely produce variation in front-end and back-end processes across media (e.g., picture stories vs. film). We describe several novel research questions derived from SPECT that we have explored. By addressing these questions, we provide greater insight into how attention, information extraction, and event model processes are dynamically coordinated to perceive and understand complex naturalistic visual events in narratives and the real world. © 2019 The Authors. Topics in Cognitive Science published by Wiley Periodicals, Inc. on behalf of Cognitive Science Society",Attention; Comics; Event perception; Eye movements; Film; Narrative comprehension; Scene perception; Visual narratives,"Attention; Cartoons as Topic; Comprehension; Eye Movements; Humans; Motion Pictures; Narration; Pattern Recognition, Visual; Psychological Theory; art; attention; comprehension; eye movement; human; movie; pattern recognition; physiology; psychological theory; verbal communication",Article,Final,,Scopus,2-s2.0-85064069095,Movies / Media
Bacha-Trams M.; Ryyppo E.; Glerean E.; Sams M.; Jaaskelainen I.P.,"Bacha-Trams, Mareike (55588323800); Ryyppo, Elisa (57196281261); Glerean, Enrico (37037426400); Sams, Mikko (7005052732); Jaaskelainen, Iiro P. (7006298797)",55588323800; 57196281261; 37037426400; 7005052732; 7006298797,Social perspective-takingshapes brain hemodynamic activity and eye movements during movie viewing,2020,Social Cognitive and Affective Neuroscience,15,2,,175,191,16.0,12,10.1093/scan/nsaa033,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084720936&doi=10.1093%2fscan%2fnsaa033&partnerID=40&md5=4de42e83c848c7b6b2e9d39e2dbef584,"Putting oneself into the shoes of others is an important aspect of social cognition.We measured brain hemodynamic activity and eye-gaze patterns while participants were viewing a shortened version of the movie 'My Sister's Keeper' from two perspectives: That of a potential organ donor, who violates moral norms by refusing to donate her kidney, and that of a potential organ recipient, who suffers in pain. Inter-subject correlation (ISC) of brain activity was significantly higher during the potential organ donor's perspective in dorsolateral and inferior prefrontal, lateral and inferior occipital, and inferior-anterior temporal areas. In the reverse contrast, stronger ISC was observed in superior temporal, posterior frontal and anterior parietal areas. Eye-gaze analysis showed higher proportion of fixations on the potential organ recipient during both perspectives. Taken together, these results suggest that during social perspective-taking different brain areas can be f lexibly recruited depending on the nature of the perspective that is taken.  © 2019 The Author(s). Published by Oxford University Press on behalf of the Annals of Botany Company. All rights reserved.",Functional magnetic resonance imaging; Inter-subject correlation; Movie viewing; Neuroimaging; Perspective-taking,Adult; Brain; Brain Mapping; Cerebral Cortex; Eye Movements; Female; Hemodynamics; Humans; Magnetic Resonance Imaging; Male; Morals; Motion Pictures; adult; brain; brain cortex; brain mapping; eye movement; female; hemodynamics; human; male; morality; movie; nuclear magnetic resonance imaging; physiology,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85084720936,Movies / Media
Huettig F.; Guerra E.; Helo A.,"Huettig, Falk (24337902700); Guerra, Ernesto (56377117400); Helo, Andrea (36086220500)",24337902700; 56377117400; 36086220500,Towards understanding the task dependency of embodied language processing: The influence of colour during language-vision interactions,2020,Journal of Cognition,3,1,41,,,,11,10.5334/joc.135,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106225855&doi=10.5334%2fjoc.135&partnerID=40&md5=745ee97c8e22fd698ec9107b7a410ea5,"A main challenge for theories of embodied cognition is to understand the task dependency of embodied language processing. One possibility is that perceptual representations (e.g., typical colour of objects mentioned in spoken sentences) are not activated routinely but the influence of perceptual representation emerges only when context strongly supports their involvement in language. To explore this question, we tested the effects of colour representations during language processing in three visual-world eye-tracking experiments. On critical trials, participants listened to sentence-embedded words associated with a prototypical colour (e.g., '...spinach...') while they inspected a visual display with four printed words (Experiment 1), coloured or greyscale line drawings (Experiment 2) and a 'blank screen' after a preview of coloured or greyscale line drawings (Experiment 3). Visual context always presented a word/object (e.g., frog) associated with the same prototypical colour (e.g. green) as the spoken target word and three distractors. When hearing spinach participants did not prefer the written word frog compared to other distractor words (Experiment 1). In Experiment 2, colour competitors attracted more overt attention compared to average distractors, but only for the coloured condition and not for greyscale trials. Finally, when the display was removed at the onset of the sentence, and in contrast to the previous blank-screen experiments with semantic competitors, there was no evidence of colour competition in the eye-tracking record (Experiment 3). These results fit best with the notion that the main role of perceptual representations in language processing is to contextualize language in the immediate environment.  © 2020 The Author(s).",Embodied cognition; Eye movements; Visual world paradigm,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85106225855,Movies / Media
Baldin E.; Zenesini C.; Bauleo S.; Montanari F.; Santi S.; Spampinato M.; Cortelli P.; D'Alessandro R.; Ascherio A.,"Baldin, Elisa (57008911300); Zenesini, Corrado (55555709100); Bauleo, Salvatore (17933323800); Montanari, Federico (57194898166); Santi, Sandra (57194901926); Spampinato, Maurizio (57216292510); Cortelli, Pietro (58327122600); D'Alessandro, Roberto (7103031093); Ascherio, Alberto (7004443355)",57008911300; 55555709100; 17933323800; 57194898166; 57194901926; 57216292510; 58327122600; 7103031093; 7004443355,Low Cost Screening for Features of Prodromal Parkinson's Disease in General Medical Practice in Italy,2020,Journal of Parkinson's Disease,10,2,,711,715,4.0,7,10.3233/JPD-191868,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083041621&doi=10.3233%2fJPD-191868&partnerID=40&md5=d75bd6f911e76d0b4350c85639b9e386,"The aim of the study was to determine the feasibility of screening older adults attending general medical practice for features suggesting prodromal Parkinson's disease (PD). Four general practitioners recruited 392 subjects aged ≥60 years, attending their primary clinics. A self-administered questionnaire collected information on history of probable rapid eye movements sleep behavior disorder (pRBD), constipation, risk markers for PD, and on subjective cognitive function. Olfactory function was tested. Constipation (27.8%), and hyposmia (19.9%), but not pRBD (4.3%), were more prevalent with age. Further supporting the feasibility of a longitudinal study, 299 subjects agreed to be followed. © 2020-IOS Press and the authors. All rights reserved.",epidemiology; health policy and practice; Parkinson's disease,"Aged; Aged, 80 and over; Cognitive Dysfunction; Constipation; Diagnostic Self Evaluation; Early Diagnosis; Feasibility Studies; Female; General Practice; Health Policy; Humans; Italy; Male; Middle Aged; Olfaction Disorders; Parkinson Disease; Prevalence; Prodromal Symptoms; REM Sleep Behavior Disorder; adult; age; aged; Article; cognition; constipation; disease marker; female; follow up; general practice; general practitioner; health care cost; human; hyposmia; Italy; major clinical study; male; middle aged; parasomnia; Parkinson disease; priority journal; prodromal symptom; questionnaire; screening test; smelling; very elderly; cognitive defect; complication; constipation; early diagnosis; economics; feasibility study; general practice; health care policy; Italy; parasomnia; Parkinson disease; prevalence; self evaluation; smelling disorder",Article,Final,,Scopus,2-s2.0-85083041621,Movies / Media
Dong W.; Yang T.; Liao H.; Meng L.,"Dong, Weihua (22233370800); Yang, Tianyu (57209027567); Liao, Hua (56059959800); Meng, Liqiu (56002214900)",22233370800; 57209027567; 56059959800; 56002214900,How does map use differ in virtual reality and desktop-based environments?,2020,International Journal of Digital Earth,13,12,,1484,1503,19.0,33,10.1080/17538947.2020.1731617,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080090756&doi=10.1080%2f17538947.2020.1731617&partnerID=40&md5=ee25e2316f5997ed45cc4c8c660f5b37,"Maps based on virtual reality (VR) are evolving and are being increasingly used in the field of geography. However, the advantages of VR based on the map use processes of users over desktop-based environments (DEs) are not fully understood. In this study, an experiment was conducted in which 120 participants performed map use tasks using maps and globes in VR and DE. The participants’ eye movements and questionnaires were collected to compare the map use performance differences. We analyzed the general metrics, information searching and processing metrics of participants (e.g. response time, RT; average fixation duration, AFD; average saccade duration, ASD; saccade frequency, SF, etc.) using maps and globes in different environments. We found that the participants using VR processed information more efficiently (AFDDE = 233.34 ms, AFDVR = 173.09 ms), and the participants using DE had both a significantly shorter response time (RTDE = 88.68 s, RTVR = 124.05 s) and a shorter visual search time (ASDDE = 60.78 ms, ASDVR = 112.13 ms; SFDE = 6.30, SFVR = 2.07). We also found similarities in accuracy, satisfaction and readability. These results are helpful for designing VR maps that can adapt to human cognition and reflect the advantages of VR. © 2020 Informa UK Limited, trading as Taylor & Francis Group.",desktop-based environment; globe; map; map use performance; Virtual reality,Eye movements; Software packages; Surveys; Average fixation durations; Human cognition; Information searching; Processed information; Visual search; accuracy assessment; cartography; computer simulation; efficiency measurement; mapping method; performance assessment; virtual reality; Virtual reality,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85080090756,Movies / Media
Rahman S.; Rahman S.; Shahid O.; Abdullah M.T.; Sourov J.A.,"Rahman, Shafin (55435301000); Rahman, Sejuti (57198872446); Shahid, Omar (55570902700); Abdullah, Md. Tahmeed (57220902655); Sourov, Jubair Ahmed (57221319271)",55435301000; 57198872446; 55570902700; 57220902655; 57221319271,Classifying eye-tracking data using saliency maps,2020,Proceedings - International Conference on Pattern Recognition,,,9412308,9288,9295,7.0,9,10.1109/ICPR48806.2021.9412308,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110468885&doi=10.1109%2fICPR48806.2021.9412308&partnerID=40&md5=beca606e6b78f45414b4fc7d44377ff4,"A plethora of research in the literature shows how human eye fixation pattern varies depending on different factors, including genetics, age, social functioning, cognitive functioning, and so on. Analysis of these variations in visual attention has already elicited two potential research avenues: 1) determining the physiological or psychological state of the subject and 2) predicting the tasks associated with the act of viewing from the recorded eye-fixation data. To this end, this paper proposes a visual saliency based novel feature extraction method for automatic and quantitative classification of eye-tracking data, which is applicable to both of the research directions. Instead of directly extracting features from the fixation data, this method employs several well-known computational models of visual attention to predict eye fixation locations as saliency maps. Comparing the saliency amplitudes, similarity and dissimilarity of saliency maps with the corresponding eye fixations maps gives an extra dimension of information which is effectively utilized to generate discriminative features to classify the eye-tracking data. Extensive experimentation using Saliency4ASD [1], Age Prediction [2], and Visual Perceptual Task [3] dataset show that our saliency-based feature can achieve superior performance, outperforming the previous state-of-the-art methods [2], [4], [5] by a considerable margin. Moreover, unlike the existing application-specific solutions, our method demonstrates performance improvement across three distinct problems from the real-life domain: Autism Spectrum Disorder screening, toddler age prediction, and human visual perceptual task classification, providing a general paradigm that utilizes the extra-information inherent in saliency maps for a more accurate classification. © 2020 IEEE",Autism spectrum disorder; Eye-tracking; Toddler age prediction; Visual perceptual task; Visual saliency,Behavioral research; Data mining; Eye tracking; Forecasting; Pattern recognition; Application specific; Autism spectrum disorders; Discriminative features; Feature extraction methods; Potential researches; Psychological state; Quantitative classifications; State-of-the-art methods; Classification (of information),Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85110468885,Movies / Media
Flis G.; Sikorski A.; Szarkowska A.,"Flis, Gabriela (57216338498); Sikorski, Adam (57216355426); Szarkowska, Agnieszka (54416458200)",57216338498; 57216355426; 54416458200,Does the dubbing effect apply to voice-over? A conceptual replication study on visual attention and immersion,2020,Journal of Specialised Translation,,33,,41,69,28.0,10,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083166417&partnerID=40&md5=dcb70a0c463c586a36e6c2b0317a6111,"In an eye-tracking study, Romero-Fresco (2016) discovered that when watching a dubbed film, Spanish viewers hardly looked at characters’ mouths and focussed instead on their eyes – a phenomenon he termed ‘the dubbing effect’. Our study is a conceptual replication of Romero-Fresco’s study, aimed at answering the question of whether a similar effect also takes place in voice-over: do viewers avoid looking at characters’ mouths to stay immersed in the film story? With this question in mind, we tested 35 Polish native speakers watching a 6-minute voiced-over excerpt from Casablanca while their eyes were monitored with an eye tracker. We also measured viewers’ immersion levels as well as their enjoyment and comprehension. In this paper, we present two experiments. In Experiment 1, by analysing viewers’ gaze behaviour and immersion levels, we found that Polish viewers did not avoid looking at characters’ mouths. In Experiment 2, we compared our results with those obtained in the original study with Spanish and English viewers. We found that visual attention distribution in Polish voice-over resembled the one observed in English viewers, who watched the film with the original soundtrack. Both Polish and English viewers spent more time looking at characters’ eyes in scenes with no dialogue compared to scenes with dialogue, as opposed to the Spanish people for whom the tendency was reversed. © 2020 University of Roehampton. All rights reserved.",Audiovisual translation; Dubbing effect; Eye tracking; Immersion; Visual attention; Voice-over,,Article,Final,,Scopus,2-s2.0-85083166417,Movies / Media
Sood E.; Tannert S.; Frassinelli D.; Bulling A.; Vu N.T.,"Sood, Ekta (57215279496); Tannert, Simon (57224856004); Frassinelli, Diego (57219808764); Bulling, Andreas (6505807414); Vu, Ngoc Thang (35744252000)",57215279496; 57224856004; 57219808764; 6505807414; 35744252000,Interpreting Attention Models with Human Visual Attention in Machine Reading Comprehension,2020,"CoNLL 2020 - 24th Conference on Computational Natural Language Learning, Proceedings of the Conference",,,,12,25,13.0,41,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173627129&partnerID=40&md5=01a8876404bfff5ebcc61ef90b950499,"While neural networks with attention mechanisms have achieved superior performance on many natural language processing tasks, it remains unclear to which extent learned attention resembles human visual attention. In this paper, we propose a new method that leverages eye-tracking data to investigate the relationship between human visual attention and neural attention in machine reading comprehension. To this end, we introduce a novel 23 participant eye tracking dataset - MQA-RC, in which participants read movie plots and answered pre-defined questions. We compare state of the art networks based on long short-term memory (LSTM), convolutional neural models (CNN) and XLNet Transformer architectures. We find that higher similarity to human attention and performance significantly correlates to the LSTM and CNN models. However, we show this relationship does not hold true for the XLNet models – despite the fact that the XLNet performs best on this challenging task. Our results suggest that different architectures seem to learn rather different neural attention strategies and similarity of neural to human attention does not guarantee best performance. © 2020 Association for Computational Linguistics.",,Behavioral research; Computational linguistics; Long short-term memory; Natural language processing systems; Network architecture; Visual languages; Attention mechanisms; Attention model; Eye-tracking; Human attention; Human visual attention; Natural languages; Neural modelling; Neural-networks; Performance; Reading comprehension; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85173627129,Movies / Media
Kaczorowska M.; Wawrzyk M.; Plechawska-Wójcik M.,"Kaczorowska, Monika (57194211584); Wawrzyk, Martyna (57194205056); Plechawska-Wójcik, Małgorzata (41262115200)",57194211584; 57194205056; 41262115200,Binary Classification of Cognitive Workload Levels with Oculography Features,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12133 LNCS,,,243,254,11.0,2,10.1007/978-3-030-47679-3_21,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086137733&doi=10.1007%2f978-3-030-47679-3_21&partnerID=40&md5=69af90da14fb9b3ff80ee3daf897b2c5,"Assessment of cognitive workload level is important to understand human mental fatigue, especially in the case of performing intellectual tasks. The paper presents a case study on binary classification of cognitive workload levels. The dataset was received from two versions of the digit symbol substitution test (DSST), conducted on 26 healthy volunteers. A screen-based eye tracker was applied during an examination gathering oculographic data. DSST test results such as total number of matches and error ratio were also applied. Classification was performed with several different machine learning models. The best accuracy (97%) was achieved with linear SVM classifier. The final dataset for classification was based on nine features selected with the Fisher score feature selection method. © 2020, Springer Nature Switzerland AG.",Binary classification; Cognitive workload; Eye-tracking signal; SVM,Eye tracking; Industrial management; Information management; Information systems; Information use; Statistical tests; Support vector machines; Binary classification; Cognitive workloads; Eye trackers; Feature selection methods; Fisher score; Healthy volunteers; Machine learning models; Mental fatigue; Classification (of information),Conference paper,Final,,Scopus,2-s2.0-85086137733,Movies / Media
Wibmer A.; Wiedmann F.; Seeber I.; Maier R.,"Wibmer, Arnold (57213608958); Wiedmann, Frederik (57213597250); Seeber, Isabella (52564380900); Maier, Ronald (24332549900)",57213608958; 57213597250; 52564380900; 24332549900,Why less is more: An eye tracking study on idea presentation and attribute attendance in idea selection,2020,"27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019",,,,,,,4,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087106929&partnerID=40&md5=a364fc020d8392c71aa15cc6477d1945,"Innovation contests often result in several hundred ideas generated. Raters have to process this huge amount of ideas that consist of attributes like idea descriptions and various types of feedback information with limited cognitive resources in order to separate good from bad ideas. It is not clear to what extent raters attend the available information during idea selection. In order to improve our understanding of how to best support raters in idea selection, this study investigated the influence of variations of the presentation mode (two versus four ideas per screen) on the attention paid to information on idea attributes using eye-tracking. We investigated attributes that refer to idea descriptions, feedback about the content of ideas (creativity score, tags) and about the community comprising the ideators and the crowd (historical success of the ideator, likes). The results of our study show that with fewer alternatives per screen, feedback attributes received more attendance, while we found no significant difference for the processing of idea descriptions. These findings provide first insights into the information-processing behaviour of raters and can inform the design of selection platforms and theory building on the effects of feedback in idea selection. © 27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019. All rights reserved.",Attendance; Attributes; Crowdsourcing; Decision making; Eye tracking; Feedback; Idea selection; Innovation contest; Presentation mode,Information systems; Information use; Cognitive resources; Eye-tracking studies; Feed back information; Less is mores; Presentation modes; Theory building; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85087106929,Movies / Media
Qin X.; Li X.; Chen G.; Chen X.; Shi M.; Liu X.-K.; Li Z.-L.; Xin Z.-E.; Gao D.,"Qin, Xiaoling (56435148500); Li, Xue (57210214690); Chen, Gang (57211685729); Chen, Xu (36561030200); Shi, Mingyu (57210203658); Liu, Xue-Kui (55991894900); Li, Zai-Li (57195426951); Xin, Zai-E (57210931017); Gao, Dianshuai (14050121400)",56435148500; 57210214690; 57211685729; 36561030200; 57210203658; 55991894900; 57195426951; 57210931017; 14050121400,Clinical Features and Correlates of Poor Nighttime Sleepiness in Patients with Parkinson's Disease,2020,Parkinson's Disease,2020,,6378673,,,,4,10.1155/2020/6378673,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092451741&doi=10.1155%2f2020%2f6378673&partnerID=40&md5=da4ee5a7735009297b9142347b266cf5,"Objective. The present study investigated the clinical features and correlates of poor nighttime sleepiness (PNS) in patients with Parkinson's disease (PD). Methods. One hundred ten patients with PD (divided into PD-PNS group and PD-nPNS group) and forty-seven controls (nPD-PNS group) were enrolled in this study. Demographic information was collected. Patients were assessed according to the unified Parkinson's disease rating scale (UPDRS) and Hoehn-Yahr (H&Y) stage scale. Patients were also evaluated according to the Pittsburgh sleep quality index (PSQI), Epworth sleepiness scale (ESS), rapid eye movement sleep behavior disorder screening questionnaire (RBD-SQ), restless leg syndrome (RLS) diagnosis, Hamilton's depression scale (HAMD), and Hamilton's anxiety scale (HAMA). Results. The prevalence of PNS was 55.45% (61/110) in patients with PD. The PD-PNS group tended to have a longer duration of disease, higher UPDRS-I and UPDRS-III scores, a higher percentage of RLS patients, and higher HAMA and HAMD scores than those of the PD-nPNS group. The PD-PNS group tended to have a higher percentage of RBD and RLS patients and higher HAMA and HAMD scores than those of the nPD-PNS group. Analysis of the PSQI components and PSQI impact factors showed that the PD-PNS group had worse subjective sleep quality (χ2 =-2.267, P = 0.023), shorter sleep latency (χ2 =-2.262, P = 0.024), fewer sleep medications (χ2 =-4.170, P ≤ 0.001), worse daytime functioning (χ2 =-2.347, P = 0.019), and an even higher prevalence of increased nocturia (χ2 = 4.447, P = 0.035), nightmares (χ2 = 7.887, P = 0.005), and pain (χ2 = 9.604, P = 0.002) than those of the nPD-PNS group. Analysis also indicated that the PSQI global score positively correlated with BMI (r = 0.216, P < 0.05), H&Y stage (r = 0.223, P < 0.05), UPDRS-I (r = 0.501, P < 0.01), UPDRS-III (r = 0.425, P < 0.01), ESS (r =-0.296, P < 0.01), RBD (r = 0.227, P < 0.05), RLS (r = 0.254, P < 0.01), HAMA (r = 0.329, P < 0.01), and HAMD (r = 0.466, P < 0.01). In the final model, H&Y stage, RLS, UPDRS-III, and HAMD remained associated with the PQSI score (P ≤ 0.001, P ≤ 0.001, P = 0.049, P ≤ 0.001, respectively). Conclusions. Our data showed that PNS was common in patients with PD. H&Y stage, UPDRS-III, HAMD, and RLS were positively associated with PNS. Attention to the management of motor symptoms, RLS, and depression may be beneficial to nighttime sleep quality in patients with PD.  © 2020 Xiaoling Qin et al.",,hypnotic agent; aged; Article; body mass; case control study; clinical feature; comparative study; controlled study; correlation coefficient; cross-sectional study; disease association; disease duration; Epworth sleepiness scale; female; functional disease; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; Hoehn and Yahr scale; human; major clinical study; male; nightmare; nocturia; pain; Parkinson disease; Pittsburgh Sleep Quality Index; poor nighttime sleepiness; prevalence; rapid eye movement sleep behavior disorder screening questionnaire; restless legs syndrome; sleep disorder assessment; sleep latency; sleep quality; somnolence; Unified Parkinson Disease Rating Scale,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85092451741,Movies / Media
Zhu R.; Obregón M.; Kreiner H.; Shillcock R.,"Zhu, Ruomeng (57223998698); Obregón, Mateo (36973868900); Kreiner, Hamutal (6603070857); Shillcock, Richard (6603785348)",57223998698; 36973868900; 6603070857; 6603785348,Synchrony and asynchrony of the two eyes in binocular fixations in the reading of English and Chinese; the implications for ocular prevalence,2020,"Proceedings for the 42nd Annual Meeting of the Cognitive Science Society: Developing a Mind: Learning in Humans, Animals, and Machines, CogSci 2020",,,,673,679,6.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139473736&partnerID=40&md5=4a3c32301b0c2ddf310c9a4b8e3a1a8c,"We explore low-level, behavioural universals in reading, across English and Chinese. We investigated binocular coordination in terms of the small non-alignments between the two eyes' fixations in time. We define a typology of nine such asynchronies and report the different spatial distributions of these types across the screen of text. We interpret them in terms of their implications for ocular prevalence-the prioritizing of the input from one eye over the input from the other eye in higher perception/cognition, after binocular fusion. The results show striking similarities of binocular reading behaviours across the two very different orthographies. Asynchronies in which one eye begins the fixation earlier and/or ends it later occur most frequently in the hemifield corresponding to that eye. We propose that such small asynchronies in binocular fixations prioritize the higher processing of the input from that eye, after binocular fusion. © 2020 The Author(s)",binocular reading; Chinese; English; eye-tracking; ocular prevalence,Binoculars; Asynchrony; Binocular reading; Chinese; English; Eye fixations; Eye-tracking; Ocular prevalence; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85139473736,Movies / Media
Godwin K.E.; Kaur F.,"Godwin, Karrie E. (36727480200); Kaur, Freya (57918307900)",36727480200; 57918307900,Investigation of Attentional Decay: Implications for Instruction,2020,"Proceedings for the 42nd Annual Meeting of the Cognitive Science Society: Developing a Mind: Learning in Humans, Animals, and Machines, CogSci 2020",,,,2931,2936,5.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139458928&partnerID=40&md5=d455c7f6f1c3942d36b97387290f5ecb,"Given that attention is a limited capacity resource we are only able to selectively attend to a small subset of information at any one time. Endogenously regulating attention during an instructional activity is effortful and can be challenging for children as well as adults. Although improvements in attention regulation have been documented with age, less is known about the duration of time individuals are able to selectively sustain attention during instruction, due in part to methodological limitations. The present study leverages eye-tracking technology to provide an objective examination of attentional decay during a lecture. Adult participants (N=96) watched a geography screencast lecture while a mobile eye-tracker was utilized to measure changes in attention over the course of the lecture. Results indicate that attention declines over time and reductions in attention occur before Minute 15. Implications for instruction are discussed. © 2020 The Author(s). This work is licensed under a Creative Commons Attribution 4.0 International License (CC BY)",Attention; Attentional decay,Attention; Attentional decay; Capacity resources; Creative Commons; Eye trackers; Eye tracking technologies; Instructional activities; Limited capacity; One-time; Screencasts,Conference paper,Final,,Scopus,2-s2.0-85139458928,Movies / Media
Trout J.; Christiansen T.; Bulkley M.B.; Tanner J.J.; Sozda C.N.; Bowers D.; Kay D.B.,"Trout, Jonathan (57214089057); Christiansen, Taylor (57214077554); Bulkley, M. Brooks (57214099560); Tanner, Jared J. (35103736100); Sozda, Christopher N. (15830857400); Bowers, Dawn (7102676979); Kay, Daniel B. (35229445300)",57214089057; 57214077554; 57214099560; 35103736100; 15830857400; 7102676979; 35229445300,Cognitive impairments and self-reported sleep in early-stage Parkinson’s disease with versus without probable REM sleep behavior disorder,2020,Brain Sciences,10,1,9,,,,14,10.3390/brainsci10010009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078111547&doi=10.3390%2fbrainsci10010009&partnerID=40&md5=5e654d55d63fd91c5c75b9e1d9f3ddea,"Parkinson’s disease (PD) is associated with cognitive and sleep impairments. The presence of rapid eye movement (REM) sleep behavior disorder (RBD) symptoms may represent a worse disease prognosis for PD individuals. We investigated cognitive functioning and self-reported sleep in early-stage PD individuals with (n = 19) or without (n = 31) probable RBD. Probable RBD was defined as >5 on the REM Sleep Behavior Disorder Screening Questionnaire. Inhibition, visuospatial cognitive abilities, working memory, sustained visual attention, verbal fluency, and episodic memory were assessed. Sleep impairments were assessed using the Pittsburgh Sleep Quality Index, Insomnia Severity Index, Epworth Sleepiness Scale, and Patient-Reported Outcomes Measurement Information System questionnaires. Chi-squared, Mann-Whitney U, and independent sample t-tests were employed to assess group differences. Participants with PD and probable RBD performed significantly worse on word reading and switching verbal fluency tasks than PD participants without probable RBD (p < 0.05). No significant differences were found in mood, PD severity, or sleep measures between PD individuals with or without probable RBD. Cognitive tasks that involve verbal or switching components may be most impaired in PD individuals with probable RBD. Larger samples are needed to determine whether other cognitive domains and sleep features are significantly associated with RBD in PD. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.",Cognition; Executive control; Parkinson’s disease; REM sleep behavior disorder; Sleep quality; Verbal fluency,aged; Article; Beck Depression Inventory; Benton judgment of line orientation; brain depth stimulation; Center for Epidemiological Studies Depression Scale; Charlson Comorbidity Index; Clinical Dementia Rating; cognition; cognitive defect; cognitive function test; continuous performance test; Delis-Kaplan executive function system; disease severity; episodic memory; Epworth sleepiness scale; female; Hamilton Depression Rating Scale; human; Insomnia Severity Index; male; Mini Mental State Examination; Montreal cognitive assessment; parasomnia; Parkinson disease; patient-reported outcome; Pittsburgh Sleep Quality Index; questionnaire; REM sleep; REM Sleep Behavior Disorder Screening Questionnaire; screening; sleep quality; Unified Parkinson Disease Rating Scale; verbal behavior; visual attention; visual memory; Wechsler memory scale; working memory,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85078111547,Movies / Media
Peters R.E.; Zhi D.; Petersen M.; Yu C.,"Peters, Ryan E. (57203704165); Zhi, Dian (57219620801); Petersen, Matthew (57919515900); Yu, Chen (16032623800)",57203704165; 57219620801; 57919515900; 16032623800,Active Vision in the Perception of Actions: An Eye Tracking Study in Naturalistic Contexts,2020,"Proceedings for the 42nd Annual Meeting of the Cognitive Science Society: Developing a Mind: Learning in Humans, Animals, and Machines, CogSci 2020",,,,2158,2164,6.0,3,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137465876&partnerID=40&md5=644d77277578783161f3ee64f1aa3174,"Infants' ability to attend actively and selectively to naturalistic stimuli is critical to early learning. Most studies on infant visual attention use screen-based paradigms wherein infants view stimuli on computer screens. Little is known about how infants observe others' activities in everyday contexts. Using head-mounted eye-tracking, this study examined how infants distributed attention when observing their parents perform an everyday task - making peanut-butter and jelly sandwiches - in a home-like environment. Infant observers attended to parents' activities less than adult observers in the same situation. However, when infants were engaged in action observation, their gaze patterns were distributed on task-relevant objects similarly to adult observers, suggesting they actively obtained rich visual input in this free-viewing situation. Moreover, infant-parent dyads coordinated visual attention during the food preparation task in similar ways as observed in other everyday tasks, such as toy play, suggesting sensorimotor processes play a critical role in coordinated attention. © 2020 The Author(s)",action observation; coordinated attention; eye-tracking; parent-child interaction; selective attention,Behavioral research; Toys; Action observation; Active Vision; Coordinated attention; Early learning; Eye-tracking; Eye-tracking studies; Parent-child interactions; Perception of action; Selective attention; Visual Attention; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85137465876,Movies / Media
Chelban V.; Carecchio M.; Rea G.; Bowirrat A.; Kirmani S.; Magistrelli L.; Efthymiou S.; Schottlaender L.; Vandrovcova J.; Salpietro V.; Salsano E.; Pareyson D.; Chiapparini L.; Jan F.; Ibrahim S.; Khan F.; Qarnain Z.; Groppa S.; Bajaj N.; Balint B.; Bhatia K.P.; Lees A.; Morrison P.J.; Wood N.W.; Garavaglia B.; Houlden H.,"Chelban, Viorica (57188682705); Carecchio, Miryam (26423486500); Rea, Gillian (36574084500); Bowirrat, Abdalla (6508353575); Kirmani, Salman (22957978500); Magistrelli, Luca (55355753500); Efthymiou, Stephanie (55567766600); Schottlaender, Lucia (36911788600); Vandrovcova, Jana (57222262768); Salpietro, Vincenzo (6507973880); Salsano, Ettore (6506343388); Pareyson, Davide (7004613502); Chiapparini, Luisa (6602188521); Jan, Farida (57209880753); Ibrahim, Shahnaz (35589181300); Khan, Fatima (57219254119); Qarnain, Zul (57218559718); Groppa, Stanislav (37080898900); Bajaj, Nin (6603851732); Balint, Bettina (25642482400); Bhatia, Kailash P. (25958636400); Lees, Andrew (57208252964); Morrison, Patrick J. (57203678422); Wood, Nicholas W. (7202960784); Garavaglia, Barbara (7004612048); Houlden, Henry (7003363686)",57188682705; 26423486500; 36574084500; 6508353575; 22957978500; 55355753500; 55567766600; 36911788600; 57222262768; 6507973880; 6506343388; 7004613502; 6602188521; 57209880753; 35589181300; 57219254119; 57218559718; 37080898900; 6603851732; 25642482400; 25958636400; 57208252964; 57203678422; 7202960784; 7004612048; 7003363686,MYORG-related disease is associated with central pontine calcifications and atypical parkinsonism,2020,Neurology: Genetics,6,2,e399,,,,23,10.1212/NXG.0000000000000399,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085357367&doi=10.1212%2fNXG.0000000000000399&partnerID=40&md5=a89e8fda06fd53346bcdb5a85670ab59,"ObjectiveTo identify the phenotypic, neuroimaging, and genotype-phenotype expression of MYORG mutations.MethodsUsing next-generation sequencing, we screened 86 patients with primary familial brain calcification (PFBC) from 60 families with autosomal recessive or absent family history that were negative for mutations in SLC20A2, PDGFRB, PDGBB, and XPR1. In-depth phenotyping and neuroimaging investigations were performed in all cases reported here.ResultsWe identified 12 distinct deleterious MYORG variants in 7 of the 60 families with PFBC. Overall, biallelic MYORG mutations accounted for 11.6% of PFBC families in our cohort. A heterogeneous phenotypic expression was identified within and between families with a median age at onset of 56.4 years, a variable combination of parkinsonism, cerebellar signs, and cognitive decline. Psychiatric disturbances were not a prominent feature. Cognitive assessment showed impaired cognitive function in 62.5% of cases. Parkinsonism associated with vertical nuclear gaze palsy was the initial clinical presentation in 1/3 of cases and was associated with central pontine calcifications. Cerebral cortical atrophy was present in 37% of cases.ConclusionsThis large, multicentric study shows that biallelic MYORG mutations represent a significant proportion of autosomal recessive PFBC. We recommend screening MYORG mutations in all patients with primary brain calcifications and autosomal recessive or negative family history, especially when presenting clinically as atypical parkinsonism and with pontine calcification on brain CT. © American Academy of Neurology.",,amino acid; complementary DNA; dopamine transporter; glycosidase; levodopa; myorg protein; platelet derived growth factor BB; platelet derived growth factor beta receptor; protein; unclassified drug; adult; aged; amino terminal sequence; Article; ataxia; ataxic gait; bradykinesia; brain calcification; bulbar paralysis; case report; cellular distribution; cerebellum atrophy; cerebellum disease; clinical article; clinical examination; clinical feature; cognition assessment; cognitive defect; cranial nerve; disability; disease duration; DNA extraction; dysarthria; dysphagia; dystonia; enzyme activity; executive function; extrapyramidal symptom; eye movement; family history; female; frameshift mutation; frontal cortex; gaze paralysis; gene frequency; gene insertion; gene mutation; genetic screening; genetic variability; genotype phenotype correlation; headache; high throughput sequencing; hippocampus; human; male; medical record review; mental disease; middle aged; Mini Mental State Examination; missense mutation; Montreal cognitive assessment; motor performance; neuroimaging; neuropsychiatry; nuclear magnetic resonance imaging; occipital cortex; onset age; paraneoplastic cerebellar degeneration; parkinsonism; phenotype; progressive supranuclear palsy; pyramidal sign; substantia nigra; temporal cortex; urine incontinence; verbal reasoning; very elderly; white matter; whole exome sequencing,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85085357367,Movies / Media
Pettit J.W.; Silverman W.K.,"Pettit, Jeremy W. (7005407988); Silverman, Wendy K. (7101997078)",7005407988; 7101997078,Editorial: Attention to Threat in Child Anxiety: Gazing Into the Future While Keeping Sight of the Past,2020,Journal of the American Academy of Child and Adolescent Psychiatry,59,1,,33,35,2.0,3,10.1016/j.jaac.2019.09.019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074519274&doi=10.1016%2fj.jaac.2019.09.019&partnerID=40&md5=ad5a21dce19dc79bc54393c95acdf067,"Since the 1960s, cognitive theories of anxiety have prioritized attention to threat in the etiology and maintenance of anxiety and its disorders.1 The development of computer-administered tasks in the 1980s, displaying threatening stimuli on the screen and relying on participants’ clicking of keys or mouse buttons to measure reaction time, permitted experimental testing of the hypothesis that individuals with anxiety disorders show biased attention to threat.2 Considerable data have since accumulated supporting this hypothesis, including in children and adolescents.1,3 However, reaction times measured by mouse button clicks are indirect and imprecise measurements of attention.4 With the availability of eye-tracking in the last decade, researchers have been able to directly and precisely measure attention. Lisk et al.,5 in this issue of the Journal, provide a systematic review and meta-analysis of studies that used eye-tracking to measure attention to threat in children and adolescents. © 2019 American Academy of Child and Adolescent Psychiatry",,Adolescent; Animals; Anxiety; Anxiety Disorders; Attention; Attentional Bias; Child; Humans; Mice; Reaction Time; anxiety disorder; attentional bias; child; child psychiatry; chronic patient; cognitive behavioral therapy; dwell time; Editorial; electroencephalography; eye tracking; human; neuroimaging; priority journal; reaction time; threat; adolescent; animal; anxiety; anxiety disorder; attention; attentional bias; mouse,Editorial,Final,,Scopus,2-s2.0-85074519274,Movies / Media
Soleymani A.; Ivanov Y.; Mathot S.; de Jong P.J.,"Soleymani, Ali (57210960536); Ivanov, Yavor (59582998000); Mathot, Sebastiaan (35316126800); de Jong, Peter J. (7402785158)",57210960536; 59582998000; 35316126800; 7402785158,Free-viewing multi-stimulus eye tracking task to index attention bias for alcohol versus soda cues: Satisfactory reliability and criterion validity,2020,Addictive Behaviors,100,,106117,,,,32,10.1016/j.addbeh.2019.106117,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072022620&doi=10.1016%2fj.addbeh.2019.106117&partnerID=40&md5=a86448541674493506f55cfe08773538,"Cognitive -motivational models point to attention bias (AB) as an important factor in the persistence of problematic drinking behavior. Unfortunately, the measures that have been used to examine AB in addiction typically showed poor psychometric properties. To bring research on AB a critical step further it would be crucial to develop tasks with acceptable reliability and construct validity. Recently, Lazarov and colleagues (2016) developed a multi-stimulus free-viewing task (participants were free to look at any part of the screen and there was no secondary task involved) that showed excellent psychometric properties in the context of social anxiety as well as depression. We, therefore, adapted this task and examined its psychometric quality within the context of alcohol use. Participants with varying levels of alcohol use (N = 100) were presented with 54 matrices each containing 8 alcoholic and 8 non-alcoholic drinks. Each matrix was presented for 6 s. First fixation (100 ms) location and latency and total dwell time were assessed for alcohol and soda pictures. Assessment of AB, craving, and alcohol use (problems) was repeated after 3–8 days. Specifically, the dwell-time based AB-measure showed excellent internal reliability and considerable stability. Supporting the validity of the current AB-measures, it was found that participants with higher scores on craving and alcohol problems (i) dwelt longer on alcohol stimuli, and (ii) more often showed a first fixation on alcohol, whereas (iii) stronger craving was associated with shorter latency of first alcohol fixations. The AB-measure showed promising psychometric properties. Thus, this free-viewing eye-tracking task seems a welcome new tool for being used in future research on AB in addiction. © 2019 Elsevier Ltd",Alcohol use; Assessment; Attention bias; Craving; Criterion validity; Reliability,Adolescent; Adult; Alcohol Drinking; Alcohol-Related Disorders; Attentional Bias; Carbonated Beverages; Craving; Cues; Eye-Tracking Technology; Female; Humans; Male; Psychometrics; Reproducibility of Results; Young Adult; addiction; adult; alcoholic beverage; Article; attentional bias; construct validity; controlled study; craving; criterion related validity; depression; eye fixation; eye tracking; female; human; human experiment; internal consistency; internal reliability; latent period; male; normal human; psychometry; reliability; satisfactory reliability; social phobia; soft drink; task performance; test retest reliability; visual stimulation; adolescent; alcoholism; association; carbonated beverage; craving; drinking behavior; psychology; reproducibility; young adult,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85072022620,Movies / Media
Shaker H.; Sénécal S.; Taboubi S.; Grégoire Y.,"Shaker, Hamid (57466723200); Sénécal, Sylvain (57200814456); Taboubi, Sihem (8872402400); Grégoire, Yany (12804327600)",57466723200; 57200814456; 8872402400; 12804327600,Price Priming Effects in Online Display Ads: An Abstract,2020,Developments in Marketing Science: Proceedings of the Academy of Marketing Science,,,,523,,,0,10.1007/978-3-030-39165-2_215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125255394&doi=10.1007%2f978-3-030-39165-2_215&partnerID=40&md5=b452becb1d9237682b5dc0b8455a4f90,"Although some studies (e.g., Drèze and Hussherr 2003; Yoo 2008) reveal that online ads can affect consumers even when they are trying to avoid them, there are no guidelines about communicating price information in online display ads as they are seen by consumers in a real online environment. Along with our interest in studying the effects of price anchor in online ads, we also study the effects of ad repetition. We focus on this attribute because ad repetition is one of the common strategies used to increase the effectiveness of the online advertisement (Malaviya et al. 1999; Yaveroglu and Donthu 2008). Again, to the best of our knowledge, the effects of ad repetition on price anchoring have not been studied in the context of incidental ad exposure in online environments. Results of an eye-tracking study show that the magnitude of price stimuli can affect consumers’ attention toward online display ads that consumers are exposed to incidentally. That is, consumers’ fixation duration (pupil size) is longer (larger) for ads that contain high-value price stimuli than ads that contain low-value price stimuli. Moreover, when ads are displayed repeatedly on the same web page, the fixation duration is increased as a function of the order of placement only when ads contain high-value price stimuli. For ads containing low-value price stimuli, the gaze behavior did not change. We suggest that the observed different gaze behavior is due to a different price-processing mechanism for incidental price stimuli: When ads contain high-magnitude price stimuli, consumers process them through the elaborative selective accessibility mechanism (Strack and Mussweiler 1997); but when ads contain low-magnitude price stimuli, consumers process them through the more direct priming mechanism of anchoring and adjustment (Tversky and Kahneman 1974). © 2020, The Academy of Marketing Science.",Eye-tracking; Non-conscious price processing; Online display ads; Price anchoring,,Book chapter,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85125255394,Movies / Media
Boy B.; Bucher H.-J.; Christ K.,"Boy, Bettina (57205472955); Bucher, Hans-Jürgen (25026735600); Christ, Katharina (57189260019)",57205472955; 25026735600; 57189260019,Audiovisual Science Communication on TV and YouTube. How Recipients Understand and Evaluate Science Videos,2020,Frontiers in Communication,5,,608620,,,,56,10.3389/fcomm.2020.608620,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105384073&doi=10.3389%2ffcomm.2020.608620&partnerID=40&md5=7280ee6ba23d57b81e3f27d22f8914bc,"With the emergence of the Internet, social media and video platforms are gaining considerable influence on the traditional media landscape in general and on science communication in particular. This has changed the role of science journalists as gatekeepers because many platforms are based on a participatory culture, in which passive consumers can become active participants. In addition to scientists, non-scientific actors also act as experts and participate in the communication process between science and the public. In contrast to the relevance of YouTube for science communication there is a lack of research focusing on the questions of how internet users receive YouTube videos to acquire information about science, how successful audiovisual media function in knowledge transfer, and what effects it has on the epistemic regime of a society. Therefore, this study combines a discourse analysis with the aim to create a typology of YouTube videos - the independent variables - and an audience study for investigating knowledge transfer - the dependent variables. In the first step, this article presents the results of a systematic analysis and categorization of 400 German science videos, from which four types of audiovisual science communication on YouTube were derived: presentation films, expert films, animation films, and narrative explanatory films. In order to clarify how powerful these new forms of science communication are in terms of knowledge transfer, attitudes, and trust toward the presentation of science, a discourse analysis of the videos is combined with a multi-level reception study and an online survey. The reception study included eye-tracking to investigate the allocation of attention and two different methods of knowledge tests (recognition and recall) of which the multiple-choice test was also applied in the online survey. The results show that the type of video has an important impact on knowledge transfer and para-social effects. One of the central results of the audience study is that the videos' gaze guidance, the recipients' allocation of attention, and the results of knowledge testing are closely intertwined. The correlation of data from eye-tracking and the two knowledge tests prove in principle that the more homogeneous the gaze patterns of the recipients are, the better they score in the multiple-choice test as well as in the concept mapping test.  © Boy, Bucher and Christ.",knowledge transfer; multimodality; reception study; science communication; YouTube,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85105384073,Movies / Media
Drew T.; Guthrie J.; Reback I.,"Drew, Trafton (15043986300); Guthrie, James (57216824121); Reback, Isabel (57216821409)",15043986300; 57216824121; 57216821409,Worse in real life: An eye-tracking examination of the cost of CAD at low prevalence.,2020,Journal of Experimental Psychology: Applied,26,4,,659,670,11.0,8,10.1037/xap0000277,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084818583&doi=10.1037%2fxap0000277&partnerID=40&md5=5221bf421e6c184654654f700fc04350,"Computer-aided detection (CAD) is applied during screening mammography for millions of women each year. Despite its popularity, several large studies have observed no benefit in breast cancer detection for practices that use CAD. This lack of benefit may be driven by how CAD information is conveyed to the radiologist. In the current study, we examined this possibility in an artificial task modeled after screening mammography. Prior work at high (50%) target prevalence suggested that CAD marks might disrupt visual attention: Targets that are missed by the CAD system are more likely to be missed by the user. However, targets are much less common in screening mammography. Moreover, the prior work on this topic has focused on simple binary CAD systems that place marks on likely locations, but some modern CAD systems employ interactive CAD (iCAD) systems that may mitigate the previously observed costs. Here, we examined the effects of target prevalence and CAD system. We found that the costs of binary CAD were exacerbated at low prevalence. Meanwhile, iCAD did not lead to a cost on unmarked targets, which suggests that this sort of CAD implementation may be superior to more traditional binary CAD implementations when targets occur infrequently. (PsycInfo Database Record (c) 2020 APA, all rights reserved)Public Significance Statement—The current research uses eye-tracking to understand how computer-aided detection (CAD) marks, which are an increasingly common tool used by clinicians to aid in cancer detection, change how naïve observers search for both common and uncommon targets. Our research suggest that detrimental costs associated with CAD are larger when targets are less common. Furthermore, we find that some of the negative effects associated with CAD can be eliminated by changing how the CAD information is conveyed to the user. (PsycInfo Database Record (c) 2020 APA, all rights reserved) © 2020 American Psychological Association",CAD; computer-aided detection; eye-tracking; mammography; medical image perception; screening tests; target prevalence; visual search,Breast Neoplasms; Computers; Early Detection of Cancer; Eye-Tracking Technology; Female; Humans; Mammography; Prevalence; breast tumor; computer; early cancer diagnosis; female; human; mammography; prevalence,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85084818583,Movies / Media
Pi Z.; Xu K.; Liu C.; Yang J.,"Pi, Zhongling (56704731200); Xu, Ke (57204140926); Liu, Caixia (57211170291); Yang, Jiumin (35797803600)",56704731200; 57204140926; 57211170291; 35797803600,"Instructor presence in video lectures: Eye gaze matters, but not body orientation",2020,Computers and Education,144,,103713,,,,75,10.1016/j.compedu.2019.103713,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072870288&doi=10.1016%2fj.compedu.2019.103713&partnerID=40&md5=23f66f64081ce29f63805331683050a7,"The instructor's on-screen presence, rather than just voice, has rapidly become a popular feature in video lectures. Eye gaze and body orientation are core indicators of an instructor's attentional focus in classroom settings, but it is not well known how these factors influence learners' attention allocation and learning performance in video lectures with the on-screen presence of instructors presenting slides. This study tested the effects of the instructor's eye gaze and body orientation on attention and learning from a video lecture in a sample of 174 undergraduates. Specifically, the instructor's presence was manipulated in terms of eye gaze (direct, guided, or averted) and body orientation (frontal or lateral). Eye tracking data revealed that regardless of an instructor's body orientation, learners who viewed the video lectures with the instructor's guided gaze paid greater attention to the slides, and those who viewed the video lectures with the instructor's direct gaze paid greater attention to her face; paper-and-pencil assessments showed that learners who viewed the video lectures with guided gaze showed better retention and transfer. These results held regardless of body orientation, suggesting that an instructor's eye gaze has a stronger influence than body orientation on attention and learning from video lectures. The findings suggest that an instructor should not look directly at the camera continuously throughout the lecture, and should instead use guided gaze to draw learners' attention to the learning materials. © 2019",Distance education and; Multimedia/hypermedia systems; Pedagogical issues; Teaching/learning strategies; telelearning,Distance education; Classroom settings; Learning from videos; Learning materials; Learning performance; Multimedia/hypermedia systems; Pedagogical issues; Teaching/learning strategy; Telelearning; Eye tracking,Article,Final,,Scopus,2-s2.0-85072870288,Movies / Media
André L.; Coutellier R.; Maïs C.; Bonnaud A.,"André, L. (57216617480); Coutellier, R. (57208386966); Maïs, C. (57202875464); Bonnaud, A. (57226111064)",57216617480; 57208386966; 57202875464; 57226111064,New technologies of human/machine interaction: A prospective study in the military naval context,2020,Proceedings of the International Ship Control Systems Symposium,1,,,,,10.0,0,10.24868/issn.2631-8741.2020.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110434056&doi=10.24868%2fissn.2631-8741.2020.003&partnerID=40&md5=895498656401e0b36f2d6382c060e6a5,"Today, military defense vessels are equipped with many systems that allow sailors to interact with each other or with their digital equipments. These systems are relatively efficient and allow mariners to perform their tasks efficiently and securely. It is important to identify new technologies that sailors can interact with, in the future. An evaluation must then be conducted to ensure compliance with their usefulness, usability and acceptability. This paper discusses how to study, upstream, various innovative technologies in order to identify the positive and negative points and to conduct a human factors evaluation following a user-centric approach, replicating operational conditions. The paper focuses then on three widely available technologies. The first is the eye-control, which allows an operator to interact with a digital system thanks to the movements and fixation of his eyes. This system allows validating information being displayed on a screen or to navigate in an interface when the operator has his hands busy with another task. Different interactions are available today (scrolling, clicking, and displaying a keyboard to write using the eyes …). However, various limitations were highlighted during the first human factors evaluations, for example visual fatigue or calibration of the eye-tracking system, which is also sensitive to the movements of the operator and those of the platform on which it is based. The second and the third technologies presented are related because they both concern communications. In very noisy environments or when there are different sound sources, it is sometimes difficult for operators to be attentive to all auditory information or to be heard effectively. Bone conduction systems (for listening and for expression) allow the operator to be attentive to different sound sources while speaking audibly. As for the bone conduction listening system, the sound vibrations conducted by the bones reproduce a listening equivalent to classical hearing. Concerning the throat microphone, the treatment of the waves captured at the throat makes it possible to transmit a clear sound, without any environmental interference, which makes it possible to guarantee the good intelligibility of the speech. This paper concludes on how these studies from the human factor service of the research and development department of Naval Group (France) are related to advance research in these areas as well as trials for future equipment that can be developed on board for naval defense vessels. © Institute of Marine Engineering Science and Technology. All rights reserved.",Bone conduction; Eye-control; Human factors; New technologies; Throat microphone,,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85110434056,Movies / Media
Zhu J.; Dawson K.; Ritzhaupt A.D.; Antonenko P.,"Zhu, Jiawen (57210338402); Dawson, Kara (16238356400); Ritzhaupt, Albert D. (23978497700); Antonenko, Pavlo (23090326200)",57210338402; 16238356400; 23978497700; 23090326200,"Investigating How Multimedia and Modality Design Principles Influence Student Learning Performance, Satisfaction, Mental Effort, and Visual Attention",2020,Journal of Educational Multimedia and Hypermedia,29,3,,265,284,19.0,4,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103214180&partnerID=40&md5=60263b21d8553d729188bfde468132e1,"This study investigated the effects of multimedia and modality design principles using a learning intervention about Australia with a sample of college students and employing measures of learning outcomes, visual attention, satisfaction, and mental effort. Seventy-five college students were systematically assigned to one of four conditions: a) text with pictures, b) text without pictures, c) narration with pictures, or d) narration without pictures. No significant differences were found among the four groups in learning performance, satisfaction, or self-reported mental effort, and participants rarely focused their visual attention on the representational pictures provided in the intervention. Neither the multimedia nor the modality principles held true in this study. However, participants in narration environments focused significantly more visual attention on the “Next” button, a navigational aid included on all slides. This study contributes to the research on visual attention and navigational aids in multimedia learning, and it suggests such features may cause distractions, particularly when spoken text is provided without on-screen text. The paper also offers implications for the design of multimedia learning resources so as to improve learning for all students. © 2020, Association for the Advancement of Computing in Education. All rights reserved.",Eye-tracking; modality principle; Multimedia learning; multimedia principle,,Article,Final,,Scopus,2-s2.0-85103214180,Movies / Media
Jang J.-H.; Sung J.E.,"Jang, Ji-Hye (57210289650); Sung, Jee Eun (21735141600)",57210289650; 21735141600,Age-related differences in sentence processing of who-questions: An eye-tracking study,2020,Communication Sciences and Disorders,25,25,,382,398,16.0,2,10.12963/CSD.20683,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089286555&doi=10.12963%2fCSD.20683&partnerID=40&md5=d4f981a6d76be754aba28e532736891c,"Objectives: The purpose of this study was to compare the performance and eye tracking data of the young and the old in sentence processing tasks using the 'who+nominative' and 'who+accusative'. Methods: Participants in this study were 21 normal young adults and 17 normal elderly adults. All subjects passed the screening test for cognition and language, and there was no difference in education between the groups. Pictures and stories were presented at the same time, then subjects were asked to choose the corresponding answer on the screen. Results: First, the accuracy of the elderly group was significantly lower than that of young group. The elderly group performed much lower in the type 'who +accusative'. Second, there was no significant difference between the groups in fixation duration for the target stimulus, but all groups had lower fixation duration in the type of 'who+accusative'. Also, the heat map shows that fixation of the elderly was more dispersed than the young group. Finally, the fixation proportion of the target stimulus according to the time interval showed that the fixation proportion of the elderly decreased in the last section of the sentence. Conclusion: The elderly group showed lower accuracy and stronger gaze dispersion in 'who+accusative' type than the young group. Furthermore, the lower rate of fixation proportion for the elderly in the last section of the sentence is due to the lower efficiency of the sentence integration process compared to the young. © 2020 Korean Academy of Speech-Language Pathology and Audiology.",Aging; Case marker; Eye-tracking study; Sentence processing; Who-questions,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85089286555,Movies / Media
Zhang J.; Sun G.; Zheng K.; Mazhar S.,"Zhang, Junjie (55755117900); Sun, Guangmin (8431278000); Zheng, Kun (57072537200); Mazhar, Sarah (57217279378)",55755117900; 8431278000; 57072537200; 57217279378,Pupil Detection Based on Oblique Projection Using a Binocular Camera,2020,IEEE Access,8,,9108229,105754,105765,11.0,6,10.1109/ACCESS.2020.3000063,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086987053&doi=10.1109%2fACCESS.2020.3000063&partnerID=40&md5=06505af001017051e1ff6ecad35560e8,"The real visual attention areas of students during the learning process are vital data. They represent the students' visual concentration and provide strong support for the analysis of learning effects. It is necessary to use professional equipment to collect the visual attention areas of students on a screen but this equipment is expensive, so it cannot be solely depended upon. A binocular camera can directly obtain the depth information under static conditions; thus, detected pupil and iris sizes do not change as the user-to-screen distance changes. Robust pupil detection is an important prerequisite for gaze detection in a real-world setting. Hence, an accurate algorithm to calculate the position of pupils and the size of irises under natural light is proposed in this paper. It is based on the positive and negative oblique projection of relative linear density. The MPIIGaze dataset was used to test the algorithm, and the experimental results show that the algorithm is resistant to changes in illumination and the presence of glasses. Moreover, compared with a system based on a monocular camera, the error in the distance between label points and gaze location is decreased by 5 pixels and dispersion is decreased by 3 pixels. Finally, the line of sight is concentrated and the dispersion is low. With the 'user-screen' distance between 60cm and 80cm, the accuracy can reach up to 1.5° to 2.2°. © 2013 IEEE.",Binocular camera; eye vector; negative oblique projection; positive oblique projection; relative linear density,Behavioral research; Binoculars; Dispersions; Pixels; Statistical tests; Students; Binocular camera; Depth information; Learning process; Monocular cameras; Oblique projections; Professional equipment; Real world setting; Static conditions; Cameras,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85086987053,Movies / Media
Hasegawa S.; Hirako A.; Zheng X.; Karimah S.N.; Ota K.; Unoki T.,"Hasegawa, Shinobu (7401474763); Hirako, Atsushi (57218363667); Zheng, Xianwen (57218365161); Karimah, Shofiyati Nur (57190859275); Ota, Koichi (14021969000); Unoki, Teruhiko (57203460019)",7401474763; 57218363667; 57218365161; 57190859275; 14021969000; 57203460019,Learner’s mental state estimation with pc built-in camera,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12206 LNCS,,,165,175,10.0,4,10.1007/978-3-030-50506-6_12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088916166&doi=10.1007%2f978-3-030-50506-6_12&partnerID=40&md5=8e23b164582ce69b5e34a0e4704d7032,"The purpose of this research is to estimate learners’ mental states such as difficulty, interest, fatigue, and concentration that change with the time series between learners and their learning tasks. Nowadays, we have many opportunities to learn specific topics in the individual learning process, such as active learning and self-directed learning. In such situations, it is challenging to grasp learners’ progress and engagement in their learning process. Several studies have estimated learners’ engagement from facial images/videos in the learning process. However, there is no extensive benchmark dataset except for the video watching process. Therefore, we gathered learners’ videos with facial expression and retrospective self-report from 19 participants through the CAB test process using a PC built-in camera. In this research, we applied an existing face image recognition library Face++ to extract the data such as estimated emotion, eye gaze, face orientation, face position (percentage on the screen) by each frame of the videos. Then, we built a couple of machine learning models, including deep learning methods, to estimate their mental states from the facial expressions and compared them with the average accuracy of prediction. The results demonstrated the potential of the proposed method to the estimation and provided the improvement plan from the accuracy point of view. © Springer Nature Switzerland AG 2020.",Machine learning; Mental state estimation; PC built-in camera,Built-in self test; Cameras; Deep learning; Face recognition; Human computer interaction; Image recognition; Benchmark datasets; Face image recognition; Facial Expressions; Improvement plans; Individual learning process; Learning methods; Machine learning models; Self-directed learning; Learning systems,Conference paper,Final,,Scopus,2-s2.0-85088916166,Movies / Media
Kirsh I.,"Kirsh, Ilan (55268400400)",55268400400,Directions and Speeds of Mouse Movements on a Website and Reading Patterns: A Web Usage Mining Case Study,2020,ACM International Conference Proceeding Series,Part F162565,,,129,138,9.0,12,10.1145/3405962.3405982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091495707&doi=10.1145%2f3405962.3405982&partnerID=40&md5=4a0af77e38822a435daf10e8dc45c6b6,"Mouse activity is known as an important indicator of user attention and interest on a web page. Many modern commercial web analytics services record and report mouse activity of users on websites. The position of the mouse cursor on the screen is the main source of information, as studies show a correlation between the cursor position during mouse activity and the user's eye gaze. This study focuses on mouse movement directions and speeds, and what they indicate, rather than on the mouse cursor position. Statistical analysis of mouse movements on a technical-educational website, which was selected for this study, sheds light on several interesting patterns. For example, most mouse movements in the examined usage data are either approximately horizontal or approximately vertical, horizontal mouse movements are more frequent than vertical mouse movements, and horizontal movements to the left and to the right are not equivalent in terms of moving time and speed. As this study shows, these statistical findings are related to the reading patterns and behaviors of web users. Associating mouse movements with text reading may potentially highlight content that most users tend to skip, and therefore, might not interest the website audience, and content that many readers read more than once or slowly, meaning it is possibly unclear. This could be useful in locating issues in textual content, in websites in general, and especially in online learning and educational technology applications.  © 2020 ACM.",Education Technology; Human-Computer Interaction; Mouse Movement; Online Learning; Reading Behaviors; Text Reading Patterns; Web Analytics; Web Pages; Web Usage Mining; Websites,Data mining; Intelligent systems; Real time systems; Semantics; Websites; Educational websites; Horizontal movements; Mouse movements; Reading patterns; Statistical finding; Technology application; Textual content; Web usage mining; Mammals,Conference paper,Final,,Scopus,2-s2.0-85091495707,Movies / Media
Botch T.L.; Garcia B.D.; Choi Y.B.; Feffer N.; Robertson C.E.,"Botch, Thomas L. (57217186010); Garcia, Brenda D. (57351596100); Choi, Yeo Bi (57204476962); Feffer, Nicholas (58062795200); Robertson, Caroline E. (57196949630)",57217186010; 57351596100; 57204476962; 58062795200; 57196949630,Active visual search in naturalistic environments reflects individual differences in classic visual search performance,2023,Scientific Reports,13,1,631,,,,8,10.1038/s41598-023-27896-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146194993&doi=10.1038%2fs41598-023-27896-7&partnerID=40&md5=069deab67bda1c6759d68e75aef459a2,"Visual search is a ubiquitous activity in real-world environments. Yet, traditionally, visual search is investigated in tightly controlled paradigms, where head-restricted participants locate a minimalistic target in a cluttered array that is presented on a computer screen. Do traditional visual search tasks predict performance in naturalistic settings, where participants actively explore complex, real-world scenes? Here, we leverage advances in virtual reality technology to test the degree to which classic and naturalistic search are limited by a common factor, set size, and the degree to which individual differences in classic search behavior predict naturalistic search behavior in a large sample of individuals (N = 75). In a naturalistic search task, participants looked for an object within their environment via a combination of head-turns and eye-movements using a head-mounted display. Then, in a classic search task, participants searched for a target within a simple array of colored letters using only eye-movements. In each task, we found that participants’ search performance was impacted by increases in set size—the number of items in the visual display. Critically, we observed that participants’ efficiency in classic search tasks—the degree to which set size slowed performance—indeed predicted efficiency in real-world scenes. These results demonstrate that classic, computer-based visual search tasks are excellent models of active, real-world search behavior. © 2023, The Author(s).",,Attention; Environment; Eye Movements; Humans; Individuality; Virtual Reality; Visual Perception; attention; environment; eye movement; human; individuality; virtual reality; vision,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85146194993,Movies / Media
Yang Y.; Mo L.; Lio G.; Huang Y.; Perret T.; Sirigu A.; Duhamel J.-R.,"Yang, Yidong (57216623635); Mo, Lei (55595990200); Lio, Guillaume (55521513300); Huang, Yulong (59097870400); Perret, Thomas (58097734500); Sirigu, Angela (7005604878); Duhamel, Jean-René (7102076700)",57216623635; 55595990200; 55521513300; 59097870400; 58097734500; 7005604878; 7102076700,"Assessing the allocation of attention during visual search using digit-tracking, a calibration-free alternative to eye tracking",2023,Scientific Reports,13,1,2376,,,,4,10.1038/s41598-023-29133-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147783721&doi=10.1038%2fs41598-023-29133-7&partnerID=40&md5=76348d06176d36713c6c3cc74b97070c,"Digit-tracking, a simple, calibration-free technique, has proven to be a good alternative to eye tracking in vision science. Participants view stimuli superimposed by Gaussian blur on a touchscreen interface and slide a finger across the display to locally sharpen an area the size of the foveal region just at the finger's position. Finger movements are recorded as an indicator of eye movements and attentional focus. Because of its simplicity and portability, this system has many potential applications in basic and applied research. Here we used digit-tracking to investigate visual search and replicated several known effects observed using different types of search arrays. Exploration patterns measured with digit-tracking during visual search of natural scenes were comparable to those previously reported for eye-tracking and constrained by similar saliency. Therefore, our results provide further evidence for the validity and relevance of digit-tracking for basic and applied research on vision and attention. © 2023, The Author(s).",,Attention; Eye Movements; Eye-Tracking Technology; Fingers; Humans; Upper Extremity; applied research; article; attention; calibration; eye tracking; human; validity; vision; eye movement; finger; upper limb,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147783721,Movies / Media
Yu C.; Ishibashi K.; Iwanaga K.,"Yu, Chuntai (58292542300); Ishibashi, Keita (8931922700); Iwanaga, Koichi (7006685775)",58292542300; 8931922700; 7006685775,Effects of fearful face presentation time and observer’s eye movement on the gaze cue effect,2023,Journal of Physiological Anthropology,42,1,8,,,,0,10.1186/s40101-023-00325-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160449143&doi=10.1186%2fs40101-023-00325-4&partnerID=40&md5=92cea9fe4ab383a0288c020f310b5707,"Background: There are many conflicting findings on the gaze cueing effect (GCE) of emotional facial expressions. This study aimed to investigate whether an averted gaze, accompanied by a fearful expression of different durations, could enhance attentional orientation, as measured by a participant’s eye movements. Methods: Twelve participants (3 females) completed the gaze cue task, reacting to a target location after observing changes in the gaze and expression of a face illustrated on a computer screen. Meanwhile, participants’ eye movements were monitored by electrooculography. The GCE was calculated by reaction time as an indicator of attention shift. Results: The analysis of the overall data did not find a significant effect of fearful facial expressions on the GCE. However, analysis of trial data that excluded a participant’s eye movement data showed that brief (0, 100 ms) presentation of the fearful facial expression enhanced the GCE compared to that during a neutral facial expression, although when the presentation time of the fearful expression was increased to 200 or 400 ms, the GCE of the fearful expression was at the same level as when model showed a neutral expression. Conclusions: The results suggest that the attention-enhancing effect of gaze cues induced by rapidly presented fearful expressions occurs only when the effect of eye movement trials is excluded. This effect may be mediated by reflexively neural circuits in the amygdala that process threatening stimuli. However, as the expression duration increased, the fearful expression’s attention-enhancing effect decreased. We suggest that future studies on the emotion modulation of GCE should consider the negative effects of participants’ saccades and blinks on the experimental results. © 2023, The Author(s).",Amygdala; Electrooculography; Fear facial expression; Gaze cueing effect; Spatial attention,Attention; Cues; Emotions; Eye Movements; Facial Expression; Fear; Female; Humans; association; attention; emotion; eye movement; facial expression; fear; female; human,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85160449143,Movies / Media
Jenner L.A.; Farran E.K.; Welham A.; Jones C.; Moss J.,"Jenner, L.A. (57850959400); Farran, E.K. (6602319057); Welham, A. (54396526400); Jones, C. (55273651000); Moss, J. (25652154200)",57850959400; 6602319057; 54396526400; 55273651000; 25652154200,The use of eye-tracking technology as a tool to evaluate social cognition in people with an intellectual disability: a systematic review and meta-analysis,2023,Journal of neurodevelopmental disorders,15,1,,42,,,3,10.1186/s11689-023-09506-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178649299&doi=10.1186%2fs11689-023-09506-9&partnerID=40&md5=ccc4aeb6c394faafa1e6faffc880787c,"BACKGROUND: Relatively little is known about social cognition in people with intellectual disability (ID), and how this may support understanding of co-occurring autism. A limitation of previous research is that traditional social-cognitive tasks place a demand on domain-general cognition and language abilities. These tasks are not suitable for people with ID and lack the sensitivity to detect subtle social-cognitive processes. In autism research, eye-tracking technology has offered an effective method of evaluating social cognition-indicating associations between visual social attention and autism characteristics. The present systematic review synthesised research which has used eye-tracking technology to study social cognition in ID. A meta-analysis was used to explore whether visual attention on socially salient regions (SSRs) of stimuli during these tasks correlated with degree of autism characteristics presented on clinical assessment tools. METHOD: Searches were conducted using four databases, research mailing lists, and citation tracking. Following in-depth screening and exclusion of studies with low methodological quality, 49 articles were included in the review. A correlational meta-analysis was run on Pearson's r values obtained from twelve studies, reporting the relationship between visual attention on SSRs and autism characteristics. RESULTS AND CONCLUSIONS: Eye-tracking technology was used to measure different social-cognitive abilities across a range of syndromic and non-syndromic ID groups. Restricted scan paths and eye-region avoidance appeared to impact people's ability to make explicit inferences about mental states and social cues. Readiness to attend to social stimuli also varied depending on social content and degree of familiarity. A meta-analysis using a random effects model revealed a significant negative correlation (r = -.28, [95% CI -.47, -.08]) between visual attention on SSRs and autism characteristics across ID groups. Together, these findings highlight how eye-tracking can be used as an accessible tool to measure more subtle social-cognitive processes, which appear to reflect variability in observable behaviour. Further research is needed to be able to explore additional covariates (e.g. ID severity, ADHD, anxiety) which may be related to visual attention on SSRs, to different degrees within syndromic and non-syndromic ID groups, in order to determine the specificity of the association with autism characteristics. © 2023. The Author(s).",Autism; Eye-tracking; Genetic syndromes; Intellectual disability; Social cognition,Autism Spectrum Disorder; Eye-Tracking Technology; Humans; Intellectual Disability; Social Cognition; Social Skills; autism; complication; eye-tracking technology; human; intellectual impairment; meta analysis; psychology; social cognition; social competence,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85178649299,Movies / Media
Niederhauser L.; Gunser S.; Waser M.; Mast F.W.; Caversaccio M.; Anschuetz L.,"Niederhauser, Laura (57210211606); Gunser, Sandra (57469736700); Waser, Manuel (57222292856); Mast, Fred W. (7006023670); Caversaccio, Marco (7004135207); Anschuetz, Lukas (57148145900)",57210211606; 57469736700; 57222292856; 7006023670; 7004135207; 57148145900,Training and proficiency level in endoscopic sinus surgery change residents’ eye movements,2023,Scientific Reports,13,1,79,,,,4,10.1038/s41598-022-25518-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145428185&doi=10.1038%2fs41598-022-25518-2&partnerID=40&md5=f369bb0f7c8b0bc066f10e6f5b59c1a7,"Nose surgery is challenging and needs a lot of training for safe and efficient treatments. Eye tracking can provide an objective assessment to measure residents’ learning curve. The aim of the current study was to assess residents’ fixation duration and other dependent variables over the course of a dedicated training in functional endoscopic sinus surgery (FESS). Sixteen residents performed a FESS training over 18 sessions, split into three surgical steps. Eye movements in terms of percent fixation on the screen and average fixation duration were measured, in addition to residents’ completion time, cognitive load, and surgical performance. Results indicated performance improvements in terms of completion time and surgical performance. Cognitive load and average fixation duration showed a significant change within the last step of training. Percent fixation on screen increased within the first step, and then stagnated. Results showed that eye movements and cognitive load differed between residents of different proficiency levels. In conclusion, eye tracking is a helpful objective measuring tool in FESS. It provides additional insights of the training level and changes with increasing performance. Expert-like gaze was obtained after half of the training sessions and increased proficiency in FESS was associated with increased fixation duration. © 2023, The Author(s).",,Clinical Competence; Endoscopy; Eye Movements; Internship and Residency; Learning Curve; adult; article; cognitive load; dependent variable; endoscopic sinus surgery; eye movement; eye tracking; female; gaze; human; human experiment; male; resident; clinical competence; endoscopy; learning curve; medical education,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85145428185,Movies / Media
Bast N.; Mason L.; Ecker C.; Baumeister S.; Banaschewski T.; Jones E.J.H.; Murphy D.G.M.; Buitelaar J.K.; Loth E.; Pandina G.; Freitag C.M.,"Bast, Nico (57200231841); Mason, Luke (55783092600); Ecker, Christine (57217221069); Baumeister, Sarah (57210652265); Banaschewski, Tobias (57207817286); Jones, Emily J. H. (13408335100); Murphy, Declan G. M. (7404062227); Buitelaar, Jan K. (57208766003); Loth, Eva (23766871300); Pandina, Gahan (6507386347); Freitag, Christine M. (7003868143)",57200231841; 55783092600; 57217221069; 57210652265; 57207817286; 13408335100; 7404062227; 57208766003; 23766871300; 6507386347; 7003868143,Sensory salience processing moderates attenuated gazes on faces in autism spectrum disorder: a case–control study,2023,Molecular Autism,14,1,5,,,,6,10.1186/s13229-023-00537-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147789129&doi=10.1186%2fs13229-023-00537-6&partnerID=40&md5=d2a07f88f29aacea5858d80b86028f75,"Background: Attenuated social attention is a key marker of autism spectrum disorder (ASD). Recent neuroimaging findings also emphasize an altered processing of sensory salience in ASD. The locus coeruleus–norepinephrine system (LC-NE) has been established as a modulator of this sensory salience processing (SSP). We tested the hypothesis that altered LC-NE functioning contributes to different SSP and results in diverging social attention in ASD. Methods: We analyzed the baseline eye-tracking data of the EU-AIMS Longitudinal European Autism Project (LEAP) for subgroups of autistic participants (n = 166, age = 6–30 years, IQ = 61–138, gender [female/male] = 41/125) or neurotypical development (TD; n = 166, age = 6–30 years, IQ = 63–138, gender [female/male] = 49/117) that were matched for demographic variables and data quality. Participants watched brief movie scenes (k = 85) depicting humans in social situations (human) or without humans (non-human). SSP was estimated by gazes on physical and motion salience and a corresponding pupillary response that indexes phasic activity of the LC-NE. Social attention is estimated by gazes on faces via manual areas of interest definition. SSP is compared between groups and related to social attention by linear mixed models that consider temporal dynamics within scenes. Models are controlled for comorbid psychopathology, gaze behavior, and luminance. Results: We found no group differences in gazes on salience, whereas pupillary responses were associated with altered gazes on physical and motion salience. In ASD compared to TD, we observed pupillary responses that were higher for non-human scenes and lower for human scenes. In ASD, we observed lower gazes on faces across the duration of the scenes. Crucially, this different social attention was influenced by gazes on physical salience and moderated by pupillary responses. Limitations: The naturalistic study design precluded experimental manipulations and stimulus control, while effect sizes were small to moderate. Covariate effects of age and IQ indicate that the findings differ between age and developmental subgroups. Conclusions: Pupillary responses as a proxy of LC-NE phasic activity during visual attention are suggested to modulate sensory salience processing and contribute to attenuated social attention in ASD. © The Author(s) 2023.",ASD; Computer vision; Eye tracking; Locus coeruleus; Naturalistic visual attention; Norepinephrine; Pupillometry; Saliency maps; Social attention; Visual exploration,Autism Spectrum Disorder; Autistic Disorder; Case-Control Studies; Female; Humans; Male; Norepinephrine; Sensation; noradrenalin; noradrenalin; adult; Article; autism; case control study; child; computer vision; controlled study; data processing; eye tracking; female; gaze; human; image segmentation; locus ceruleus; major clinical study; male; mental disease; pupillometry; salience network; stimulus response; striate cortex; visual attention; sensation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147789129,Movies / Media
Kuang Z.; Wang F.; Xie H.; Mayer R.E.; Hu X.,"Kuang, Ziyi (57256354300); Wang, Fuxing (57191895027); Xie, Heping (57192430939); Mayer, Richard E. (7403065717); Hu, Xiangen (7404710283)",57256354300; 57191895027; 57192430939; 7403065717; 7404710283,Effect of the Instructor’s Eye Gaze on Student Learning from Video Lectures: Evidence from Two Three-Level Meta-Analyses,2023,Educational Psychology Review,35,4,109,,,,1,10.1007/s10648-023-09820-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176334390&doi=10.1007%2fs10648-023-09820-7&partnerID=40&md5=cc50aaeb473cc7ce9e926c615ea378c9,"The instructor’s eye gaze can serve as an important social cue in video lectures. The current study used two sets of three-level meta-analyses to explore the effects of the instructor’s guided gaze or the instructor’s direct gaze on learning outcomes, fixation time, perception of parasocial interaction, and cognitive load. A total of eight meta-analyses [2(eye gazes)×4(dependent variables)] were included. Eighteen studies with a total of 203 effect sizes were identified. The results showed that guided gaze significantly promoted learning outcomes [g = 0.33; guided gaze vs. no guided gaze (i.e., direct gaze, averted gaze, or no gaze)], and direct gaze significantly promoted learning outcomes [g = 0.30; direct gaze vs. no direct gaze (i.e., averted gaze or no gaze)], significantly increased perception of parasocial interaction (g = 0.34), and significantly reduced fixation time on the learning material (g = -0.65). Moderating effect analyses showed that learning outcomes of fixed guided gaze (g = 0.57; instructors look at the instructional screen) were significantly better than that of shifting guided gaze (g = 0.27; instructors switch their eye gaze between the instructional screen and camera). Learning outcome effects with a control group with averted gaze (g = 0.76) were significantly higher than those with direct gaze (g = 0.32) or no gaze (g = 0.22). This study suggested that guided gaze and direct gaze have different effects on learning. In practical teaching, instructors should use guided gaze and direct gaze, while avoiding averted gaze and no gaze. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Cognitive load; Eye gaze; Meta-analysis; Parasocial interaction; Video lecture,,Article,Final,,Scopus,2-s2.0-85176334390,Movies / Media
Dritsa S.; Mallas A.; Xenos M.,"Dritsa, Stavroula (58934430200); Mallas, Andreas (57211256509); Xenos, Michalis (55185679800)",58934430200; 57211256509; 55185679800,Screen Reading Regions in Social Media Comments: An Eye-Tracking Analysis of Visual Attention on Smartphones,2023,ACM International Conference Proceeding Series,,,,95,101,6.0,1,10.1145/3635059.3635074,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187553579&doi=10.1145%2f3635059.3635074&partnerID=40&md5=37294819b2f2f17c983a7f2e95581799,"Our study examines how formatted text influences reading behavior concerning the smartphone screen regions users utilize on social media comments. Aiming to research visual attention in scrollable content, we investigate the differences in the distribution of visual attention in screen regions between social media comment sections and the users' preferred reading regions across all cases examined. An experiment was conducted with participants (n = 47) engaging in reading activities on the comment section of four social media -Twitter, YouTube (in two versions), Facebook, and Instagram- chosen due to their popularity and the users' familiarity with them. Results showed that users' visual attention is distributed differently between social media. Different reading styles were observed, with users not utilizing the entirety of the screen but instead focusing on specific screen regions that varied between users. © 2023 Owner/Author.",Eye-tracking; Mobile Reading; Screen Regions; Social Media; User Attention; User Study,Behavioral research; Eye tracking; Social networking (online); Eye-tracking; Eye-tracking analysis; Mobile reading; Reading activities; Screen region; Smart phones; Social media; User attention; User study; Visual Attention; Smartphones,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85187553579,Movies / Media
Cooper C.; Meso A.I.,"Cooper, Chloe (58651619000); Meso, Andrew Isaac (24824938200)",58651619000; 24824938200,Cognitive-perceptual traits associated with autism and schizotypy influence use of physics during predictive visual tracking,2023,European Journal of Neuroscience,58,10,,4236,4254,18.0,1,10.1111/ejn.16169,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174229035&doi=10.1111%2fejn.16169&partnerID=40&md5=36aa3b40f10c631a59927411c57e845b,"Schizophrenia and autism spectrum disorder (ASD) can disrupt cognition and consequently behaviour. Traits of ASD and the subclinical manifestation of schizophrenia called schizotypy have been studied in healthy populations with overlap found in trait profiles linking ASD social deficits to negative schizotypy and ASD attention to detail to positive schizotypy. Here, we probed the relationship between subtrait profiles, cognition and behaviour, using a predictive tracking task to measure individuals' eye movements under three gravity conditions. A total of 48 healthy participants tracked an on-screen projected ball under familiar gravity, inverted upward acceleration (against gravity) and horizontal gravity control conditions while eye movements were recorded and dynamic performance quantified. Participants completed ASD and schizotypy inventories generating highly correlated scores, r = 0.73. All tracked best under the gravity condition, producing anticipatory downward responses from stimulus onset which were delayed under upward inverted gravity. Tracking performance was not associated with overall ASD or schizotypy trait levels. Combining measures using principal components analysis (PCA), we decomposed the inventories into subtraits unveiling interesting patterns. Positive schizotypy was associated with ASD dimensions of rigidity, odd behaviour and face processing, which all linked to anticipatory tracking responses under inverted gravity. In contrast, negative schizotypy was associated with ASD dimensions of social interactions and rigidity and to early stimulus-driven tracking under gravity. There was also substantial nonspecific overlap between ASD and schizotypy dissociated from tracking. Our work links positive-odd traits with anticipatory tracking when physics rules are violated and negative-social traits with exploitation of physics laws of motion. © 2023 The Authors. European Journal of Neuroscience published by Federation of European Neuroscience Societies and John Wiley & Sons Ltd.",ASD; eye movements; gravity; prediction; schizotypy,Autism Spectrum Disorder; Autistic Disorder; Cognition; Humans; Physics; Schizotypal Personality Disorder; Article; autism; disease association; eye movement; gravity; human; mathematical model; physics; schizophrenia; social interaction; cognition; schizotypal personality disorder,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85174229035,Movies / Media
Zhang S.; Huang X.; An R.; Xiao W.; Wan Q.,"Zhang, Shifang (57218267702); Huang, Xiuxiu (57210798077); An, Ran (58904974100); Xiao, Weizhong (7202456442); Wan, Qiaoqin (56861738500)",57218267702; 57210798077; 58904974100; 7202456442; 56861738500,The application of saccades to assess cognitive impairment among older adults: a systematic review and meta-analysis,2023,Aging Clinical and Experimental Research,35,11,,2307,2321,14.0,6,10.1007/s40520-023-02546-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169934791&doi=10.1007%2fs40520-023-02546-0&partnerID=40&md5=804b975ba9c42e38d6d5599c0cbf572e,"Background: Saccade is a novel and feasible method for cognition assessment and has potential to screen older people with cognitive impairment. Objectives: To systematically summarize the evidence and determine whether different saccade parameters can effectively identify patients with mild cognitive impairment (MCI) and Alzheimer’s disease (AD). Methods: English and Chinese databases were searched until 19 April 2022. Studies analyzing saccade parameters in older adults with normal cognition, MCI, or AD were included. Two researchers independently performed the screening, data extraction, and quality appraisal. Meta-analyses were conducted and standard mean differences and 95% confidence intervals were estimated with a random effects model. Results: Thirty-five studies were included, and 26 studies were pooled for the meta-analysis. The results demonstrated that patients with cognitive impairment exhibited longer latency and lower accuracy rates in the prosaccade and antisaccade tasks, along with lower corrected error rates in the antisaccade tasks. However, the pooled results for antisaccades were more stable, providing the ability to distinguish patients with cognitive impairment among older adults. The results of the subgroup analyses revealed that only the accuracy rates of the antisaccades differed significantly between people with MCI and AD. Regarding the differences between older adults with normal cognition and those with MCI, the effect sizes of latency and the accuracy rates of saccades as well as the corrected error rates of antisaccades were significant. Conclusions: Saccades, especially antisaccades, are a potential screening and assessment tool for distinguishing older adults with MCI or AD from those with normal cognition. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.",Cognitive impairment; Dementia; Eye tracking; Saccade; Systematic review,Aged; Alzheimer Disease; Cognition; Cognitive Dysfunction; Humans; Saccades; adult; aged; Alzheimer disease; cognitive defect; data extraction; dementia; effect size; eye tracking; female; human; male; meta analysis; middle aged; mild cognitive impairment; Review; saccadic eye movement; systematic review; Alzheimer disease; cognition; cognitive defect; saccadic eye movement,Review,Final,,Scopus,2-s2.0-85169934791,Movies / Media
Jamalzadeh M.; Rekik Y.; Grisoni L.,"Jamalzadeh, Milad (57215318188); Rekik, Yosra (55841843300); Grisoni, Laurent (11441057800)",57215318188; 55841843300; 11441057800,The Effect of Attention Saturating Task on Eyes-Free Gesture Production on Mobile Devices,2023,ISS 2023 - Proceedings of the 2023 Conference on Interactive Surfaces and Spaces,,,,27,31,4.0,1,10.1145/3626485.3626535,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177661699&doi=10.1145%2f3626485.3626535&partnerID=40&md5=013b799a56ac064b01cfef0202018352,"Touch screens are popular input methods for mobile devices, but they compete for visual attention with users' real-world tasks, leading to performance hindrances. In this study, we investigated the effect of an attention-saturating task on eyes-free gestures. A user study was conducted with 13 participants who performed eyes-free gestures on a smartphone using their dominant or non-dominant hand, alone or while performing a primary task that saturates attention. The results indicated that performing another task while drawing a gesture shortened the length and size of the gesture, reduced the duration of gesture entry, while the finger maintained the same speed across the touchscreen. Additionally, drawing a gesture with the nondominant hand increased the length of the gesture but generated less directional movements around the z-axis.  © 2023 ACM.",attention saturating task; Eyes-free gestures; gestures features; mobile device; phone movements,Behavioral research; Eye movements; Attention saturating task; Eye-free gesture; Gesture features; Input methods; Performance; Phone movement; Real-world task; Smart phones; User study; Visual Attention; Touch screens,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85177661699,Movies / Media
Wong S.W.; Crowe P.,"Wong, Shing Wai (55344576600); Crowe, Philip (35511035700)",55344576600; 35511035700,Visualisation ergonomics and robotic surgery,2023,Journal of Robotic Surgery,17,5,,1873,1878,5.0,33,10.1007/s11701-023-01618-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159663196&doi=10.1007%2fs11701-023-01618-7&partnerID=40&md5=0f852bf53ee51dc57574e4edd1caf845,"Stereopsis may be an advantage of robotic surgery. Perceived robotic ergonomic advantages in visualisation include better exposure, three-dimensional vision, surgeon camera control, and line of sight screen location. Other ergonomic factors relating to visualisation include stereo-acuity, vergence–accommodation mismatch, visual–perception mismatch, visual–vestibular mismatch, visuospatial ability, visual fatigue, and visual feedback to compensate for lack of haptic feedback. Visual fatigue symptoms may be related to dry eye or accommodative/binocular vision stress. Digital eye strain can be measured by questionnaires and objective tests. Management options include treatment of dry eye, correction of refractive error, and management of accommodation and vergence anomalies. Experienced robotic surgeons can use visual cues like tissue deformation and surgical tool information as surrogates for haptic feedback. © 2023, The Author(s).",Ergonomics; Robotic surgery; Visual fatigue; Visualisation,"Accommodation, Ocular; Asthenopia; Depth Perception; Ergonomics; Humans; Robotic Surgical Procedures; Ergonomics; Stereo image processing; Surgical equipment; Visual communication; Visual servoing; Visualization; eye drops; Camera controls; Dry eye; Haptic feedbacks; Line of Sight; Lines-of-sight; Robotics surgery; Three dimensional vision; Vergences; Visual fatigue; Visual perception; artifact; asthenopia; binocular convergence; binocular vision; dry eye; ergonomics; eye movement; fatigue; human; laparoscopy; physiological stress; rectum cancer; refraction error; Review; robot assisted surgery; stereoscopic vision; tactile feedback; task performance; vision; visual attention; visual feedback; visual information; visual stimulation; accommodation; asthenopia; depth perception; ergonomics; procedures; Robotic surgery",Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85159663196,Movies / Media
Maranzano A.; Verde F.; Colombo E.; Poletti B.; Doretti A.; Bonetti R.; Gagliardi D.; Meneri M.; Maderna L.; Messina S.; Corti S.; Morelli C.; Silani V.; Ticozzi N.,"Maranzano, Alessio (57216738733); Verde, Federico (57201021914); Colombo, Eleonora (57531696700); Poletti, Barbara (16646951300); Doretti, Alberto (26435780300); Bonetti, Ruggero (57945607000); Gagliardi, Delia (57200126382); Meneri, Megi (57208670204); Maderna, Luca (6508270561); Messina, Stefano (57216049523); Corti, Stefania (7003759380); Morelli, Claudia (35242968500); Silani, Vincenzo (7006146949); Ticozzi, Nicola (23062054500)",57216738733; 57201021914; 57531696700; 16646951300; 26435780300; 57945607000; 57200126382; 57208670204; 6508270561; 57216049523; 7003759380; 35242968500; 7006146949; 23062054500,Regional spreading pattern is associated with clinical phenotype in amyotrophic lateral sclerosis,2023,Brain,146,10,,4105,4116,11.0,21,10.1093/brain/awad129,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174533238&doi=10.1093%2fbrain%2fawad129&partnerID=40&md5=f39b71d3aa400a33f306d34e5b980026,"Increasing evidence shows that disease spreading in amyotrophic lateral sclerosis (ALS) follows a preferential pattern with more frequent involvement of contiguous regions from the site of symptom onset. The aim of our study was to assess if: (i) the burden of upper (UMN) and lower motor neuron (LMN) involvement influences directionality of disease spreading; (ii) specific patterns of disease progression are associated with motor and neuropsychological features of different ALS subtypes (classic, bulbar, primary lateral sclerosis, UMN-predominant, progressive muscular atrophy, flail arm, flail leg); and (iii) specific clinical features may help identify ALS subtypes, which remain localized to the site of onset for a prolonged time (regionally entrenching ALS). A single-centre, retrospective cohort of 913 Italian ALS patients was evaluated to assess correlations between directionality of the disease process after symptom onset and motor/neuropsychological phenotype. All patients underwent an extensive evaluation including the following clinical scales: Penn Upper Motor Neuron Score (PUMNS), MRC Scale for Muscle Strength and the Edinburgh Cognitive and Behavioural ALS Screen (ECAS). The most frequent initial spreading pattern was that towards adjacent horizontal regions (77.3%), which occurred preferentially in patients with lower MRC scores (P = 0.038), while vertical diffusion (21.1%) was associated with higher PUMNS (P < 0.001) and with reduced survival (P < 0.001). Non-contiguous disease spreading was associated with more severe UMN impairment (P = 0.003), while contiguous disease pattern with lower MRC scores. Furthermore, non-contiguous disease spreading was associated with more severe cognitive impairment in both executive and visuospatial ECAS domains. Individuals with regionally entrenching ALS were more frequently female (45.6% versus 36.9%; P = 0.028) and had higher frequencies of symmetric disease onset (40.3% versus 19.7%; P < 0.001) and bulbar phenotype (38.5% versus 16.4%; P < 0.001). Our study suggests that motor phenotypes characterized by a predominant UMN involvement are associated with a vertical pattern of disease progression reflecting ipsilateral spreading within the motor cortex, while those with predominant LMN involvement display more frequently a horizontal spreading from one side of the spinal cord to the other. These observations raise the hypothesis that one of the mechanisms underlying disease spreading in ALS pathology is represented by diffusion of toxic factors in the neuron microenvironment. Finally, it is possible that in our cohort, regionally entrenching ALS forms are mainly observed in patients with atypical bulbar phenotypes, characterized by a slowly progressive course and relatively benign prognosis.  © 2023 The Author(s).",amyotrophic lateral sclerosis (ALS); disease progression; motor neuron disease (MND); motor phenotype; site of onset; somatotopic organization of motor system,adult; amyotrophic lateral sclerosis; Amyotrophic Lateral Sclerosis Functional Rating Scale-Revised; Article; behavior assessment; brain region; bulbar lateral sclerosis; classic lateral sclerosis; clinical feature; cognition assessment; cognitive defect; cohort analysis; controlled study; depth perception; disease exacerbation; Edinburgh Cognitive and Behavioral Amyotrophic Lateral Sclerosis Screen; executive function; female; human; human cell; lower motor neuron; major clinical study; male; middle aged; motoneuron; motor cortex; motor performance; movement perception; musculoskeletal disease assessment; neurologic disease assessment; neuropsychological assessment; neuropsychology; Penn Upper Motor Neuron Score; phenotype; primary lateral sclerosis; prognosis; progressive muscular atrophy; retrospective study; saccadic eye movement; scale for muscle strength; survival,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85174533238,Movies / Media
Ekin M.; Koçoğlu K.; Eraslan Boz H.; Akkoyun M.; Tüfekci I.Y.; Cesim E.; Yalınçetin B.; Özbek S.U.; Bora E.; Akdal G.,"Ekin, Merve (58130869100); Koçoğlu, Koray (57199691364); Eraslan Boz, Hatice (57210947226); Akkoyun, Müge (57969752400); Tüfekci, Işıl Yağmur (58130983900); Cesim, Ezgi (57376528000); Yalınçetin, Berna (36107138300); Özbek, Simge Uzman (57393710300); Bora, Emre (8881509300); Akdal, Gülden (56027611400)",58130869100; 57199691364; 57210947226; 57969752400; 58130983900; 57376528000; 36107138300; 57393710300; 8881509300; 56027611400,Antisaccade and memory-guided saccade in individuals at ultra-high-risk for bipolar disorder,2023,Journal of Affective Disorders,339,,,965,972,7.0,3,10.1016/j.jad.2023.07.109,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165868629&doi=10.1016%2fj.jad.2023.07.109&partnerID=40&md5=17e6c01278b891b22438de0153f96028,"Background: Ultra-high-risk for bipolar disorder (UHR-BD) is an important paradigm to investigate the potential early-stage biomarkers of bipolar disorder, including eye-tracking abnormalities and cognitive functions. Antisaccade (AS) described as looking in the opposite direction of the target, and memory-guided saccade (MGS), identified as maintaining fixation, and remembering the location of the target, were used in this study. The aim of this study was to evaluate the differences in saccadic eye movements between UHR-BD and healthy controls (HCs) via AS-MGS. Methods: The study included 28 UHR-BD and 29 HCs. Participants were selected using a structured clinical interview for prodromal symptoms of BD. AS-MGS were measured with parameters like uncorrected errors, anticipatory saccades, and latency. Eye movements were recorded with the EyeLink 1000-Plus eye-tracker. Results: In the AS, the number of correct saccades was significantly decreased in UHR-BD (p = 0.020). Anticipatory (p = 0.009) and express saccades (p = 0.040) were increased in UHR-BD. In the MGS paradigm, the correct saccades were reduced in UHR-BD (p = 0.031). In addition, anticipatory (p = 0.004) and express saccades (p = 0.012) were significantly increased in cue-screen in UHR-BD. Conclusions: To our knowledge, this is the first study to evaluate cognitive functions with eye movements in individuals at UHR-BD. The current findings showed that eye movement functions, particularly in saccadic parameters related to inhibition and spatial perception, may be affected in the UHR-BD group. Therefore, assessment of oculomotor functions may provide observation of clinical and cognitive functions in the early-stage of bipolar disorder. However, further research is needed because the potential effects of medication may affect saccadic results. © 2023 Elsevier B.V.",Antisaccade; Bipolar disorder; Memory-guided saccade; Ultra-high risk,"Bipolar Disorder; Cognition; Humans; Inhibition, Psychological; Mental Recall; Reaction Time; Saccades; adult; Article; bipolar disorder; clinical assessment; controlled study; demographics; eye movement; female; human; major clinical study; male; memory; prodromal symptom; saccadic eye movement; bipolar disorder; cognition; inhibition (psychology); physiology; psychology; reaction time; recall; saccadic eye movement",Article,Final,,Scopus,2-s2.0-85165868629,Movies / Media
,,,Proceedings - SUI 2023: ACM Symposium on Spatial User Interaction,2023,Proceedings - SUI 2023: ACM Symposium on Spatial User Interaction,,,,,,494.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176106289&partnerID=40&md5=0373d9892c7d70abfe8b1b5e465d17a1,The proceedings contain 67 papers. The topics discussed include: advantage of gaze-only contents browsing in VR using cumulative dwell time compared to hand controller; minimizing eye movements and distractions in head-mounted augmented reality through eye-gaze adaptiveness; blink don’t wink: exploring blinks as input for VR games; guiding visual attention on 2D screens: effects of gaze cues from avatars and humans; low-Fi VR controller: improved mobile virtual reality interaction via camera-based tracking; VibAware: context-aware tap and swipe gestures using bio-acoustic sensing; ExtEdge: haptic augmentation of visual experiences of a smartphone by electro-tactile sensation through the edges; OptiRing: low-resolution optical sensing for subtle thumb-to-index input; PalmGazer: unimanual eye-hand menus in augmented reality; and in-the-wild experiences with an interactive glanceable AR system for everyday use.,,,Conference review,Final,,Scopus,2-s2.0-85176106289,Movies / Media
Tao Z.; Sun N.; Yuan Z.; Chen Z.; Liu J.; Wang C.; Li S.; Ma X.; Ji B.; Li K.,"Tao, Zhanbo (58669927300); Sun, Ningxia (8622506400); Yuan, Zhen (9277747400); Chen, Zeyuan (58556815000); Liu, Jiakang (58117438900); Wang, Chen (58117605300); Li, Shuwu (57215545668); Ma, Xiaowen (57361037700); Ji, Bin (7102565395); Li, Kai (57210170184)",58669927300; 8622506400; 9277747400; 58556815000; 58117438900; 58117605300; 57215545668; 57361037700; 7102565395; 57210170184,Research on a New Intelligent and Rapid Screening Method for Depression Risk in Young People Based on Eye Tracking Technology,2023,Brain Sciences,13,10,1415,,,,3,10.3390/brainsci13101415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175183612&doi=10.3390%2fbrainsci13101415&partnerID=40&md5=a41e6956b06966182f78c8f0ed22d529,"Depression is a prevalent mental disorder, with young people being particularly vulnerable to it. Therefore, we propose a new intelligent and rapid screening method for depression risk in young people based on eye tracking technology. We hypothesized that the “emotional perception of eye movement” could characterize defects in emotional perception, recognition, processing, and regulation in young people at high risk for depression. Based on this hypothesis, we designed the “eye movement emotional perception evaluation paradigm” and extracted digital biomarkers that could objectively and accurately evaluate “facial feature perception” and “facial emotional perception” characteristics of young people at high risk of depression. Using stepwise regression analysis, we identified seven digital biomarkers that could characterize emotional perception, recognition, processing, and regulation deficiencies in young people at high risk for depression. The combined effectiveness of an early warning can reach 0.974. Our proposed technique for rapid screening has significant advantages, including high speed, high early warning efficiency, low cost, and high intelligence. This new method provides a new approach to help effectively screen high-risk individuals for depression. © 2023 by the authors.",affective computing; depression; eye movement tracking technique; screening; young adults,biological marker; adult; angry; Article; attention; audio comprehension skill; binary logistic regression; controlled study; coronavirus disease 2019; data processing; depression; diagnostic test accuracy study; digital biomarker; digital identity; emotion; eye-tracking technology; facial expression; facies; false discovery rate; female; happiness; human; human experiment; intelligence; logistic regression analysis; male; Patient Health Questionnaire 9; perception; psychologic assessment; quantitative analysis; rapid screening method; receiver operating characteristic; recognition; risk assessment; saccadic eye movement; sad; screening; sensitivity and specificity; skill; task performance; visual comprehension skill; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85175183612,Movies / Media
Chuang C.-H.; Hsu H.-C.,"Chuang, Chun-Hsiang (26653452200); Hsu, Hao-Che (57265027500)",26653452200; 57265027500,Pseudo-mutual gazing enhances interbrain synchrony during remote joint attention tasking,2023,Brain and Behavior,13,10,e3181,,,,5,10.1002/brb3.3181,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165909963&doi=10.1002%2fbrb3.3181&partnerID=40&md5=f2b3377d33e387f87f5dbc94987ff5c8,"Introduction: Mutual gaze enables people to share attention and increase engagement during social interactions through intentional and implicit messages. Although previous studies have explored gaze behaviors and neural mechanisms underlying in-person eye contact, the growing prevalence of remote communication has raised questions about how to establish mutual gaze remotely and how the brains of interacting individuals synchronize. Methods: To address these questions, we conducted a study using eye trackers to create a pseudo-mutual gaze channel that mirrors the gazes of each interacting dyad on their respective remote screens. To demonstrate fluctuations in coupling across brains, we incorporated electroencephalographic hyperscanning techniques to simultaneously record the brain activity of interacting dyads engaged in a joint attention task in player-observer, collaborative, and competitive modes. Results: Our results indicated that mutual gaze could improve the efficiency of joint attention activities among remote partners. Moreover, by employing the phase locking value, we could estimate interbrain synchrony (IBS) and observe low-frequency couplings in the frontal and temporal regions that varied based on the interaction mode. While dyadic gender composition significantly affected gaze patterns, it did not impact the IBS. Conclusion: These results provide insight into the neurological mechanisms underlying remote interaction through the pseudo-mutual gaze channel and have significant implications for developing effective online communication environments. © 2023 The Authors. Brain and Behavior published by Wiley Periodicals LLC.",cooperation and competition; hyperscanning EEG; interbrain synchrony; joint attention; mutual gaze; phase locking value,adult; Article; competition; cooperation; electroencephalogram; electroencephalography; eye movement; female; functional connectivity; gaze; human; human experiment; interbrain synchrony; male; mental function assessment; normal human; pseudo-mutual gazing; remote joint attention tasking; social behavior; target-searching time; time,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85165909963,Movies / Media
Gao Q.; Zhang L.,"Gao, Qian (58481051500); Zhang, Liwei (57192977077)",58481051500; 57192977077,Brief mindfulness meditation intervention improves attentional control of athletes in virtual reality shooting competition: Evidence from fNIRS and eye tracking,2023,Psychology of Sport and Exercise,69,,102477,,,,12,10.1016/j.psychsport.2023.102477,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164387620&doi=10.1016%2fj.psychsport.2023.102477&partnerID=40&md5=f33c360476c4b82f8131718c87a9ac52,"Attentional control is a crucial cognitive ability for sports performance. The current research aimed to investigate whether a brief (20-min) pre-competition mindfulness meditation (MM) intervention enhances athletes' attentional control during competitions and alters the activity of brain regions related to attentional control. We created a virtual reality shooting competition to compare the eye-gaze indicators and functional near-infrared spectroscopy (fNIRS) parameters of 78 university athletes after 20 min of MM or 20 min of mind wandering (MW). Participants’ average fixation durations (AFDs) on task-relevant information (targets) were significantly longer in the MM group. In contrast, both average fixation counts (AFCs) and AFDs on task-irrelevant information (the ranking screen) were significantly lower in the MM group than in the MW group. Additionally, the MM group exhibited significantly stronger activation of the left and right dorsolateral prefrontal cortex (dlPFC) as well as higher levels of oxygenated haemoglobin [HbO] and greater functional connectivity (FC) of the right dlPFC, which was considered evidence of recruitment for attentional control. Moreover, the MM group achieved significantly better shooting performance than the MW group. Overall, the findings suggest that one session 20-min MM practice pre-competition facilitates focus during competition and improves athletic performance. We recommend the application of brief mindfulness practice in sports, especially in closed-skill sports that require high attention participation (e.g., shooting, archery, darts, golf, gymnastics, skating etc.). © 2023 Elsevier Ltd",Attentional control; Eye tracking; fNIRS; Mindfulness meditation; Shooting; Virtual reality,,Article,Final,,Scopus,2-s2.0-85164387620,Movies / Media
Lowry M.; Julian A.K.; Tribby C.; Perna F.,"Lowry, Mark (57222095312); Julian, Anne K. (55640015200); Tribby, Calvin (55070684100); Perna, Frank (56500163500)",57222095312; 55640015200; 55070684100; 56500163500,Consumers pay attention to ingredients on the front of a label: an eye tracking study,2023,Translational Behavioral Medicine,13,10,,768,774,6.0,1,10.1093/tbm/ibad038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174641832&doi=10.1093%2ftbm%2fibad038&partnerID=40&md5=30ab37d28108753a1076d29c95a329ff,"Sunscreen is an important part of skin cancer prevention. The Food and Drug Administration (FDA) proposed numerous changes to sunscreen labeling including adding active ingredients to the front of a label. The purpose of the study was to identify and describe differences in attention between current label formatting and the proposed label formatting. Forty-seven participants were interviewed. Participants were presented with mock sunscreen labels that resembled current labeling or labeling based on the proposed FDA rule. While reading the labels, eye movements were recorded. Participants spent 12.3 s longer looking at the front of the proposed rule-compliant label than they did on the front of the current label. They spent the longest time reading the directions (13-14 seconds) compared with other areas. Placing active ingredients on the front of a label in relatively large font makes it more likely consumers will look at the information. © 2023 Published by Oxford University Press on behalf of the Society of Behavioral Medicine.",Active ingredients; Attention; Eye tracking; Proposed FDA rule; Sunscreen labels,Choice Behavior; Consumer Behavior; Eye-Tracking Technology; Food Labeling; Humans; Sunscreening Agents; non prescription drug; sunscreen; water; sunscreen; adult; Article; cancer prevention; consumer; drug labeling; eye movement; eye tracking; eye-tracking technology; female; Food and Drug Administration; human; human experiment; language; male; normal human; skin cancer; task performance; consumer attitude; decision making; food packaging,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85174641832,Movies / Media
Dalmaso M.,"Dalmaso, Mario (52363482800)",52363482800,Foot cues can elicit covert orienting of attention,2023,Psychological Research,87,8,,2440,2448,8.0,2,10.1007/s00426-023-01827-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152705337&doi=10.1007%2fs00426-023-01827-7&partnerID=40&md5=4f86ce537f38b9e9fdc095f6d9e597e1,"Humans tend to orient their attentional resources towards the same location indicated by spatial signals coming from the others, such as pointing fingers, head turns, or eye-gaze. Here, two experiments investigated whether an attentional orienting response can be elicited even by foot cues. Participants were asked to localize a peripheral target while a task-irrelevant picture of a naked human foot, oriented leftward or rightward, was presented on the centre of the screen. The foot appeared in a neutral posture (i.e., standing upright) or an action-oriented posture (i.e., walking/running). In Experiment 1, neutral and action-oriented feet were presented in two distinct blocks, while in Experiment 2 they were presented intermixed. The results showed that the action-oriented foot, but not the neutral one, elicited an orienting response, though this only emerged in Experiment 2. This work suggests that attentional shifts can be induced by action-oriented foot cues, as long as these stimuli are made contextually salient. © 2023, The Author(s).",,"Attention; Cues; Fixation, Ocular; Humans; Posture; Reaction Time; Standing Position; association; attention; body position; eye fixation; human; physiology; reaction time; standing",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85152705337,Movies / Media
Chen C.; Lee V.G.,"Chen, Chen (57674436300); Lee, Vanessa G. (35279609200)",57674436300; 35279609200,Looking away to see: The acquisition of a search habit away from the saccade direction,2023,Vision Research,211,,108276,,,,3,10.1016/j.visres.2023.108276,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162906753&doi=10.1016%2fj.visres.2023.108276&partnerID=40&md5=13e69f06098de323ea4fd85aefdde661,"Growing evidence has shown that attention can be habit-like, unconsciously and persistently directed toward locations that have frequently contained search targets in the past. The attentional preference typically arises when the eye gaze aligns with the attended location. Here we tested whether this spatial alignment is necessary for the acquisition of a search habit. To divert eye movements away from an attended location, we used gaze-contingent eye tracking, restricting the visible portion of the screen to an area opposite to the current gaze. Participants searched for a T target amidst a circular array of L distractors. Unbeknownst to them, the target appeared more frequently in one screen quadrant. Despite fixating on a location diametrically opposite to the visible, attended region, participants acquired probability cuing, producing quicker responses when the target appeared in the high-probability quadrant. They also showed a speed advantage in the diagonal quadrant. The attentional preference for the high-probability quadrant persisted during a testing phase in which the target's location was unbiased, but only when participants continued to search with the restricted view. These results indicate that a search habit can be acquired even when participants are required to look away from the high-probability locations. The finding suggests that the learned search habit is not solely a result of oculomotor learning. © 2023 Elsevier Ltd",Eye movements; Location probability learning; Selection history effects; Spatial attention; Visual search,Attention; Habits; Humans; Reaction Time; Saccades; Space Perception; adult; article; eye movement; eye tracking; female; gaze; human; human experiment; learning; male; probability learning; saccadic eye movement; spatial attention; velocity; attention; depth perception; habit; physiology; reaction time,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85162906753,Movies / Media
Xu J.; Han H.; Shi L.; Tong G.,"Xu, Jinbo (59474657300); Han, Hui (59473979400); Shi, Lei (59476661300); Tong, Guanglei (57219721407)",59474657300; 59473979400; 59476661300; 57219721407,Research advances of eye tracking technology in children with autism spectrum disorder; [眼动追踪技术在儿童孤独症谱系障碍中的研究进展],2023,Chinese Journal of General Practice,21,9,,1571,1575,4.0,2,10.16766/j.cnki.issn.1674-4152.003173,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212215907&doi=10.16766%2fj.cnki.issn.1674-4152.003173&partnerID=40&md5=1eb9a66cffb8aa727d432954bcc2d700,"Autism spectrum disorder (ASD) is a group of neurodevelopmental disorder whose core symptoms are social deficits, narrow interests, and repetitive stereotype-like behaviors. Abnormal eye fixation is one of the clinical symptoms and early behavioral markers in children with ASD. Eye movement characteristics of children with ASD differ significantly from those of normally developing children, mainly in terms of reduced or absent visual gaze to socially attributed stimuli. Analysis of eye movement characteristics can provide an objective indicator for ASD research. Eye tracking (ET) technology is a new objective and non-invasive examination technique that can visually and accurately observe visual gaze duration and time allocation, and can provide more accurate and sensitive measurements of social attention, restricted interest, and emotion recognition in children with ASD. It has become a research hotspot in the field of ASD. In early identification screening, ET can understand and assess the early behavioral development of children with ASD and serve as one of the pathways for early identification screening. In diagnosis, ET combines subjective behavioral observations with objective behavioral indicators. In treatment, ET can assist in developing individualized intervention plans. In analyzing prognosis, ET can serve as a predictive tool for symptom severity. The application of ET in early screening and identification, early diagnosis, early intervention and treatment, prognosis analysis and the research progress of the neural mechanism of eye movement in children with ASD are summarized. Future research should further explore the neural mechanisms of eye movements in children with ASD and combine ET with 5G technology, virtual technology, and robotics to expand the application of ET and provide new ideas and methods for the exploration of the etiology and rehabilitation treatment of ASD. © 2023 Publishing House of Chinese Journal of General Practice. All rights reserved.",Autism spectrum disorder; Children; Early identification; Eye tracking; Visual attention,,Review,Final,,Scopus,2-s2.0-85212215907,Movies / Media
Ferreira M.E.C.; Carmo E.C.; Frota-Júnior L.S.; de Sousa Fortes L.,"Ferreira, Maria Elisa Caputo (23979925800); Carmo, Everton Crivoi (36124840600); Frota-Júnior, Luiz Solon (58475696300); de Sousa Fortes, Leonardo (54986005700)",23979925800; 36124840600; 58475696300; 54986005700,Head-to-head opponent mitigates mental fatigue effects during a 20-km time trial in well-trained cyclists,2023,Scandinavian Journal of Medicine and Science in Sports,33,10,,1984,1997,13.0,2,10.1111/sms.14445,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164120654&doi=10.1111%2fsms.14445&partnerID=40&md5=b5fb14ed50e8a65bf98954843eb34a02,"We aimed to analyze the effect of a head-to-head virtual race on 20-km time trial performance in well-trained mentally fatigued cyclists. A total of 24 male professional cyclists participated in the present study, which was conducted in a within-factors design [four experimental conditions × four times (throughout 20-km time trial cycling)]. An avatar representing the participant on the racecourse was visible during the time trials. Then, a second virtual avatar representing the opponent was projected onto the screen in the mental fatigue head-to-head and control head-to-head experimental conditions. Measurements [rating of perceived exertion, heart rate, and eye-tracking measures (i.e., pupil diameter)] were performed every 5-km throughout the 20-km time trial. As a result, impaired total time, power output, and cadence throughout the 20-km cycling time trial were found for mental fatigue compared to mental fatigue head-to-head, control head-to-head, and control conditions (p < 0.05). Also, impaired 20-km time trial performance (total time, power output, and cadence) was found for mental fatigue head-to-head compared to control head-to-head (p < 0.05). Moreover, lower RPE was found for the control and control head-to-head conditions than mental fatigue head-to-head and mental fatigue experimental conditions (p < 0.05). Higher pupil diameter was also found for mental fatigue head-to-head, control head-to-head, and control than the mental fatigue experimental condition (p < 0.05). In summary, the overall performance throughout the 20-km cycling time trial was improved by the presence of a virtual opponent for the mentally fatigued cyclists. © 2023 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.",aerobic performance; brain; cognitive effort; fatigue; neuroscience,Athletic Performance; Bicycling; Heart Rate; Humans; Male; Mental Fatigue; athletic performance; cycling; heart rate; human; male; mental fatigue,Article,Final,,Scopus,2-s2.0-85164120654,Movies / Media
Hueber S.; Jang E.; Borchers J.,"Hueber, Sebastian (57219112817); Jang, Eunae (58650535400); Borchers, Jan (7005473180)",57219112817; 58650535400; 7005473180,Attentive Notifications: Minimizing Distractions of Mobile Notifications through Gaze Tracking,2023,"Proceedings of the 25th International Conference on Mobile Human-Computer Interaction, MobileHCI 2023 Companion",,,1,,,,3,10.1145/3565066.3608695,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174229240&doi=10.1145%2f3565066.3608695&partnerID=40&md5=19dc74f8cb4366abefac3783b91b9653,"Notifications on smartphones typically appear at the top of the screen, resulting in interruptions caused by content overlaps of toolbars and potential accidental activation of a notification. As returning to a workflow which got interrupted proves difficult for the general user, interface designers should thoughtfully design the visual disruption caused by notifications. We explore possible designs of gaze-attentive notifications to overcome this issue. By placing the notification banner as far from the user's current gazing point as possible they result in less visual overlap and our study participants experienced them as less distracting.  © 2023 Owner/Author.",gaze tracking; interaction techniques; notifications; occlusion,'current; Gaze-tracking; In-interruption; Interaction techniques; Interface designers; Notification; Occlusion; Smart phones; Toolbars; Work-flows; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85174229240,Movies / Media
Sauter M.; Wagner T.; Hirzle T.; Lin B.X.; Rukzio E.; Huckauf A.,"Sauter, Marian (56763649100); Wagner, Tobias (57215298980); Hirzle, Teresa (57203517985); Lin, Bao Xin (58184056200); Rukzio, Enrico (18233783900); Huckauf, Anke (6701503895)",56763649100; 57215298980; 57203517985; 58184056200; 18233783900; 6701503895,Behind the Screens: Exploring Eye Movement Visualization to Optimize Online Teaching and Learning,2023,ACM International Conference Proceeding Series,,,,67,80,13.0,3,10.1145/3603555.3603560,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171172136&doi=10.1145%2f3603555.3603560&partnerID=40&md5=98e19ec661c8fab6e28258171ac2f9db,"The effective delivery of e-learning depends on the continuous monitoring and management of student attention. While instructors in traditional classroom settings can easily assess crowd attention through gaze cues, these cues are largely unavailable in online learning environments. To address this challenge and highlight the significance of our study, we collected eye movement data from twenty students and developed four visualization methods: (a) a heat map, (b) an ellipse map, (c) two moving bars, and (d) a vertical bar, which were overlaid on 13 instructional videos. Our results revealed unexpected preferences among the instructors. Contrary to expectations, they did not prefer the established heat map and vertical bar for live online instruction. Instead, they chose the less intrusive ellipse visualization. Nevertheless, the heat map remained the preferred choice for retrospective analysis due to its more detailed information. Importantly, all visualizations were found to be useful and to help restore emotional connections in online learning. In conclusion, our innovative visualizations of crowd attention show considerable potential for a wide range of applications, extending beyond e-learning to all online presentations and retrospective analyses. The significant results of our study underscore the critical role these visualizations will play in enhancing both the effectiveness and emotional connectedness of future e-learning experiences, thereby facilitating the educational landscape.  © 2023 Owner/Author.",education; eye tracking; gaze visualizations; learning; online teaching; quantitative methods,Computer aided instruction; Data visualization; E-learning; Eye movements; Learning systems; Students; Visualization; Continuous monitoring; E - learning; Eye-tracking; Gaze visualization; Heat maps; Learning; Online teaching; Online teaching and learning; Quantitative method; Retrospective analysis; Eye tracking,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85171172136,Movies / Media
Kassem K.; Shahu A.; Tüchler C.; Wintersberger P.; Michahelles F.,"Kassem, Khaled (57200211902); Shahu, Ambika (57645626800); Tüchler, Christina (58575160300); Wintersberger, Philipp (55485458100); Michahelles, Florian (6507384553)",57200211902; 57645626800; 58575160300; 55485458100; 6507384553,Enhancing the Supervision of Out-of-View Robots: A Study on Multimodal Feedback and Monitoring Screens,2023,ACM International Conference Proceeding Series,,,,487,491,4.0,0,10.1145/3603555.3608550,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171153483&doi=10.1145%2f3603555.3608550&partnerID=40&md5=9845696dae875ff9f58986b1aa93b91b,"Objective: investigating the effect of two support methods (multimodal feedback, monitoring screens, and a combination of both) on human dual-task performance, cognitive workload, and user experience when supervising an out-of-sight autonomous robot. Method: A 2x2 within-group user study was conducted in VR with 26 participants involving a cognitive-cognitive dual-task setting. Participants had to simultaneously solve math problems and supervise the robot. Different support methods were provided: multimodal feedback, a screen showing real-time robot activity, and a combination of both. Objective performance metrics and subjective feedback on cognitive load and user experience were collected using standard questionnaires. Data were statistically analyzed, and thematic analysis was performed on post-study debriefing interviews. Results: The support methods improved overall user experience and positively impacted robot collaboration performance while decreasing math task performance. Cognitive load was unaffected. Multimodal feedback with a monitoring screen was perceived as the most helpful. Conclusion: The results suggest that multimodal feedback can improve user experience and improve supervision, but may partially decrease primary task performance. The findings highlight the importance of examining the effect of support methods in specific situations, depending on task priority.  © 2023 Owner/Author.",,User interfaces; Cognitive loads; Cognitive workloads; Dual-task performance; Dual-tasks; Group users; Multimodal feedback; Support method; Task performance; User study; Users' experiences; Robots,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85171153483,Movies / Media
Yu W.; Tang J.; Zhang Y.; Hu M.; Wu Y.,"Yu, Wangyang (57224880889); Tang, Jingyu (57326047800); Zhang, Yudong (35786830100); Hu, Menghan (55818700700); Wu, Yue (57195521602)",57224880889; 57326047800; 35786830100; 55818700700; 57195521602,Glaucoma visual field quantification with eye tracker,2023,Displays,79,,102465,,,,6,10.1016/j.displa.2023.102465,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162093665&doi=10.1016%2fj.displa.2023.102465&partnerID=40&md5=cedf3916a030c5f16db2618795fd3f81,"Glaucoma is a group of diseases that manifest as atrophy and depression of the optic papilla, visual field defects, and vision loss, representing one of the three leading causes of blindness worldwide. Traditional visual field examinations – an important diagnostic tool for glaucoma – present various challenges including patients’ inability to maintain fixed vision, delays in detecting vision loss, passive position detection, difficulty in detection, and limitations in reflecting physiological visual field damage. Early diagnosis and intervention are crucial for improving patients’ condition and enhancing their later-life abilities and life quality. Herein, we proposed two vision field detection systems to overcome these limitations. First, we establish a dynamic visual field detection system to reduce the complexity of traditional detection experiments and to enhance their operability. Instead of fixating on a central point, subjects are only required to search for the target in the picture. We analyze the heat map and trajectory map of visual attention for visual interpretation, and the analysis of experimental data reveals that the average finding time of subjects in the experimental task varies. In response to the scenario where visual field defects are not detected by the dynamic visual field detection system, we have developed a static visual field detection system based on the former. The system obtains eye movement data and automatically generates a map of the extent of the physiological blind spot without any action required from the patient. The experiment results provide evidence for the effectiveness of the static visual field detection system in detecting the physiological blind spot. Given the well-established association between glaucoma and an enlarged physiological blind spot, the use of an eye tracker to assess the extent of the subject's blind spot represents an easy-to-use and reliable method for preliminary glaucoma screening. © 2023 Elsevier B.V.",Eye movement technology; Glaucoma; Visual field examination,Aldehydes; Behavioral research; Damage detection; Defects; Diagnosis; Eye protection; Eye tracking; Ophthalmology; Patient treatment; Blind spots; Detection system; Eye movement technology; Eye trackers; Field detections; Glaucoma; Vision loss; Visual field defects; Visual field examination; Visual fields; Eye movements,Article,Final,,Scopus,2-s2.0-85162093665,Movies / Media
Fournier J.; Etchamendy E.; Chérel M.; Outtas M.; Zhang L.,"Fournier, Julie (57950156300); Etchamendy, Elise (57219114475); Chérel, Myriam (57219110768); Outtas, Meriem (57194037179); Zhang, Lu (37007172100)",57950156300; 57219114475; 57219110768; 57194037179; 37007172100,The impact of the affinity on ASD people visual engagement,2023,ACM International Conference Proceeding Series,,,,28,33,5.0,0,10.1145/3617233.3617236,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182588803&doi=10.1145%2f3617233.3617236&partnerID=40&md5=ddf7056cedc5a5990119aabf54320ebb,"Autism spectrum disorders affect the way people perceive their environment and interact with it. Many autistic people have a passion for an object or a topic, such as a film, planes, or geography maps to name very few of them, which is called an affinity. This affinity is sometimes described as an obsession that prevents the ASD subjects to connect with the surrounding world, but it is also considered as a key to the autistic world and a way to make a connection. In this paper we investigate the specific role of affinity in the autistic person's attention. We have conducted eye tracking experiments over 44 autistic subjects from 3 different institutions. We have shown them neutral images and images with their own affinity and recorded their gaze position. Results are not conclusive in all the 3 institutions, but in the 2 first ones we got significant differences between the 2 sets of images indicating a higher visual attention for the affinity. © 2023 ACM.",affinity; Autism Spectrum Disorders; eye tracking; visual behavior,Behavioral research; Diseases; Affinity; Autism spectrum disorders; Eye-tracking; Film planes; Visual Attention; Visual behavior; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85182588803,Movies / Media
Valtr L.; Psotta R.; Dostál D.,"Valtr, Ludvík (56904271900); Psotta, Rudolf (6505984468); Dostál, Daniel (54782348000)",56904271900; 6505984468; 54782348000,Effects of the Specific Eye Fixation Training on Fine Visuomotor Coordination in Children with Attention Deficit Hyperactivity Disorder,2023,Children,10,10,1648,,,,2,10.3390/children10101648,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175055633&doi=10.3390%2fchildren10101648&partnerID=40&md5=a3540c7e0f8e8a44f6764c24b0230b4f,"This study investigated the effects of quiet eye training (QET) on the neuropsychological functioning and fine motor performance of children with attention deficits. The participant cohort consisted of 106 children with attention deficit hyperactivity disorder (ADHD) between the ages of 8 and 12 years. The children were assigned to either the QET group (n = 54) or the control group (n = 52). The QET group went through a 5-week intervention in which the performance of blocks of targeting tasks was preceded by watching split-screen video footage featuring the gaze and body movements of a skilled model performing a throwing motion. Both groups underwent pre-test and post-test assessments, which included the reaction test of alertness, go/no-go inhibition test, and motor performance series test. The QET group demonstrated significant improvements in attentional engagement, inhibitory control, and fine motor skills, which require precise and fast visuomotor coordination. These results highlight the potential benefits of QET intervention in ameliorating attention deficits and enhancing fine aiming motor skills in children with ADHD. However, task specificity was evident, indicating that the intervention effects were most pronounced for the hand fine motor aiming tasks requiring both precision and speed. © 2023 by the authors.",ADHD; attention; children; intervention; manual dexterity,alertness; analytical research; Article; attention; attention deficit hyperactivity disorder; child; cohort analysis; depth perception; executive function; eye fixation; eye tracking; female; gaze; go no go inhibition test; human; intervention study; learning; major clinical study; male; motor performance; neuropsychological assessment; neuropsychology; reaction time; school child; skill; training; videorecording; visuomotor coordination,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85175055633,Movies / Media
Lian X.; Sunar M.S.; Lian Q.; Mokhtar M.K.,"Lian, Xiaojie (57224070775); Sunar, Mohd Shahrizal (7004071446); Lian, Qingqing (58316386100); Mokhtar, Mohd Khalid (59206279100)",57224070775; 7004071446; 58316386100; 59206279100,Evaluating user interface of a mobile augmented reality coloring application for children with autism: An eye-tracking investigation,2023,International Journal of Human Computer Studies,178,,103085,,,,10,10.1016/j.ijhcs.2023.103085,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162104128&doi=10.1016%2fj.ijhcs.2023.103085&partnerID=40&md5=bfa319c6409e9a41322cfdb6d018a84e,"Mobile augmented reality (AR) solutions are increasingly being used to facilitate learning and skills training for children with autism spectrum disorder (ASD). Derived from the fact that mobile AR systems can be embedded with multimedia effects, such as 3D animations, sounds or personalized images, with potential benefits for learning and engagement. Many mobile AR-based applications have been developed over the past decade; however, little is known about how children with autism interact with mobile AR application interface elements, which limits the accessible user interface (UI) design of such applications. In this study, we conducted an eye-tracking experiment to examine how children with autism interact differently with the UI of mobile AR coloring apps compared to typically developing (TD) children. Both quantitative and qualitative data suggest that 1) icons and images were more attractive to ASD children and could facilitate their understanding of the task more effectively; 2) a richer interface makes participants with autism focus more on irrelevant elements; and 3) the size and position of icons affected their speed of information processing. We recommend that UI be designed to suit the characteristics of children with autism. For example, visual stimuli such as icons or images should be meaningful; screen elements need to be simple and clear; background distractions should be avoided; and text also needs to be brief and precise. This study is expected to inspire researchers to provide AR apps with accessible UIs in the future and improve the user experience (UX) of children with autism. © 2023",Accessible user interface; Autism children; Coloring augmented reality; Eye tracking; Mobile augmented reality app,Diseases; Embedded systems; Eye tracking; User interfaces; Accessible user interface; Autism child; Autism spectrum disorders; Children with autisms; Coloring augmented reality; Evaluating user interfaces; Eye-tracking; Mobile augmented reality; Mobile augmented reality app; Skill training; Augmented reality,Article,Final,,Scopus,2-s2.0-85162104128,Movies / Media
,,,Mensch und Computer 2023: Building Bridges - Proceedings,2023,ACM International Conference Proceeding Series,,,,,,582.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171172556&partnerID=40&md5=86672aaa415c24f76c097cbd905dd5d0,The proceedings contain 75 papers. The topics discussed include: understanding the effects of perceived avatar appearance on latency sensitivity in full-body motion-tracked virtual reality; increasing realism of displayed vibrating AR objects through edge blurring; head-anchored text placements and cognitive load in information-rich virtual environments; how are your participants feeling today? accounting for and assessing emotions in virtual reality; patient journey value mapping: illustrating values and experiences along the patient journey to support eHealth design; behind the screens: exploring eye movement visualization to optimize online teaching and learning; scalable design evaluation for everyone! designing configuration systems for crowd-feedback request generation; predicting mouse positions beyond a system’s latency can increase throughput and user experience in linear steering tasks; and HapticCollider: ungrounded force feedback for rigid collisions during virtual tool use.,,,Conference review,Final,,Scopus,2-s2.0-85171172556,Movies / Media
Shin J.H.; Shin D.A.; Lee C.Y.; Chang H.J.; Woo K.A.; Kim H.-J.; Lee J.C.; Jeon B.,"Shin, Jung Hwan (57200396056); Shin, Dong Ah (57314207900); Lee, Chan Young (57226649403); Chang, Hee Jin (57731595800); Woo, Kyung Ah (57204116157); Kim, Han-Joon (36067006300); Lee, Jung Chan (37960940900); Jeon, Beomseok (7102161956)",57200396056; 57314207900; 57226649403; 57731595800; 57204116157; 36067006300; 37960940900; 7102161956,Inability to suppress head rotation during the saccade test as a clinical biomarker for cognitive dysfunction in Parkinson's disease,2023,Neuroscience Letters,812,,137356,,,,1,10.1016/j.neulet.2023.137356,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164334440&doi=10.1016%2fj.neulet.2023.137356&partnerID=40&md5=37147f066599b4d096c8ab655ff43950,"Background: There is a need for development of reliable and accessible clinical biomarker for detecting cognitive dysfunction in PD. This study aimed to investigate whether involuntary head rotation during the saccade test could serve as a potential biomarker for screening cognitive dysfunction in PD. Methods: A total of 27 PD patients and nine age- and sex-matched healthy controls were prospectively enrolled in this study. A custom-designed gyroscope was attached to the forehead of each participant, and a saccade test consisting of 20 trials was conducted. The entire test was recorded on video, and two movement disorder experts independently rated the degree of head rotation, blinded to the patients' clinical information. The peak angular velocity of head rotation was derived from the gyroscope data. Participants underwent Montreal Cognitive Assessment (MoCA) as the cognitive evaluation. Correlation analysis was performed to assess the relationship between head rotation and MoCA scores. Results: The mean peak angular velocity of head rotation significantly correlated with the MoCA scores (R = -0.52, p = 0.0023) including age, sex, disease duration, and education duration as cofactors. The optimal peak angular velocity thresholds for head rotation, which aligned with the manual ratings, were determined to be 5°/s and 10°/s for raters 1 and 2, respectively. The MoCA scores exhibited significant correlations with the number of head rotations, using both the 5°/s (R = -0.36, p = 0.042) and 10°/s (R = -0.49, p = 0.0048) thresholds. Furthermore, the mean angular velocity of the head demonstrated a 100% positive predictive value and specificity for the detection of cognitive impairment (MoCA < 26), based on the cut-offs of 5°/s and 10°/s. Conclusion: Inability to suppress head rotation during saccades may serve as a potential clinical biomarker for screening cognitive dysfunction in PD. © 2023 Elsevier B.V.",Cognitive dysfunction; Head rotation; Parkinson disease; Saccade,Biomarkers; Cognitive Dysfunction; Humans; Mental Status and Dementia Tests; Parkinson Disease; Saccades; biological marker; biological marker; age distribution; aged; Article; clinical article; clinical evaluation; clinical feature; cognition; cognitive defect; controlled study; correlation analysis; demographics; disease duration; educational status; female; forehead; head movement; human; male; medical information; Montreal cognitive assessment; Parkinson disease; predictive value; prospective study; saccadic eye movement; saccadic velocity; screening test; sensitivity and specificity; sex difference; threshold limit value; videorecording; cognitive defect; complication; dementia assessment; Parkinson disease; psychology; saccadic eye movement,Article,Final,,Scopus,2-s2.0-85164334440,Movies / Media
Gál V.; Dömötör Z.,"Gál, Vera (57981021200); Dömötör, Zsuzsanna (56556752700)",57981021200; 56556752700,The role of connection with nature in empirical studies with physiological measurements: a systematic literature review,2023,Biologia Futura,74,3,,281,294,13.0,5,10.1007/s42977-023-00185-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174384292&doi=10.1007%2fs42977-023-00185-0&partnerID=40&md5=954bd3478e4b611575794fa4eb564207,"It is well described that exposure to nature reduces physiological stress, and connectedness to nature can have a moderating effect. However, few studies have so far examined the construction of the connection with nature in relation to physiological processes. In this systematic review, we collected studies that used a physiological measure and included a scale to measure connectedness to nature. Our aim was to assess the role of nature relatedness at the level of physiological processes and to summarize the results published so far. Our review was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. A literature search was conducted in 3 different databases (PubMed, ScienceDirect and Google Scholar). As keywords, we used all the different questionnaires that measure connectedness to nature, combined with terms related to physiological measures. After final screening, 28 articles met the inclusion criteria for the review. The studies were very diverse in terms of purpose, intervention and methods, so narrative synthesis was conducted without measures of effect. We found evidence for a mediating effect of nature connectedness on the associations between nature exposure and cognitive function, brain activity, blood pressure, cortisol level and mental health. Studies investigating nature relatedness as state-like characteristics have shown that exposure to nature increases the level of connection to nature. Eye-tracking studies have confirmed that this measurement method can be used to investigate nature relatedness at a physiological level, which could be a useful complement to self-report questionnaires in future studies. © 2023, The Author(s).",Connectedness to nature; Nature relatedness; Physiology; Stress,Humans; Mental Health; Surveys and Questionnaires; hydrocortisone; blood pressure; blood pressure monitoring; brain function; cognition; electroencephalogram; empiricism; eye tracking; human; human experiment; mental health; meta analysis; physiological process; physiological stress; questionnaire; Review; self report; systematic review; mental health,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85174384292,Movies / Media
Cui Y.; Liu X.; Cheng Y.,"Cui, Ying (57189663338); Liu, Xiao (58125967200); Cheng, Yuqin (58126718900)",57189663338; 58125967200; 58126718900,Attention-consuming or attention-saving: An eye tracking study on punctuation in Chinese subtitling of English trailers,2023,Multilingua,42,5,,739,763,24.0,2,10.1515/multi-2022-0138,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150425560&doi=10.1515%2fmulti-2022-0138&partnerID=40&md5=a877643483ca00c34f404beed8a08974,"Chinese subtitling of English trailers is essential for marketing foreign films in China, and there is a need to focus on audience reception. Ideal subtitles are expected to provide a necessary aid to the audience but to attract as little attention as possible. Paralinguistic factors like punctuation can influence the audience's attention and reception. Therefore, this study aims to explore the impact of punctuation on a Chinese audience's attention distribution between subtitles and visuals via the eye tracking technique. We recruited 62 participants and selected ten English trailers for films to be released. We prepared two parallel Chinese versions for each trailer, one using punctuation marks and the other using spaces. The participants were randomly assigned into two groups to watch the two versions respectively and filled out a questionnaire afterwards to rate their desire to watch those films. Data analyses show that, while punctuation does not have a significant impact on participants' attitudes towards the films, the version without punctuation causes less fixation on subtitles, implying that omitting punctuation marks can ensure more attention to the visual and hence a better viewing experience.  © 2023 Walter de Gruyter GmbH, Berlin/Boston.",attention; punctuation; subtitle; trailer; translation,,Article,Final,,Scopus,2-s2.0-85150425560,Movies / Media
Wiebe A.; Aslan B.; Brockmann C.; Lepartz A.; Dudek D.; Kannen K.; Selaskowski B.; Lux S.; Ettinger U.; Philipsen A.; Braun N.,"Wiebe, Annika (57659776400); Aslan, Behrem (57216769975); Brockmann, Charlotte (58260533800); Lepartz, Alexandra (58262271100); Dudek, Dominika (58716896500); Kannen, Kyra (57449172200); Selaskowski, Benjamin (57660098000); Lux, Silke (7005576971); Ettinger, Ulrich (6602766172); Philipsen, Alexandra (6603416864); Braun, Niclas (55972275100)",57659776400; 57216769975; 58260533800; 58262271100; 58716896500; 57449172200; 57660098000; 7005576971; 6602766172; 6603416864; 55972275100,Multimodal assessment of adult attention-deficit hyperactivity disorder: A controlled virtual seminar room study,2023,Clinical Psychology and Psychotherapy,30,5,,1111,1129,18.0,6,10.1002/cpp.2863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159669263&doi=10.1002%2fcpp.2863&partnerID=40&md5=d407f2aebc2419d58cac5bd9523293ba,"In the assessment of adult attention-deficit hyperactivity disorder (ADHD) symptoms, the diagnostic value of neuropsychological testing is limited. Partly, this is due to the rather low ecological validity of traditional neuropsychological tests, which usually present abstract stimuli on a computer screen. A potential remedy for this shortcoming might be the use of virtual reality (VR), which enables a more realistic and complex, yet still standardized test environment. The present study investigates a new VR-based multimodal assessment tool for adult ADHD, the virtual seminar room (VSR). Twenty-five unmedicated ADHD patients, 25 medicated ADHD patients, and 25 healthy controls underwent a virtual continuous performance task (CPT) in the VSR with concurrent visual, auditive, and audiovisual distractions. Simultaneously, head movements (actigraphy), gaze behaviour (eye tracking), subjective experience, electroencephalography (EEG), and functional near-infrared spectroscopy (fNIRS) were recorded. Significant differences between unmedicated patients with ADHD and healthy controls were found in CPT performance, head actigraphy, distractor gaze behaviour, and subjective experience. Moreover, CPT performance parameters demonstrated potential utility for assessing medication effects within the ADHD population. No group differences were found in the Theta-Beta-Ratio (EEG) or dorsolateral-prefrontal oxy-haemoglobin (fNIRS). Overall, the results are very promising regarding the potential of the VSR as an assessment tool for adult ADHD. In particular, the combined assessment of CPT, actigraphy, and eye tracking parameters appears to be a valid approach to more accurately capture the heterogeneous symptom presentation of the disorder. © 2023 The Authors. Clinical Psychology & Psychotherapy published by John Wiley & Sons Ltd.",ADHD; assessment; continuous performance task; eye tracking; fNIRS; virtual reality,Adult; Attention; Attention Deficit Disorder with Hyperactivity; Humans; Neuropsychological Tests; Research Design; Virtual Reality; adult; attention; attention deficit hyperactivity disorder; human; methodology; neuropsychological assessment; psychology; virtual reality,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85159669263,Movies / Media
Li H.; Lin S.; Wan B.,"Li, Haifeng (57269895500); Lin, Shiqing (58286324500); Wan, Bowen (58286857800)",57269895500; 58286324500; 58286857800,Value-directed attentional refreshing and its mechanism,2023,Acta Psychologica Sinica,55,8,,1234,1242,8.0,0,10.3724/SP.J.1041.2023.01234,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160048660&doi=10.3724%2fSP.J.1041.2023.01234&partnerID=40&md5=f22440509b58a93911270c319fd71bb6,"Attentional refreshing is the process of promoting and prolonging the activation of information in working memory (WM) by returning it to the focus of attention. This process can prevent the information in WM from fading over time or being disrupted by distractors. Previous studies have demonstrated that attentional refreshing can be guided by retro-cues or influenced by various experiences, such as reward-related or self-related stimuli. Recent studies have also explored the value effect in WM and found that people tend to prioritize more valuable information in WM, indicating that value may play a role in guiding attentional refreshing during retention. In a groundbreaking study by Atkinson et al. (2022), attentional refreshing was shown to partially explain the value effect in WM. However, the study was unable to determine why high-value information was prioritized for refreshing. It has been suggested that the value effect in WM may be due to a biased attentional refreshing procedure where individuals tend to focus more frequently or for longer periods on the more valuable item during retention, as compared to the other items. To investigate the value-directed attentional refreshing and its underlying mechanism, this study conducted three experiments. The sample size for each experiment was determined using G*power based on prior research, with 24, 23, and 24 participants in Experiments 1, 2, and 3, respectively. All experiments were designed with a within-subject design, with the independent variable being the value of the item (high or low). In Experiments 1 and 2, a value-directed memory paradigm and a dot probe task were used to examine whether high-value information was refreshed with higher priority than low-value information. Participants were asked to memorize 6 letters simultaneously (Experiment 1) or sequentially (Experiment 2) that were each assigned a value (e.g., 1 or 9) and perform a dot probe task during the memory retention stage. The probe stimuli appeared in either high-or low-value positions, and participants had to identify whether the two dots were arranged vertically or horizontally. They were then asked to recall the letters they remembered. Experiment 3 combined a value-directed memory paradigm and a blank screen paradigm and used Eeylink to further explore the mechanism of value-directed attentional refreshing. Participants were asked to memorize 4 regular grey graphs simultaneously, each with a corresponding value, and then a blank screen was presented to record their eye movements. Finally, one of the graphs was probed to test their memory. The results of Experiment 1 and Experiment 2 indicated that participants exhibited better recall performance for high-value items compared to low-value items, regardless of whether they were presented simultaneously or sequentially. Furthermore, participants had faster reaction times when responding to the dot probe task at the location of high-value items as opposed to low-value items. Experiment 3 also supported the finding that recall performance was better for high-value items than low-value items. Additionally, the study found that participants tended to have more fixations at the location of high-value items than low-value items during the blank screen period. However, there was no significant difference in fixation duration between high-value and low-value items. The above experiments directly confirmed the value-directed attentional refreshing that high-value information received priority for attentional refreshing in WM retention when compared to low-value information. More importantly, the results indicated that value-directed attentional refreshing might be achieved by increasing the refresh rate of high-value information rather than deploying more time on it. This study contributes to the research on attentional refreshing and provides new insights into how people prioritize information in their daily lives. Moreover, it sheds light on the mechanism of value-directed attentional refreshing and helps develop the time-based resource-sharing model to a certain extent. These findings can aid researchers in developing computational models that simulate people's attentional refreshing process. © 2023, Science Press. All rights reserved.",attentional refreshing; fixation duration; refresh rate; value-directed; working memory,,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85160048660,Movies / Media
Pina A.; Petersheim C.; Cherian J.; Lahey J.N.; Alexander G.; Hammond T.,"Pina, Angel (57880860100); Petersheim, Corbin (57879887900); Cherian, Josh (57201384313); Lahey, Joanna Nicole (25522396000); Alexander, Gerianne (7401920552); Hammond, Tracy (8552693500)",57880860100; 57879887900; 57201384313; 25522396000; 7401920552; 8552693500,Using Machine Learning with Eye-Tracking Data to Predict if a Recruiter Will Approve a Resume,2023,Machine Learning and Knowledge Extraction,5,3,,713,724,11.0,4,10.3390/make5030038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172769291&doi=10.3390%2fmake5030038&partnerID=40&md5=1ecb1113b405f737cdc9931de8c7130b,"When job seekers are unsuccessful in getting a position, they often do not get feedback to inform them on how to develop a better application in the future. Therefore, there is a critical need to understand what qualifications recruiters value in order to help applicants. To address this need, we utilized eye-trackers to measure and record visual data of recruiters screening resumes to gain insight into which Areas of Interest (AOIs) influenced recruiters’ decisions the most. Using just this eye-tracking data, we trained a machine learning classifier to predict whether or not a recruiter would move a resume on to the next level of the hiring process with an AUC of 0.767. We found that features associated with recruiters looking outside the content of a resume were most predictive of their decision as well as total time viewing the resume and time spent on the Experience and Education sections. We hypothesize that this behavior is indicative of the recruiter reflecting on the content of the resume. These initial results show that applicants should focus on designing clear and concise resumes that are easy for recruiters to absorb and think about, with additional attention given to the Experience and Education sections. © 2023 by the authors.",eye-tracking; machine learning; recruiter; resumes,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85172769291,Movies / Media
Koyano K.; Konishi Y.; Koyano K.; Nakamura S.; Kato I.; Nishida T.; Kusaka T.,"Koyano, Kaori (55559193100); Konishi, Yukihiko (37120632000); Koyano, Kosuke (26658129800); Nakamura, Shinji (55461817700); Kato, Ikuko (16316438700); Nishida, Tomoko (36194230200); Kusaka, Takashi (55774254200)",55559193100; 37120632000; 26658129800; 55461817700; 16316438700; 36194230200; 55774254200,Developmental changes in visual–cognitive and attentional functions in infancy,2023,Early Human Development,183,,105810,,,,0,10.1016/j.earlhumdev.2023.105810,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162930827&doi=10.1016%2fj.earlhumdev.2023.105810&partnerID=40&md5=177500d4c1b4cb66dd1af46e17597f57,"Background: Identifying developmental changes in visual-cognitive and attentional functions during infancy may lead to early diagnosis of neurodevelopmental disorders such as ASD and ADHD. Aims: To clarify the developmental changes in visual–cognitive and attentional functions during infancy (3–36 months of age). Study design: Cross-sectional study. Subjects: We included 23, 24, 31, and 26 participants aged 3, 9, 18, and 36 months, respectively (full-term births). Fifteen children who cried intensely or whose data could not be accurately recorded were excluded. Outcome measures: Three activities were given to each child while they were seated in front of a gaze-tracking device to evaluate re-gaze, motion transparency, and color–motion integration. We analyzed whether the child's attention shifted to the new stimulus in their peripheral vision in the re-gaze task. In the motion transparency and color–motion integration tasks, two images were presented simultaneously on the screen. In the motion transparency task, participants preferred random dots moving in opposite directions; in the color–motion task, they preferred subjective contours from apparent motion stimuli consisting of random red and green dots with different luminance. Results: In the re-gaze task, fewer 3-month-olds gazed at the new target than other age groups participants. All ages showed preference for target stimuli in the motion transparency task, but 3-month-olds showed significantly lower preference in the color–motion integration task. Conclusion: These tasks may be useful for measuring visual–cognitive and attentional functions in infants. © 2023 Elsevier B.V.",Eye tracker; Infant; Subjective contours from apparent motion; Transparent motion,Attention; Child; Cognition; Cross-Sectional Studies; Humans; Infant; Motion Perception; Visual Perception; Article; attention; color; controlled study; cross-sectional study; eye movement; eye tracking; female; gaze; human; infancy; infant; luminance; male; nervous system development; peripheral vision; vision; attention; child; cognition; movement perception; vision,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85162930827,Movies / Media
Eum B.; Dolbier S.; Rangel A.,"Eum, Brenden (58502947500); Dolbier, Stephanie (57755378100); Rangel, Antonio (55197210600)",58502947500; 57755378100; 55197210600,Peripheral Visual Information Halves Attentional Choice Biases,2023,Psychological Science,34,9,,984,998,14.0,4,10.1177/09567976231184878,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165549668&doi=10.1177%2f09567976231184878&partnerID=40&md5=0d79563449fd78f1e1ab788b9574f20c,"A growing body of research has shown that simple choices involve the construction and comparison of values at the time of decision. These processes are modulated by attention in a way that leaves decision makers susceptible to attentional biases. Here, we studied the role of peripheral visual information on the choice process and on attentional choice biases. We used an eye-tracking experiment in which participants (N = 50 adults) made binary choices between food items that were displayed in marked screen “shelves” in two conditions: (a) where both items were displayed, and (b) where items were displayed only when participants fixated within their shelves. We found that removing the nonfixated option approximately doubled the size of the attentional biases. The results show that peripheral visual information is crucial in facilitating good decisions and suggest that individuals might be influenceable by settings in which only one item is shown at a time, such as e-commerce. © The Author(s) 2023.",attention; decision making; fixations; neuroeconomics; simple choice,"Adult; Attention; Attentional Bias; Bias; Choice Behavior; Fixation, Ocular; Humans; adult; attention; attentional bias; decision making; eye fixation; human; statistical bias",Article,Final,,Scopus,2-s2.0-85165549668,Movies / Media
Jin H.; Shen H.; Liu C.; Wang L.; Mao C.; Chen J.; Liu C.-F.; Zhang Y.,"Jin, Hong (57195285408); Shen, Hong (58486178300); Liu, Chang (57730448800); Wang, Lanxiang (57730458500); Mao, Chengjie (23970983200); Chen, Jing (55974911600); Liu, Chun-feng (16750782000); Zhang, Yuan (35212316000)",57195285408; 58486178300; 57730448800; 57730458500; 23970983200; 55974911600; 16750782000; 35212316000,Decreased serum BDNF contributes to the onset of REM sleep behavior disorder in Parkinson's disease patients,2023,Neuroscience Letters,812,,137380,,,,2,10.1016/j.neulet.2023.137380,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164705975&doi=10.1016%2fj.neulet.2023.137380&partnerID=40&md5=0fdf8187f4718ad2a8004aa5946ee2b2,"Background: Brain-derived neurotrophic factor (BDNF) promotes neuroprotection and neuroregeneration. BDNF enhances the survival of dopaminergic neurons and improves dopaminergic neurotransmission and motor performance in patients with Parkinson's disease (PD). However, the association between BDNF levels and rapid eye movement (REM) sleep behavior disorder (RBD) in PD patients has received limited attention. Methods: We employed the Rapid Eye Movement Sleep Behavior Disorder Questionnaire-Hong Kong version (RBDQ-HK) and the Rapid Eye Movement Sleep Behavior Disorder Screening Questionnaire (RBDSQ) for RBD diagnosis. Patients were categorized into three groups: healthy controls (n = 53), PD patients without RBD (PD-nRBD; n = 56), and PD patients with RBD (PD-RBD; n = 45). Serum BDNF concentrations, demographic information, medical history, and motor/non-motor manifestations were compared between the three groups. Logistic regression analysis was performed to identify independent factors associated with PD and RBD. P-trend analysis was used to assess the relationship between BDNF levels and the risk of PD and RBD onset. Interaction effects were analyzed between BDNF, patients’ age, and gender on the risk of RBD onset in PD patients. Results: Our findings indicate that serum BDNF levels were significantly lower in PD patients compared to healthy controls (p < 0.001). PD-RBD patients exhibited higher motor symptom scores (UPDRS III) than PD-nRBD patients (p = 0.021). Additionally, the PD-RBD group demonstrated lower cognitive function scores as measured by the Montreal Cognitive Assessment (MoCA) (p < 0.001) and Mini-Mental State Examination (MMSE) (p = 0.015). PD-RBD patients displayed significantly lower BDNF levels compared to both PD-nRBD and healthy control groups (p < 0.001). Univariate and multivariate logistic regression analyses showed that reduced BDNF levels were associated with an increased risk of RBD in PD patients (p = 0.005). P-trend analysis further confirmed the progressive relationship between decreased BDNF levels and the risk of PD and RBD onset. Furthermore, our interaction analysis highlighted the importance of monitoring younger PD patients with low serum BDNF levels for potential RBD onset. Conclusions: This study illustrates that decreased serum BDNF levels may be linked to the development of RBD in PD patients, highlighting the potential utility of BDNF as a biomarker in clinical practice. © 2023",Brain-derived neurotrophic factor (BDNF); Parkinson's disease; Pathogenesis; Rapid Eye Movement Sleep Behavior Disorder (RBD); Serum levels; Sleep disturbances,Brain-Derived Neurotrophic Factor; Humans; Parkinson Disease; Polysomnography; REM Sleep Behavior Disorder; Surveys and Questionnaires; brain derived neurotrophic factor; levodopa; brain derived neurotrophic factor; adult; Article; blood sampling; cognition; cohort analysis; controlled study; disease duration; enzyme linked immunosorbent assay; female; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; Hoehn and Yahr scale; human; major clinical study; male; middle aged; Mini Mental State Examination; Montreal cognitive assessment; neurologic disease assessment; Parkinson disease; Parkinson disease questionnaire 39; protein blood level; rapid eye movement sleep behavior disorder questionnaire hong kong version; rapid eye movement sleep behavior disorder screening questionnaire; REM sleep behavior disorder; risk; sleep disorder assessment; Unified Parkinson Disease Rating Scale; Parkinson disease; polysomnography; questionnaire; REM sleep behavior disorder,Article,Final,,Scopus,2-s2.0-85164705975,Movies / Media
Bhadila G.Y.; Alyafi D.A.,"Bhadila, Ghalia Y. (57210700794); Alyafi, Dana A. (58553127600)",57210700794; 58553127600,The Use of Eye-Tracking Technology in Pediatric Orofacial Clefts: A Systematic Review and Meta-Analysis,2023,Children,10,8,1425,,,,2,10.3390/children10081425,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169063777&doi=10.3390%2fchildren10081425&partnerID=40&md5=7080a38a48584a6d3bedfeaf9324ebfb,"This systematic review and meta-analysis assessed the quality of the peer-reviewed literature and evaluated the usefulness of eye-tracking technology in evaluating observers’ perceptions of pediatric patients with orofacial clefts. PubMed, Science Direct, Wiley, and Web of Science were searched. Articles were screened in accordance with the Preferred Reporting Items for Systematic Review and Meta-analysis guidelines, and their methodological quality was assessed. Of the 10,254 identified studies, 12 were included. Eleven studies were cross-sectional, and one was a prospective cohort study. The main areas of interest analyzed were the eyes, nose, and mouth. Nine studies used assessment scales to analyze the link between perceived attractiveness and visualization patterns and measures. For the fixation duration outcome, six studies were eligible for inclusion in the meta-analysis. All studies reported on fixation duration in milliseconds and reported on a standard deviation. The meta-analysis demonstrated a significant difference in the measurements between the control groups and the patients with orofacial clefts. This might indicate the usefulness of eye-tracking technology as a metric for assessing the success of cleft repairs based on the perceptions of different populations. Future studies should be comprehensively reported on for comparability and reproducibility purposes. © 2023 by the authors.",cleft lip; craniofacial anomalies; eye tracking; pediatric dentistry; systematic review,cleft lip; cleft palate; eye-tracking technology; facial expression; facial recognition; human; Likert scale; meta analysis; pediatric patient; perception; Review; systematic review; visual attention; visual stimulation,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85169063777,Movies / Media
Dæhlen A.; Heldal I.; Ali Q.,"Dæhlen, Are (58026837400); Heldal, Ilona (6506576998); Ali, Qasim (57219972381)",58026837400; 6506576998; 57219972381,Technologies Supporting Screening Oculomotor Problems: Challenges for Virtual Reality,2023,Computers,12,7,134,,,,2,10.3390/computers12070134,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166397772&doi=10.3390%2fcomputers12070134&partnerID=40&md5=954519516cc17504ea88655f8560654c,"Oculomotor dysfunctions (OMDs) are problems relating to coordination and accuracy of eye movements for processing visual information. Eye-tracking (ET) technologies show great promise in the identification of OMDs. However, current computer technologies for vision screening are specialized devices with limited screen size and the inability to measure depth, while visual field and depth are important information for detecting OMDs. In this experimental study, we examine the possibilities of immersive virtual reality (VR) technologies compared with laptop technologies for increased user experiences, presence, immersiveness, and the use of serious games for identifying OMDs. The results present increased interest in VR-based screening, motivating users to focus better using VR applications free from outside distractions. These limitations currently include lower performance and confidence in results of identifying OMDs with the used HMDs. Using serious games for screening in VR is also estimated to have great potential for developing a more robust vision screening tool, especially for younger children. © 2023 by the authors.",eye-tracking; head-mounted display; immersiveness; oculomotor dysfunction; presence,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85166397772,Movies / Media
Levantini V.; Muratori P.; Calderoni S.; Inguaggiato E.; Masi G.; Milone A.; Tonacci A.; Billeci L.,"Levantini, Valentina (57194113964); Muratori, Pietro (36904806800); Calderoni, Sara (6506584767); Inguaggiato, Emanuela (56033320900); Masi, Gabriele (7005105897); Milone, Annarita (7004113345); Tonacci, Alessandro (55811791000); Billeci, Lucia (26533929800)",57194113964; 36904806800; 6506584767; 56033320900; 7005105897; 7004113345; 55811791000; 26533929800,Psychopathic traits and emotion processing in a clinical sample of children with disruptive behavior disorder,2023,Current Psychology,42,23,,19981,19990,9.0,9,10.1007/s12144-022-03138-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129153653&doi=10.1007%2fs12144-022-03138-3&partnerID=40&md5=be0075977074b4f4623d46b69dbee7cb,"Previous research identified emotion processing (i.e., emotion recognition and gaze pattern towards emotional stimuli) deficits in youths with callous-unemotional (CU) traits, though mixed results have emerged. CU traits frequently co-occur with high levels of the other psychopathy dimensions, namely narcissism and impulsivity, and overall, psychopathic traits in youths might be better understood from a multidimensional perspective. However, little is known about the contribution of narcissism and impulsivity. Participants included a clinical sample of 116 boys (aged 7–12) with Oppositional Defiant Disorder and Conduct Disorder based on the DSM-IV criteria. Psychopathic traits were assessed with the Antisocial Process Screening Device. Gaze pattern was recorded with an eye-tracker while participants completed a computerized emotion recognition task. Partial correlations showed negative associations between CU traits and sadness recognition and between narcissism and disgust recognition. Also, CU traits were associated with reduced attention to the mouth of angry faces and the eyes of sad and disgusted faces. Impulsivity was associated with greater attention to the eyes of angry and fearful faces. Narcissism was negatively associated with disgust recognition and the number of fixation to the eyes of angry faces, and positively associated with fixation count and duration to the mouth of angry faces. Findings support the association between CU traits and emotion processing deficits even after controlling for the effects of the other psychopathy dimensions. Our results also preliminary suggested emotional processing impairments associated with narcissism and impulsivity. A better understanding of emotional processing impairments associated with youths’ psychopathy dimensions would provide a new key to interpret extant literature and, more importantly, constitute a first step towards developing early tailored interventions. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Callous unemotional; Emotion recognition; Eye-tracking; Impulsivity; Narcissism,,Article,Final,,Scopus,2-s2.0-85129153653,Movies / Media
Chisari C.G.; Sciacca G.; Reggio E.; Terravecchia C.; Patti F.; Zappia M.,"Chisari, Clara Grazia (55338662900); Sciacca, Giorgia (6602140429); Reggio, Ester (6601999993); Terravecchia, Claudio (57211468567); Patti, Francesco (7006700571); Zappia, Mario (7004347995)",55338662900; 6602140429; 6601999993; 57211468567; 7006700571; 7004347995,Subclinical involvement of eye movements detected by video-based eye tracking in myasthenia gravis,2023,Neurological Sciences,44,7,,2555,2559,4.0,0,10.1007/s10072-023-06736-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150860866&doi=10.1007%2fs10072-023-06736-6&partnerID=40&md5=dc41489e71e71f798dcfaa050aadf05d,"Background: Ocular abnormalities in myasthenia gravis (MG) are characterized by severely limited movements and rapid saccades. Data about eye motility of MG patients whose ocular movements are apparently normal are lacking. Our study assessed the eye movement parameters in MG patients without clinical eye motility dysfunctions and investigated the effects of neostigmine administration on the eye motility in these patients. Materials: In this longitudinal study, we screened all patients diagnosed with MG referring to the Neurologic Clinic of the University of Catania between October 1, 2019, and June 30, 2021. Ten age- and sex-matched healthy controls were enrolled. Patients underwent eye movement recording using the EyeLink1000 Plus® eye tracker at baseline and after 90 min from the intramuscular administration of neostigmine (0.5 mg). Results: A total of 14 MG patients with no clinical signs of ocular motor dysfunction (64.3% men, with a mean age of 50.4 ± 14.4 years) were enrolled. At baseline, saccades in MG patients showed slower velocities and longer latencies compared to controls. Moreover, the fatigue test induced a reduction in saccadic velocity and an increase in latencies. After neostigmine administration, the ocular motility analysis showed shorter saccadic latencies and a significant improvement of velocities. Conclusions: Eye motility is impaired even in MG patients with no clinical evidence of ocular movement disturbance. Video-based eye tracking may detect subclinical involvement of eye movements in patients with MG. © 2023, Fondazione Società Italiana di Neurologia.",Eye movements; Myasthenia gravis; Neostigmine; Saccades,Adult; Eye Movements; Eye-Tracking Technology; Female; Humans; Longitudinal Studies; Male; Middle Aged; Myasthenia Gravis; Neostigmine; Saccades; neostigmine; neostigmine; adult; aged; Article; clinical article; controlled study; eye movement; eye tracking; female; human; latent period; longitudinal study; male; myasthenia gravis; saccadic velocity; videorecording; eye-tracking technology; middle aged; myasthenia gravis; saccadic eye movement,Article,Final,,Scopus,2-s2.0-85150860866,Movies / Media
Völter C.J.; Tomašić A.; Nipperdey L.; Huber L.,"Völter, Christoph J. (55953494400); Tomašić, Ana (58500673600); Nipperdey, Laura (58500794400); Huber, Ludwig (7102868913)",55953494400; 58500673600; 58500794400; 7102868913,Dogs' expectations about occlusion events: from expectancy violation to exploration,2023,Proceedings of the Royal Society B: Biological Sciences,290,2003,20230696,,,,8,10.1098/rspb.2023.0696,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165520448&doi=10.1098%2frspb.2023.0696&partnerID=40&md5=5f73499bb3a12aea583156766153b812,"Previous research on human infants has shown that violations of basic physical regularities can stimulate exploration, which may represent a type of hypothesis testing aimed at acquiring knowledge about new causal relationships. In this study, we examined whether a similar connection between expectancy violation and exploration exists in nonhuman animals. Specifically, we investigated how dogs react to expectancy violations in the context of occlusion events. Throughout three experiments, dogs exhibited longer looking times at expectancy-inconsistent events than at consistent ones. This finding was further supported by pupil size analyses in the first two eye-tracking experiments. Our results suggest that dogs expect objects to reappear when they are not obstructed by a screen and consider the size of the occluding screen in relation to the occluded object. In Experiment 3, expectancy violations increased the dogs' exploration of the target object, similar to the findings with human infants. We conclude that expectancy violations can provide learning opportunities for nonhuman animals as well.  © 2023 The Authors.",canine cognition; eye tracking; information seeking; physical cognition; pupillometry; violation of expectation,Animals; Dogs; Humans; Infant; Learning; Motivation; cognition; detection method; experimental study; exploration; hypothesis testing; tracking; animal; dog; human; infant; learning; motivation,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85165520448,Movies / Media
Yin Y.; Wang H.; Liu S.; Sun J.; Jing P.; Liu Y.,"Yin, Yunpeng (58128209900); Wang, Han (56969829000); Liu, Shuai (55798338500); Sun, Jinglin (57204103351); Jing, Peiguang (56971244300); Liu, Yu (57221874222)",58128209900; 56969829000; 55798338500; 57204103351; 56971244300; 57221874222,Internet of Things for Diagnosis of Alzheimer's Disease: A Multimodal Machine Learning Approach Based on Eye Movement Features,2023,IEEE Internet of Things Journal,10,13,,11476,11485,9.0,13,10.1109/JIOT.2023.3245067,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149388941&doi=10.1109%2fJIOT.2023.3245067&partnerID=40&md5=a718eb73fe622cd253b7f710a4c45e25,"Alzheimer's disease (AD) is a degenerative neurological disease that occurs in the elderly with typical symptoms of decline in cognition, manifested by eye movement behaviors. The key to AD treatment requires early detection of cognitive impairment, which relies on frequent medical screening. This article proposes an Internet of Things (IoT) architecture constructed with eye-tracker (ET) nodes and cloud-based diagnosis enabled by machine learning (ML), which can provide convenient screening of oculomotor abnormalities and automatic identification of early-stage AD. The bespoke ET nodes collect 3-D oculomotor responses from diverse stereo video stimulation trials and transmit data into a dedicated multimodal ML (MMML) algorithm in the cloud. The algorithm incorporates multimodal features extracted from diverse oculomotor types to enhance the classification accuracy and optimized data dimension reduction in feature fusion to improve the classifier's performance. From evaluation, the proposed method can distinguish AD patients from the control group with 86% accuracy (ACC), 78% true positive rate (TPR), and 90% positive predictive value (PPV). The results confirm the effectiveness of our MMML algorithm in AD diagnosis with the fusion of multimodal oculomotor features and prove the feasibility of our IoT-powered eye-tracking solution for AD screening.  © 2014 IEEE.",Alzheimer-s disease (AD); eye tracking; feature fusion; Internet of Things (IoT); multimodal machine learning (MMML); oculomotor behavior,Automation; Data mining; Diagnosis; Eye movements; Feature extraction; Internet of things; Job analysis; Stereo image processing; Alzheimer; Alzheimer’s disease; Cloud-computing; Eye-tracking; Features extraction; Features fusions; Gaze-tracking; Machine-learning; Multi-modal; Multimodal machine learning; Oculomotor behavior; Sensitivity; Task analysis; Eye tracking,Article,Final,,Scopus,2-s2.0-85149388941,Movies / Media
De Roeck L.; Gillebert C.R.; Van Aert R.C.M.; Vanmeenen A.; Klein M.; Taphoorn M.J.B.; Gehring K.; Lambrecht M.; Sleurs C.,"De Roeck, Laurien (57202918812); Gillebert, Celine R. (23990683200); Van Aert, Robbie C.M. (56043510400); Vanmeenen, Amber (58518471400); Klein, Martin (35454106200); Taphoorn, Martin J.B. (7004048810); Gehring, Karin (24174209400); Lambrecht, Maarten (35177617700); Sleurs, Charlotte (57189522125)",57202918812; 23990683200; 56043510400; 58518471400; 35454106200; 7004048810; 24174209400; 35177617700; 57189522125,Cognitive outcomes after multimodal treatment in adult glioma patients: A meta-analysis,2023,Neuro-Oncology,25,8,,1395,1414,19.0,20,10.1093/neuonc/noad045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166442431&doi=10.1093%2fneuonc%2fnoad045&partnerID=40&md5=7ef18c617c714c93eb171d235b487c55,"Background: Cognitive functioning is increasingly assessed as a secondary outcome in neuro-oncological trials. However, which cognitive domains or tests to assess, remains debatable. In this meta-analysis, we aimed to elucidate the longer-term test-specific cognitive outcomes in adult glioma patients. Methods: A systematic search yielded 7098 articles for screening. To investigate cognitive changes in glioma patients and differences between patients and controls 1-year follow-up, random-effects meta-analyses were conducted per cognitive test, separately for studies with a longitudinal and cross-sectional design. A meta-regression analysis with a moderator for interval testing (additional cognitive testing between baseline and 1-year posttreatment) was performed to investigate the impact of practice in longitudinal designs. Results: Eighty-three studies were reviewed, of which 37 were analyzed in the meta-analysis, involving 4078 patients. In longitudinal designs, semantic fluency was the most sensitive test to detect cognitive decline over time. Cognitive performance on mini-mental state exam (MMSE), digit span forward, phonemic and semantic fluency declined over time in patients who had no interval testing. In cross-sectional studies, patients performed worse than controls on the MMSE, digit span backward, semantic fluency, Stroop speed interference task, trail-making test B, and finger tapping. Conclusions: Cognitive performance of glioma patients 1 year after treatment is significantly lower compared to the norm, with specific tests potentially being more sensitive. Cognitive decline over time occurs as well, but can easily be overlooked in longitudinal designs due to practice effects (as a result of interval testing). It is warranted to sufficiently correct for practice effects in future longitudinal trials.  © The Author(s) 2023.",Adult; Cognition; Cognitive evaluation; Glioma; Meta-analysis,Adult; Cognition; Cognition Disorders; Combined Modality Therapy; Cross-Sectional Studies; Glioma; Humans; Neuropsychological Tests; cancer patient; cancer therapy; cognition; eye tracking; finger; follow up; glioma; histology; human; language; mental health; mental performance; meta analysis; Mini Mental State Examination; multimodal chemotherapy; neuropsychological assessment; nuclear magnetic resonance imaging; outcome assessment; prevalence; quality of life; randomized controlled trial (topic); Review; sensitivity and specificity; Stroop test; systematic review; trail making test; velocity; verbal memory; visual memory; working memory; adult; cognition; cognitive defect; complication; cross-sectional study; glioma; multimodality cancer therapy,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85166442431,Movies / Media
Wolf J.; Luchmann D.; Lohmeyer Q.; Farshad M.; Fürnstahl P.; Meboldt M.,"Wolf, Julian (57222473698); Luchmann, Dietmar (58107893100); Lohmeyer, Quentin (43461718100); Farshad, Mazda (36489356000); Fürnstahl, Philipp (24766313100); Meboldt, Mirko (22835485400)",57222473698; 58107893100; 43461718100; 36489356000; 24766313100; 22835485400,"How different augmented reality visualizations for drilling affect trajectory deviation, visual attention, and user experience",2023,International Journal of Computer Assisted Radiology and Surgery,18,8,,1363,1371,8.0,15,10.1007/s11548-022-02819-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148365441&doi=10.1007%2fs11548-022-02819-5&partnerID=40&md5=5e4985fb201477abd3ba501c791292fc,"Purpose: Previous work has demonstrated the high accuracy of augmented reality (AR) head-mounted displays for pedicle screw placement in spinal fusion surgery. An important question that remains unanswered is how pedicle screw trajectories should be visualized in AR to best assist the surgeon. Methodology: We compared five AR visualizations displaying the drill trajectory via Microsoft HoloLens 2 with different configurations of abstraction level (abstract or anatomical), position (overlay or small offset), and dimensionality (2D or 3D) against standard navigation on an external screen. We tested these visualizations in a study with 4 expert surgeons and 10 novices (residents in orthopedic surgery) on lumbar spine models covered by Plasticine. We assessed trajectory deviations (∘) from the preoperative plan, dwell times (%) on areas of interest, and the user experience. Results: Two AR visualizations resulted in significantly lower trajectory deviations (mixed-effects ANOVA, p<0.0001 and p<0.05) compared to standard navigation, whereas no significant differences were found between participant groups. The best ratings for ease of use and cognitive load were obtained with an abstract visualization displayed peripherally around the entry point and with a 3D anatomical visualization displayed with some offset. For visualizations displayed with some offset, participants spent on average only 20% of their time examining the entry point area. Conclusion: Our results show that real-time feedback provided by navigation can level task performance between experts and novices, and that the design of a visualization has a significant impact on task performance, visual attention, and user experience. Both abstract and anatomical visualizations can be suitable for navigation when not directly occluding the execution area. Our results shed light on how AR visualizations guide visual attention and the benefits of anchoring information in the peripheral field around the entry point. © 2023, The Author(s).",Cognitive load; Eye tracking; Mixed reality; Surgical navigation; Usability,"Augmented Reality; Humans; Lumbar Vertebrae; Pedicle Screws; Spinal Fusion; Surgery, Computer-Assisted; adult; analysis of variance; Article; augmented reality; cognitive load; comparative study; controlled study; dwell time; eye tracking; Friedman test; gold standard; human; lumbar spine; normal distribution; orthopedic surgery; personal experience; preoperative evaluation; questionnaire; resident; task performance; usability; visual attention; computer assisted surgery; lumbar vertebra; procedures; spine fusion; surgery",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85148365441,Movies / Media
Barbierato E.; Berti D.; Ranfagni S.; Hernández-Álvarez L.; Bernetti I.,"Barbierato, Elena (57210319768); Berti, Danio (58125763200); Ranfagni, Silvia (17344402700); Hernández-Álvarez, Luis (57215213212); Bernetti, Iacopo (6507189173)",57210319768; 58125763200; 17344402700; 57215213212; 6507189173,Wine label design proposals: an eye-tracking study to analyze consumers’ visual attention and preferences,2023,International Journal of Wine Business Research,35,3,,365,389,24.0,21,10.1108/IJWBR-06-2022-0021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149307649&doi=10.1108%2fIJWBR-06-2022-0021&partnerID=40&md5=85ebb1b1cd1a8251d1738db07f1987bf,"Purpose: The main purpose of this study is to analyze how consumers’ visual attention to wine label design correlates with their preferences. Accordingly, this study uses quantitative eye-tracking metrics to understand which design proposal has greater visual salience. A more specific objective was to assess which design proposal was preferred to be marketed. Design/methodology/approach: The experiment involved evaluating of three different labeling proposals of an Italian winery. Infrared eye-tracking was used to measure implicit eye movements on the three bottles displayed, simultaneously, on a computer screen. A generalized linear model was used to test how consumers' visual attention to wine label design correlated with their preferences. Findings: The design proposals were evaluated significantly differently, with one set being preferred. In general, a strong positive relationship was found between pausing to peruse a specific design proposal and making an explicit choice of the same bottle. Research limitations/implications: The main limitation of the experiment concerns the sample interviewed. As the sample is homogeneous, the results may not be generalizable to other segments. Furthermore, the addition of electroencephalographic devices that monitor brain activity could provide crucial information for understanding consumer behavior during the purchase decision-making process. Practical implications: Eye-tracking methods could be useful for designers and wine producers during the evaluation process of design projects. Originality/value: The use of eye-tracking for evaluating design proposals before placing a product on the market is relatively novel. This method provides objective, quantitative and predictive information on consumer preferences contributing guidelines to designers and marketers during the product conception phase. © 2023, Elena Barbierato, Danio Berti, Silvia Ranfagni, Luis Hernández-Álvarez and Iacopo Bernetti.",Consumer behavior; Eye-tracking; Neuromarketing; Visual attention; Wine label design,,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85149307649,Movies / Media
Tsang T.; Naples A.J.; Barney E.C.; Xie M.; Bernier R.; Dawson G.; Dziura J.; Faja S.; Jeste S.S.; McPartland J.C.; Nelson C.A.; Murias M.; Seow H.; Sugar C.; Webb S.J.; Shic F.; Johnson S.P.,"Tsang, Tawny (56526327400); Naples, Adam J. (15751541600); Barney, Erin C. (57189043347); Xie, Minhang (57727116400); Bernier, Raphael (57203215362); Dawson, Geraldine (59028708100); Dziura, James (6602746173); Faja, Susan (11940331000); Jeste, Shafali Spurling (34971242400); McPartland, James C. (7005050670); Nelson, Charles A. (35446590800); Murias, Michael (8053526600); Seow, Helen (59857136100); Sugar, Catherine (6602747302); Webb, Sara J. (7402908124); Shic, Frederick (6507802882); Johnson, Scott P. (7406328099)",56526327400; 15751541600; 57189043347; 57727116400; 57203215362; 59028708100; 6602746173; 11940331000; 34971242400; 7005050670; 35446590800; 8053526600; 59857136100; 6602747302; 7402908124; 6507802882; 7406328099,Attention Allocation During Exploration of Visual Arrays in ASD: Results from the ABC-CT Feasibility Study,2023,Journal of Autism and Developmental Disorders,53,8,,3220,3229,9.0,2,10.1007/s10803-022-05569-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131325323&doi=10.1007%2fs10803-022-05569-0&partnerID=40&md5=1a03810f8a891a3d9451b9932c419a9a,"Visual exploration paradigms involving object arrays have been used to examine salience of social stimuli such as faces in ASD. Recent work suggests performance on these paradigms may associate with clinical features of ASD. We evaluate metrics from a visual exploration paradigm in 4-to-11-year-old children with ASD (n = 23; 18 males) and typical development (TD; n = 23; 13 males). Presented with arrays containing faces and nonsocial stimuli, children with ASD looked less at (p = 0.002) and showed fewer fixations to (p = 0.022) faces than TD children, and spent less time looking at each object on average (p = 0.004). Attention to the screen and faces correlated positively with social and cognitive skills in the ASD group (ps <.05). This work furthers our understanding of objective measures of visual exploration in ASD and its potential for quantifying features of ASD. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Autism spectrum disorder; Eye-tracking; Visual exploration; Visual processing; Visual search,"Autism Spectrum Disorder; Benchmarking; Child; Child, Preschool; Feasibility Studies; Humans; Male; Tomography, X-Ray Computed; Article; autism; child; clinical article; controlled study; feasibility study; female; human; male; skill; social competence; vision; autism; benchmarking; preschool child; psychology; x-ray computed tomography",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85131325323,Movies / Media
Takai S.; Kanno A.; Kawase T.; Shirakura M.; Suzuki J.; Nakasato N.; Kawashima R.; Katori Y.,"Takai, Shunsuke (58194227500); Kanno, Akitake (7005078869); Kawase, Tetsuaki (7202598372); Shirakura, Masayuki (57201417809); Suzuki, Jun (55628567177); Nakasato, Nobukatsu (7006207307); Kawashima, Ryuta (7005986241); Katori, Yukio (7004061253)",58194227500; 7005078869; 7202598372; 57201417809; 55628567177; 7006207307; 7005986241; 7004061253,Possibility of additive effects by the presentation of visual information related to distractor sounds on the contra-sound effects of the N100m responses,2023,Hearing Research,434,,108778,,,,1,10.1016/j.heares.2023.108778,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153381320&doi=10.1016%2fj.heares.2023.108778&partnerID=40&md5=c6984dccb5429a7a5e2d69893f1375f9,"Auditory-evoked responses can be affected by different types of contralateral sounds or by attention modulation. The present study examined the additive effects of presenting visual information about contralateral sounds as distractions during dichotic listening tasks on the contralateral effects of N100m responses in the auditory-evoked cortex in 16 subjects (12 males and 4 females). In magnetoencephalography, a tone-burst of 500 ms duration at a frequency of 1000 Hz was played to the left ear at a level of 70 dB as a stimulus to elicit the N100m response, and a movie clip was used as a distractor stimulus under audio-only, visual-only, and audio-visual conditions. Subjects were instructed to pay attention to the left ear and press the response button each time they heard a tone-burst stimulus in their left ear. The results suggest that the presentation of visual information related to the contralateral sound, which worked as a distractor, significantly suppressed the amplitude of the N100m response compared with only the contralateral sound condition. In contrast, the presentation of visual information related to contralateral sound did not affect the latency of the N100m response. These results suggest that the integration of contralateral sounds and related movies may have resulted in a more perceptually loaded stimulus and reduced the intensity of attention to tone-bursts. Our findings suggest that selective attention and saliency mechanisms may have cross-modal effects on other modes of perception. © 2023 Elsevier B.V.",Cross-modal effects; Magnetoencephalography; N100m; Saliency; Selective attention,"Auditory Cortex; Auditory Perception; Evoked Potentials, Auditory; Female; Humans; Magnetoencephalography; Male; Sound; additive effect; adult; alpha rhythm; Article; attention; auditory cortex; auditory stimulation; brain cortex; clinical article; contralateral sound; dichotic listening; Edinburgh Handedness Inventory score; electroencephalography; electrophysiology; event related potential; eye tracking; female; Fourier transform; habituation; human; latent period; magnetoencephalography; male; mesencephalon; perception; scoring system; selective attention; signal noise ratio; sound; stimulus; visual information; visual stimulation; auditory cortex; auditory evoked potential; hearing; magnetoencephalography; physiology; procedures; sound",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85153381320,Movies / Media
Tang Z.; Liu X.; Huo H.; Tang M.; Qiao X.; Chen D.; Dong Y.; Fan L.; Wang J.; Du X.; Guo J.; Fan Y.,"Tang, Zhili (57226890312); Liu, Xiaoyu (57218655037); Huo, Hongqiang (57202436822); Tang, Min (57226893595); Qiao, Xiaofeng (57704039100); Chen, Duo (57216855150); Dong, Ying (57222476946); Fan, Linyuan (57704040700); Wang, Jinghui (57699015300); Du, Xin (57704726900); Guo, Jieyi (58155870300); Fan, Yubo (55648008700)",57226890312; 57218655037; 57202436822; 57226893595; 57704039100; 57216855150; 57222476946; 57704040700; 57699015300; 57704726900; 58155870300; 55648008700,Sex differences in eye movements and neural oscillations during mental rotation in virtual reality,2023,Medicine in Novel Technology and Devices,18,,100233,,,,4,10.1016/j.medntd.2023.100233,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154052419&doi=10.1016%2fj.medntd.2023.100233&partnerID=40&md5=97446a7865057fdbeed87de94337a536,"Virtual reality (VR) has been a promising tool for developing visuospatial tasks. Among visuospatial tasks, mental rotation tasks are widely used in the assessment of visuospatial ability. Males have a distinct advantage in mental rotation ability compared to females, yet it is generally produced by investigations based on two-dimensional (2D) images on a computer screen. Sex differences in mental rotation tasks with three-dimensional (3D) objects in VR were not fully investigated. It is unclear whether the male's advantages in 2D mental rotation tasks are weakened in 3D tasks. The aim of this study was to provide new insights into the understanding of sex differences in mental rotation tasks presented in VR. Here, we developed a VR mental rotation task (VR-MRT) using 3D objects presented by a head-mounted display (HMD) and used VR-based eye tracking and electroencephalography (EEG) to examine eye movements and neural oscillations for males and females. Our results showed that females preferred a piecemeal strategy compared to males, suggesting a significant sex difference in visual strategy. More importantly, we found no significant sex differences in alpha-band and beta-band oscillations related to rotation processes of VR-MRT. These findings indicated that sex differences in the VR-MRT were mainly attributed to the selection of visual strategy rather than the rotation processes. The study helps to comprehensively understand the dominant factors contributing to the sex differences in the VR-MRT. © 2023",Alpha oscillations; Eye movements; Mental rotation; Sex differences; Virtual reality,adult; Article; behavior; cognition; electroencephalography; eye movement; eye tracking; female; human; human experiment; image analysis; imagery; male; normal human; oscillation; rotation; sex difference; three-dimensional imaging; virtual reality; young adult,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85154052419,Movies / Media
Xu Z.; Hu J.; Wang Y.,"Xu, Zhenjie (58184774200); Hu, Jie (58184636100); Wang, Yingying (56708986100)",58184774200; 58184636100; 56708986100,Bilateral eye movements disrupt the involuntary perceptual representation of trauma-related memories,2023,Behaviour Research and Therapy,165,,104311,,,,6,10.1016/j.brat.2023.104311,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152596385&doi=10.1016%2fj.brat.2023.104311&partnerID=40&md5=14469cb0053ffd8a83a648b018c0663d,"Bilateral eye movement (EM) is a critical component in eye movement desensitization and reprocessing (EMDR), an effective treatment for post-traumatic stress disorder. However, the role of bilateral EM in alleviating trauma-related symptoms is unclear. Here we hypothesize that bilateral EM selectively disrupts the perceptual representation of traumatic memories. We used the trauma film paradigm as an analog for trauma experience. Nonclinical participants viewed trauma films followed by a bilateral EM intervention or a static Fixation period as a control. Perceptual and semantic memories for the film were assessed with different measures. Results showed a significant decrease in perceptual memory recognition shortly after the EM intervention and subsequently in the frequency and vividness of film-related memory intrusions across one week, relative to the Fixation condition. The EM intervention did not affect the explicit recognition of semantic memories, suggesting a dissociation between perceptual and semantic memory disruption. Furthermore, the EM intervention effectively reduced psychophysiological affective responses, including the skin conductance response and pupil size, to film scenes and subjective affective ratings of film-related intrusions. Together, bilateral EMs effectively reduce the perceptual representation and affective response of trauma-related memories. Further theoretical developments are needed to elucidate the mechanism of bilateral EMs in trauma treatment. © 2023 Elsevier Ltd",Eye movement desensitization and reprocessing (EMDR); Memory intrusions; Pupil size; Skin conductance response (SCR); Trauma film paradigm (TFP),"Attention; Eye Movement Desensitization Reprocessing; Eye Movements; Humans; Memory; Stress Disorders, Post-Traumatic; Treatment Outcome; adult; article; controlled study; dissociation; electrodermal response; eye movement; eye movement desensitization and reprocessing; human; memory; pupil diameter; semantic memory; theoretical study; attention; eye movement; memory; physiology; posttraumatic stress disorder; procedures; psychology; treatment outcome",Article,Final,,Scopus,2-s2.0-85152596385,Movies / Media
Ehlers J.; Grimmer J.,"Ehlers, Jan (56624120300); Grimmer, Janine (57223223362)",56624120300; 57223223362,Visual Center Biasing in a Stimulus-Free Laboratory Setting,2023,Eye Tracking Research and Applications Symposium (ETRA),,,22,,,,0,10.1145/3588015.3588421,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161238098&doi=10.1145%2f3588015.3588421&partnerID=40&md5=a17898c9db654082dbdcf9f77fd9adc0,"Looking at nothing has recently become of particular interest as it may reveal insights into the nature of spatial cognition in terms of integrated mental representations from visual and auditory input. The current study applies individual time sensitive and emotional ideas to quantify visuo-spatial biases in a stimulus-free laboratory setting. We observe a strong visual bias across all experimental conditions supporting earlier assumptions of a screen center or motor bias. The tendency towards the center was particular evident during trials that lack any specific assignment. A time-sensitive differentiation of eye movements with regards to memory and anticipation tasks could not be recorded. Also, pupil diameter indicated no relationship between changes in bodily arousal and spontaneous fixation behavior. In addition, we replicate a strong left side gaze asymmetry that is interwoven with the center bias featuring spontaneous fixations to mainly cluster left from the screen center.  © 2023 Owner/Author.",Center Bias; Eye movements; Gaze Asymmetry; Pupil Diameter,'current; Center bias; Experimental conditions; Gaze asymmetry; Mental representations; Pupil diameter; Spatial cognition; Eye movements,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85161238098,Movies / Media
Li W.-C.; Korek W.T.; Liang Y.H.; Lin J.J.H.,"Li, Wen-Chin (36064620900); Korek, Wojciech Tomasz (57218262943); Liang, Yung Hsiang (57768278800); Lin, John J.H. (58912142500)",36064620900; 57218262943; 57768278800; 58912142500,Touchscreen Controls for Future Flight Deck Design: Investigating Visual Parameters on Human-Computer Interactions between Pilot Flying and Pilot Monitoring,2023,"Journal of Aeronautics, Astronautics and Aviation ",55,2,,201,211,10.0,1,10.6125/JoAAA.202306_55(2).08,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158866773&doi=10.6125%2fJoAAA.202306_55%282%29.08&partnerID=40&md5=bce3ad70ca480719dff5c9388ee688fd,"This study is concentrated on investigating the different visual behaviors and HCI patterns between pilot flying and pilot monitoring while interacting with touchscreen controls on the flight deck. Twelve participants with flight experiences (M=1150, SD=4019.9) attended this research. The apparatus included Future Systems Simulator (FSS), eye tracker, and system usability scale (SUS). The designated scenario in the experiment was an instrument landing. All participants were required to perform two instrument landings in two different roles, pilot flying (PF) and pilot monitoring (PM). The order of role of randomized to eliminate practice effects. The results revealed that fixation counts of pilot flying were different among four AOIs, F (3, 9) = 10.58, p = .003, ηp2 = .78. On the other hand, the FC of pilot monitoring demonstrated a significant difference among four AOIs, F (3, 8) = 8.69, p = .007, ηp2 = .77. There was a significant difference between PF and PM on the subjective assessment of SUS total score, t (11) =3.85, p = 0.003, Cohen’s d= 1.11. The application of a touchscreen can integrate input and output in the same area for visual feedback. There is a rising need to simplify the future flight deck design based on the principle of human-centered design. Conclusion: The application of touchscreen flight controls may have the potential to facilitate single-pilot operations flight deck design in the future. TSCs considerations must be consistent with human information processing and pilots’ operational characteristics on the future flight deck. © 2023 The Aeronautical and Astronautical Society of the Republic of China. All rights reserved.",Future System Simulator; Human-Computer Interactions; System Usability; Touchscreen Controls; Visual Attention,Behavioral research; Eye tracking; Visual communication; Eye trackers; Flight deck design; Flight decks; Future system simulator; Subjective assessments; System simulator; System usability; Touchscreen controls; Visual Attention; Visual behavior; Human computer interaction,Article,Final,,Scopus,2-s2.0-85158866773,Movies / Media
Cicero C.E.; Luca A.; Mostile G.; Donzuso G.; Giuliano L.; Zappia M.; Nicoletti A.,"Cicero, Calogero Edoardo (56684992200); Luca, Antonina (21233947000); Mostile, Giovanni (35798804700); Donzuso, Giulia (41561290700); Giuliano, Loretta (55920088300); Zappia, Mario (7004347995); Nicoletti, Alessandra (7005326571)",56684992200; 21233947000; 35798804700; 41561290700; 55920088300; 7004347995; 7005326571,Influence of RBD onset on the clinical characteristics of Parkinson’s disease patients: a retrospective study,2023,Journal of Neurology,270,6,,3171,3178,7.0,11,10.1007/s00415-023-11659-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149639854&doi=10.1007%2fs00415-023-11659-5&partnerID=40&md5=ce077c00382f0dbaa637413ff9f1648d,"Introduction: In Parkinson’s disease (PD), rapid eye movement (REM) sleep behavior disorder (RBD) might either precede the appearance of motor symptoms, or develop during the disease course. PD patients with RBD are characterized by a higher burden of cognitive impairment and hallucinations. However, few studies have analyzed the clinical characteristics of PD patients according to the timeline of RBD onset. Methods: PD patients have been retrospectively enrolled. Presence and onset of probable RBD (pRBD) has been evaluated using RBD Screening Questionnaire (score ≥ 6). Presence of Mild Cognitive Impairment (MCI) at baseline has been evaluated using the MDS criteria level II. Presence of motor complications and hallucinations has been evaluated at a 5-year follow-up. Results: A total of 115 PD patients (65 men, 56.5%; mean age 62.5 ± 9.7 years; mean disease duration 3.7 ± 3.9 years) have been enrolled. Out of these, 63 fulfilled the diagnosis of pRBD (54.8%) with 21 (33.3%) reporting the RBD onset before the onset of the motor symptoms (PD-RBDpre), and 42 (66.7%) after the motor symptoms (PD-RBDpost). At enrolment presence of MCI was associated with PD-RBDpre patients (OR 5.04; 95% CI 1.33–19.05; p value 0.02). At follow-up, a higher risk of developing hallucinations was also associated with PD-RBDpre (OR 4.68; 95% CI 1.24–17.63; p = 0.022). Conclusions: PD patients with RBD occurring before the onset of motor symptoms represent a subgroup of patients with a more severe cognitive phenotype and with a higher risk of developing hallucinations along the disease course, with significant implications in terms of prognostic stratification and therapeutic approach. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany.",Cognitive impairment; Hallucinations; Parkinson’s disease; REM sleep behavior disorder,Disease Progression; Hallucinations; Humans; Parkinson Disease; Prognosis; REM Sleep Behavior Disorder; Retrospective Studies; adult; Article; clinical feature; clock drawing test; cognition; controlled study; disease course; disease duration; evaluation study; executive function; female; follow up; hallucination; human; major clinical study; male; middle aged; Mini Mental State Examination; neuropsychological assessment; outpatient department; Parkinson disease; REM sleep behavior disorder; retrospective study; Rey auditory verbal learning test; semi structured interview; Stroop test; Unified Parkinson Disease Rating Scale; complication; disease exacerbation; hallucination; Parkinson disease; prognosis; psychology; REM sleep behavior disorder,Article,Final,,Scopus,2-s2.0-85149639854,Movies / Media
Ozawa M.; Murakami H.; Shiraishi T.; Umehara T.; Omoto S.; Iguchi Y.,"Ozawa, Masakazu (57967257000); Murakami, Hidetomo (36853003100); Shiraishi, Tomotaka (57202753478); Umehara, Tadashi (36085559800); Omoto, Shusaku (14061018100); Iguchi, Yasuyuki (10242457700)",57967257000; 36853003100; 57202753478; 36085559800; 14061018100; 10242457700,Rapid eye movement sleep behavior disorder is associated with decreased quality of life and stigma in people with Parkinson’s disease,2023,Acta Neurologica Belgica,123,3,,1073,1079,6.0,4,10.1007/s13760-023-02213-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150445337&doi=10.1007%2fs13760-023-02213-1&partnerID=40&md5=d47edab0e457084ea9bc6f76c9fcb0d1,"Background: Individuals with Parkinson’s disease (PD) may present with rapid eye movement sleep behavior disorder (RBD). We therefore investigated the association between RBD and quality of life (QOL) in people with PD. Methods: Individuals with PD and a Mini–Mental State Examination score ≥ 24 were divided into two groups using the RBD screening questionnaire (RBDSQ): those with an RBDSQ score ≥ 5 were assigned to the “probable RBD” (pRBD) group, and those with a score < 5 to the “non-pRBD” group. Participants were then evaluated for motor symptoms (Movement Disorder Society-Unified Parkinson’s Disease Rating Scale part III and modified Hoehn and Yahr Scale), cognitive functions (Montreal Cognitive Assessment and Frontal Assessment Battery [FAB]), anhedonia (Snaith–Hamilton Pleasure Scale), and QOL (Parkinson’s Disease Questionnaire [PDQ]-39 total and subscores for mobility, activities of daily living, emotional well-being, stigma, social support, cognition, communication, and bodily discomfort). Each measure was compared between the two groups (Mann–Whitney U test/χ2 test). Multiple regression analyses were performed to identify factors contributing to the total score and the subscore of the stigma domain of the PDQ-39. Results: Ninety-three individuals with PD were recruited (mean ± standard deviation age, 67.0 ± 10.6 years). The pRBD group exhibited a longer disease duration (P = 0.006), worse FAB (P = 0.015) and PDQ-39 total (P = 0.032) scores. RBDSQ scores correlated with higher scores in the PDQ-39 stigma domain (B = 2.44, P = 0.033). Conclusion: RBD is associated with worse QOL and stigma in people with PD. The RBDSQ is a useful tool for the prediction of such disturbances in QOL. © 2023, The Author(s) under exclusive licence to Belgian Neurological Society.",Parkinson’s disease; Quality of life; Rapid eye movement sleep behavior disorder screening questionnaire; Stigma,Activities of Daily Living; Aged; Humans; Middle Aged; Parkinson Disease; Quality of Life; REM Sleep Behavior Disorder; Surveys and Questionnaires; aged; algorithm; anhedonia; anxiety; Article; cognition; controlled study; cross-sectional study; daily life activity; disease duration; disease severity; emotional well-being; eye movement; female; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; Hoehn and Yahr scale; human; Likert scale; major clinical study; male; Mini Mental State Examination; Montreal cognitive assessment; motor dysfunction; multiple regression; nerve cell differentiation; Parkinson disease; pleasure; polysomnography; prediction; quality of life; questionnaire; rank sum test; rating scale; REM sleep; REM sleep behavior disorder; self report; sleep quality; social support; stigma; Unified Parkinson Disease Rating Scale; wellbeing; complication; middle aged; psychology; quality of life; REM sleep behavior disorder,Article,Final,,Scopus,2-s2.0-85150445337,Movies / Media
Baertsch T.; Huang Y.-Y.; Menozzi M.,"Baertsch, Tanja (57748952100); Huang, Ying-Yin (55336625500); Menozzi, Marino (7005529658)",57748952100; 55336625500; 7005529658,Head-mounted display versus computer monitor for visual attention screening: A comparative study,2023,Heliyon,9,6,e16610,,,,2,10.1016/j.heliyon.2023.e16610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161526539&doi=10.1016%2fj.heliyon.2023.e16610&partnerID=40&md5=423688c9f9ae9f50fe8a4bcbac32304b,"Visual attention is crucial to many tasks during working. When it is impaired, the risk of occupational accidents is increased. A potential accident prevention would be the tracking of employees' attentional states to construct break regimes. There is a promising visual attention test administered on a computer monitor (CM) that has several advantages over widely used continuous performance tests in detecting inattentiveness in occupational environments. However, as the setup with a CM is impractical for the use in particular working environments (e.g., lack of space or disturbing exposure to light), the test was implemented into a head-mounted display (HMD). This study aimed to investigate whether the HMD version of the test is a suitable alternative to the CM version. For this purpose, participants (N = 30; 20–29 y) performed both tests. The performance on the HMD was significantly lower than on the CM. Moreover, the performances were compared with normative data recorded with a CM in a previous study. These data significantly differ from the data recorded with the CM in the present study. This emphasizes the importance of a standardized test environment, which could be provided by an HMD. Conclusively, this study revealed that the new VR tool, based on a previous test designed to assess visual skills in a complex visual environment, exhibited good psychometric property regarding the reliability. In additional, no problems were revealed regarding the functionality and usability of the HMD. © 2023 The Authors",Cognitive workload; Detectability; Head-mounted display; Occupational health practice; Visual attention,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85161526539,Movies / Media
Ayala N.; Mardanbegi D.; Duchowski A.; Niechwiej-Szwedo E.; Cao S.; Kearns S.; Irving E.,"Ayala, Naila (57202583510); Mardanbegi, Diako (42761947400); Duchowski, Andrew (6701824388); Niechwiej-Szwedo, Ewa (8592081600); Cao, Shi (54580778600); Kearns, Suzanne (36025314800); Irving, Elizabeth (7004439553)",57202583510; 42761947400; 6701824388; 8592081600; 54580778600; 36025314800; 7004439553,On the Visibility of Fiducial Markers for Mobile Eye Tracking,2023,Eye Tracking Research and Applications Symposium (ETRA),,,13,,,,4,10.1145/3588015.3588413,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161147982&doi=10.1145%2f3588015.3588413&partnerID=40&md5=bfc464187438c2ee28034a6d25228c12,"Invisible fiducial markers are introduced for localization of Areas Of Interest (AOIs) in mobile eye tracking applications. Fiducial markers are made invisible through the use of film passing Infra-Red (IR) light while blocking the visible spectrum. An IR light source is used to illuminate the markers which are then detected by an IR-sensitive camera, but which are imperceptible by the human eye. We provide the first empirical study that demonstrates such invisible markers are not distracting to a given task, as demonstrated in a flight simulator where distraction of visible and invisible markers are compared between experienced and novice pilots. Fixation frequency and subjective distraction scores showed that visible markers disrupted natural gaze behaviour, particularly in novice pilots. Our findings show that invisible markers should be used when there is a need for them to remain inconspicuous.  © 2023 ACM.",augmented reality; aviation; eye tracking; virtual reality,Augmented reality; Flight simulators; Light sources; Virtual reality; Area of interest; Blockings; Eye-tracking; Fiducial marker; Infra red; Invisible markers; Localisation; Mobile eye-tracking; Red light; Tracking application; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85161147982,Movies / Media
Kimble M.; Cappello O.; Fleming K.,"Kimble, Matthew (7004260030); Cappello, Olivia (57990484800); Fleming, Kevin (35933205300)",7004260030; 57990484800; 35933205300,Hypervigilance and depression as predictors of eye tracking to ambiguous pictures in trauma survivors,2023,International Journal of Psychophysiology,187,,,27,33,6.0,6,10.1016/j.ijpsycho.2023.01.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148672546&doi=10.1016%2fj.ijpsycho.2023.01.007&partnerID=40&md5=4e294016953345acd28c637876d5b1be,"Hypervigilance, attentional bias, and negative views of the world play a significant role in post trauma symptomatology and can be associated with both clinical depression and posttraumatic stress. However, both theory and research suggest there may be discernible differences in attentional patterns between these two outcomes. While depression may be associated with a general negativity bias, posttraumatic stress may be specifically associated with visual scanning, hypervigilance, and threat detection. In this study, seventy-seven community trauma survivors completed self-assessments for hypervigilance, depression, and posttraumatic cognitions and then had their eyes tracked while looking at a series of thirty neutral but ambiguous and complex pictures on a computer screen. Mean age of the sample was 36.3 with 52 % of the sample identifying as female. We found that hypervigilance scores and negative views of the world predicted both the number of fixations and area of the picture covered. These factors did not predict pupil size. These findings suggest that there are discernable gaze patterns after trauma associated with posttraumatic stress but not depression. Specifically, ambiguous pictures generate more fixations and scanning that is associated with vigilance but not depression. © 2023",Depression; Eye tracking; Hypervigilance; Posttraumatic stress; Trauma,"Anxiety; Attention; Eye-Tracking Technology; Female; Humans; Stress Disorders, Post-Traumatic; Survivors; adult; Article; demographics; depression; Depression, Anxiety and Stress Scale; detection algorithm; electroencephalogram; eye tracking; female; gaze; human; informed consent; major clinical study; male; posttraumatic stress disorder; posttraumatic stress disorder checklist; pupil diameter; racial background; reaction time; self evaluation; anxiety; attention; diagnosis; survivor",Article,Final,,Scopus,2-s2.0-85148672546,Movies / Media
De Bruyne J.; Joundi J.; Morton J.; Zheleva A.; Van Kets N.; Van Wallendael G.; Talsma D.; Saldien J.; De Marez L.; Durnez W.; Bombeke K.,"De Bruyne, Jonas (57226611325); Joundi, Jamil (57205079702); Morton, Jessica (57225838886); Zheleva, Aleksandra (57217857323); Van Kets, Niels (56786203200); Van Wallendael, Glenn (35749154000); Talsma, Durk (6602556543); Saldien, Jelle (27868010800); De Marez, Lieven (24830473200); Durnez, Wouter (55743705400); Bombeke, Klaas (55567481800)",57226611325; 57205079702; 57225838886; 57217857323; 56786203200; 35749154000; 6602556543; 27868010800; 24830473200; 55743705400; 55567481800,I spy with my AI: The effects of AI-based visual cueing on human operators’ performance and cognitive load in CCTV control rooms,2023,International Journal of Industrial Ergonomics,95,,103444,,,,6,10.1016/j.ergon.2023.103444,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151257684&doi=10.1016%2fj.ergon.2023.103444&partnerID=40&md5=e144218e793b786eefdb04747929d380,"The increased number of security cameras in modern cities has elevated the video-feed monitoring demands of closed-circuit television (CCTV) operators. As a result, new AI-driven support systems that leverage the power of computer vision algorithms have been deployed to facilitate the operators' work. However, to effectively design intuitive, AI-driven interfaces and validate their impact on the operators' performance, extensive user testing is required. To address this, we previously developed and tested a virtual reality (VR) control room that can be used to iteratively evaluate intelligent computer assistants and interfaces while operators are subjected to different cognitive load. In the present study, we use this VR environment and physiological markers (e.g., eye tracking measures) to investigate how AI-based visual cueing (i.e., pushing forward video streams on which detections are highlighted by rectangles drawn around targets) affects operator performance and cognitive load. Results suggest that support systems using such technology in a control room improve operators’ performance and decrease their cognitive load, as reflected by changes in pupil dilation and subjective reports irrespective of induced cognitive load. © 2023 Elsevier B.V.",Artificial intelligence; CCTV; Cognitive load; User testing; Virtual reality; Visual cueing,Cognitive systems; Eye tracking; Iterative methods; Virtual addresses; Closed circuit television; Cognitive loads; Human operator; Operator performance; Power; Security cameras; Support systems; Television control; User testing; Visual cueing; adult; Article; artificial intelligence; cognitive load; computer simulation; eye tracking; female; human; job performance; male; operator; pupil dilation; pupil reflex; video surveillance; virtual reality; young adult; Virtual reality,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85151257684,Movies / Media
Luke S.G.; Jensen T.,"Luke, Steven G (36106197300); Jensen, Tanner (57813556700)",36106197300; 57813556700,The effect of sudden-onset distractors on reading efficiency and comprehension,2023,Quarterly Journal of Experimental Psychology,76,5,,1195,1206,11.0,2,10.1177/17470218221108355,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134580077&doi=10.1177%2f17470218221108355&partnerID=40&md5=662e94c2d29b623b2acc5342b5288baa,"Reading is an essential skill that requires focused attention. However, much reading is done in non-optimal environments. These days, reading is often done on digital devices or with a digital device nearby. These devices often introduce momentary distractions during reading, interrupting with alerts, notifications, and pop-ups. In two eye-tracking experiments, we investigated how such momentary distractions affect reading. Participants read paragraphs while their eye movements were monitored. During half of the paragraphs, distractions appeared periodically on the screen that required a response from the participants. In Experiment 1, the distractions were arrows that the participant had to respond to and then could immediately forget. In Experiment 2, the participants performed a 1-back task that required them to remember the identity of the last distractor. Compared with the no-distraction condition, the respond-and-forget distractors of Experiment 1 had minimal impact on reading behaviour and comprehension, but the working-memory-load distractors of Experiment 2 led to increased rereading and decreased reading comprehension. It seems a simple pop-up does not disrupt reading, but a message you must remember will. © Experimental Psychology Society 2022.",distraction; eye movements; Reading; working memory,Attention; Comprehension; Eye Movements; Humans; Mental Recall; Reading; attention; comprehension; eye movement; human; physiology; reading; recall,Article,Final,,Scopus,2-s2.0-85134580077,Movies / Media
Hirsch J.; Zhang X.; Noah J.A.; Bhattacharya A.,"Hirsch, Joy (35299240000); Zhang, Xian (9939485300); Noah, J. Adam (36789839000); Bhattacharya, Aishwarya (58131812300)",35299240000; 9939485300; 36789839000; 58131812300,Neural mechanisms for emotional contagion and spontaneous mimicry of live facial expressions,2023,Philosophical Transactions of the Royal Society B: Biological Sciences,378,1875,20210472,,,,11,10.1098/rstb.2021.0472,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149512837&doi=10.1098%2frstb.2021.0472&partnerID=40&md5=1280a561cd9539acb4dad7af43cbc3b6,"Viewing a live facial expression typically elicits a similar expression by the observer (facial mimicry) that is associated with a concordant emotional experience (emotional contagion). The model of embodied emotion proposes that emotional contagion and facial mimicry are functionally linked although the neural underpinnings are not known. To address this knowledge gap, we employed a live two-person paradigm (n = 20 dyads) using functional near-infrared spectroscopy during live emotive face-processing while also measuring eye-tracking, facial classifications and ratings of emotion. One dyadic partner, 'Movie Watcher', was instructed to emote natural facial expressions while viewing evocative short movie clips. The other dyadic partner, 'Face Watcher', viewed the Movie Watcher's face. Task and rest blocks were implemented by timed epochs of clear and opaque glass that separated partners. Dyadic roles were alternated during the experiment. Mean cross-partner correlations of facial expressions (r = 0.36 ± 0.11 s.e.m.) and mean cross-partner affect ratings (r = 0.67 ± 0.04) were consistent with facial mimicry and emotional contagion, respectively. Neural correlates of emotional contagion based on covariates of partner affect ratings included angular and supramarginal gyri, whereas neural correlates of the live facial action units included motor cortex and ventral face-processing areas. Findings suggest distinct neural components for facial mimicry and emotional contagion. This article is part of a discussion meeting issue 'Face2face: advancing the science of social interaction'.  © 2023 The Authors.",emotional contagion; facial mimicry; functional near-infrared spectroscopy (fNIRS); hyperscanning; interactive face-processing,Emotions; Facial Expression; Humans; Knowledge; Motor Cortex; Parietal Lobe; cognition; correlation; detection method; experimental study; spectroscopy; emotion; facial expression; human; knowledge; motor cortex; parietal lobe,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85149512837,Movies / Media
Jiang Y.; Leiva L.A.; Rezazadegan Tavakoli H.; R. B. Houssel P.; Kylmälä J.; Oulasvirta A.,"Jiang, Yue (57209399308); Leiva, Luis A. (34880363200); Rezazadegan Tavakoli, Hamed (57695037700); R. B. Houssel, Paul (58285485800); Kylmälä, Julia (57566129300); Oulasvirta, Antti (13006124600)",57209399308; 34880363200; 57695037700; 58285485800; 57566129300; 13006124600,UEyes: Understanding Visual Saliency across User Interface Types,2023,Conference on Human Factors in Computing Systems - Proceedings,,,285,,,,26,10.1145/3544548.3581096,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158105925&doi=10.1145%2f3544548.3581096&partnerID=40&md5=77c74467b63591cc634cebb18f45e58b,"While user interfaces (UIs) display elements such as images and text in a grid-based layout, UI types differ significantly in the number of elements and how they are displayed. For example, webpage designs rely heavily on images and text, whereas desktop UIs tend to feature numerous small images. To examine how such differences affect the way users look at UIs, we collected and analyzed a large eye-tracking-based dataset, UEyes (62 participants and 1,980 UI screenshots), covering four major UI types: webpage, desktop UI, mobile UI, and poster. We analyze its differences in biases related to such factors as color, location, and gaze direction. We also compare state-of-the-art predictive models and propose improvements for better capturing typical tendencies across UI types. Both the dataset and the models are publicly available. © 2023 Owner/Author.",Computer Vision; Deep Learning; Eye Tracking; Human Perception and Cognition; Interaction Design,Computer vision; Deep learning; Eye tracking; Large dataset; Websites; Deep learning; Desktop user interface; Eye-tracking; Human cognition; Human perception; Interaction design; Interface displays; Perception and cognition; Visual saliency; Web-page; User interfaces,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85158105925,Movies / Media
Wahn B.; Schmitz L.; Gerster F.N.; Weiss M.,"Wahn, Basil (56676361200); Schmitz, Laura (57189242399); Gerster, Frauke Nora (58260558600); Weiss, Matthias (55232324000)",56676361200; 57189242399; 58260558600; 55232324000,Offloading under cognitive load: Humans are willing to offload parts of an attentionally demanding task to an algorithm,2023,PLoS ONE,18,5-May,e0286102,,,,14,10.1371/journal.pone.0286102,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159649900&doi=10.1371%2fjournal.pone.0286102&partnerID=40&md5=a22ae1742d9dcae19f4d44071ab84b5e,"In the near future, humans will increasingly be required to offload tasks to artificial systems to facilitate daily as well as professional activities. Yet, research has shown that humans are often averse to offloading tasks to algorithms (so-called “algorithmic aversion”). In the present study, we asked whether this aversion is also present when humans act under high cognitive load. Participants performed an attentionally demanding task (a multiple object tracking (MOT) task), which required them to track a subset of moving targets among distractors on a computer screen. Participants first performed the MOT task alone (Solo condition) and were then given the option to offload an unlimited number of targets to a computer partner (Joint condition). We found that participants significantly offloaded some (but not all) targets to the computer partner, thereby improving their individual tracking accuracy (Experiment 1). A similar tendency for offloading was observed when participants were informed beforehand that the computer partner’s tracking accuracy was flawless (Experiment 2). The present findings show that humans are willing to (partially) offload task demands to an algorithm to reduce their own cognitive load. We suggest that the cognitive load of a task is an important factor to consider when evaluating human tendencies for offloading cognition onto artificial systems. Copyright: © 2023 Wahn et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Affect; Algorithms; Cognition; Computers; Humans; accuracy; adult; Article; artificial general intelligence; attentionally demanding task; aversion; cognitive load; computer analysis; eye tracking; female; human; Joint condition; learning algorithm; male; multiple object tracking task; offload task; offloading; Solo condition; Student t test; task performance; affect; algorithm; cognition,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85159649900,Movies / Media
Amin A.A.; Hassan S.; Lee S.; Huenerfauth M.,"Amin, Akhter Al (56623925700); Hassan, Saad (57224309524); Lee, Sooyeon (57189050289); Huenerfauth, Matt (12240800100)",56623925700; 57224309524; 57189050289; 12240800100,Understanding How Deaf and Hard of Hearing Viewers Visually Explore Captioned Live TV News,2023,ACM International Conference Proceeding Series,,,,54,65,11.0,4,10.1145/3587281.3587287,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158129580&doi=10.1145%2f3587281.3587287&partnerID=40&md5=4d4945e1a57e1b0f13ef8ef158c91cc2,"Captions blocking visual information in live television news leads to dissatisfaction among Deaf and Hard of Hearing (DHH) viewers, who cannot see important information on the screen. Prior work has proposed generic guidelines for caption placement but not specifically for live television news, and important genre of television with dense placement of onscreen information regions, e.g., current news topic, scrolling news, etc. To understand DHH viewers' gaze behavior while watching television news, both spatially and temporally, we conducted an eye-Tracking study with 19 DHH participants. Participants' gaze behavior varied over time as measured by their proportional fixation time on information regions on the screen. An analysis of gaze behavior coupled with open-ended feedback revealed four thematic categories of information regions. Our work motivates considering the time dimension when considering caption placement, to avoid blocking information regions, as their importance varies over time. © 2023 ACM.",Accessibility; Area of Interest; Attention; Caption,Audition; Interactive television; Accessibility; Area of interest; Attention; Blockings; Caption; Gaze behaviours; Hard of hearings; Live television; TV news; Visual information; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85158129580,Movies / Media
Flores R.; Tlachac M.L.; Shrestha A.; Rundensteiner E.,"Flores, Ricardo (57479121800); Tlachac, M.L. (57203187245); Shrestha, Avantika (57888001200); Rundensteiner, Elke (7005195084)",57479121800; 57203187245; 57888001200; 7005195084,Temporal Facial Features for Depression Screening,2023,UbiComp/ISWC 2022 Adjunct - Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2022 ACM International Symposium on Wearable Computers,,,,488,493,5.0,13,10.1145/3544793.3563424,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158973269&doi=10.1145%2f3544793.3563424&partnerID=40&md5=108992437465ced35422e7e07330a4c5,"Depression is a common and debilitating mental illness. Given the shortage of mental health professionals, there are delays in depression detection. Interviews conducted by virtual agents could expedite depression screenings. While the interview audio and transcript have received more attention, facial features offer an attractive privacy-preserving screening modality. Thus, we conduct a comprehensive comparative evaluation of the effectiveness of temporal facial features to screen for depression. We extract time series of eye gaze, landmark, and action unit features from video responses to 15 clinical interview questions. We input them into CNN, LSTM, and recurrent convolutional neural network (RCNN) models. An extra attention layer proved critical for CNN and LSTM performance. For a general wellbeing question, eye gaze features screened for depression with an F1 of 0.81. Our study informs the use of temporal facial features in future digital mental illness screening technologies. © 2022 ACM.",Convolutional Neural Network; Digital health; Recurrent Convolutional Neural Network; Recurrent Neural Network; Time Series Classification,Convolution; Convolutional neural networks; Long short-term memory; Time series; Convolutional neural network; Digital health; Eye-gaze; Facial feature; Health professionals; Mental health; Mental illness; Recurrent convolutional neural network; Time series classifications; Diseases,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85158973269,Movies / Media
Chidi-Egboka N.C.; Jalbert I.; Golebiowski B.,"Chidi-Egboka, Ngozi Charity (57204084484); Jalbert, Isabelle (6603063260); Golebiowski, Blanka (9635494800)",57204084484; 6603063260; 9635494800,Smartphone gaming induces dry eye symptoms and reduces blinking in school-aged children,2023,Eye (Basingstoke),37,7,,1342,1349,7.0,24,10.1038/s41433-022-02122-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131539150&doi=10.1038%2fs41433-022-02122-2&partnerID=40&md5=4f093be64959e5f337e9c38fe26076cb,"Purpose: Smartphone use by children is rising rapidly, but its ocular surface impact is unknown. This study examined the effect of smartphone use on blinking, symptoms, and tear function in children. Methods: Prospective intervention study where 36 children aged 6–15years (14 M:22 F) played games on a smartphone continuously for one hour. Symptoms (SANDE, IOSS, NRS) and tear film (lipid layer thickness, tear secretion, stability) were assessed before and after gaming. Blink rate and interblink interval were measured in situ using an eye tracking headset, before (during conversation) and continuously throughout gaming. Symptoms and tear film changes were examined using paired t-tests. Changes in blinking throughout one hour were examined using repeated measures ANOVA, post-hoc comparisons with Bonferroni correction. Associations examined using Pearson bivariate correlation. Significance level was 0.05. Results: Symptoms worsened following one hour smartphone gaming (SANDE + 8.2units, p = 0.01; IOSS + 1.3units, p < 0.001; NRS-average +6.3units, p = 0.03; NRS-comfort +7.6units, p = 0.04; NRS-tiredness +10.1units, p = 0.01), but tear film remained unchanged. Blink rate reduced from 20.8 blinks/min to 8.9 blinks/min (p < 0.001) and interblink interval increased from 2.9 s to 8.7 s (p = 0.002) within the first minute of gaming relative to baseline conversation, and this effect remained unchanged throughout one hour of gaming. Conclusions: Smartphone use in children results in dry eye symptoms and immediate and sustained slowing of blinking, with no change in tear function evident up to one hour. Given the ubiquitous use of smartphones by children, future work should examine whether effects reported herein persist or get worse over a longer term causing cumulative damage to the ocular surface. © 2022, The Author(s).",,Blinking; Child; Dry Eye Syndromes; Humans; Prospective Studies; Smartphone; Tears; Video Games; lipid; adolescent; Article; blinking; child; clinical article; clinical assessment; controlled study; conversation; dry eye; eye; eye tracking; eyelid reflex; fatigue; female; general condition deterioration; human; interblink interval; knee meniscus rupture; lacrimal fluid; lacrimation; lipid layer thickness; male; patient comfort; preschool child; prospective study; symptom; tear film; video game; visual system parameters; blinking; dry eye syndrome; lacrimal fluid,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85131539150,Movies / Media
Wang T.; Liao G.; Chen L.; Zhuang Y.; Zhou S.; Yuan Q.; Han L.; Wu S.; Chen K.; Wang B.; Mi J.; Gao Y.; Lin J.; Zhang M.,"Wang, Tong (58108490400); Liao, Guoliang (57921548600); Chen, Lin (58407063800); Zhuang, Yan (57202549361); Zhou, Sibo (57921581400); Yuan, Qiongzhen (57266234900); Han, Lin (57211040514); Wu, Shanshan (57206186799); Chen, Ke (56237325900); Wang, Binjian (58076198500); Mi, Junyu (58076198600); Gao, Yunxia (57200687063); Lin, Jiangli (7501725651); Zhang, Ming (56796912200)",58108490400; 57921548600; 58407063800; 57202549361; 57921581400; 57266234900; 57211040514; 57206186799; 56237325900; 58076198500; 58076198600; 57200687063; 7501725651; 56796912200,Intelligent Diagnosis of Multiple Peripheral Retinal Lesions in Ultra-widefield Fundus Images Based on Deep Learning,2023,Ophthalmology and Therapy,12,2,,1081,1095,14.0,5,10.1007/s40123-023-00651-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146766602&doi=10.1007%2fs40123-023-00651-x&partnerID=40&md5=bb76dc3aec247a626261a7931a8c7cd8,"Introduction: Compared with traditional fundus examination techniques, ultra-widefield fundus (UWF) images provide 200° panoramic images of the retina, which allows better detection of peripheral retinal lesions. The advent of UWF provides effective solutions only for detection but still lacks efficient diagnostic capabilities. This study proposed a retinal lesion detection model to automatically locate and identify six relatively typical and high-incidence peripheral retinal lesions from UWF images which will enable early screening and rapid diagnosis. Methods: A total of 24,602 augmented ultra-widefield fundus images with labels corresponding to 6 peripheral retinal lesions and normal manifestation labelled by 5 ophthalmologists were included in this study. An object detection model named You Only Look Once X (YOLOX) was modified and trained to locate and classify the six peripheral retinal lesions including rhegmatogenous retinal detachment (RRD), retinal breaks (RB), white without pressure (WWOP), cystic retinal tuft (CRT), lattice degeneration (LD), and paving-stone degeneration (PSD). We applied coordinate attention block and generalized intersection over union (GIOU) loss to YOLOX and evaluated it for accuracy, sensitivity, specificity, precision, F1 score, and average precision (AP). This model was able to show the exact location and saliency map of the retinal lesions detected by the model thus contributing to efficient screening and diagnosis. Results: The model reached an average accuracy of 96.64%, sensitivity of 87.97%, specificity of 98.04%, precision of 87.01%, F1 score of 87.39%, and mAP of 86.03% on test dataset 1 including 248 UWF images and reached an average accuracy of 95.04%, sensitivity of 83.90%, specificity of 96.70%, precision of 78.73%, F1 score of 81.96%, and mAP of 80.59% on external test dataset 2 including 586 UWF images, showing this system performs well in distinguishing the six peripheral retinal lesions. Conclusion: Focusing on peripheral retinal lesions, this work proposed a deep learning model, which automatically recognized multiple peripheral retinal lesions from UWF images and localized exact positions of lesions. Therefore, it has certain potential for early screening and intelligent diagnosis of peripheral retinal lesions. © 2023, The Author(s).",Deep learning; Object detection; Peripheral retinal lesion; Ultra-widefield fundus; You Only Look Once X,accuracy; adult; Article; blurred vision; cystic retinal tuft; deep learning; diagnostic test accuracy study; eye fundus; eye movement; female; fibrosis; human; lattice degeneration; liquefaction; major clinical study; male; ophthalmologist; recall; retina degeneration; retinopathy; retrospective study; rhegmatogenous  retinal detachment; rotation; sensitivity and specificity; subretinal fluid; training,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85146766602,Movies / Media
Putkinen V.; Nazari-Farsani S.; Karjalainen T.; Santavirta S.; Hudson M.; Seppälä K.; Sun L.; Karlsson H.K.; Hirvonen J.; Nummenmaa L.,"Putkinen, Vesa (17344532500); Nazari-Farsani, Sanaz (56786607900); Karjalainen, Tomi (57204081896); Santavirta, Severi (57214998231); Hudson, Matthew (30267756300); Seppälä, Kerttu (57212172187); Sun, Lihua (57213619586); Karlsson, Henry K. (55955101600); Hirvonen, Jussi (7102669528); Nummenmaa, Lauri (57203071148)",17344532500; 56786607900; 57204081896; 57214998231; 30267756300; 57212172187; 57213619586; 55955101600; 7102669528; 57203071148,Pattern recognition reveals sex-dependent neural substrates of sexual perception,2023,Human Brain Mapping,44,6,,2543,2556,13.0,4,10.1002/hbm.26229,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147963144&doi=10.1002%2fhbm.26229&partnerID=40&md5=9ea309d86acf81c8e483868d043eec15,"Sex differences in brain activity evoked by sexual stimuli remain elusive despite robust evidence for stronger enjoyment of and interest toward sexual stimuli in men than in women. To test whether visual sexual stimuli evoke different brain activity patterns in men and women, we measured hemodynamic brain activity induced by visual sexual stimuli in two experiments with 91 subjects (46 males). In one experiment, the subjects viewed sexual and nonsexual film clips, and dynamic annotations for nudity in the clips were used to predict hemodynamic activity. In the second experiment, the subjects viewed sexual and nonsexual pictures in an event-related design. Men showed stronger activation than women in the visual and prefrontal cortices and dorsal attention network in both experiments. Furthermore, using multivariate pattern classification we could accurately predict the sex of the subject on the basis of the brain activity elicited by the sexual stimuli. The classification generalized across the experiments indicating that the sex differences were task-independent. Eye tracking data obtained from an independent sample of subjects (N = 110) showed that men looked longer than women at the chest area of the nude female actors in the film clips. These results indicate that visual sexual stimuli evoke discernible brain activity patterns in men and women which may reflect stronger attentional engagement with sexual stimuli in men. © 2023 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.",fMRI; MVPA; pattern-classification; sex differences; sexual arousal,Arousal; Female; Humans; Male; Perception; Pleasure; Sex Characteristics; Sexual Behavior; adult; Article; brain function; controlled study; dorsal attention network; eye tracking; female; functional magnetic resonance imaging; functional neuroimaging; hemodynamics; human; human experiment; male; normal human; pattern recognition; pornography; prefrontal cortex; sex difference; sexual arousal; vision; visual stimulation; arousal; perception; physiology; pleasure; sexual behavior; sexual characteristics,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147963144,Movies / Media
Fadda R.; Congiu S.; Roeyers H.; Skoler T.,"Fadda, Roberta (24824317300); Congiu, Sara (28267464200); Roeyers, Herbert (6701645061); Skoler, Tricia (57216464058)",24824317300; 28267464200; 6701645061; 57216464058,Elements of Biophilic Design Increase Visual Attention in Preschoolers,2023,Buildings,13,5,1160,,,,13,10.3390/buildings13051160,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160673012&doi=10.3390%2fbuildings13051160&partnerID=40&md5=ddb8c67357b3d8fc161f9ec908f6bc85,"Biophilic design increases attention among adults, but little is known about the influence of biophilic design on attention in childhood. We assessed visual attention in 4–5-year-old children as a function of high and low degrees of biophilic design. In the high-biophilic-design condition, the children saw four plants, which were placed on their desks. In the low-biophilic-design condition, the children saw no plants on their desks. The children viewed a series of abstract images on a computer screen while their visual attention was measured with an eye tracker. We found that the durations of the children’s first fixations were significantly higher in the high-biophilic-design compared to those in the low-biophilic-design. This study demonstrates the potential of biophilic design to increase visual attention in indoor environments. The implications of this finding for architecture and building design are discussed. © 2023 by the authors.",biophilia; biophilic design; eye tracking; preschool children; school environment; visual attention,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85160673012,Movies / Media
Kumaran R.; Kim Y.-J.; Milner A.E.; Bullock T.; Giesbrecht B.; Höllerer T.,"Kumaran, Radha (57201993070); Kim, You-Jin (57887995500); Milner, Anne E. (57888221900); Bullock, Tom (56526466300); Giesbrecht, Barry (6701319493); Höllerer, Tobias (8358959700)",57201993070; 57887995500; 57888221900; 56526466300; 6701319493; 8358959700,The Impact of Navigation Aids on Search Performance and Object Recall in Wide-Area Augmented Reality,2023,Conference on Human Factors in Computing Systems - Proceedings,,,710,,,,19,10.1145/3544548.3581413,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160019602&doi=10.1145%2f3544548.3581413&partnerID=40&md5=73da54068e48cab854a83b3a9d8e9c72,"Head-worn augmented reality (AR) is a hotly pursued and increasingly feasible contender paradigm for replacing or complementing smartphones and watches for continual information consumption. Here, we compare three different AR navigation aids (on-screen compass, on-screen radar and in-world vertical arrows) in a wide-area outdoor user study (n=24) where participants search for hidden virtual target items amongst physical and virtual objects. We analyzed participants' search task performance, movements, eye-gaze, survey responses and object recall. There were two key findings. First, all navigational aids enhanced search performance relative to a control condition, with some benefit and strongest user preference for in-world arrows. Second, users recalled fewer physical objects than virtual objects in the environment, suggesting reduced awareness of the physical environment. Together, these findings suggest that while navigational aids presented in AR can enhance search task performance, users may pay less attention to the physical environment, which could have undesirable side-effects. © 2023 Owner/Author.",Behavior; Lighting Conditions; Mobile Augmented Reality; Navigation Aids; Perception; User Study; Wide-Area,Eye movements; Navigation; Behavior; Lighting conditions; Mobile augmented reality; Navigation aids; Object Recall; Physical objects; Search performance; User study; Virtual objects; Wide-area; Augmented reality,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85160019602,Movies / Media
Tsitsi P.; Nilsson M.; Seimyr G.Ö.; Larsson O.; Svenningsson P.; Markaki I.,"Tsitsi, Panagiota (57204128425); Nilsson, Mattias (57192377443); Seimyr, Gustaf Öqvist (56041325000); Larsson, Olof (57222987761); Svenningsson, Per (7004099018); Markaki, Ioanna (6507833432)",57204128425; 57192377443; 56041325000; 57222987761; 7004099018; 6507833432,Reading Alterations in Parkinson's Disease Indicate Worse Cognitive Status,2023,Movement Disorders Clinical Practice,10,4,,579,585,6.0,6,10.1002/mdc3.13663,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148305193&doi=10.1002%2fmdc3.13663&partnerID=40&md5=c2eaa9cec723dcd8f1e5838f24535984,"Background: Reading difficulties are commonly reported in Parkinson's disease (PD). So far, only a few studies have assessed reading in PD, most of them confirming a different pattern in patients compared with healthy populations. Impaired oculomotor control is an early feature of PD. Cognitive deficits, on the other hand, may appear early, but they are most prominent at later stages. Although these two factors are thought to be responsible for the alterations in reading performance, it is unclear how each factor contributes to them. Objectives: To evaluate eye movements during reading in PD and healthy controls (HCs). Methods: Data from 42 HCs (36% men) and 48 patients with PD (67% men) at Hoehn and Yahr stages ≤3 were analyzed. PD participants were further divided into 2 groups based on their Montreal Cognitive Assessment (MoCA) score using a cutoff of ≥26. Eye movements were recorded with Tobii Pro Spectrum, a screen-based eye tracker with a sampling rate of 1200 Hz. Results: PD participants performed fewer fixations per second (P = 0.033), with a longer mean (P = 0.037) and standard deviation fixation duration (P = 0.033) than HC, and further analysis showed that only patients with a lower MoCA score performed worse than HCs. Reading parameters were weakly associated with MoCA scores, irrespective of age and education. Conclusion: Changes in the reading pattern of PD patients are probably attributed to cognitive rather than pure oculomotor alterations. © 2023 The Authors. Movement Disorders Clinical Practice published by Wiley Periodicals LLC on behalf of International Parkinson and Movement Disorder Society.",Cognition; Eye-movements; Fixation duration; Parkinson's Disease; Reading,levodopa; adult; aged; Article; clinical article; cognition; cognitive defect; controlled study; data processing; depth perception; education; euclidean saccade; executive function; eye movement; eye movement control; eye tracking; female; fixation dispersion; fixation duration; fixation saccades ratio; fixations; human; male; middle aged; Minimum Angle of Resolution  score; Montreal cognitive assessment; neuropsychological assessment; normal human; oculomotor system; Parkinson disease; pupil diameter; reading; regression frequency; saccade distance; Schwab and England score; scoring system; spectrum; Unified Parkinson Disease Rating Scale; visual acuity; visual stimulation; words,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85148305193,Movies / Media
Onnasch L.; Schweidler P.; Wieser M.,"Onnasch, Linda (35111634600); Schweidler, Paul (58062461000); Wieser, Maximilian (57222490764)",35111634600; 58062461000; 57222490764,Effects of Predictive Robot Eyes on Trust and Task Performance in an Industrial Cooperation Task,2023,ACM/IEEE International Conference on Human-Robot Interaction,,,,442,446,4.0,2,10.1145/3568294.3580123,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150448915&doi=10.1145%2f3568294.3580123&partnerID=40&md5=f86905a552f27477d18307503f330090,"Industrial cobots can perform variable action sequences. For human-robot interaction (HRI) this can have detrimental effects, as the robot's actions can be difficult to predict. In human interaction, eye gaze intuitively directs attention and communicates subsequent actions. Whether this mechanism can benefit HRI, too, is not well understood. This study investigated the impact of anthropomorphic eyes as directional cues in robot design. 42 participants worked on two subsequent tasks in an embodied HRI with a Sawyer robot. The study used a between-subject design and presented either anthropomorphic eyes, arrows or a black screen as control condition on the robot's display. Results showed that neither directional stimuli nor the anthropomorphic design in particular led to increased trust. But anthropomorphic robot eyes improved the prediction speed, whereas this effect could not be found for non-anthropomorphic cues (arrows). Anthropomorphic eyes therefore seem to be better suitable for an implementation on an industrial robot. © 2023 IEEE Computer Society. All rights reserved.",anthropomorphism; artificial eyes; collaborative robot (cobot); Human-robot interaction; robot design; task performance; trust in HRI,Anthropomorphic robots; Machine design; Man machine systems; Anthropomorphism; Artificial eye; Collaborative robot; Collaborative robots; Humans-robot interactions; Industrial cooperation; Robot designs; Task performance; Trust in human-robot interaction; Human robot interaction,Conference paper,Final,,Scopus,2-s2.0-85150448915,Movies / Media
Liberman L.; Dubovi I.,"Liberman, Liat (57985686700); Dubovi, Ilana (57194381219)",57985686700; 57194381219,The effect of the modality principle to support learning with virtual reality: An eye-tracking and electrodermal activity study,2023,Journal of Computer Assisted Learning,39,2,,547,557,10.0,23,10.1111/jcal.12763,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142894221&doi=10.1111%2fjcal.12763&partnerID=40&md5=e6358219e8aa36f4341a35754e8f01a7,"Background: Virtual reality (VR) is considered a promising approach to support learning. An instructional design is essential to optimize cognitive processes. Studies show that VR has unique instructional and pedagogical requirements. Objectives: To evaluate the effectiveness and applicability of the modality principle, which was previously validated in 2D classic multimedia, for learning with VR. The modality principle states that multimedia information presented as spoken narration is superior to on-screen text. Methods: A prospective experimental study with two compared conditions of instruction: VR-based learning guided by on-screen text (n = 34) versus spoken narration (n = 28). Students' cognitive learning experiences were captured by eye-tracking and electrodermal activity (EDA). In addition, students' knowledge was evaluated using a pre–post knowledge test. Results and Conclusions: Overall, there was no significant difference in knowledge retention between the participants who learned with on-screen text compared to spoken narration. However, results from the eye-tracking analysis showed that students who learned with the on-screen text devoted longer visual attention toward important learning activity areas of interest, suggesting a better ability to discern between relevant and irrelevant information. Conversely, students who learned with the spoken narration expressed significantly more EDA peak responses, proposing a higher cognitive load. Implications: This study outlines that while learning with VR was effective, the modality principle might not apply to learning with VR. Moreover, the analysis of the learning process suggests even an inverse effect, favouring the provision of instructional scaffolds as on-screen text. Future research should evaluate this effect on long-term knowledge retention. © 2022 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.",EDA; eye-tracking; modality principle; multimedia; simulation; virtual reality,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85142894221,Movies / Media
Moulder R.; Booth B.; Abitino A.; D'Mello S.,"Moulder, Robert (57188537848); Booth, Brandon (57191862448); Abitino, Angelina (57205548639); D'Mello, Sidney (14053463100)",57188537848; 57191862448; 57205548639; 14053463100,Recurrence Quantification Analysis of Eye Gaze Dynamics during Team Collaboration,2023,ACM International Conference Proceeding Series,,,,430,440,10.0,4,10.1145/3576050.3576113,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149324772&doi=10.1145%2f3576050.3576113&partnerID=40&md5=8033a3c18251c53bf679b7b5e03f7424,"Shared visual attention between team members facilitates collaborative problem solving (CPS), but little is known about how team-level eye gaze dynamics influence the quality and successfulness of CPS. To better understand the role of shared visual attention during CPS, we collected eye gaze data from 279 individuals solving computer-based physics puzzles while in teams of three. We converted eye gaze into discrete screen locations and quantified team-level gaze dynamics using recurrence quantification analysis (RQA). Specifically, we used a centroid-based auto-RQA approach, a pairwise team member cross-RQAs approach, and a multi-dimensional RQA approach to quantify team-level eye gaze dynamics from the eye gaze data of team members. We find that teams differing in composition based on prior task knowledge, gender, and race show few differences in team-level eye gaze dynamics. We also find that RQA metrics of team-level eye gaze dynamics were predictive of task success (all ps < .001). However, the same metrics showed different patterns of feature importance depending on predictive model and RQA type, suggesting some redundancy in task-relevant information. These findings signify that team-level eye gaze dynamics play an important role in CPS and that different forms of RQA pick up on unique aspects of shared attention between team-members.  © 2023 Owner/Author.",eye gaze dynamics; recurrence quantification analysis; shared attention; team collaboration; team dynamics,Behavioral research; Analysis approach; Collaborative problem solving; Eye gaze dynamic; Eye-gaze; Recurrence quantification analysis; Shared attention; Team collaboration; Team dynamics; Team members; Visual Attention; Dynamics,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85149324772,Movies / Media
Mihelčič M.; Podlesek A.,"Mihelčič, Matjaž (55788940600); Podlesek, Anja (9271994600)",55788940600; 9271994600,Cognitive workload affects ocular accommodation and pupillary response,2023,Journal of Optometry,16,2,,107,115,8.0,4,10.1016/j.optom.2022.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133245640&doi=10.1016%2fj.optom.2022.05.001&partnerID=40&md5=f08316a4bbc0f01211edcee00a9cfa14,"Significance: Cognitive involvement in reading causes variations in the tonus of autonomic nerve system. The aim of this study was to examine the effect of short-term cognitive load on accommodation and pupils’ absolute values and temporal variability in test persons performing three different types of tasks. Purpose: We aimed to show how cognitive tasks of different type and difficulty level affect accommodation and pupil behavior during a short time interval. Methods: Participants (n = 58; mean age 16.4 years, SD = 0.56) performed reading from a 10-inch LCD screen placed at 40 cm distance. Three different types of tasks (numerical, textual, and the Stroop task), each at three different levels of cognitive load were introduced. Participants had 90 s to complete each task. Accommodative and pupillary responses were measured with videoretinoscope Power Refractor 3 at 50 Hz. Results: Pupil size was largest in the Stroop task (M = 5.20 mm, SD = 0.75 mm), followed by the numerical tasks (M = 5.02 mm, SD = 0.72 mm) and textual tasks (M = 4.78 mm, SD = 0.71 mm). Accommodative fluctuations – measured as accommodation SD – were largest in the textual tasks (M = 0.67 D, SD = 0.34 D), followed by the numerical tasks (M = 0.61 D, SD = 0.40 D) and the Stroop task (M = 0.52 D, SD = 0.21 D). Conclusions: In our experiment, short-term cognitive load was associated with altered pupillary and accommodative response to near tasks. In conflicting tasks (Stroop) or in performing continuing calculations, the pupils were larger; in tasks requiring logical reasoning, the accommodative fluctuations were greater. These effects can potentially be associated with current near-point stress and myopia growth models. © 2022 Spanish General Council of Optometry",Accommodation; Cognitive load; Myopia; Pupils; Refraction,"Accommodation, Ocular; Adolescent; Cognition; Humans; Myopia; Pupil; Reading; Refraction, Ocular; accommodation; adolescent; cognition; eye refraction; human; myopia; physiology; pupil; reading",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85133245640,Movies / Media
Mo X.; Yang X.; Hu B.,"Mo, Xiaohong (57218631701); Yang, Xian (51666138500); Hu, Bin (57212305362)",57218631701; 51666138500; 57212305362,The interaction of clothing design factors: how to attract consumers' visual attention and enhance emotional experience,2023,Journal of Fashion Marketing and Management,27,2,,220,240,20.0,17,10.1108/JFMM-10-2021-0269,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129710060&doi=10.1108%2fJFMM-10-2021-0269&partnerID=40&md5=036a57c14110e510306fdfcb5e0f1700,"Purpose: This paper aims to study consumers’ visual attention and emotional experience with clothing design factors and their combinations from the perspective of cognition and emotion and propose an interaction phenomenon to evaluate the combined effect of clothing factors to better guide online clothing design and sales. Design/methodology/approach: An eye movement physiology experiment was conducted, 33 participants screened by questionnaires were invited for this experiment. Hypotheses of visual attention were verified by the FIRST_FIXATION_TIME indicator, DWELL_TIME indicator and FIXATION_COUNT indicator. Hypotheses of emotional experience were verified by the PUPIL_SIZE indicator. Findings: First, on the product list page, it is better to use only the three factors of clothing and a small number of stimulating factors. Second, when the stimulus is consistent with the cognitive task performed by the consumer, the efficiency of the task and the consumer's user experience will be improved. Third, the positive interaction phenomenon of clothing design factors and their combinations could significantly attract consumers' visual attention and improve their emotional experience. Research limitations/implications: This work argues consumer interest and emotional experience with online clothing can be expressed through eye movement physiological indicators, and the concept of interaction was proposed to evaluate the design and display of online clothing. Originality/value: This paper conducted interaction research on online clothing design factors and their combinations from the perspective of cognition and emotion, which provided an objective quantitative method for online clothing designers and online clothing retailers. © 2022, Emerald Publishing Limited.",Emotional experience; Eye movement indicator; Interaction phenomenon; Online clothing; Visual factor,,Article,Final,,Scopus,2-s2.0-85129710060,Movies / Media
Zhao Z.; Wei J.; Xing J.; Zhang X.; Qu X.; Hu X.; Lu J.,"Zhao, Zhong (57008361600); Wei, Jiwei (57827552700); Xing, Jiayi (57221818825); Zhang, Xiaobin (57213160782); Qu, Xingda (57194640319); Hu, Xinyao (55345595400); Lu, Jianping (57203465974)",57008361600; 57827552700; 57221818825; 57213160782; 57194640319; 55345595400; 57203465974,Use of Oculomotor Behavior to Classify Children with Autism and Typical Development: A Novel Implementation of the Machine Learning Approach,2023,Journal of Autism and Developmental Disorders,53,3,,934,946,12.0,5,10.1007/s10803-022-05685-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135272310&doi=10.1007%2fs10803-022-05685-x&partnerID=40&md5=70f60b83348b90deeb6adbd9c785682b,"This study segmented the time series of gaze behavior from nineteen children with autism spectrum disorder (ASD) and 20 children with typical development in a face-to-face conversation. A machine learning approach showed that behavior segments produced by these two groups of participants could be classified with the highest accuracy of 74.15%. These results were further used to classify children using a threshold classifier. A maximum classification accuracy of 87.18% was achieved, under the condition that a participant was considered as ‘ASD’ if over 46% of the child’s 7-s behavior segments were classified as ASD-like behaviors. The idea of combining the behavior segmentation technique and the threshold classifier could maximally preserve participants’ data, and promote the automatic screening of ASD. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Autism; Behavior segmentation; Entropy; Eye-tracking; Machine learning; Oculomotor,Autism Spectrum Disorder; Autistic Disorder; Child; Communication; Eye Movements; Humans; Machine Learning; Article; attention deficit hyperactivity disorder; autism; child; clinical article; comparative study; controlled study; DSM-IV; emotion; entropy; eye tracking; female; gaze; human; intelligence; intelligence quotient; latent period; machine learning; male; measurement accuracy; mental health; mental health center; neuroimaging; preschool child; psychiatrist; saccadic eye movement; schizophrenia; support vector machine; time series analysis; autism; eye movement; interpersonal communication; machine learning,Article,Final,,Scopus,2-s2.0-85135272310,Movies / Media
Kühnlenz K.,"Kühnlenz, Kolja (8611373500)",8611373500,Eye-Movement Dependency of Peripheral Visual Perception of Anthropomorphism Using an 80ms Robot Picture Stimulus,2023,ACM/IEEE International Conference on Human-Robot Interaction,,,,253,257,4.0,1,10.1145/3568294.3580083,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150462569&doi=10.1145%2f3568294.3580083&partnerID=40&md5=5073abbeafcab6b3ef6d36a3b6ff1e01,"This paper investigates the impact of types of eye-movements (static vs. pursuit) on dimensions of perceived anthropomorphism of robots in the peripheral visual field (covert visual attention) in a strongly controlled video-based study design. It replicates a previous study with a contrasting re_nement of using a short-term stimulus of only 80ms in order to avoid the e_ect of potential short direct saccades towards the stimulus. In a between-subjects design, test participants are told to follow a point target, which is either static at the screen center or moving linearly. The robot head picture is then brie_y presented in the peripheral field of view region for 80ms. After stimulation, a questionnaire based on the HRIES scale on anthropomorphism is completed. Signi_cant results show di_erences in anthropomorphism perception with the sociability sub-scale being a_ected. Other dimensions are not found to be affected, which may be subject to potential motion dependency or ambiguity of the other HRIES sub-scales. The findings may have an impact on task performance in close HRI, if a robot is only visible in the peripheral visual field and perceived covertly, while overt (foveated) visual attention of an interacting human focuses on tasks requiring hand or arm movements. © 2023 IEEE Computer Society. All rights reserved.",anthropomorphism; eye-movements; human-robot interaction; visual attention,Behavioral research; Human robot interaction; Machine design; Anthropomorphism; Design tests; Field of views; Humans-robot interactions; Peripheral visual field; Point targets; Robot head; Study design; Visual Attention; Visual perception; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85150462569,Movies / Media
Yan D.; Chen L.,"Yan, Dongning (56963248700); Chen, Li (55739265400)",56963248700; 55739265400,The Influence of Personality Traits on User Interaction with Recommendation Interfaces,2023,ACM Transactions on Interactive Intelligent Systems,13,1,3,,,,4,10.1145/3558772,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151887786&doi=10.1145%2f3558772&partnerID=40&md5=6caa5f205dea827a0d780dbba50d2157,"Users' personality traits can take an active role in affecting their behavior when they interact with a computer interface. However, in the area of recommender systems (RS), though personality-based RS has been extensively studied, most works focus on algorithm design, with little attention paid to studying whether and how the personality may influence users' interaction with the recommendation interface. In this manuscript, we report the results of a user study (with 108 participants) that not only measured the influence of users' personality traits on their perception and performance when using the recommendation interface but also employed an eye-tracker to in-depth reveal how personality may influence users' eye-movement behavior. Moreover, being different from related work that has mainly been conducted in a single product domain, our user study was performed in three typical application domains (i.e., electronics like smartphones, entertainment like movies, and tourism like hotels). Our results show that mainly three personality traits, i.e., Openness to experience, Conscientiousness, and Agreeableness, significantly influence users' perception and eye-movement behavior, but the exact influences vary across the domains. Finally, we provide a set of guidelines that might be constructive for designing a more effective recommendation interface based on user personality.  © 2023 Association for Computing Machinery.",eye-tracking experiment; Recommendation interface; user personality,Eye movements; Algorithm design; Eye-tracking; Eye-tracking experiment; Movement behaviour; Performance; Personality traits; Recommendation interface; User interaction; User personalities; User study; Eye tracking,Article,Final,,Scopus,2-s2.0-85151887786,Movies / Media
Drew T.; Konold C.E.; Lavelle M.; Brunyé T.T.; Kerr K.F.; Shucard H.; Weaver D.L.; Elmore J.G.,"Drew, Trafton (15043986300); Konold, Catherine E. (58258821900); Lavelle, Mark (57221716745); Brunyé, Tad T. (35232274200); Kerr, Kathleen F. (7102934181); Shucard, Hannah (57190847288); Weaver, Donald L. (57896495400); Elmore, Joann G. (7005693005)",15043986300; 58258821900; 57221716745; 35232274200; 7102934181; 57190847288; 57896495400; 7005693005,Pathologist pupil dilation reflects experience level and difficulty in diagnosing medical images,2023,Journal of Medical Imaging,10,2,25503,,,,4,10.1117/1.JMI.10.2.025503,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159556935&doi=10.1117%2f1.JMI.10.2.025503&partnerID=40&md5=22241cc64e5a8e74f62b4f128f976a57,"Purpose: Digital whole slide imaging allows pathologists to view slides on a computer screen instead of under a microscope. Digital viewing allows for real-time monitoring of pathologists' search behavior and neurophysiological responses during the diagnostic process. One particular neurophysiological measure, pupil diameter, could provide a basis for evaluating clinical competence during training or developing tools that support the diagnostic process. Prior research shows that pupil diameter is sensitive to cognitive load and arousal, and it switches between exploration and exploitation of a visual image. Different categories of lesions in pathology pose different levels of challenge, as indicated by diagnostic disagreement among pathologists. If pupil diameter is sensitive to the perceived difficulty in diagnosing biopsies, eye-tracking could potentially be used to identify biopsies that may benefit from a second opinion. Approach: We measured case onset baseline-corrected (phasic) and uncorrected (tonic) pupil diameter in 90 pathologists who each viewed and diagnosed 14 digital breast biopsy cases that cover the diagnostic spectrum from benign to invasive breast cancer. Pupil data were extracted from the beginning of viewing and interpreting of each individual case. After removing 122 trials (<10 %) with poor eye-tracking quality, 1138 trials remained. We used multiple linear regression with robust standard error estimates to account for dependent observations within pathologists. Results: We found a positive association between the magnitude of phasic dilation and subject-centered difficulty ratings and between the magnitude of tonic dilation and untransformed difficulty ratings. When controlling for case diagnostic category, only the tonic-difficulty relationship persisted. Conclusions: Results suggest that tonic pupil dilation may indicate overall arousal differences between pathologists as they interpret biopsy cases and could signal a need for additional training, experience, or automated decision aids. Phasic dilation is sensitive to characteristics of biopsies that tend to elicit higher difficulty ratings and could indicate a need for a second opinion.  © 2023 Society of Photo-Optical Instrumentation Engineers (SPIE).",decision-making; diagnostic accuracy; expertise; medical image perception; pathology; pupillometry,Biopsy; Decision support systems; Eye tracking; Linear regression; Medical imaging; Neurophysiology; Decisions makings; Diagnostic accuracy; Diagnostic process; Expertise; Eye-tracking; Medical image perception; Pupil diameter; Pupil dilation; Pupillometry; Second opinions; acceleration; adult; Article; breast biopsy; comparative study; controlled study; decision making; diagnostic accuracy; diagnostic imaging; ductal breast carcinoma in situ; eye movement; eye tracking; feedback system; gaze; histopathology; human; human tissue; invasive breast cancer; longitudinal study; middle aged; multiple linear regression analysis; mydriasis; observational study; pathologist; perception; pupil diameter; pupillometry; residency education; university hospital; waveform; work experience; Decision making,Article,Final,,Scopus,2-s2.0-85159556935,Movies / Media
Saghravanian S.J.; Asadollahi A.,"Saghravanian, Seyed Javad (57190746051); Asadollahi, Ali (6506014431)",57190746051; 6506014431,Acclimatizing and training freely viewing marmosets for behavioral and electrophysiological experiments in oculomotor tasks,2023,Physiological Reports,11,3,e15594,,,,1,10.14814/phy2.15594,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147723354&doi=10.14814%2fphy2.15594&partnerID=40&md5=a6ba3c4de0a47c5527d5d77463c10471,"The marmoset is a small-bodied primate with behavioral capacities and brain structures comparable to macaque monkeys and humans. Its amenability to modern biotechnological techniques like optogenetics, chemogenetics, and generation of transgenic primates have attracted neuroscientists' attention to use it as a model in neuroscience. In the past decade, several laboratories have been developing and refining tools and techniques for performing behavioral and electrophysiological experiments in this new model. In this regard, we developed a protocol to acclimate the marmoset to sit calmly in a primate chair; a method to calibrate the eye-tracking system while marmosets were freely viewing the screen; and a procedure to map motor field of neurons in the SC in freely viewing marmosets. Using a squeeze-walled transfer box, the animals were acclimatized, and chair trained in less than 4 weeks, much shorter than what other studies reported. Using salient stimuli allowed quick and accurate calibration of the eye-tracking system in untrained freely viewing marmosets. Applying reverse correlation to spiking activity and saccadic eye movements, we were able to map motor field of SC neurons in freely viewing marmosets. These refinements shortened the acclimation period, most likely reduced stress to the subjects, and allowed more efficient eye calibration and motor field mapping in freely viewing marmosets. With a penetration angle of 38 degrees, all 16 channels of the electrode array, that is, all recorded neurons across SC layers, had overlapping visual receptive and motor fields, indicating perpendicular penetration to the SC. © 2023 The Authors. Physiological Reports published by Wiley Periodicals LLC on behalf of The Physiological Society and the American Physiological Society.",eye tracking; marmoset; oculomotor; superior colliculus,Animals; Brain; Callithrix; Eye Movements; Humans; Saccades; cefazolin; ketamine; meloxicam; morphine; povidone iodine; acclimatization; animal experiment; Article; Callitrichinae; controlled study; electrophysiological procedures; eye movement; eye tracking; heart rate; male; nonhuman; nuclear magnetic resonance imaging; oculomotor system; optogenetics; single drug dose; training; visual stimulation; animal; brain; Callithrix; eye movement; human; physiology; saccadic eye movement,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147723354,Movies / Media
Jing M.; Kadooka K.; Franchak J.; Kirkorian H.L.,"Jing, Mengguo (57208367449); Kadooka, Kellan (57218878091); Franchak, John (36096593400); Kirkorian, Heather L. (6505817429)",57208367449; 57218878091; 36096593400; 6505817429,The effect of narrative coherence and visual salience on children's and adults' gaze while watching video,2023,Journal of experimental child psychology,226,,,105562,,,3,10.1016/j.jecp.2022.105562,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142403046&doi=10.1016%2fj.jecp.2022.105562&partnerID=40&md5=c6cf71dab3f330b3099094e23338cb13,"Low-level visual features (e.g., motion, contrast) predict eye gaze during video viewing. The current study investigated the effect of narrative coherence on the extent to which low-level visual salience predicts eye gaze. Eye movements were recorded as 4-year-olds (n = 20) and adults (n = 20) watched a cohesive versus random sequence of video shots from a 4.5-min full vignette from Sesame Street. Overall, visual salience was a stronger predictor of gaze in adults than in children, especially when viewing a random shot sequence. The impact of narrative coherence on children's gaze was limited to the short period of time surrounding cuts to new video shots. The discussion considers potential direct effects of visual salience as well as incidental effects due to overlap between salient features and semantic content. The findings are also discussed in the context of developing video comprehension. Copyright © 2022 Elsevier Inc. All rights reserved.",Attention development; Eye movements; Gaze prediction; Video viewing; Visual attention; Visual salience,"Adult; Attention; Child; Child, Preschool; Comprehension; Eye Movements; Fixation, Ocular; Humans; Semantics; adult; attention; child; comprehension; eye fixation; eye movement; human; preschool child; semantics",Article,Final,,Scopus,2-s2.0-85142403046,Movies / Media
Neuhofer Z.; McFadden B.R.; Rihn A.L.; Wei X.; Khachatryan H.,"Neuhofer, Zachary (57215203233); McFadden, Brandon R. (55966266100); Rihn, Alicia L. (38862647100); Wei, Xuan (57191723046); Khachatryan, Hayk (55985061700)",57215203233; 55966266100; 38862647100; 57191723046; 55985061700,Association between visual attention to nutrition priming and subsequent beverage choice,2023,Food Quality and Preference,104,,104721,,,,7,10.1016/j.foodqual.2022.104721,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138790364&doi=10.1016%2fj.foodqual.2022.104721&partnerID=40&md5=cb89d86e14fdca09ca22bc63a5170b98,"This study used eye-tracking data to determine if attention to nutrition information before making purchasing decisions between beverages was associated with selecting a sugar-sweetened beverage and whether the updated Nutrition Facts Label (NFL) garnered more attention than the previous NFL. Participants were randomly assigned to view either the previous or updated NFL, and time to first fixation (TFF) and total visit duration (TVD) were collected while participants viewed NFLs for beverages without additional product details. TFF and TVD were collected for three areas of interest – sugar content, calorie content, and the entire NFL. After viewing nutrition information without product details, participants made non-hypothetical choices between beverages that varied by sugar and calorie content. Results show that without additional product information, the sugar content presented by the updated NFL was more salient and garnered more attention. Although, results about the influence of information salience and the attention given to information on subsequent beverage choices were mixed. Attention to nutrition information may outweigh salience when forming decisions. The updated NFL was more effective at priming individuals with a higher body mass index by influencing subsequent beverage choices. © 2022",Artificially-sweetened beverage; Eye-tracking; Fruit juice; Sugar avoidance; Sugar-sweetened beverage,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85138790364,Movies / Media
Chen G.; Liu S.; Wu H.; Gan J.; Wang X.; Ji Y.,"Chen, Gang (58463988600); Liu, Shuai (55798338500); Wu, Hao (57195204375); Gan, Jinghuan (57220051300); Wang, Xiaodan (54942103000); Ji, Yong (7402076691)",58463988600; 55798338500; 57195204375; 57220051300; 54942103000; 7402076691,Analysis of clinical characteristics of mirror and TV signs in Alzheimer's disease and dementia with Lewy bodies,2023,Journal of International Medical Research,51,2,,,,,4,10.1177/03000605231156098,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148114977&doi=10.1177%2f03000605231156098&partnerID=40&md5=935446dd9312db114a8ac828732e3451,"Objective: This study explored the clinical features of dementia with Lewy bodies (DLB) and Alzheimer's disease (AD) and analyzed the differences in neurologic syndromes, including mirror and TV signs, between different groups. Methods: Patients with AD and DLB (325 and 115, respectively) hospitalized in our institution were enrolled. We compared psychiatric symptoms and neurologic syndromes between the DLB and AD groups and within each subgroup, including the mild-moderate and severe subgroups. Results: The prevalence rates of visual hallucination, parkinsonism, rapid eye movement sleep behavior disorder, depression, delusion, and the Pisa sign were significantly higher in the DLB group than in the AD group. Furthermore, within the mild-moderate subgroup, the mirror sign and Pisa sign prevalence rates were significantly higher in the DLB group than in the AD group. In the severe subgroup, no significant difference was found in any neurologic sign between the DLB and AD groups. Conclusion: Mirror and TV signs are rare and often disregarded because they are not usually invoked during routine inpatient or outpatient interviews. According to our findings, the mirror sign is uncommon in early AD patients but common in early DLB patients and should receive increased attention. © The Author(s) 2023.",Alzheimer's disease; delusional misidentification syndrome; Dementia with Lewy bodies; mirror sign; psychiatric symptom; TV sign,Alzheimer Disease; Hallucinations; Humans; Lewy Body Disease; aged; Alzheimer disease; amnesia; Article; clinical dementia rating scale; cognitive defect; controlled study; delusion; dementia; depression; female; Gilles de la Tourette syndrome; hospitalization; human; Lewy body; male; mental disease; Mini Mental State Examination; mirror sign; multicenter study; neurologic disease; neuropsychological assessment; observational study; Parkinson disease; parkinsonism; physical disease by body function; rapid eye movement sleep behavior disorder; retrospective study; TS sign; visual hallucination; Alzheimer disease; diffuse Lewy body disease; hallucination,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85148114977,Movies / Media
Kim S.B.; Bong S.H.; Lee J.H.; Choi T.Y.; Yoon S.Y.; Kim J.W.,"Kim, Seung Bhin (58131934000); Bong, Su Hyun (57219670611); Lee, Jong Hun (56593376000); Choi, Tae Young (55694739600); Yoon, Seo Young (56449806300); Kim, Jun Won (57191681410)",58131934000; 57219670611; 56593376000; 55694739600; 56449806300; 57191681410,The Usefulness of Quantitative Electroencephalography in Diagnosis and Severity Evaluation of Delirium: A Retrospective Study,2023,Psychiatry Investigation,20,2,,144,151,7.0,1,10.30773/pi.2022.0294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149520831&doi=10.30773%2fpi.2022.0294&partnerID=40&md5=f65fcc7eee9b8cbe6c80316f2a9c62b8,"Objective Incontrovertible disease markers are absent in delirium. This study investigated the usefulness of quantitative electroenceph-alography (qEEG) in diagnosing delirium. Methods This retrospective case-control study reviewed medical records and qEEG data of 69 age/sex-matched patients (delirium group, n=30; control group, n=39). The first minute of artifact-free EEG data with eyes closed was selected. Nineteen electrodes’ sensitivity, specificity, and correlation with delirium rating scale-revised-98 were analyzed. Results On comparing the means of absolute power by frontal, central, and posterior regions, the delta and theta powers showed significant differences (p<0.001) in all regions, and the magnitude of the absolute power was higher in the delirium group than in the control group; only the posterior region showed a significant (p<0.001) difference in beta power. The spectral power of theta at the frontal region (area under the curve [AUC]=0.84) and theta at the central and posterior regions (AUC=0.83) showed 90% sensitivity and 79% specificity, respectively, in differentiating delirious patients and controls. The beta power of the central region showed a significant negative correlation with delirium severity (R=-0.457, p=0.011). Conclusion Power spectrum analysis of qEEG showed high accuracy in screening delirium among patients. The study suggests qEEG as a potential aid in diagnosing delirium. © 2023 Korean Neuropsychiatric Association.",Biomarker; Delirium; Disease severity; Electroencephalography; Retrospective study,adult; aged; agitation; anxiety; area under the curve; Article; artifact; attention; case control study; Clinical Global Impression-severity scale; cognition; controlled study; correlation analysis; delirium; Delirium Rating Scale-revised; diagnostic test accuracy study; disease severity; electroencephalography; eye movement; female; frontal cortex; human; major clinical study; male; medical record; mental disease; power spectrum; psychiatry; psychomotor activity; quantitative analysis; rating scale; receiver operating characteristic; retrospective study; sensitivity and specificity; sleep disordered breathing; spatiotemporal analysis; spectroscopy,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85149520831,Movies / Media
Schmitz I.; Einhäuser W.,"Schmitz, Inka (57936728600); Einhäuser, Wolfgang (8701678900)",57936728600; 8701678900,Gaze estimation in videoconferencing settings,2023,Computers in Human Behavior,139,,107517,,,,8,10.1016/j.chb.2022.107517,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140337409&doi=10.1016%2fj.chb.2022.107517&partnerID=40&md5=0e160a1781636f9aba29f80586f71b84,"Screen-based communication increasingly replaces face-to-face interactions. Gaze information is important for nonverbal communication. Therefore, we investigate how humans (“receivers”) estimate gaze direction of others (“senders”) in videoconferencing-like settings, a major example of screen-based communication. In two online experiments, receivers estimated gaze targets – which were known to the experimenters – from images of senders. As in real videoconferencing settings, receivers had no information about the geometry of the senders' setup (camera position, etc.), but had to rely on the information available on screen. In Experiment 1, we found that gaze-target estimates were more closely related to the actual target positions in the horizontal than in the vertical direction, a bias toward the sender's head position, and some advantage of presenting the same sender in succession. For Experiment 2, we created a new database of sender images, in which the senders' head position in the image and gaze-target position were systematically varied. Additionally, images of natural scenes were presented whose content served as potential gaze targets. At large, we replicated the findings of Experiment 1, and found only little effect of image content on the estimates. As gaze is an important part of intuitive human-machine interaction, our findings bear relevance beyond videoconferencing. © 2022 The Authors",Eye movements; Gaze following; Joint attention; Videoconferencing,Video conferencing; Face-to-face interaction; Gaze direction; Gaze estimation; Gaze following; Head position; Joint attention; Non-verbal communications; On-line experiments; Target position; Videoconferencing; Eye movements,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85140337409,Movies / Media
Sardar S.D.; Yeo S.-H.; Allsop J.E.; Punt T.D.,"Sardar, S.D. (58071994200); Yeo, S.-H. (26322215300); Allsop, J.E. (55850970000); Punt, T.D. (57199159349)",58071994200; 26322215300; 55850970000; 57199159349,Overt visual attention and between-limb asynchrony for bimanual reaching movements,2023,Experimental Brain Research,241,2,,649,660,11.0,2,10.1007/s00221-023-06552-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146596470&doi=10.1007%2fs00221-023-06552-6&partnerID=40&md5=783e72cfe3940081c776a589c5663300,"Although synchrony between the limbs is an often-cited feature of bimanual coordination, recent studies have also highlighted the small asynchronies that can occur. The visuo-motor demands of any bimanual task are considered central to the emergence of asynchrony, but the relationship between the two remains largely unexplored. This study aimed to address this issue. Hand and eye movements were measured in 19 participants, while they made either unimanual or bimanual reach-to-point (aiming) movements to targets presented on a touchscreen. Bimanual movements were either congruent (same-sized targets) or incongruent (different-sized targets). Resulting hand data showed many of the typical patterns of movement previously reported. While temporal coupling between the limbs remained largely evident for bimanual movements, small between-limb asynchronies were apparent and demonstrated clear associations with the competing precision requirements of the targets and related visual attention. Participants mainly directed their gaze towards the more difficult target with corresponding reaching movements demonstrating greater precision than for the easier target. Additionally, there was a reliable tendency for the hand reaching towards the more difficult target to lead. Importantly, it was the competing visuo-motor demands of individual movements rather than overall difficulty that resulted in greater between-limb asynchrony; accordingly, where both targets were small (i.e., the most difficult condition), asynchrony was significantly less pronounced than for incongruent bimanual conditions. The results show how the visuo-motor system balances its apparent drive for synchrony in coordinating bimanual movements with the competing demands that characterise the constituent unimanual movements. © 2023, The Author(s).",Asynchrony; Bimanual coordination; Coupling; Eye-hand coordination; Movement; Reaching,Eye Movements; Functional Laterality; Hand; Humans; Movement; Psychomotor Performance; Reaction Time; Upper Extremity; adult; article; clinical article; eye hand coordination; eye movement; female; gaze; human; human experiment; limb; male; motor system; visual attention; hand; hemispheric dominance; movement (physiology); psychomotor performance; reaction time; upper limb,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85146596470,Movies / Media
Wang J.; Zhang L.; Li T.; Liu W.; Xue H.; Liu S.; Ming D.,"Wang, Junling (58098107500); Zhang, Ludan (57226054354); Li, Tao (58761656500); Liu, Wei (57205722830); Xue, Huiqin (58157831600); Liu, Shuang (56290438100); Ming, Dong (58026507100)",58098107500; 57226054354; 58761656500; 57205722830; 58157831600; 56290438100; 58026507100,Atypical scanning strategies of emotional faces for individuals with high autistic traits,2023,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",,,,,,,1,10.1109/EMBC40787.2023.10340609,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179648753&doi=10.1109%2fEMBC40787.2023.10340609&partnerID=40&md5=eeea382eeaaebd853feec18bee17c579,"Autism has become one of the primary diseases causing disability in children, and the incidence has risen rapidly in recent years. The preclinical study on individuals with high autistic traits is extremely important to reduce genetic risks of autism because high autistic traits is the susceptibility marker of autism. However, few studies explored the face scanning pattern of people with high autistic traits in typical developing populations. In this study, we designed a facial emotion recognition experiment including four emotions (happy, neutral, sad, angry) and three angles (0°, 45°, 90°) , and informed the participants to identify the facial emotion. Forty-two college students with typical development were recruited and divided into high autistic traits (HAT) group and low autistic traits (LAT) group by the Autism-Spectrum Quotient, and we collected the eye movement data using eye-tracking technology when they performed the task. The response time, recognition accuracy, AOI based proportional fixation time and pupil diameter were computed and analyzed for both groups. HATs showed significantly lower recognition accuracy and lower pupil diameter than LATs when recognizing negative emotions (P<0.05) , indicating HATs kept poor autonomic nervous arousal. What ' s more, the proportional fixation time of HATs were significantly more in mouth area but less in eye area than that of LAT group (P<0.05) , revealed HATs had an atypical emotional faces scanning strategies that paid less attention to eyes and more attention to mouth. Our research provides a feasible objective biomarker for screening high autistic traits population. © 2023 IEEE.",,Autistic Disorder; Child; Emotions; Eye Movements; Facial Expression; Happiness; Humans; Diagnosis; Diseases; Eye movements; Eye tracking; Students; Atypicals; College students; Emotion recognition; Facial emotions; Fixation time; Genetic risks; Preclinical studies; Pupil diameter; Recognition accuracy; Scanning strategies; autism; child; emotion; eye movement; facial expression; happiness; human; physiology; Emotion Recognition,Conference paper,Final,,Scopus,2-s2.0-85179648753,Movies / Media
Tang Z.; Liu X.; Huo H.; Tang M.; Qiao X.; Chen D.; Dong Y.; Fan L.; Wang J.; Du X.; Guo J.; Tian S.; Fan Y.,"Tang, Zhili (57226890312); Liu, Xiaoyu (57218655037); Huo, Hongqiang (57202436822); Tang, Min (57226893595); Qiao, Xiaofeng (57704039100); Chen, Duo (57216855150); Dong, Ying (57222476946); Fan, Linyuan (57704040700); Wang, Jinghui (57699015300); Du, Xin (57704726900); Guo, Jieyi (58155870300); Tian, Shan (55886236700); Fan, Yubo (55648008700)",57226890312; 57218655037; 57202436822; 57226893595; 57704039100; 57216855150; 57222476946; 57704040700; 57699015300; 57704726900; 58155870300; 55886236700; 55648008700,Eye movement characteristics in a mental rotation task presented in virtual reality,2023,Frontiers in Neuroscience,17,,1143006,,,,5,10.3389/fnins.2023.1143006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152531785&doi=10.3389%2ffnins.2023.1143006&partnerID=40&md5=4de18a5ab22ab4809bbb4623bbbfac92,"Introduction: Eye-tracking technology provides a reliable and cost-effective approach to characterize mental representation according to specific patterns. Mental rotation tasks, referring to the mental representation and transformation of visual information, have been widely used to examine visuospatial ability. In these tasks, participants visually perceive three-dimensional (3D) objects and mentally rotate them until they identify whether the paired objects are identical or mirrored. In most studies, 3D objects are presented using two-dimensional (2D) images on a computer screen. Currently, visual neuroscience tends to investigate visual behavior responding to naturalistic stimuli rather than image stimuli. Virtual reality (VR) is an emerging technology used to provide naturalistic stimuli, allowing the investigation of behavioral features in an immersive environment similar to the real world. However, mental rotation tasks using 3D objects in immersive VR have been rarely reported. Methods: Here, we designed a VR mental rotation task using 3D stimuli presented in a head-mounted display (HMD). An eye tracker incorporated into the HMD was used to examine eye movement characteristics during the task synchronically. The stimuli were virtual paired objects oriented at specific angular disparities (0, 60, 120, and 180°). We recruited thirty-three participants who were required to determine whether the paired 3D objects were identical or mirrored. Results: Behavioral results demonstrated that the response times when comparing mirrored objects were longer than identical objects. Eye-movement results showed that the percent fixation time, the number of within-object fixations, and the number of saccades for the mirrored objects were significantly lower than that for the identical objects, providing further explanations for the behavioral results. Discussion: In the present work, we examined behavioral and eye movement characteristics during a VR mental rotation task using 3D stimuli. Significant differences were observed in response times and eye movement metrics between identical and mirrored objects. The eye movement data provided further explanation for the behavioral results in the VR mental rotation task. Copyright © 2023 Tang, Liu, Huo, Tang, Qiao, Chen, Dong, Fan, Wang, Du, Guo, Tian and Fan.",eye movements; mental rotation; naturalistic stimuli; three-dimensional stimuli; virtual reality; visual perception,adult; Article; eye movement; eye tracking; female; human; human experiment; male; mental representation; mental rotation test; normal human; saccadic eye movement; spatial attention; three-dimensional imaging; virtual reality; visual feedback; visual information,Article,Final,,Scopus,2-s2.0-85152531785,Movies / Media
Ma L.; Qu X.; Yu S.,"Ma, Liangliang (58679409000); Qu, Xiaomeng (58001553100); Yu, Shu (57226697719)",58679409000; 58001553100; 57226697719,How to Explore the CV Screening Spatial Location: Towards an Eye Movement Experiment,2023,"2023 8th International Conference on Image, Vision and Computing, ICIVC 2023",,,,443,448,5.0,0,10.1109/ICIVC58118.2023.10270766,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175613287&doi=10.1109%2fICIVC58118.2023.10270766&partnerID=40&md5=6ca27b190af5f88a7062498951ff0ca9,"The main purpose of this research is to statistically analysis the method of resume screening results and correlation between resume format, at the same time to explore the attention of resume format. The study was conducted from the perspective of psychology, introducing the point of eye movement research method, the attention in the process of resume screening and reading resume browsing rule, finally providing some advice and help for college graduates. Finally, through the results from eye movements, the best resume template is obtained, that is, work experience in C, school experience in D, winning experience in E area. © 2023 IEEE.",eye movement; resume screening; spatial location; text information,College graduates; Research method; Resume screening; Spatial location; Statistically analysis; Text information; Work experience; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85175613287,Movies / Media
Han N.X.; Eckstein M.P.,"Han, Nicole X. (57222178030); Eckstein, Miguel P. (7101859525)",57222178030; 7101859525,Head and body cues guide eye movements and facilitate target search in real-world videos,2023,Journal of Vision,23,6,5,,,,0,10.1167/JOV.23.6.5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163908548&doi=10.1167%2fJOV.23.6.5&partnerID=40&md5=b726e16d788815e09c9befce9a8d32f5,"Static gaze cues presented in central vision result in observer shifts of covert attention and eye movements, and benefits in perceptual performance in the detection of simple targets. Less is known about how dynamic gazer behaviors with head and body motion influence search eye movements and performance in perceptual tasks in real-world scenes. Participants searched for a target person (yes/no task, 50% presence), whereas watching videos of one to three gazers looking at a designated person (50% valid gaze cue, looking at the target). To assess the contributions of different body parts, we digitally erase parts of the gazers in the videos to create three different body parts/whole conditions for gazers: floating heads (only head movements), headless bodies (only lower body movements), and the baseline condition with intact head and body.We show that valid dynamic gaze cues guided participants’ eye movements (up to 3 fixations) closer to the target, speeded the time to foveate the target, reduced fixations to the gazers, and improved target detection. The effect of gaze cues in guiding eye movements to the search target was the smallest when the gazer’s head was removed from the videos. To assess the inherent information about gaze goal location for each body parts/whole condition, we collected perceptual judgments estimating gaze goals by a separate group of observers with unlimited time. Observers’ perceptual judgments showed larger estimate errors when the gazer’s head was removed. This suggests that the reduced eye movement guidance from lower body cueing is related to observers’ difficulty extracting gaze information without the presence of the head. Together, the study extends previous work by evaluating the impact of dynamic gazer behaviors on search with videos of real-world cluttered scenes. © 2023 The Authors",attention; dynamic gaze; eye movements; gaze cues,"Cues; Eye Movements; Fixation, Ocular; Head Movements; Humans; Vision, Ocular; association; eye fixation; eye movement; head movement; human; vision",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85163908548,Movies / Media
Chen X.; Wang S.; Yang X.; Yu C.; Ni F.; Yang J.; Tian Y.; Ye J.; Liu H.; Luo R.,"Chen, Xiaolu (57190134940); Wang, Sihan (58723583200); Yang, Xiaowen (59147853300); Yu, Chunmei (58669161000); Ni, Fang (58669979200); Yang, Jie (57941558800); Tian, Yu (59524084800); Ye, Jiucai (54994053100); Liu, Hao (58723566700); Luo, Rong (55599203900)",57190134940; 58723583200; 59147853300; 58669161000; 58669979200; 57941558800; 59524084800; 54994053100; 58723566700; 55599203900,Utilizing artificial intelligence-based eye tracking technology for screening ADHD symptoms in children,2023,Frontiers in Psychiatry,14,,1260031,,,,6,10.3389/fpsyt.2023.1260031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177837085&doi=10.3389%2ffpsyt.2023.1260031&partnerID=40&md5=a3c08d667ff489fa2f4da112918dfab5,"Objective: To explore the potential of using artificial intelligence (AI)-based eye tracking technology on a tablet for screening Attention-deficit/hyperactivity disorder (ADHD) symptoms in children. Methods: We recruited 112 children diagnosed with ADHD (ADHD group; mean age: 9.40 ± 1.70 years old) and 325 typically developing children (TD group; mean age: 9.45 ± 1.59 years old). We designed a data-driven end-to-end convolutional neural network appearance-based model to predict eye gaze to permit eye-tracking under low resolution and sampling rates. The participants then completed the eye tracking task on a tablet, which consisted of a simple fixation task as well as 14 prosaccade (looking toward target) and 14 antisaccade (looking away from target) trials, measuring attention and inhibition, respectively. Results: Two-way MANOVA analyses demonstrated that diagnosis and age had significant effects on performance on the fixation task [diagnosis: F(2, 432) = 8.231, ***p < 0.001; Wilks’ Λ = 0.963; age: F(2, 432) = 3.999, *p < 0.019; Wilks’ Λ = 0.982], prosaccade task [age: F(16, 418) = 3.847, ***p < 0.001; Wilks’ Λ = 0.872], and antisaccade task [diagnosis: F(16, 418) = 1.738, *p = 0.038; Wilks’ Λ = 0.938; age: F(16, 418) = 4.508, ***p < 0.001; Wilks’ Λ = 0.853]. Correlational analyses revealed that participants with higher SNAP-IV score were more likely to have shorter fixation duration and more fixation intervals (r = −0.160, 95% CI [0.250, 0.067], ***p < 0.001), poorer scores on adjusted prosaccade accuracy, and poorer scores on antisaccade accuracy (Accuracy: r = −0.105, 95% CI [−0.197, −0.011], *p = 0.029; Adjusted accuracy: r = −0.108, 95% CI [−0.200, −0.015], *p = 0.024). Conclusion: Our AI-based eye tracking technology implemented on a tablet could reliably discriminate eye movements of the TD group and the ADHD group, providing a potential solution for ADHD screening outside of clinical settings. Copyright © 2023 Chen, Wang, Yang, Yu, Ni, Yang, Tian, Ye, Liu and Luo.",ADHD; AI eye-tracking technology; antisaccade; intrusive saccades; prosaccade,accuracy; Article; artificial intelligence; attention; attention deficit hyperactivity disorder; calibration; child; color blindness; controlled study; diagnostic test accuracy study; DSM-5; eye movement; eye movement disorder; eye-tracking technology; female; follow up; human; human experiment; male; patient-reported outcome; saccadic eye movement; school child; screening; seizure; visual acuity; visual field,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85177837085,Movies / Media
Serpa E.; Alecka M.; Berzina A.; Goliskina V.; Kassaliete E.; Klavinska A.; Koleda M.; Mikelsone R.; Ozola E.; Ruza T.; Svede A.; Toloka D.; Vasiljeva S.; Volberga L.; Ceple I.; Krumina G.,"Serpa, Evita (58636937800); Alecka, Madara (58636999900); Berzina, Asnate (58636968200); Goliskina, Viktorija (58636904700); Kassaliete, Evita (55750109800); Klavinska, Anete (58636904800); Koleda, Marija (58636874100); Mikelsone, Rita (58636874200); Ozola, Elizabete (58636874300); Ruza, Tomass (58636812100); Svede, Aiga (6507252396); Toloka, Daniela (58637000000); Vasiljeva, Sofija (58636781800); Volberga, Liva (58636874400); Ceple, Ilze (57222431861); Krumina, Gunta (12238899900)",58636937800; 58636999900; 58636968200; 58636904700; 55750109800; 58636904800; 58636874100; 58636874200; 58636874300; 58636812100; 6507252396; 58637000000; 58636781800; 58636874400; 57222431861; 12238899900,Assessment of Children Eye Movement Performance: An Eye-Tracker Approach,2023,IFMBE Proceedings,89,,,246,250,4.0,0,10.1007/978-3-031-37132-5_31,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176784482&doi=10.1007%2f978-3-031-37132-5_31&partnerID=40&md5=ec57d2d36ec0be4df38563331b7a137c,"Eye movement disorders can have various impacts on reading difficulties, such as tracking difficulties, unstable fixation, issues related to visual processing and attention. A comprehensive understanding of patient’s visual functions and reading ability may require a precise evaluation of their eye movements by vision or speech specialists. Eye tracking is a widely applied method for assessing eye movement parameters during reading and other visual tasks. By using eye tracking, it is possible to track eye movements across words and sentences without requiring any overt verbal or motor response from the child. The aim of our study was to develop an objective method for the assessing eye movement performance in children using eye-tracking technology. We tested this method on 53 s-grade school-aged children (7 and 8 years old) using special reading tasks displayed on a computer screen and eye movement recording with a Tobii Pro Fusion eye tracking device (250 Hz). Speech therapists assessed the children’s reading skills using the Acadience Reading test. Our results indicated a correlation between the children’s reading performance and the number of eye fixations, average fixation duration, and total reading time. Based on our results, we conclude that the developed method based on eye-tracking works well both as a screening method and as a diagnostic method for assessing eye movements during reading. This method will be particularly useful for optometrists, speech therapists, and other specialists involved in children’s vision, health, and academic achievements. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Acadience Reading test; Eye Tracking; Fixation Duration; Fixations; Reading Speed,Diagnosis; Eye tracking; Acadience reading test; Eye trackers; Eye-tracking; Fixation; Fixation duration; Movement disorders; Movement performance; Reading speed; Visual Attention; Visual-processing; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85176784482,Movies / Media
Gao J.; Zhao L.; Zhong T.; Li C.; He Z.; Wei Y.; Zhang S.; Guo L.; Liu T.; Han J.; Zhang T.,"Gao, Jiaxing (57671814700); Zhao, Lin (57748941700); Zhong, Tianyang (58260861300); Li, Changhe (57669997400); He, Zhibin (57209242288); Wei, Yaonai (57671201500); Zhang, Shu (55363657100); Guo, Lei (56428255600); Liu, Tianming (58741130700); Han, Junwei (24450644400); Zhang, Tuo (35191407900)",57671814700; 57748941700; 58260861300; 57669997400; 57209242288; 57671201500; 55363657100; 56428255600; 58741130700; 24450644400; 35191407900,Prediction of Cognitive Scores by Joint Use of Movie-Watching fMRI Connectivity and Eye Tracking via Attention-CensNet,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14221 LNCS,,,287,296,9.0,1,10.1007/978-3-031-43895-0_27,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174690727&doi=10.1007%2f978-3-031-43895-0_27&partnerID=40&md5=6b185dc66ec0e77af33a032f9a955d14,"Brain functional connectivity under the naturalistic paradigm has been demonstrated to be better at predicting individual behaviors than other brain states, such as rest and task. Nevertheless, the state-of-the-art methods are difficult to achieve desirable results from movie-watching paradigm fMRI(mfMRI) induced brain functional connectivity, especially when the datasets are small, because it is difficult to quantify how much useful dynamic information can be extracted from a single mfMRI modality to describe the state of the brain. Eye tracking, becoming popular due to its portability and less expense, can provide abundant behavioral features related to the output of human’s cognition, and thus might supplement the mfMRI in observing subjects’ subconscious behaviors. However, there are very few works on how to effectively integrate the multimodal information to strengthen the performance by unified framework. To this end, an effective fusion approach with mfMRI and eye tracking, based on Convolution with Edge-Node Switching in Graph Neural Networks (CensNet), is proposed in this article, with subjects taken as nodes, mfMRI derived functional connectivity as node feature, different eye tracking features used to compute similarity between subjects to construct heterogeneous graph edges. By taking multiple graphs as different channels, we introduce squeeze-and-excitation attention module to CensNet (A-CensNet) to integrate graph embeddings from multiple channels into one. The experiments demonstrate the proposed model outperforms the one using single modality, single channel and state-of-the-art methods. The results suggest that brain functional activities and eye behaviors might complement each other in interpreting trait-like phenotypes. Our code will make public later. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Attention; CensNet; Eye Movement; Functional Connectivity; Naturalistic Stimulus,Brain; Eye movements; Functional neuroimaging; Graph neural networks; Graph theory; Attention; Behavioral features; Brain state; Censnet; Dynamic information; Eye-tracking; Functional connectivity; Individual behavior; Naturalistic stimulus; State-of-the-art methods; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85174690727,Movies / Media
Tan Z.; Liu Z.; Guo Z.; Gong S.,"Tan, Zhiya (58413407100); Liu, Zhen (57203466991); Guo, Zixin (58558521900); Gong, Shiqi (58413407000)",58413407100; 57203466991; 58558521900; 58413407000,Designing a Robot for Enhancing Attention of Office Workers with the Heavily Use of Screen,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14031 LNCS,,,246,261,15.0,3,10.1007/978-3-031-35696-4_18,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169448026&doi=10.1007%2f978-3-031-35696-4_18&partnerID=40&md5=7544981e73cde06fef1741a504fcbc91,"In the context of the epidemic and the Internet era, the computer screen has become a necessary device for people in the workplace. According to statistics, office workers face the computer for eight hours a day on average. Prolonged gaze at the screen has been shown to be one of the causes of reduced productivity, in addition to workplace loneliness, distraction, lack of motivation, and lack of work planning are the current state of low productivity. Existing work has shown that companion robotics has achieved remarkable success in helping humans and improving human well-being. In this paper, we design a work companion robot to improve worker productivity in the work office in three dimensions: mental, physical, and mental health. To support our study, we conducted a survey of daily computer office workers to understand where the problems lie and to gather information about the possible use of robots to support workers. Then, we proposed the concept of a companion robot to alert workers and suggest next actions by monitoring their pupil status, sight tracking, and blink frequency to determine their concentration and fatigue. To convert between pupil state and concentration level, we collected attention-related eye movement data under task state from a group of computer workers based on the Stroop paradigm and classified and quantified the concentration status using a random forest regression model. Finally, we designed the appearance of the robot, its internal structure, and its interaction. Future work will focus on experimentally verifying the effectiveness of this robot in improving workers’ attention and work isolation, and refining more features. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Attention; Companion Robot; Eye Movement Data; Feature Selection; Gaze Tracking; Pupil Response; Stroop Paradigm; Workplace Loneliness,Eye movements; Eye tracking; Forestry; Machine design; Office buildings; Regression analysis; Attention; Companion robot; Eye movement datum; Features selection; Gaze-tracking; Office workers; Pupil response; Stroop paradigm; Workers'; Workplace loneliness; Robots,Conference paper,Final,,Scopus,2-s2.0-85169448026,Movies / Media
Lekhnitskaya P.A.,"Lekhnitskaya, Polina A. (58683671900)",58683671900,Non-visual Eye-Movements Model During Performing Cognitive Tasks in Short-Term Memory,2023,Studies in Computational Intelligence,1120,,,173,178,5.0,0,10.1007/978-3-031-44865-2_19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175801981&doi=10.1007%2f978-3-031-44865-2_19&partnerID=40&md5=19a020823a3b659753b362290e1d1789,"In the blank screen paradigm participants solved cognitive tasks. Current fixation duration and saccade peak velocity differ in learning and performing some kinds of tasks. Retrieving information from memory and following mental processing depends on the characteristics of input task and its difficulty. The best fixation accuracy performance was in the participants who named only two levels of task difficulty, the best saccade accuracy performance was in Random Forest Classifier for saccades. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Cognition; Eye Tracking; Non-visual Eye Movements,,Conference paper,Final,,Scopus,2-s2.0-85175801981,Movies / Media
Akshay S.; Shukla A.; Raman V.K.,"Akshay, S. (23466346300); Shukla, Anupam (58727745500); Raman, Vishnu K (58617283900)",23466346300; 58727745500; 58617283900,UEye: Insights on User Interface Design Using Eye Movement Visualizations,2023,Communications in Computer and Information Science,1848 CCIS,,,253,264,11.0,0,10.1007/978-3-031-37940-6_21,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172288264&doi=10.1007%2f978-3-031-37940-6_21&partnerID=40&md5=16ccf0f7e0ce6a4d6bbb563789d3be8c,"The internet has become a primary need in the present, and understanding the importance of a well-designed User Interfaces(UI) is a prerequisite. Eye-tracking can help design appropriate UI that can have a positive impact on any business. Eye Tracking is the method of knowing where a person is looking. This study presents a novel eye-tracking system that uses a high-resolution webcam to record raw eye gaze data. The system includes an initial calibration process that adapts to the user’s screen size and lighting conditions to improve tracking accuracy. After calibration, the system records eye movement data during a user’s interaction with a designated test subject. Preprocessing is applied to ensure data reliability, and fixations are calculated based on Euclidean distance, time differences, and velocity thresholds. The resulting fixations are used to generate visual heat maps and scan paths that reveal user behavior on the test subject. Further analysis, such as region-wise attraction percentages, helps identify important UI components that users focus on the most. Overall, this eye- tracking system provides valuable insights into user behavior and can inform UI design decisions to enhance user experience. The proposed system is not only cost-effective but also provides decent accuracy of 83%, making it a useful tool for designers and organization to optimize their UI components for user attention. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Eye tracking; Fixation; Heatmap; User Interface; Visualization,Behavioral research; Calibration; Cost effectiveness; Eye movements; User interfaces; Visualization; Eye tracking systems; Eye-gaze; Eye-tracking; Fixation; Heatmaps; High resolution; User behaviors; User interface components; User interface designs; WebCams; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85172288264,Movies / Media
Shilaskar S.; Bhatlawande S.; Gadad T.; Ghulaxe S.; Gaikwad R.,"Shilaskar, Swati (57189017229); Bhatlawande, Shripad (55212307900); Gadad, Tejal (58136327500); Ghulaxe, Shruti (58136327600); Gaikwad, Rachana (58135906300)",57189017229; 55212307900; 58136327500; 58136327600; 58135906300,Student Eye Gaze Tracking and Attention Analysis System using Computer Vision,2023,"Proceedings - 7th International Conference on Computing Methodologies and Communication, ICCMC 2023",,,,889,895,6.0,7,10.1109/ICCMC56507.2023.10083874,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153563849&doi=10.1109%2fICCMC56507.2023.10083874&partnerID=40&md5=8dc4bba4907198986d2e5ebc9e2b2131,"Along with self-reports and periodic assessments students' engagement in online lectures can be understood with the help of eye gaze tracking. This data can provide valuable insights on the learning pattern of students and areas of difficulty which further aid the teachers in improving their teaching style. Extensive research has been performed in eye gaze tracking based on their location, shape, texture, or a combination of these features. Usually, deep learning-based neural networks are used for this purpose due to its increased efficiency and accuracy. Deep learning requires huge amount of high-quality annotated data to train the model and has high complexity. Thus, this paper proposes an approach for analyzing the attention of students in online classes by tracking the eye gaze using computer vision which is computationally cheap. This technique is being used in various applications such as human-computer interaction, cognitive psychology, and security systems. Using eye-tracking technology, researchers can follow and measure eye movements, pupil dilation, point of glance, and blinking to identify where study subjects' visual attention is focused, what they pay attention to, and what they ignore. With the help of Haar Cascade and pupil detection algorithms such as Daugman algorithm, Hough Circular Transform, Blob Detection, and Centroid Detection, the eye movements are tracked. In order to map the eye gaze onto the monitor's screen a geometric model is proposed which can classify the gaze direction into nine states with respect to the screen: center, left, right, top, top left, top right, bottom, bottom left, and bottom right. The system calculates the amount of time a student is not paying attention to the screen based on which the attentiveness in online lectures is decided. There are three classifications for students' attention states: alert, sleepy, and not attentive. This system is sensitive to glares, head movements, varying lightings, and motion blur due to the lower accuracy and difficulty in detecting the pupil by computer vision algorithms. © 2023 IEEE.",Attention analysis; Computer Vision; Gaze-tracking; Haar Cascade; Pupil-detection,Behavioral research; Cognitive systems; Computer vision; Deep learning; Eye movements; Human computer interaction; Students; Textures; Analysis system; Attention analyse; Eye gaze tracking; Eye-gaze; Gaze-tracking; Haar cascade; Learning patterns; Periodic assessment; Pupils detection; Student engagement; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85153563849,Movies / Media
Saravanan G.; Helenprabha K.; Juliet P.S.; Yuvaraj S.; Gnanavel N.; Srinivasan C.,"Saravanan, G. (57191347937); Helenprabha, K. (35221578900); Juliet, P. Sudha (57934868100); Yuvaraj, S. (57214287052); Gnanavel, N. (58893777300); Srinivasan, C. (57204028096)",57191347937; 35221578900; 57934868100; 57214287052; 58893777300; 57204028096,Convolutional Neural Networks-based Real-time Gaze Analysis with IoT Integration in User Experience Design,2023,"2nd International Conference on Automation, Computing and Renewable Systems, ICACRS 2023 - Proceedings",,,,1564,1569,5.0,46,10.1109/ICACRS58579.2023.10404296,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185385606&doi=10.1109%2fICACRS58579.2023.10404296&partnerID=40&md5=075d501fa1f91a4336323bf924fa5134,"Internet of Things (IoT) technology in user experience design has transformed its use of digital devices and apps. This transformation includes real-time user gaze analysis, which may greatly improve user experience. It uses machine learning to provide real-time gaze analysis and IoT device integration for a smooth and customized user experience. Gaze tracking and analysis are very accurate using machine learning techniques, especially deep learning models. It uses Convolutional Neural Networks (CNNs) to identify and predict user gaze patterns. IoT devices may adjust to user preferences in real time by analyzing eye movements and focus spots, making them more intuitive and immersive. It discusses IoT infrastructure for gaze analysis and user experience improvement. Gaze data from IoT sensors and cameras is analyzed locally or in the cloud using machine learning algorithms. To improve user experience, insights are utilized to change screen content, illumination, and augmented reality feedback. Gaze analysis and IoT integration privacy and ethics are also addressed. This research addresses real-time gaze analysis systems challenges by combining CNNs with IoT. Problems with scalability and practical adaptation impact recent methods, such as attention-based models and cloud computing. The suggested system designs address these issues by seamlessly integrating CNNs with IoT, giving an efficient and context-aware solution for better user experience design. The might transform user experience design by making interfaces more users, flexible, andcustomized. © 2023 IEEE.",Convolutional Neural Networks; Gaze Tracking; IoT Integration; User Data; User Experience Design,Augmented reality; Convolution; Convolutional neural networks; Deep learning; Digital devices; Eye tracking; Integration; Learning algorithms; Learning systems; Real time systems; User interfaces; Convolutional neural network; Gaze analysis; Gaze-tracking; Internet of thing integration; Internet of things technologies; Network-based; Real- time; User data; User experience design; Users' experiences; Internet of things,Conference paper,Final,,Scopus,2-s2.0-85185385606,Movies / Media
Choi S.,"Choi, Sungmook (56124260900)",56124260900,Visual saliency in captioned digital videos and learning of English collocations: An eye-tracking study,2023,Language Learning and Technology,27,1,,1,21,20.0,6,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205477052&partnerID=40&md5=a53d15e22f853fb66a843322b5d5aca1,"This study explored how visual input enhancement impacts caption-reading behaviors, the acquisition of English collocations, and the recall of onscreen captions. The participants comprised 53 Korean undergraduate students at a high-intermediate level of English proficiency. They were assigned to either a baseline or an enhancement group. The baseline group viewed a digital video with unenhanced captions, whereas the enhancement group watched the same video with enhanced captions (i.e., captions including yellow-colored collocations). The eye movements of the participants were measured using an eye tracker. Thereafter, they completed a collocation test and a caption recall test. The results showed that the baseline and enhancement groups did not vary in their caption-reading behaviors. Conversely, the enhancement group significantly outperformed the baseline group on the collocation test. In the caption recall test, the enhancement group recalled significantly more target collocations than the baseline group, whereas the two groups did not differ in recalling unenhanced captions. Finally, correlational analyses revealed nonsignificant correlations between attention to target collocations and collocation test scores in both groups. This evidence suggests that enhanced video captions may be an effective means of stimulating collocational competence that is not at the expense of second language learners’ ability to learn video content. © (2023), (University of Hawaii at Manoa). All rights reserved.",Caption; Collocation; Eye Tracking; Visual Input Enhancement,,Article,Final,,Scopus,2-s2.0-85205477052,Movies / Media
Jia L.-X.; Huang S.; Ding Y.-Q.; Tu Y.; Wang L.-L.,"Jia, Li-Xiu (58462269500); Huang, Sheng (58621969400); Ding, Yi-Quan (58523462100); Tu, Yan (7201525685); Wang, Li-Li (57207491164)",58462269500; 58621969400; 58523462100; 7201525685; 57207491164,Visual fatigue measurement of display mode based on ECG and eye movement signal,2023,Chinese Journal of Liquid Crystals and Displays,38,9,,1205,1214,9.0,1,10.37188/CJLCD.2022-0324,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172444071&doi=10.37188%2fCJLCD.2022-0324&partnerID=40&md5=e1b3718a1c6e3596323eb8b25c66c959,"The combined measurement methods of subjective questionnaires，ECG signals，eye movement signals and ophthalmological parameters are used to study the effect of different types of display modes on visual fatigue of 2D and 3D TVs. The results show that the relative changes of BCDVA，TBUT，pupil diameter and Shannon entropy after watching 3D mode are significantly greater than those after watching 2D mode. Differences in relative RR interval values and heart rate（HR）induced by viewing 2D and 3D modes gradually increase after 50 min. Different types of display modes have different effects on subjective scoring symptoms，ophthalmological parameters，ECG parameters and eye movement parameters. The visual fatigue caused by watching 3D mode is greater than that caused by watching 2D mode，especially after watching 2D/3D mode 50 min，which has reference value for 3D movie production. © 2023, Science Press. All rights reserved.",display mode; eye movement; heart rate variability; stereo display; visual fatigue,,Article,Final,,Scopus,2-s2.0-85172444071,Movies / Media
Aloran S.; Nakhleh S.; Alrhmman I.A.,"Aloran, Saher (59239717200); Nakhleh, Saed (59239807000); Alrhmman, Issa Abd (59240063500)",59239717200; 59239807000; 59240063500,Developing a Non-Invasive Eye Tracking Screening Tool for early Detection of Alzheimer's Disease,2023,"2nd International Engineering Conference on Electrical, Energy, and Artificial Intelligence, EICEEAI 2023",,,,,,,1,10.1109/EICEEAI60672.2023.10590133,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199966172&doi=10.1109%2fEICEEAI60672.2023.10590133&partnerID=40&md5=adbd0d5fa003256784dc4a7a3eb6559c,"Alzheimer's disease (AD) is a common neurodegenerative condition that impairs daily functioning, memory, and cognition. The ability to treat and manage the disease effectively depends on early detection, but current diagnostic techniques frequently fall short of this goal. This study assesses the potential of eye tracking parameters, remarkably smooth pursuit amplitude, and fixation stability, as biomarkers for AD screening in the early-mid stages to address this issue. A visual tracking task is used in the study to measure participants' fixation stability and smooth pursuit amplitude. The sample includes individuals diagnosed with AD and healthy older adults, to compare eye-tracking parameters between the two groups. The study's findings show that smooth pursuit amplitude and fixation stability are significantly different between AD and healthy controls. This study highlights the importance of investigating novel and non-invasive methods for early detection of AD and establishes the foundation for further investigations in this area. The results of this study will help develop a cost-effective screening tool that is easily accessible for early-stage AD. Importantly, the study reported that the AUC of the AD group was 0.966 and the AUC of the control group was 0.869, with a sensitivity of 93% and specificity of 100%, and an overall accuracy of 96.5%. The promising findings of this study will help create a low-cost screening tool that is easily accessible for AD in its early stages. © 2023 IEEE.",Alzheimer's Disease; eye movement; eye tracking; Screening tool,Cost effectiveness; Diagnosis; Eye movements; Neurodegenerative diseases; Noninvasive medical procedures; Alzheimers disease; Condition; Current diagnostics; Diagnostics techniques; Disease screening; Eye-tracking; Neurodegenerative; Screening tool; Smooth pursuit; Visual Tracking; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85199966172,Movies / Media
Shajhutdinova R.I.,"Shajhutdinova, Ruzalina I. (59013706300)",59013706300,How do Eye Movements and Visual Attention in Letter-Finding Tasks Differ in Children with Different Levels of Reading Skills?,2023,"RUDN Journal of Language Studies, Semiotics and Semantics",14,4,,1107,1121,14.0,0,10.22363/2313-2299-2023-14-4-1107-1121,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192099078&doi=10.22363%2f2313-2299-2023-14-4-1107-1121&partnerID=40&md5=b8b6a7d48a1da3c3a517deab859778cf,"Children with different levels of reading proficiency demonstrate different information processing speed, reading accuracy and cognitive strategies. The study presents the results of analyses of eye movement features when performing letter search tasks in lexical and sub-lexical environments. The task of searching for a particular grapheme by the respondents is approximated to real-life conditions, since in the course of language learning students regularly face the tasks of searching for certain orthograms in educational texts or self-checking tasks (i.e., errors in their own texts), which is especially important for children with dysorphographia, regulatory dysgraphia, and other learning difficulties. Forty-nine children aged 9 to 10 years participated in the study. Reading skills were assessed using the Standardized Assessment of Reading Skills (SARS). Nonverbal intelligence was assessed by using Raven’s coloured progressive matrices. Participants performed a letter search task in text and letter list, eye movements were recorded using the EyeLink 1000 Plus eye tracker. Rank correlation analyses showed that the level of reading skill development was related to the efficiency of finding specific items in a given context. In addition, the duration and number of gaze fixations on the searched units in the letter list were not always related to the number of correct answers, indicating a complex process of visual attention during the search task. In addition, it was observed that foveal vision was not always necessary for performing search tasks in children with normally developed reading skill levels. The study also investigated the concept of functional visual field and how the surroundings of the items being searched affect the attentional mechanisms involved in visual search. Overall, this study provides evidence on the relationship between reading skills, attention and visual information processing, which contributes to understanding reading strategies in children with dyslexia and creating new methods for screening children with dyslexia in the future. © Shajhutdinova R.I., 2023.",attention; dyslexia; eye tracking; functional visual field; letter-finding tasks; reading skills; visual information processing,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85192099078,Movies / Media
Gao Z.; Yang R.; Li J.; Zhang J.; Liu Z.,"Gao, Zenggui (57203146070); Yang, Ruining (57739169000); Li, Jiaying (57550760600); Zhang, Jinmei (58139840100); Liu, Zheng (55607408100)",57203146070; 57739169000; 57550760600; 58139840100; 55607408100,Usability Evaluation of Spacecraft Digital Twin System Based on Eye Movement,2023,Lecture Notes in Electrical Engineering,994 LNEE,,,167,175,8.0,0,10.1007/978-981-19-9338-1_22,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149992210&doi=10.1007%2f978-981-19-9338-1_22&partnerID=40&md5=25292e4f38c98c81b6f7d7ef4a0ef3be,"Purpose To do a usability test of the spacecraft digital twin system interface to discuss the user's focus on content, information search efficiency and satisfaction when using the system, and analyse existing problems for subsequent iterative optimization. Method Obtain user’s eye movement data to conduct an objective usability analysis, and combined with SUS usability scale, users’ subjective evaluation was obtained. Result When users used the spacecraft digital twin system, simulation monitoring screen, the health status of the organization and the torque change were paid more attention; the system layout is reasonable, but the user's search efficiency for detailed data is not high, which is more suitable for professionals. The user experience of this system remains to be improved. Conclusion Based on the results of eye movement experiments, reasonable suggestions can be made for the subsequent iterations of the spacecraft digital twin system interface. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Digital Twin; Eye movement; Spacecraft; SUS; Usability test,Efficiency; Iterative methods; Search engines; Spacecraft; Usability engineering; Content information; Existing problems; Information search; Iterative Optimization; Search efficiency; SUS; Systems interfaces; Usability evaluation; Usability tests; User focus; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85149992210,Movies / Media
Ziman K.; Kimmel S.C.; Farrell K.T.; Graziano M.S.A.,"Ziman, Kirsten (57201697598); Kimmel, Sarah C. (58633660600); Farrell, Kathryn T. (58633784300); Graziano, Michael S.A. (7005346225)",57201697598; 58633660600; 58633784300; 7005346225,Predicting the attention of others,2023,Proceedings of the National Academy of Sciences of the United States of America,120,42,e2307584120,,,,6,10.1073/pnas.2307584120,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173328517&doi=10.1073%2fpnas.2307584120&partnerID=40&md5=75cfdfdb8c2b0c087801e380979eef7d,"As social animals, people are highly sensitive to the attention of others. Seeing someone else gaze at an object automatically draws one’s own attention to that object. Monitoring the attention of others aids in reconstructing their emotions, beliefs, and intentions and may play a crucial role in social alignment. Recently, however, it has been suggested that the human brain constructs a predictive model of other people’s attention that is far more involved than a moment-by-moment monitoring of gaze direction. The hypothesized model learns the statistical patterns in other people’s attention and extrapolates how attention is likely to move. Here, we tested the hypothesis of a predictive model of attention. Subjects saw movies of attention displayed as a bright spot shifting around a scene. Subjects were able to correctly distinguish natural attention sequences (based on eye tracking of prior participants) from altered sequences (e.g., played backward or in a scrambled order). Even when the attention spot moved around a blank background, subjects could distinguish natural from scrambled sequences, suggesting a sensitivity to the spatial–temporal statistics of attention. Subjects also showed an ability to recognize the attention patterns of different individuals. These results suggest that people possess a sophisticated model of the normal statistics of attention and can identify deviations from the model. Monitoring attention is therefore more than simply registering where someone else’s eyes are pointing. It involves predictive modeling, which may contribute to our remarkable social ability to predict the mind states and behavior of others. © 2023 the Author(s).",attention; eye movement; predictive models; social attention; social cognition,"Brain; Cognition; Emotions; Eye; Humans; Vision, Ocular; adult; algorithm; Article; attention; emotion; eye movement; eye position; eye tracking; facial recognition; female; human; human experiment; male; normal human; prediction; predictive model; recognition; sensitivity analysis; social cognition; spatiotemporal analysis; visual stimulation; brain; cognition; eye; vision",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85173328517,Movies / Media
Chen Y.; Li M.; Guo F.; Wang X.,"Chen, Yuhan (58017962000); Li, Mingming (57222633115); Guo, Fu (55202044200); Wang, Xueshuang (57105856600)",58017962000; 57222633115; 55202044200; 57105856600,The effect of short-form video addiction on users’ attention,2023,Behaviour and Information Technology,42,16,,2893,2910,17.0,58,10.1080/0144929X.2022.2151512,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144073233&doi=10.1080%2f0144929X.2022.2151512&partnerID=40&md5=ae3c7ff9e250303f65b06458b941bd66,"Short-form videos are popular worldwide as a thriving form of entertainment. Its fragmentation pattern, which presents users with intensive and engaging information, might lead to addiction and adverse effects. This study aims to investigate the effect of addiction to short-form videos on users’ attention, including attention while watching videos and the ability of attentional concentration after watching time. Users addicted or non-addicted to short-form videos were screened to participate in a short-form video watching task and a Stroop task based on eye-tracking technology. The results showed that addicted users reported less interest, centration, and more distractions and exhibited more fixation counts and shorter average fixation duration during watching short-form videos than non-addicted users. In the Stroop task, addicted users achieved longer response time and less accuracy and showed longer average fixation duration, more fixation counts, and saccades between the targets and the distractors than non-addicted users. The results suggest that addicted users might suffer more difficulties maintaining attention, have more attention deficits while watching short-form videos, and have impaired attentional concentration for processing interference. The findings contribute to understanding the effect of addiction to short-form videos and provide helpful insight into using it healthily and preventing addiction. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",addiction; attention; eye-tracking; Short-form videos; Stroop task; user characteristics,Eye movements; Addiction; Adverse effect; Attention; Average fixation durations; Eye-tracking; Fragmentations pattern; Short-form video; Stroop task; User attention; User characteristics; Eye tracking,Article,Final,,Scopus,2-s2.0-85144073233,Movies / Media
Recker L.; Poth C.H.,"Recker, Lukas (57842277800); Poth, Christian H. (8533567200)",57842277800; 8533567200,Test–retest reliability of eye tracking measures in a computerized Trail Making Test,2023,Journal of Vision,23,8,15,,,,3,10.1167/JOV.23.8.15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168284009&doi=10.1167%2fJOV.23.8.15&partnerID=40&md5=f0e2afcfd01b24b456a7b4e3776bb448,"The Trail Making Test (TMT) is a frequently applied neuropsychological test that evaluates participants’ executive functions based on their time to connect a sequence of numbers (TMT-A) or alternating numbers and letters (TMT-B). Test performance is associated with various cognitive functions ranging from visuomotor speed to working memory capabilities. However, although the test can screen for impaired executive functioning in a variety of neuropsychiatric disorders, it provides only little information about which specific cognitive impairments underlie performance detriments. To resolve this lack of specificity, recent cognitive research combined the TMT with eye tracking so that eye movements could help uncover reasons for performance impairments. However, using eye-tracking-based test scores to examine differences between persons, and ultimately apply the scores for diagnostics, presupposes that the reliability of the scores is established. Therefore, we investigated the test–retest reliabilities of scores in an eye-tracking version of the TMT recently introduced by Recker et al. (2022).We examined two healthy samples performing an initial test and then a retest 3 days (n = 31) or 10 to 30 days (n = 34) later. Results reveal that, although reliabilities of classic completion times were overall good, comparable with earlier versions, reliabilities of eye-tracking-based scores ranged from excellent (e.g., durations of fixations) to poor (e.g., number of fixations guiding manual responses). These findings indicate that some eye-tracking measures offer a strong basis for assessing interindividual differences beyond classic behavioral measures when examining processes related to information accumulation processes but are less suitable to diagnose differences in eye–hand coordination. © 2023 The Authors",Bland–Altman; individual differences; intraclass correlation; neuropsychological assessment,Cognition; Eye-Tracking Technology; Humans; Neuropsychological Tests; Reproducibility of Results; Trail Making Test; cognition; eye-tracking technology; human; neuropsychological assessment; reproducibility; trail making test,Article,Final,,Scopus,2-s2.0-85168284009,Movies / Media
Gao J.; Zhao L.; Zhong T.; Li C.; He Z.; Wei Y.; Zhang S.; Guo L.; Liu T.; Han J.; Jiang X.; Zhang T.,"Gao, Jiaxing (57671814700); Zhao, Lin (57748941700); Zhong, Tianyang (58260861300); Li, Changhe (57669997400); He, Zhibin (57209242288); Wei, Yaonei (57671201500); Zhang, Shu (55363657100); Guo, Lei (56428255600); Liu, Tianming (58741130700); Han, Junwei (24450644400); Jiang, Xi (56002790900); Zhang, Tuo (35191407900)",57671814700; 57748941700; 58260861300; 57669997400; 57209242288; 57671201500; 55363657100; 56428255600; 58741130700; 24450644400; 56002790900; 35191407900,Prediction of cognitive scores by joint use of movie-watching fMRI connectivity and eye tracking via Attention-CensNet,2023,Psychoradiology,3,,kkad011,,,,7,10.1093/psyrad/kkad011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169912791&doi=10.1093%2fpsyrad%2fkkad011&partnerID=40&md5=18002e9e2e1e256acc195b72c684ff48,"Background: Brain functional connectivity under the naturalistic paradigm has been shown to be better at predicting individual behaviors than other brain states, such as rest and doing tasks. Nevertheless, the state-of-the-art methods have found it difficult to achieve desirable results from movie-watching paradigm functional magnetic resonance imaging (mfMRI) -induced brain functional connectivity, especially when there are fewer datasets. Incorporating other physical measurements into the prediction method may enhance accuracy. Eye tracking, becoming popular due to its portability and lower expense, can provide abundant behavioral features related to the output of human's cognition, and thus might supplement the mfMRI in observing participants' subconscious behaviors. However, there are very few studies on how to effectively integrate the multimodal information to strengthen the performance by a unified framework. Objective: A fusion approach with mfMRI and eye tracking, based on convolution with edge-node switching in graph neural networks (CensNet), is proposed in this article. Methods: In this graph model, participants are designated as nodes, mfMRI derived functional connectivity as node features, and different eye-tracking features are used to compute similarity between participants to construct heterogeneous graph edges. By taking multiple graphs as different channels, we introduce squeeze-and-excitation attention module to CensNet (A-CensNet) to integrate graph embeddings from multiple channels into one. Results: The proposed model outperforms those using a single modality and single channel, and state-of-the-art methods. Conclusions: The results indicate that brain functional activities and eye behaviors might complement each other in interpreting trait-like phenotypes.  © 2023 The Author(s). Published by Oxford University Press on behalf of West China School of Medicine/West China Hospital (WCSM/WCH) of Sichuan University.",attention; CensNet; eye movement; functional connectivity; naturalistic stimulus,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85169912791,Movies / Media
Gong Z.; Kanai H.,"Gong, Ziting (58244544300); Kanai, Hideaki (36133034700)",58244544300; 36133034700,Comparison of Two Methods for Altering the Appearance of Interviewers: Analysis of Multiple Biosignals,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14017 LNAI,,,53,64,11.0,0,10.1007/978-3-031-35392-5_4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171467168&doi=10.1007%2f978-3-031-35392-5_4&partnerID=40&md5=edbe91beb99b09deb82969dccd73c503,"This study uses a simulation of an actual video interview to compare the effects of acquaintance and animated character scenes as interviewers on participants’ mental stress and perceptions. The acquaintance group tended to have lower anxiety levels in the self-state anxiety assessment and in the change in nasal tip temperature during the anticipation and presentation phases. Furthermore, the results of eye movements during the presentation showed that the acquaintance group paid more attention to the interviewer and perceived the interviewer with a higher frequency than the animated character group. In addition, we used the functional Near-Infrared Spectroscopy (fNIRS) technique to explore the effects of interview stress on brain activity. The stranger group tended to increase cerebral blood flow in both the left and right prefrontal cortices of the participants within 4 s of meeting the interviewer on the screen. This result may be related to mental stress, which promotes the brain’s regulatory function. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",fNIRS; mental stress; video interview,Brain; Functional neuroimaging; Infrared devices; Near infrared spectroscopy; Animated characters; Anxiety levels; Biosignals; Brain activity; Cerebral blood flow; Functional near infrared spectroscopy; High frequency HF; Mental stress; State-anxiety; Video interview; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85171467168,Movies / Media
Choi M.; Han K.; Wang X.; Zhang Y.; Liu Z.,"Choi, Minkyu (57188692097); Han, Kuan (57200620235); Wang, Xiaokai (57221770466); Zhang, Yizhen (59450412500); Liu, Zhongming (8511950700)",57188692097; 57200620235; 57221770466; 59450412500; 8511950700,A Dual-Stream Neural Network Explains the Functional Segregation of Dorsal and Ventral Visual Pathways in Human Brains,2023,Advances in Neural Information Processing Systems,36,,,,,,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201168924&partnerID=40&md5=fd3e8274753feba0165480092fc09755,"The human visual system uses two parallel pathways for spatial processing and object recognition. In contrast, computer vision systems tend to use a single feedforward pathway, rendering them less robust, adaptive, or efficient than human vision. To bridge this gap, we developed a dual-stream vision model inspired by the human eyes and brain. At the input level, the model samples two complementary visual patterns to mimic how the human eyes use magnocellular and parvocellular retinal ganglion cells to separate retinal inputs to the brain. At the backend, the model processes the separate input patterns through two branches of convolutional neural networks (CNN) to mimic how the human brain uses the dorsal and ventral cortical pathways for parallel visual processing. The first branch (WhereCNN) samples a global view to learn spatial attention and control eye movements. The second branch (WhatCNN) samples a local view to represent the object around the fixation. Over time, the two branches interact recurrently to build a scene representation from moving fixations. We compared this model with the human brains processing the same movie and evaluated their functional alignment by linear transformation. The WhereCNN and WhatCNN branches were found to differentially match the dorsal and ventral pathways of the visual cortex, respectively, primarily due to their different learning objectives, rather than their distinctions in retinal sampling or sensitivity to attention-driven eye movements. These model-based results lead us to speculate that the distinct responses and representations of the ventral and dorsal streams are more influenced by their distinct goals in visual attention and object recognition than by their specific bias or selectivity in retinal inputs. This dual-stream model takes a further step in brain-inspired computer vision, enabling parallel neural networks to actively explore and understand the visual surroundings. © 2023 Neural information processing systems foundation. All rights reserved.",,Convolutional neural networks; Feedforward neural networks; Linear transformations; Machine vision; Neurons; Visual servoing; Functionals; Human brain; Human Visual System; Neural-networks; Objects recognition; Parallel pathways; Spatial objects; Spatial processing; System use; Visual pathways; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85201168924,Movies / Media
Fang Y.; Merino L.; Thill S.; Gomez R.,"Fang, Yu (57261733400); Merino, Luis (7003946345); Thill, Serge (36624312800); Gomez, Randy (12806763700)",57261733400; 7003946345; 36624312800; 12806763700,Designing Visual and Auditory Attention-Driven Movements of a Tabletop Robot,2023,"IEEE International Workshop on Robot and Human Communication, RO-MAN",,,,2232,2237,5.0,3,10.1109/RO-MAN57019.2023.10309568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187018028&doi=10.1109%2fRO-MAN57019.2023.10309568&partnerID=40&md5=db1a6973e3c63fcb72940dd1256e6aeb,"This work presents a framework for a visual-auditory attention-driven robot eye-head gaze movement, which combines visual and auditory inputs to determine the direction of gaze movement for a social robot. The framework computes the most salient changes in position by considering both visual and auditory cues. The proposed system was implemented on Haru, a tabletop social robot, where eye-head gaze movement was controlled using visual input from a camera positioned above the eyes and auditory input from a seven-channel microphone. This allowed for eye movement on a two-dimensional flat screen and body rotation towards the person who is speaking. This framework provides a representation of the robot's attentional gaze that leverages both visual and auditory cues, resulting in more natural and responsive coordinated eye-head gaze movements of the social robot. The potential benefits include improved communication, increased engagement, and a stronger sense of connection with the robot. © 2023 IEEE.",,Robots; Auditory attention; Auditory cues; Flat-screens; Gaze movements; Potential benefits; Social robots; Two-dimensional; Visual Attention; Visual cues; Eye movements,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85187018028,Movies / Media
Wang Y.; Hashimoto H.; Nomura T.; Tsukada A.; Maeda Y.,"Wang, Yuxuan (58097978000); Hashimoto, Honami (58097935600); Nomura, Taishin (7403421729); Tsukada, Akira (57214000989); Maeda, Yoshinobu (55687025600)",58097978000; 58097935600; 7403421729; 57214000989; 55687025600,Efficiency of a Visual Search Explained by the Small-World Features of a Gaze Position Network,2023,Advanced Biomedical Engineering,12,,,37,50,13.0,1,10.14326/abe.12.37,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147798944&doi=10.14326%2fabe.12.37&partnerID=40&md5=9bc0cb77e7d5c962e8fe31d142a20e95,"A visual search is implemented when the eye moves to find a target symbol amongst many other symbols (distractors). The efficiency of a visual search is described by Hick’s law, which shows that the search time increases logarithmically as the number of symbols increases. In this paper, the efficiency of visual search was analyzed from the perspective of the network features of a conceptual ‘unobservable’ gaze position network superimposed on a monitor screen filled with many symbols (search array board). We assume that the gaze position does not move freely around the search array board, but rather moves in a way restricted to the unobservable gaze position network. First, we statistically verified that the artificial gaze position network designed from the data of visual search experiments have small-world features, and depends on the ratio of the saccades. Second, by implementing gaze step simulations on such small-world networks, we statistically verified that the simulation search times were close to those obtained from the experiments and also to the minimum search times. Thus, this study suggests that an efficient visual search can be explained by a small-world architecture hidden in the unobservable gaze position network and thus has to be artificially designed. © 2023, Japan Soc. of Med. Electronics and Biol. Engineering. All rights reserved.",clustering coefficient; discriminant analysis; Hick’s law; saccade; spatial extent of attention,Efficiency; Eye movements; Small-world networks; Clustering coefficient; Hick’s law; Network features; Search time; Small worlds; Spatial extent; Spatial extent of attention; Step simulation; Unobservable; Visual search; Discriminant analysis,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85147798944,Movies / Media
Schipper-Eindhoven S.M.; de Knegt N.C.; Mevissen L.; van Loon J.; de Vries R.; Zhuniq M.; Bekker M.H.J.,"Schipper-Eindhoven, Simone M. (58838939600); de Knegt, Nanda C. (36637060400); Mevissen, Liesbeth (35262738700); van Loon, Jos (56274944400); de Vries, Ralph (57201342966); Zhuniq, Majlinda (58838691400); Bekker, Marrie H. J. (7007082252)",58838939600; 36637060400; 35262738700; 56274944400; 57201342966; 58838691400; 7007082252,EMDR treatment for people with intellectual disabilities: a systematic review about difficulties and adaptations,2023,Frontiers in Psychiatry,14,,1328310,,,,4,10.3389/fpsyt.2023.1328310,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182986218&doi=10.3389%2ffpsyt.2023.1328310&partnerID=40&md5=fff592456ec5c7a8f71da2e0d0d01963,"Introduction: People with intellectual disabilities (ID) are at increased risk for developing Post Traumatic Stress Disorder (PTSD). Emerging evidence indicates that Eye Movement Desensitization and Reprocessing (EMDR) therapy is feasible and potentially effective for this group. However, communication, cognition, stress regulation, and attachment difficulties may interfere with the EMDR process. Adaptation of the EMDR protocol seems therefore required for this population. Aim: This review aims to systematically identify and categorize the difficulties in applying EMDR to people with ID and the adaptations made by therapists to overcome these challenges. Methods: A literature search was performed in May 2023. Article selection was based on inclusion and exclusion criteria and quality appraisal. Results: After screening, 13 articles remained for further review. The identified difficulties and adaptations were categorized into the three domains of adaptive functioning (i.e., conceptual, social, and practical functioning). Considerable difficulties in applying the EMDR protocol for this group were reported. The adaptations made by therapists to overcome these difficulties were highly variable. They could be divided into three main categories: adaptions in EMDR delivery (e.g., tuning to the developmental level of the client, simplifying language, decreasing pace), involvement of others (e.g., involving family or support staff during or in between sessions), and the therapeutic relationship (e.g., taking more time, supportive attitude). Discussion: The variability of the number of mentioned difficulties and adaptations per study seems to be partly related to the specific EMDR protocol that was used. In particular, when the Shapiro adult protocol was administered, relatively more detailed difficulties and adaptations were described than in publications based on derived existing versions of an EMDR protocol for children and adolescents. A probable explanation is that already embedded modifications in these protocols facilitate the needed attunement to the client’s level of functioning. Practical implications: The authors of this review suggest that EMDR protocols for children and adolescents could be adapted for people with an intellectual disability. Further research should focus on the involvement of trusted others in EMDR therapy for people with ID and the therapeutic relationship from an attachment and relational-based perspective. Copyright © 2024 Schipper-Eindhoven, de Knegt, Mevissen, van Loon, de Vries, Zhuniq and Bekker.",EMDR; eye movement desensitization and reprocessing; ID; intellectual disabilities; post-traumatic stress disorder; PTSD; trauma,adaptation; caregiver; cognition; cognitive stress; data extraction; eye movement desensitization and reprocessing; human; injury; intellectual impairment; internal validity; physiological stress; posttraumatic stress disorder; qualitative research; Review; screening; systematic review; training,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85182986218,Movies / Media
Ogaki K.; Fujita H.; Nozawa N.; Shiina T.; Sakuramoto H.; Suzuki K.,"Ogaki, Keitaro (57221797712); Fujita, Hiroaki (56463368700); Nozawa, Narihiro (57210450841); Shiina, Tomohiko (57198421924); Sakuramoto, Hirotaka (55218193400); Suzuki, Keisuke (56879571700)",57221797712; 56463368700; 57210450841; 57198421924; 55218193400; 56879571700,Factors contributing to sleep disturbances and excessive daytime sleepiness in patients with Parkinson's disease,2023,Frontiers in Neurology,14,,1097251,,,,6,10.3389/fneur.2023.1097251,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150717541&doi=10.3389%2ffneur.2023.1097251&partnerID=40&md5=9c4d52970e1b339e678b9fa4740fa1fe,"Background: Sleep disturbances and excessive daytime sleepiness (EDS) are common non-motor symptoms in patients with Parkinson's disease (PD). The purpose of this study was to identify the contributors to sleep disturbances, including insomnia, restless legs syndrome, rapid eye movement sleep behavior disorder (RBD), sleep-disordered breathing, nocturnal akinesia and EDS, in patients with PD. Methods: We conducted a cross-sectional study including 128 consecutive Japanese patients with PD. Sleep disturbances and EDS were defined as a PD Sleep Scale-2 (PDSS-2) total score ≥15 and an Epworth Sleepiness Scale (ESS) score >10, respectively. The patients were divided into four groups according to the presence or absence of sleep disturbances and EDS. We evaluated the disease severity, motor symptoms, cognition, olfactory test, the Scales for Outcomes in PD-Autonomic dysfunction (SCOPA-AUT), the Beck Depression Inventory-II (BDI-II), and the RBD Screening Questionnaire Japanese version (RBDSQ-J). Results: Of 128 patients, 64 had neither EDS nor sleep disturbances, 29 had sleep disturbances without EDS, 14 had EDS without sleep disturbances, and 21 had both EDS and sleep disturbances. Patients with sleep disturbances had higher BDI-II scores than those without sleep disturbances. Probable RBD was more frequent in patients with both sleep disturbances and EDS than in those with neither EDS nor sleep disturbances. The SCOPA-AUT score was lower in patients with neither EDS nor sleep disturbances than in patients in the other three groups. Using multivariable logistic regression analysis with neither sleep disturbances nor EDS as a reference group, that the SCOPA-AUT score was an independent contributor to sleep disturbances (adjusted OR, 1.192; 95% CI, 1.065–1.333; P = 0.002) or EDS (OR, 1.245; 95% CI, 1.087–1.424; P = 0.001) and that the BDI-II (OR, 1.121; 95% CI, 1.021–1.230; P = 0.016) and RBDSQ-J scores (OR, 1.235; 95% CI, 1.007–1.516; P = 0.043) as well as the SCOPA-AUT score (OR, 1.137; 95% CI, 1.006–1.285; P = 0.040) were independent contributors to both sleep disturbances and EDS. Conclusions: Autonomic symptoms were associated with patients with sleep disturbances or EDS, and depressive and RBD symptoms in addition to autonomic symptoms were associated with patients with both sleep disturbances and EDS. Copyright © 2023 Ogaki, Fujita, Nozawa, Shiina, Sakuramoto and Suzuki.",autonomic symptoms; depressive symptoms; excessive daytime sleepiness; Parkinson's disease; rapid eye movement sleep behavior disorder; sleep disturbances,dopamine receptor stimulating agent; levodopa; aged; akinesia; Article; autonomic neuropathy; Beck Depression Inventory; cognition; controlled study; cross-sectional study; disease association; disease risk assessment; disease severity; Epworth sleepiness scale; excessive daytime sleepiness; female; function test; human; insomnia; Japanese (people); major clinical study; male; mental test; motor dysfunction; multivariate logistic regression analysis; nocturnal akinesia; olfactory test; Parkinson disease; PD Sleep Scale 2; questionnaire; rapid eye movement sleep behavior disorder; rating scale; RBD Screening Questionnaire Japanese version; restless legs syndrome; risk factor; Scales for Outcomes in PD-Autonomic dysfunction; scoring system; sleep disorder; sleep disordered breathing; symptom,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85150717541,Movies / Media
Kulper P.,"Kulper, Perry (35191965900)",35191965900,Instagram as Interface: The New Picture Plane,2023,Drawing Attention: Architecture in the Age of Social Media,,,,10,14,4.0,1,10.4324/9781003351740-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169761050&doi=10.4324%2f9781003351740-3&partnerID=40&md5=14ed96dca81d8c1ec5e65b8c4d9d6012,"The introduction and consumption of Instagram has produced an entirely different field of play. Instagram’s reach has increasingly lured audiences and influences away from paperbased dissemination in favour of the rapid movement of digits on smallish, rechargeable, shiny screens. Vision, constructed through a new kind of picture plane, is driven by an alternative rapid eye movement that results from tickling the seductively high-res screen, scrolling from image to image at breakneck speed, in sometimes distracted states of attention. Significantly, whether in the space of drawing, erasing and redrawing on sheets of paper, or in the keyboard commands of varied digital interfaces, the work of design still largely happens in the drawing, or its digital counterpart, the computer. The new picture plane has arrived, forever transforming, and setting up the next gravities for architectural, spatial and cultural influence. © RIBA Publishing, 2023.",,,Book chapter,Final,,Scopus,2-s2.0-85169761050,Movies / Media
Kayleva N.A.; Kulesh A.A.; Starikova N.L.; Karakulova Yu.V.; Galimshin A.R.,"Kayleva, N.A. (57216885277); Kulesh, A.A. (55656523400); Starikova, N.L. (6602798418); Karakulova, Yu.V. (12647536000); Galimshin, A.R. (59009588500)",57216885277; 55656523400; 6602798418; 12647536000; 59009588500,TOLOSA–HUNT SYNDROME; [СИНДРОМ ТОЛОСЫ–ХАНТА],2023,Russian Neurological Journal,28,6,,56,61,5.0,0,10.30629/2658-7947-2023-28-6-56-61,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191776523&doi=10.30629%2f2658-7947-2023-28-6-56-61&partnerID=40&md5=e05f81a18b3dca516c86a91a6da7df5c,A description of a clinical case of Tolosa–Hunt syndrome (THS) and a brief review of the literature are presented. The described clinical case is characterized by three features that have not received sufficient attention in the literature: 1) the presence of recurrent pain outside the orbit in combination with ptosis without diplopia several years before the development of a typical episode of THS; 2) insufficient and unstable clinical response to standard doses of glucocorticoids with high efficiency of pulse therapy with methylprednisolone followed by oral administration of prednisolone; 3) a longer than required according to the international classification of headaches (ICHD-3) time interval between the development of cephalalgia and the appearance of oculomotor disorders. This clinical observation expands the understanding of the clinical picture and treatment of THS. © 2023 Medicinskoe Informacionnoe agentstvo. All rights reserved.,corticosteroids; diagnosis; MRI; Tolosa–Hunt syndrome,glucocorticoid; methylprednisolone; prednisolone; Article; case report; clinical feature; clinical observation; diplopia; drug pulse therapy; eye movement disorder; ICHD-3; orbit; pain; ptosis (eyelid); recurrent disease; Tolosa Hunt syndrome; treatment response,Article,Final,,Scopus,2-s2.0-85191776523,Movies / Media
Gupta N.; Sharma A.; Dawar S.; Kudal P.; Patnaik A.; Sharma M.,"Gupta, Nishu (57225763167); Sharma, Arpita (57210811871); Dawar, Sunny (57202959102); Kudal, Pallavi (57402751000); Patnaik, Amitabh (57962550500); Sharma, Meenakshi (57224333903)",57225763167; 57210811871; 57202959102; 57402751000; 57962550500; 57224333903,Gender Differences in Financial Consumer Service Behavior: Exploring Eye-Tracking Technology,2023,Journal of System and Management Sciences,13,5,,294,310,16.0,1,10.33168/JSMS.2023.0519,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173738650&doi=10.33168%2fJSMS.2023.0519&partnerID=40&md5=60c47dca7f8dacbc78095d53b93625b5,"Understanding the factors that influence the attention of financial service consumers when viewing advertisements is crucial for effective marketing strategies. Furthermore, considering the impact of gender and cognitive behavior on consumer behavior provides valuable insights for companies seeking to tailor their ads to individual preferences. This investigation aims to determine the key visual factors that influence the attention of financial service consumers, with a specific focus on gender and cognitive behavior. By conducting an experiment using Tobii's eye tracking device and employing quantitative analysis, the study explores the impact of visual factors on financial consumers based on gender. The study consisted of two parts. First, an experiment was conducted using Tobii's eye tracking device to collect visual data on four mutual funds tombstone ads. This allowed for the measurement of participants' eye movements and fixation durations while viewing the advertisements. Second, a quantitative analysis was performed on the collected data using discriminant analysis in SPSS. This analysis aimed to identify the visual factors that influence financial consumers based on their gender. The findings of the study indicate that several visual factors capture the attention of participants. These factors include Time to First Fixation (TTFF), First Fixation Duration (FFD), Total Visit Duration (TVD), and Visit Count (VC). Among these factors, FFD was identified as the most significant factor in distinguishing between males and females. This investigation provides valuable insights into how male and female consumers of financial products perceive visual information. The study's findings highlight the importance of FFD in capturing consumers' attention and suggest that gender differences play a role in the visual perception of financial advertisements. © 2023, Success Culture Press. All rights reserved.",Advertisement; Cognitive behaviour; Discriminant analysis; Visual factors,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85173738650,Movies / Media
Chen C.-C.; Wu E.H.-K.; Chen Y.-Q.; Tsai H.-J.; Chung C.-R.; Yeh S.-C.,"Chen, Chun-Chuan (8942129700); Wu, Eric Hsiao-Kuang (55366211300); Chen, Yan-Qing (57444020800); Tsai, Ho-Jung (58109725100); Chung, Chia-Ru (57211181873); Yeh, Shih-Ching (14619911100)",8942129700; 55366211300; 57444020800; 58109725100; 57211181873; 14619911100,Neuronal Correlates of Task Irrelevant Distractions Enhance the Detection of Attention Deficit/Hyperactivity Disorder,2023,IEEE Transactions on Neural Systems and Rehabilitation Engineering,31,,,1302,1310,8.0,10,10.1109/TNSRE.2023.3241649,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148449402&doi=10.1109%2fTNSRE.2023.3241649&partnerID=40&md5=740a537967b3733f957c08568cb10186,"Early diagnosis and treatment can reduce the symptoms of Attention Deficit/Hyperactivity Disorder (ADHD) in children, but medical diagnosis is usually delayed. Hence, it is important to increase the efficiency of early diagnosis. Previous studies used behavioral and neuronal data during GO/NOGO task to help detect ADHD and the accuracy differed considerably from 53% to 92%, depending on the employed methods and the number of electroencephalogram (EEG) channels. It remains unclear whether data from a few EEG channels can still lead to a good accuracy of detecting ADHD. Here, we hypothesize that introducing distractions into a VR-based GO/NOGO task can augment the detection of ADHD using 6-channel EEG because children with ADHD are easily distracted. Forty-nine ADHD children and 32 typically developing children were recruited. We use a clinically applicable system with EEG to record data. Statistical analysis and machine learning methods were employed to analyze the data. The behavioral results revealed significant differences in task performance when there are distractions. The presence of distractions leads to EEG changes in both groups, indicating immaturity in inhibitory control. Importantly, the distractions additionally enhanced the between-group differences in NOGO α and γ power, reflecting insufficient inhibition in different neural networks for distraction suppression in the ADHD group. Machine learning methods further confirmed that distractions enhance the detection of ADHD with an accuracy of 85.45%. In conclusion, this system can assist in fast screenings for ADHD and the findings of neuronal correlates of distractions can help design therapeutic strategies.  © 2001-2011 IEEE.",Attention deficit/hyperactivity disorder (ADHD); continuous performance test (CPT); distractions; electroencephalography (EEG); go/no-go task; machine learning; virtual reality (VR),Electrophysiology; Learning systems; Neural networks; Neurons; Virtual reality; Attention deficit hyperactivity disorder; Attention deficit/hyperactivity disorder; Continuous performance test; Distraction; Early diagnosis; Electroencephalography; Go/no-go tasks; Machine-learning; Performance tests; Virtual reality; accuracy; area under the curve; Article; artificial neural network; attention deficit hyperactivity disorder; auditory distractions; auditory stimulation; child; clinical article; continuous performance test; controlled study; distance learning; electrodermal response; electroencephalogram; electroencephalography; eye movement; female; Go No Go task; human; immaturity; machine learning; male; nerve cell network; neuroimaging; neuropsychological assessment; perception test; sensitivity and specificity; signal processing; Task Irrelevant Distractions; task performance; virtual reality; visual distractions; visual stimulation; Electroencephalography,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85148449402,Movies / Media
Gibert C.; Roger F.; Icart E.; Brugulat M.; Bucci M.P.,"Gibert, Charlotte (57200753810); Roger, Florent (58074238400); Icart, Emmanuel (55749785300); Brugulat, Marie (58073720000); Bucci, Maria Pia (7102861305)",57200753810; 58074238400; 55749785300; 58073720000; 7102861305,A New Immersive Rehabilitation Therapy (MoveR) Improves More Than Classical Visual Training Visual Perceptual Skills in Dyslexic Children,2023,Biomedicines,11,1,21,,,,0,10.3390/biomedicines11010021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146639680&doi=10.3390%2fbiomedicines11010021&partnerID=40&md5=bc7669b067d9764995c54ffad859b0cb,"Highlights: What are the main findings? A new immersive rehabilitation therapy (MoveR) tool based to reinforce visual dis-crimination, visual attention, saccadic and vergence system and spatial orien-tation in dyslexics has been developed. What is the implication of the main finding? This new immersive rehabilitation therapy (MoveR) is able to improve visual per-ceptual skills better than classical visual training in children with dyslexia. In this study, we wonder how to compare the improvement in visual perceptual skills (by using the test of visual perceptual skills, TVPS) in children with dyslexia after two visual training types (a new immersive rehabilitation therapy called MoveR, and the classical vision therapy). Thirty-nine children with dyslexia were enrolled in the study. They were split into two groups (G1 and G2) matched in IQ (intelligence quotient), sex, and age. Children of the group G1 underwent to MoveR training while children of the group G2 underwent to visual training. TVPS scores of four subtests were assessed twice before and 6 months after the two different types of training (MoveR or visual). MoveR training is an immersive therapy to reinforce visual discrimination, visual attention, saccadic/vergence system and spatial orientation. Visual therapy is based by training different types of eyes movements (horizontal, vertical and oblique pursuits and saccades, convergence and divergence movements), reading task and some exercise for improving eyes–head coordination. Each training type lasted 30 min a day, five days a week, for two weeks. Before training, the TVPS scores of the four subtests measured were statistically similar for both groups of children with dyslexia (G1 and G2). After training, both group of children (G1 and G2) improved the TVPS score of the four subtests assessed; however, such improvement reached significance in G1 only. We conclude that MoveR training could be a more useful tool than classical visual training to improve visual perceptual abilities in dyslexic children. Follow up studies on a larger number of dyslexic children will be necessary in order to explore whether such improvement persists over time and its eventual implication in reading or other classroom’s activities. © 2022 by the authors.",children; dyslexia; new immersive rehabilitation therapy (MoveR); TVPS; visual perceptual skills; visual training,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85146639680,Movies / Media
Martínez-Rojas A.; Reijers H.A.; Jiménez-Ramírez A.; Enríquez J.G.,"Martínez-Rojas, A. (57211522155); Reijers, H.A. (6603060277); Jiménez-Ramírez, A. (53979785300); Enríquez, J.G. (56203929000)",57211522155; 6603060277; 53979785300; 56203929000,What Are You Gazing At? An Approach to Use Eye-Tracking for Robotic Process Automation,2023,Lecture Notes in Business Information Processing,491 LNBIP,,,120,134,14.0,5,10.1007/978-3-031-43433-4_8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173581307&doi=10.1007%2f978-3-031-43433-4_8&partnerID=40&md5=b9b39a0ad90829be724f126345622802,"User Interface (UI) logs are crucial in capturing and analyzing user behavior, enabling a comprehensive understanding of business processes and eventual process automation with Robotic Process Automation (RPA). However, extracting meaningful insights from UI logs becomes challenging, especially when dealing with complex and information-dense graphical user interfaces. This paper presents a novel approach that leverages eye-tracking technology to address this challenge. The proposed solution incorporates gaze fixation (i.e., where the user pays attention to the user interfaces) into the UI log, which is then used to filter irrelevant information from it. Two gaze-based filtering methods are presented and evaluated using synthetic and real-life screenshots. Preliminary results demonstrate that the method effectively reduces the irrelevant UI elements by an average of 76% while keeping meaningful information on the screen. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Eye-tracking; Relevance detection; Robotic Process Automation; User Interface,Behavioral research; Eye tracking; Graphical user interfaces; Process control; Business Process; Eye tracking technologies; Eye-tracking; Filtering method; Interface elements; Process automation; Relevance detection; Robotic process automation; Screenshots; User behaviors; Robotics,Conference paper,Final,,Scopus,2-s2.0-85173581307,Movies / Media
Liu G.; Liu J.; Dai L.,"Liu, Guangyu (58210038800); Liu, Jie (57211671848); Dai, Licao (15044041400)",58210038800; 57211671848; 15044041400,Research on the fatigue detection method of operators in digital main control rooms of nuclear power plants based on multi-feature fusion,2023,"2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms, EEBDA 2023",,,,1459,1463,4.0,0,10.1109/EEBDA56825.2023.10090719,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154595776&doi=10.1109%2fEEBDA56825.2023.10090719&partnerID=40&md5=0b02cef5f8853a547075dcec0734738b,"Timely waking up the operators in the digital main control rooms of nuclear power plants from fatigue can effectively prevent accidents in nuclear power plants. During the operator's work, real -time evaluation of the fatigue state of operators is very important. Because the operators needs to constantly receive and process information from the computer screen through their eyes, it is easy to make their eyes tired and causes mental fatigue to the operators, so we propose to conduct fatigue detection for the operators. By focusing on the state of eyes, combined with the state of mouth and head movement, the efficiency of fatigue detection for operators can be effectively improved. The fatigue detection method was designed to integrate the classification results of three machine learning classification algorithms, logistic regression (LR), random forest (RF), and support vector machine (SVM), by fusing multi- feature such as slow blinks, PERCLOS, yawns, and head movements. Through experimental comparison, this method has higher accuracy compared with the multi-feature fusion method also based on the NTHU-DDD video dataset. © 2023 IEEE.",Fatigue detection; Machine Learning; Multi-feature Fusion; Operators in the digital main control rooms of nuclear power plants,E-learning; Eye movements; Feature extraction; Learning systems; Nuclear energy; Nuclear fuels; Support vector machines; Computer screens; Detection methods; Fatigue detection; Head movements; Machine-learning; Main control room; Multi-feature fusion; Operator in the digital main control room of nuclear power plant; Process information; Real time evaluation; Nuclear power plants,Conference paper,Final,,Scopus,2-s2.0-85154595776,Movies / Media
Colombi C.; Chericoni N.; Bargagna S.; Costanzo V.; Devescovi R.; Lecciso F.; Pierotti C.; Prosperi M.; Contaldo A.,"Colombi, Costanza (23476667900); Chericoni, Natasha (57192339842); Bargagna, Stefania (6701839377); Costanzo, Valeria (57192340426); Devescovi, Raffaella (7801605474); Lecciso, Flavia (55014651600); Pierotti, Caterina (57202235104); Prosperi, Margherita (57191966635); Contaldo, Annarita (6507441040)",23476667900; 57192339842; 6701839377; 57192340426; 7801605474; 55014651600; 57202235104; 57191966635; 6507441040,Case report: Preemptive intervention for an infant with early signs of autism spectrum disorder during the first year of life,2023,Frontiers in Psychiatry,14,,1105253,,,,9,10.3389/fpsyt.2023.1105253,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159918082&doi=10.3389%2ffpsyt.2023.1105253&partnerID=40&md5=d3704bea6d35e213fc51e24d531dc239,"Autism spectrum disorder (ASD) includes neurodevelopmental conditions traditionally considered to bring life long disabilities, severely impacting individuals and their families. Very early identification and intervention during the very first phases of life have shown to significantly diminish symptom severity and disability, and improve developmental trajectories. Here we report the case of a young child showing early behavioral signs of ASD during the first months of life, including diminished eye contact, reduced social reciprocity, repetitive movements. The child received a pre-emptive parent mediated intervention based on the Infant Start, an adaptation of the Early Start Denver Model (ESDM), specifically developed for children with ASD signs during the first year of life. The child here described received intervention from 6 to 32 months of age, in combination with educational services. Diagnostic evaluations performed at several time points (8, 14, 19, and 32 months) showed progressive improvements in his developmental level and ASD symptoms. Our case study supports the possibility of identifying ASD symptoms and providing services as soon as concerns emerge even during the first year of life. Our report, in combination with recent infant identification and intervention studies, suggests the need for very early screening and preemptive intervention to promote optimal outcomes. Copyright © 2023 Colombi, Chericoni, Bargagna, Costanzo, Devescovi, Lecciso, Pierotti, Prosperi and Contaldo.",autism spectrum disorder; early development; ESDM; parent mediated intervention; preemptive intervention,adaptive behavior; Article; autism; behavior therapy; case report; child behavior; child development; clinical article; clinical evaluation; cognition; compulsion; disability severity; early diagnosis; early intervention; Early Start Denver Model; education; electroencephalography; eye contact; eye movement; facial expression; human; imitation; independence; infant; interpersonal communication; male; motor performance; nonverbal communication; nuclear magnetic resonance imaging; plagiocephaly; play; preemptive therapy; social adaptation; social interaction; special education; symptom; treatment outcome; verbal communication; visual evoked potential; visual system examination,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85159918082,Movies / Media
Heuer C.; Disse L.; Ledergerber D.; Jelcic I.; Imbach L.L.,"Heuer, Christine (57778457500); Disse, Leah (58029578500); Ledergerber, Debora (9133620600); Jelcic, Ilijas (6602588142); Imbach, Lukas L. (6507251817)",57778457500; 58029578500; 9133620600; 6602588142; 6507251817,EEG-Delta brushes in DPPX encephalitis – Welcome to the club,2023,Clinical Neurophysiology Practice,8,,,12,15,3.0,3,10.1016/j.cnp.2022.11.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144710424&doi=10.1016%2fj.cnp.2022.11.003&partnerID=40&md5=11f9a81a2971f602331ccc7aab425b74,"Background: Extreme Delta Brushes are a rare interictal EEG pattern that was first described in NMDA-R encephalitis and has been considered a pathognomonic pattern for this subtype of autoimmune encephalitis. Recently, extreme delta brushes have been described as a rare EEG phenomenon in other forms of encephalitis. Case report: We describe to our knowledge the first occurrence of EEG Delta brushes in DPPX encephalitis. In this article, we present a comprehensive case report and discuss clinical differential diagnosis with special emphasis on the diagnostic value of the EEG, leading the way to the correct diagnosis. We also present current diagnostic criteria and clinical screening scales for initial evaluation for patients with suspected autoimmune encephalitis. © 2022 International Federation of Clinical Neurophysiology",Autoimmune encephalitis; EEG; Extreme Delta brushes,antibody; corticosteroid; dipeptidyl peptidase like protein 6; dipeptidyl peptidase like protein 6 antibody; immunoglobulin G; oligoclonal band; protein; rituximab; unclassified drug; adult; amnesia; arm; Article; ataxia; ataxic gait; attention deficit hyperactivity disorder; auditory stimulation; autoimmune encephalitis; autonomic dysfunction; beta rhythm; biosynthesis; body weight loss; brain disease; brain radiography; case report; cerebrospinal fluid analysis; clinical article; constipation; delta rhythm; depression; diagnostic value; differential diagnosis; disease classification; drug megadose; drug pulse therapy; electroencephalogram; encephalitis; erectile dysfunction; evaluation study; executive function; fatigue; follow up; head; hospital admission; human; hyperreflexia; hypersensitivity; hypersomnia; intensive care; intestinal dysmotility; involuntary movement; knowledge; leg; leukoencephalopathy; maintenance therapy; male; mental instability; middle aged; multiple cycle treatment; myalgia; neurologic examination; nuclear magnetic resonance imaging; personality disorder; plasma exchange; protein cerebrospinal fluid level; remission; saccadic eye movement; screening; spasticity; startle reflex; tactile hypersensitivity; touch; treatment outcome; tremor; urinary hesitancy; wakefulness; walking difficulty; wide based gait,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85144710424,Movies / Media
Herlina H.; Nugraha K.A.,"Herlina, Herlina (57203100492); Nugraha, Kristian Adi (57348376900)",57203100492; 57348376900,Evaluating The Usability of Massive Open Online Course User Interface Based on Eye-Tracker Data,2023,"2023 3rd International Conference on Intelligent Cybernetics Technology and Applications, ICICyTA 2023",,,,272,277,5.0,0,10.1109/ICICyTA60173.2023.10429001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186744695&doi=10.1109%2fICICyTA60173.2023.10429001&partnerID=40&md5=1a22db60d78f1d19438528f59c614b63,"Massive Open Online Course (MOOC) is a learning platform widely used today, especially since the Covid-19 pandemic. MOOC allows someone to gain knowledge from various universities around the world quickly. MOOCs have become a popular source for seeking knowledge because the costs are relatively cheap. The number of users is quite large worldwide, so a universal user interface (UI) is essential for a MOOC because different backgrounds and cultures can cause people to have different ways of interacting with interfaces. MOOCs should have good UX when used by people from various regions. To measure the UX of an UI, we can use several metrics, one of which is behavioral metrics. This research examines user behavior towards several types of MOOC layouts with the help of an eye tracker to measure user behavior when interacting with MOOC. Test results show that users only pay attention to the first appeared content when they did not have any goals yet. However, if the user understands their goals, UI appearance variations only slightly impact user behavior. Therefore, in MOOCs, important content should be located in the center of the screen, both vertically and horizontally. Apart from that, content considered the most important must appear first compared to other content. © 2023 IEEE.",eye tracking; online course; usability; user experience; user interface,Behavioral research; E-learning; User interfaces; Eye trackers; Eye-tracker data; Eye-tracking; Learning platform; Massive open online course; Online course; Usability; User behaviors; Users' experiences; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85186744695,Movies / Media
Sharma A.S.; Amin M.R.; Fuad M.,"Sharma, Arnab Sen (57274039300); Amin, Mohammad Ruhul (57217788251); Fuad, Muztaba (9336648600)",57274039300; 57217788251; 9336648600,Augmenting Online Classes with an Attention Tracking Tool May Improve Student Engagement,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14040 LNCS,,,105,121,16.0,2,10.1007/978-3-031-34411-4_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169007748&doi=10.1007%2f978-3-031-34411-4_9&partnerID=40&md5=95bbf81e809cb43ee8cf5cac74c24d70,"Online remote learning has certain advantages, such as higher flexibility and greater inclusiveness. However, a caveat is the teachers’ limited ability to monitor student interaction during an online class, especially while teachers are sharing their screens. We have taken feedback from 12 teachers experienced in teaching undergraduate level online classes on the necessity of an attention tracking tool to understand student engagement during an online class. This paper outlines the design of such a monitoring tool that automatically tracks the attentiveness of the whole class by tracking students’ gazes on the screen and alerts the teacher when the attention score goes below a certain threshold. We assume the benefits are twofold; 1) teachers will be able to ascertain if the students are attentive or being engaged with the lecture contents and 2) the students will become more attentive in online classes because of this passive monitoring system. In this paper, we present the preliminary design and feasibility of using the proposed tool and discuss its applicability in augmenting online classes. Finally, we surveyed with 31 students asking their opinion on the usability as well as the ethical and privacy concerns of using such a monitoring tool. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Augmenting Online Classes; Gaze-Tracking,Eye tracking; Augmenting online class; Gaze-tracking; High flexibility; Monitoring tools; Online class; Passive monitoring; Remote learning; Student engagement; Student interactions; Teachers'; Students,Conference paper,Final,,Scopus,2-s2.0-85169007748,Movies / Media
Cavalcanti M.; Melo F.; Silva T.; Falcão M.; de Queiroz Cavalcanti D.; Becker V.,"Cavalcanti, Matheus (57773369000); Melo, Felipe (57773196100); Silva, Thiago (57189006999); Falcão, Matheus (58592738000); de Queiroz Cavalcanti, Daniel (58590957500); Becker, Valdecir (56372303300)",57773369000; 57773196100; 57189006999; 58592738000; 58590957500; 56372303300,Incorporating Eye Tracking into an EEG-Based Brainwave Visualization System,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14011 LNCS,,,392,403,11.0,1,10.1007/978-3-031-35596-7_25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171478697&doi=10.1007%2f978-3-031-35596-7_25&partnerID=40&md5=77a5d7dc503f86a9708c6a853a08a04d,"This article describes the incorporation of eye tracking into a brainwaves visualization and analysis system, based on electroencephalography (EEG), to map attention during fruition of audiovisual content. The visualization system was developed in Python, using an Emotiv Insight headset. During the tests, there was a need to identify whether the reactions mapped by the EEG were in fact related to the fruition of the content or whether they originated from elements external to the screen, with the individual looking away and, consequently, losing attention. Based on the Design Science Research methodology, eye tracking was incorporated into the system architecture. For validation, tests were performed with 10 users. Analyzing the generated data, it was possible to identify the correlation between the information presented by the EEG and the gaze of the individuals. In this way, it is possible to increase confidence about the origin of user’s emotions during the fruition of audiovisual content. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Audiovisual Fruition; EEG; Eye Tracking,Electroencephalography; Electrophysiology; Visualization; Analysis system; Audio-visual content; Audiovisual fruition; Brain wave; Design-science researches; Eye-tracking; Research methodologies; Systems architecture; Visualization and analysis; Visualization system; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85171478697,Movies / Media
Cao L.; Doherty S.; Lee J.F.,"Cao, Lu (58243011300); Doherty, Stephen (56137159600); Lee, James F. (14522982300)",58243011300; 56137159600; 14522982300,The process and product of translation revision: empirical data from student translators using eye tracking and screen recording,2023,Interpreter and Translator Trainer,17,4,,548,565,17.0,2,10.1080/1750399X.2023.2207070,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158832670&doi=10.1080%2f1750399X.2023.2207070&partnerID=40&md5=b79785c53439fb6479d838df9ccc419c,"As the final phase of the translation process, self-revision has traditionally been a relatively neglected component despite it being widely acknowledged as critical to achieving high-quality translation and in translator training. To identify effective educational interventions for self-revision, the current paper reports on a study that collected empirical data from student translators (n = 72) who were randomly assigned to different conditions (traditional, screen recording, and eye tracking) in highly ecologically valid bidirectional tasks. Six features of eye tracking and screen recording were identified as indicators of potential translation difficulties which could be used to direct student translator’s overt visual attention in the revision phase. We found that eye tracking was the most effective way of assisting student translators in self-revising their translations, regardless of the direction of translation. Further, average fixation duration and backward saccades in the eye tracking recording condition, and pauses and concurrent revision activity in the screen recording condition were the most useful features in helping the student translators to identify potential translation errors and thereby enhance the quality of their translation after revisions. Qualitative data showed that the student translators became more confident and had a clearer understanding of their own translation processes after watching the recordings. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",eye tracking; revision; screen recording; translation process research; translation quality; Translator training,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85158832670,Movies / Media
Karmakar S.; Chatterjee D.; Varghese T.; Gavas R.D.; Mithun B.S.; Ramakrishnan R.K.; Pal A.,"Karmakar, Somnath (57405714100); Chatterjee, Debatri (55931825200); Varghese, Tince (57404736500); Gavas, Rahul Dasharath (56946879400); Mithun, B.S. (56358133000); Ramakrishnan, Ramesh Kumar (57213589493); Pal, Arpan (57203638167)",57405714100; 55931825200; 57404736500; 56946879400; 56358133000; 57213589493; 57203638167,Quantification of Active Visual Attention using RGB camera,2023,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",,,,,,,0,10.1109/EMBC40787.2023.10340011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179648684&doi=10.1109%2fEMBC40787.2023.10340011&partnerID=40&md5=32a587cddbf66f668648467d6251d294,"Active visual attention (AVA) is the cognitive ability that helps to focus on important visual information while responding to a stimulus and is important for human-behavior and psychophysiological research. Existing eye-trackers/camera-based methods are either expensive or impose privacy issues as face videos are recorded for analysis. Proposed approach using blink-rate variability (BRV), is inexpensive, easy to implement, efficient and handles privacy issues, making it amenable to real-time applications. Our solution uses laptop camera/webcams and a single blink feature, namely BRV. First, we estimated participant's head pose to check camera alignment and detect if he is looking at the screen. Next, subject-specific threshold is computed using eye aspect ratio (EAR) to detect blinks from which BRV signal is constructed. Only EAR values are saved, and participant's face video is NOT saved or transmitted. Finally, a novel AVA score is computed. Results shows that the proposed score is robust across participants, ambient light conditions and occlusions like spectacles. © 2023 IEEE.",,Blinking; Cognition; Humans; Male; Behavioral research; Cameras; Computer vision; Eye tracking; Laptop computers; Aspect-ratio; Blink rates; Camera-based; Cognitive ability; Eye trackers; Human behaviors; Privacy issue; RGB cameras; Visual Attention; Visual information; blinking; cognition; human; male; Aspect ratio,Conference paper,Final,,Scopus,2-s2.0-85179648684,Movies / Media
Mahmood B.; Omeroglu F.B.; Abbasi E.; Li Y.,"Mahmood, Bilal (58590500900); Omeroglu, Fatih Baha (57768762800); Abbasi, Elahe (57218277339); Li, Yueqing (7502087274)",58590500900; 57768762800; 57218277339; 7502087274,The Impact of Blue Light and Dark UI on Eye Fatigue and Cognitive Workload,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14017 LNAI,,,131,142,11.0,0,10.1007/978-3-031-35392-5_10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171434373&doi=10.1007%2f978-3-031-35392-5_10&partnerID=40&md5=dd4310ba8af8242128d3b00c7291877b,"The effects of lights from computer screens, specifically the blue light has been a debated research topic in this digital area we are living in. Past research initially has shown the negative effects of blue light on eyestrain, sleep and even focus. However, some recent studies have also shown that blue light might improve the focus and wakefulness of individuals. In addition to blue light usage, dark user interface (UI) themes have become extremely common in our daily usage of technology. Even though, it seems to be a very popular option within users, its effect on cognitive performance is still yet to be researched thoroughly. Some of the past research showed negative effects of dark UI on reading performances. On the other hand, dark UI seemed to cause less eye strain and less fatigue. Based on the past research and some other implications, this research created a custom blue light inspired UI and studied its effects on cognitive workload and eye strain in comparison to dark UI and default UI using EEG and eye trackers. Under each user interface condition, participants performed a hybrid-search task and EEG frequency bands and pupil size measures are collected. As a result of the analysis, statistical trend and individual feedback were gathered however none of the results were significant. It’s our belief that, this preliminary study can be the precursor of an improved, well versed usability research with increased sample size and more dependent variables. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Cognitive workload; EEG; eye tracking; Usability; User interfaces; User research,User interfaces; Blue light; Cognitive performance; Cognitive workloads; Computer screens; Eye fatigue; Eye strain; Eye-tracking; Research topics; Usability; User research; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85171434373,Movies / Media
Bao Y.; Ya Y.; Liu J.; Zhang C.; Wang E.; Fan G.,"Bao, Yiqing (58481847100); Ya, Yang (57211960599); Liu, Jing (57259205600); Zhang, Chenchen (58504353200); Wang, Erlei (57212349804); Fan, Guohua (57205882113)",58481847100; 57211960599; 57259205600; 58504353200; 57212349804; 57205882113,Regional homogeneity and functional connectivity of freezing of gait conversion in Parkinson’s disease,2023,Frontiers in Aging Neuroscience,15,,1179752,,,,2,10.3389/fnagi.2023.1179752,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165678439&doi=10.3389%2ffnagi.2023.1179752&partnerID=40&md5=651a0ce7044dd10cb4feecddc4c1082b,"Background: Freezing of gait (FOG) is common in the late stage of Parkinson’s disease (PD), which can lead to disability and impacts the quality of life. Therefore, early recognition is crucial for therapeutic intervention. We aimed to explore the abnormal regional homogeneity (ReHo) and functional connectivity (FC) in FOG converters and evaluate their diagnostic values. Methods: The data downloaded from the Parkinson’s Disease Progression Markers Project (PPMI) cohort was subdivided into PD-FOG converters (n = 16) and non-converters (n = 17) based on whether FOG appeared during the 3-year follow-up; 16 healthy controls were well-matched. ReHo and FC analyses were used to explore the variations in spontaneous activity and interactions between significant regions among three groups of baseline data. Correlations between clinical variables and the altered ReHo values were assessed in FOG converter group. Last, logistic regression and receiver operating characteristic curve (ROC) were used to predict diagnostic value. Results: Compared with the non-converters, FOG converters had reduced ReHo in the bilateral medial superior frontal gyrus (SFGmed), which was negatively correlated with the postural instability and gait difficulty (PIGD) score. ReHo within left amygdala/olfactory cortex/putamen (AMYG/OLF/PUT) was decreased, which was correlated with anxiety and autonomic dysfunction. Also, increased ReHo in the left supplementary motor area/paracentral lobule was positively correlated with the rapid eye movement sleep behavior disorder screening questionnaire. FOG converters exhibited diminished FC in the basal ganglia, limbic area, and cognitive control cortex, as compared with non-converters. The prediction model combined ReHo of basal ganglia and limbic area, with PIGD score was the best predictor of FOG conversion. Conclusion: The current results suggested that abnormal ReHo and FC in the basal ganglia, limbic area, and cognitive control cortex may occur in the early stage of FOG. Basal ganglia and limbic area dysfunction combined with higher PIGD score are useful for the early recognition of FOG conversion. Copyright © 2023 Bao, Ya, Liu, Zhang, Wang and Fan.",freezing of gait; functional connectivity; Parkinson’s disease; receiver operating characteristic curve; regional homogeneity,adult; amygdala; anxiety; Article; autonomic dysfunction; basal ganglion; brain region; clinical article; cohort analysis; controlled study; diagnostic test accuracy study; diagnostic value; executive function; female; follow up; freezing of gait; functional connectivity; human; limbic cortex; logistic regression analysis; male; olfactory cortex; Parkinson disease; prediction; predictive model; putamen; receiver operating characteristic; regional homogeneity; REM sleep behavior disorder; superior frontal gyrus; supplementary motor area,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85165678439,Movies / Media
Becker V.; Cavalcanti M.; Melo F.; Silva T.; Falcão M.,"Becker, Valdecir (56372303300); Cavalcanti, Matheus (57773369000); Melo, Felipe (57773196100); Silva, Thiago (57189006999); Falcão, Matheus (58592738000)",56372303300; 57773369000; 57773196100; 57189006999; 58592738000,Using Eye Tracking to Map Attention in an EEG-Based Brainwave Graphic Visualization System,2023,Communications in Computer and Information Science,1820 CCIS,,,129,143,14.0,2,10.1007/978-3-031-45611-4_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176010672&doi=10.1007%2f978-3-031-45611-4_9&partnerID=40&md5=adc32b29e64df080f6145e8f075beb1c,"This article describes the incorporation of eye tracking in a brainwaves visualization and analysis system, based on electroencephalography (EEG). The visualization system was developed in Python, using a Emotiv Insight headset, to analyze the fruition of audiovisual content. During the tests, there was a need to identify whether the reactions mapped by the EEG were in fact related to the enjoyment of the content or whether they originated from external elements, with the individual looking away from the screen and, consequently, losing his attention. Based on the Design Science Re-search methodology, eye tracking was incorporated into the system architecture. For validation, tests were performed with 10 users, using a movie trailer. Analyzing the generated data, it was possible to identify the correlation between the information presented by the EEG and the gaze of the individuals. In this way, it is possible to increase certainty about the origin of emotions during the fruition of audiovisual content. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Audiovisual Fruition; EEG; Eye Tracking,Electroencephalography; Electrophysiology; Visualization; Analysis system; Audio-visual content; Audiovisual fruition; Brain wave; Design science; Eye-tracking; Graphics visualizations; Systems architecture; Visualization and analysis; Visualization system; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85176010672,Movies / Media
Xu W.; Tong Z.,"Xu, Wenjuan (57226027294); Tong, Zheng (58784030200)",57226027294; 58784030200,Research on Relationship Between Bullet Screen Attributes in Medical Popular Science Videos and The audience's cognitive load,2023,"Proceedings of the 2023 IEEE 6th International Conference on Knowledge Innovation and Invention, ICKII 2023",,,,585,589,4.0,0,10.1109/ICKII58656.2023.10332737,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180753044&doi=10.1109%2fICKII58656.2023.10332737&partnerID=40&md5=b788d7518533f947454fa043a426d6e8,"This article aims to explore the relationship between bullet screen attributes in medical popular science videos and the audience's cognitive load. The evaluation indicators for cognitive load included subjects' blink frequency, gaze count, and response to task completion in eye-tracking experiments. The connection between the audience's cognitive load and the opacity and speed attributes of bullet screens in popular science videos was investigated, and the impact of different bullet screen attributes on the audience's cognitive load was explored. By analyzing the relationship between attributes such as bullet screen content, density, speed, and the audience's cognitive load in watching medical science videos, the attention allocation patterns of the audience towards bullet screens and video content were analyzed using eye-tracking technology. Experimental results indicated that the opacity of bullet screens impacted cognitive load significantly with the lowest cognitive load of audiences. The speed of bullet screens also affected the audience's cognitive load with slower speeds resulting in a less cognitive impact and lower cognitive load.  © 2023 IEEE.",bullet screen parameter; cognitive load; eye-tracking technology; medical popular science video,Eye tracking; Allocation patterns; Blink frequencies; Bullet screen parameter; Cognitive loads; Evaluation indicators; Eye tracking technologies; Eye-tracking; Medical popular science video; Medical science; Screen parameters; Opacity,Conference paper,Final,,Scopus,2-s2.0-85180753044,Movies / Media
Riek H.C.; Brien D.C.; Coe B.C.; Huang J.; Perkins J.E.; Yep R.; McLaughlin P.M.; Orange J.B.; Peltsch A.J.; Roberts A.C.; Binns M.A.; Lou W.; Abrahao A.; Arnott S.R.; Beaton D.; Black S.E.; Dowlatshahi D.; Finger E.; Fischer C.E.; Frank A.R.; Grimes D.A.; Kumar S.; Lang A.E.; Lawrence-Dewar J.M.; Mandzia J.L.; Marras C.; Masellis M.; Pasternak S.H.; Pollock B.G.; Rajji T.K.; Sahlas D.J.; Saposnik G.; Seitz D.P.; Shoesmith C.; Steeves T.D.L.; Strother S.C.; Sunderland K.M.; Swartz R.H.; Tan B.; Tang-Wai D.F.; Tartaglia M.C.; Turnbull J.; Zinman L.; Munoz D.P.,"Riek, Heidi C. (57659595400); Brien, Donald C. (8896316400); Coe, Brian C. (7006220583); Huang, Jeff (57195805066); Perkins, Julia E. (57222497188); Yep, Rachel (57201885862); McLaughlin, Paula M. (36496959600); Orange, Joseph B. (7004197592); Peltsch, Alicia J. (23111809100); Roberts, Angela C. (57193125372); Binns, Malcolm A. (7005230966); Lou, Wendy (7006030594); Abrahao, Agessandro (58448607000); Arnott, Stephen R. (7005583955); Beaton, Derek (12645535700); Black, Sandra E. (35400981300); Dowlatshahi, Dar (6602400834); Finger, Elizabeth (36477160300); Fischer, Corinne E. (7402486754); Frank, Andrew R. (57210925408); Grimes, David A. (57218886204); Kumar, Sanjeev (57020377400); Lang, Anthony E. (57200105561); Lawrence-Dewar, Jane M. (57194755981); Mandzia, Jennifer L. (6507268342); Marras, Connie (6701861586); Masellis, Mario (7004107743); Pasternak, Stephen H. (8770273000); Pollock, Bruce G. (7103208387); Rajji, Tarek K. (22980785600); Sahlas, Demetrios J. (6603627989); Saposnik, Gustavo (7004063552); Seitz, Dallas P. (12143339200); Shoesmith, Christen (6508119995); Steeves, Thomas D. L. (7004361367); Strother, Stephen C. (7005637437); Sunderland, Kelly M. (57193663544); Swartz, Richard H. (7103250210); Tan, Brian (57221693896); Tang-Wai, David F. (57200266613); Tartaglia, Maria Carmela (12773657100); Turnbull, John (7201518452); Zinman, Lorne (7004020872); Munoz, Douglas P. (7103163217)",57659595400; 8896316400; 7006220583; 57195805066; 57222497188; 57201885862; 36496959600; 7004197592; 23111809100; 57193125372; 7005230966; 7006030594; 58448607000; 7005583955; 12645535700; 35400981300; 6602400834; 36477160300; 7402486754; 57210925408; 57218886204; 57020377400; 57200105561; 57194755981; 6507268342; 6701861586; 7004107743; 8770273000; 7103208387; 22980785600; 6603627989; 7004063552; 12143339200; 6508119995; 7004361367; 7005637437; 57193663544; 7103250210; 57221693896; 57200266613; 12773657100; 7201518452; 7004020872; 7103163217,Cognitive correlates of antisaccade behaviour across multiple neurodegenerative diseases,2023,Brain Communications,5,2,fcad049,,,,20,10.1093/braincomms/fcad049,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153271138&doi=10.1093%2fbraincomms%2ffcad049&partnerID=40&md5=a976d9899bd2625e8099f488e8746d54,"Oculomotor tasks generate a potential wealth of behavioural biomarkers for neurodegenerative diseases. Overlap between oculomotor and disease-impaired circuitry reveals the location and severity of disease processes via saccade parameters measured from eye movement tasks such as prosaccade and antisaccade. Existing studies typically examine few saccade parameters in single diseases, using multiple separate neuropsychological test scores to relate oculomotor behaviour to cognition; however, this approach produces inconsistent, ungeneralizable results and fails to consider the cognitive heterogeneity of these diseases. Comprehensive cognitive assessment and direct inter-disease comparison are crucial to accurately reveal potential saccade biomarkers. We remediate these issues by characterizing 12 behavioural parameters, selected to robustly describe saccade behaviour, derived from an interleaved prosaccade and antisaccade task in a large cross-sectional data set comprising five disease cohorts (Alzheimer's disease/mild cognitive impairment, amyotrophic lateral sclerosis, frontotemporal dementia, Parkinson's disease, and cerebrovascular disease; n = 391, age 40-87) and healthy controls (n = 149, age 42-87). These participants additionally completed an extensive neuropsychological test battery. We further subdivided each cohort by diagnostic subgroup (for Alzheimer's disease/mild cognitive impairment and frontotemporal dementia) or degree of cognitive impairment based on neuropsychological testing (all other cohorts). We sought to understand links between oculomotor parameters, their relationships to robust cognitive measures, and their alterations in disease. We performed a factor analysis evaluating interrelationships among the 12 oculomotor parameters and examined correlations of the four resultant factors to five neuropsychology-based cognitive domain scores. We then compared behaviour between the abovementioned disease subgroups and controls at the individual parameter level. We theorized that each underlying factor measured the integrity of a distinct task-relevant brain process. Notably, Factor 3 (voluntary saccade generation) and Factor 1 (task disengagements) significantly correlated with attention/working memory and executive function scores. Factor 3 also correlated with memory and visuospatial function scores. Factor 2 (pre-emptive global inhibition) correlated only with attention/working memory scores, and Factor 4 (saccade metrics) correlated with no cognitive domain scores. Impairment on several mostly antisaccade-related individual parameters scaled with cognitive impairment across disease cohorts, while few subgroups differed from controls on prosaccade parameters. The interleaved prosaccade and antisaccade task detects cognitive impairment, and subsets of parameters likely index disparate underlying processes related to different cognitive domains. This suggests that the task represents a sensitive paradigm that can simultaneously evaluate a variety of clinically relevant cognitive constructs in neurodegenerative and cerebrovascular diseases and could be developed into a screening tool applicable to multiple diagnoses.  © 2023 The Author(s). Published by Oxford University Press on behalf of the Guarantors of Brain.",antisaccade; cognitive impairment; dementia; neurodegenerative disease; prosaccade,,Article,Final,,Scopus,2-s2.0-85153271138,Movies / Media
Qin Y.; Wang L.; Guo L.; Han J.; Hu X.,"Qin, Yang (58615123700); Wang, Liting (57194832125); Guo, Lei (56428255600); Han, Junwei (24450644400); Hu, Xintao (56177187200)",58615123700; 57194832125; 56428255600; 24450644400; 56177187200,Selective Visual Attention Revealed by Integrating FMRI and Eye-Tracking,2023,Proceedings - International Symposium on Biomedical Imaging,2023-April,,,,,,0,10.1109/ISBI53787.2023.10230382,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172070911&doi=10.1109%2fISBI53787.2023.10230382&partnerID=40&md5=e1065af079d4bd73781b63fb6f6f3eea,"Selective visuo-spatial attention (SVSA), consisting of both bottom-up and top-down processes, prioritizes relevant visual information while filtering out the rest. The research interests in SVSA tend to shift from isolating the two processes to depicting the interplay between them. Existing studies have highlighted the combination of computational, behavioral, and naturalistic paradigm neuroimaging enables the study of SVSA in ecologically valid contexts. However, several critical issues need to be revisited. First, the computational visual saliency model that bridges external video stimuli and brain activities in previous studies are designed for static images rather than dynamic videos. Second, both the computational saliency maps and the eye-gaze heatmaps could be noisy. Third, the participant cohort is relatively small. In this study, we investigate the SVSA using the large-scale movie-watching functional magnetic resonance imaging (fMRI) data in the Human Connectome Project (HCP), and by integrating the potential solutions to the limitations discussed above. Our experimental results highlight the importance of visual and auditory interactions in forming the bottom-up visual attention, as well as the engagement of high-order visual cortices and the ventral frontoparietal network in the bottom-up modulatory effect in naturalistic conditions. © 2023 IEEE.",Computational visual saliency model; Eye-tracking; Functional MRI; Visuo-spatial attention,Behavioral research; Brain; Eye tracking; Functional neuroimaging; Information filtering; Visualization; Bottom-up and top-down; Computational visual saliency model; Eye-tracking; Functional MRI; Spatial attention; Top-down process; Visual Attention; Visual information; Visual saliency model; Visuo-spatial attention; Magnetic resonance imaging,Conference paper,Final,,Scopus,2-s2.0-85172070911,Movies / Media
Fann S.-C.,"Fann, Shih-Cheng (57195638151)",57195638151,A Preliminary Study on the Kansei Evaluation of Physical and Virtual Operation Interfaces,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14054 LNCS,,,54,66,12.0,0,10.1007/978-3-031-48038-6_4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178552325&doi=10.1007%2f978-3-031-48038-6_4&partnerID=40&md5=475c6ee3927a5b7ef2d823b377d94228,"The rapid advancement of technology has prompted significant changes in the design of high-tech products, transitioning from physical operation interfaces to virtual interfaces, such as touch screens. This study focuses on the operation interface of automotive control panels and investigates the differences in kansei evaluation and user preferences between physical and virtual interfaces. Through kansei evaluations and eye-tracking experiments, participants’ subjective evaluations and visual attention patterns towards both interface types are analyzed. The findings indicate that participants’ attention is primarily directed towards the control panel interface and the steering wheel, highlighting the considerable impact of these designs on kansei evaluations. Furthermore, the control panel interface receives a greater number of visual fixations compared to the steering wheel, indicating users’ heightened visual focus on this area. Additionally, the position and size of the screen significantly influence the distribution of participants’ visual attention, with vertical or large screens attracting more gaze. This research contributes to a comprehensive understanding of the kansei differences during the transition from physical to virtual interfaces. The findings provide valuable insights for interface design research and offer practical design recommendations for automotive control panel interfaces. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Car design; Eye tracking; Kansei Engineering,Automobile steering equipment; Behavioral research; Product design; Touch screens; Wheels; Automotive control; Car designs; Control panels; Eye-tracking; Kansei Engineering; Kansei evaluation; Operation interface; Panels interface; Virtual interfaces; Visual Attention; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85178552325,Movies / Media
Yao J.-Y.; Zheng Z.-W.; Zhang Y.; Su S.-S.; Wang Y.; Tao J.; Peng Y.-H.; Wu Y.-R.; Jiang W.-H.; Qiu J.-Y.,"Yao, Jia-Yu (57814379900); Zheng, Zi-Wei (57814185500); Zhang, Yi (57188770700); Su, Shan-Shan (55365461800); Wang, Yuan (57814380000); Tao, Jing (55444721600); Peng, Yi-Hua (57218439114); Wu, Yan-Ru (57190415051); Jiang, Wen-Hui (55483610200); Qiu, Jian-Yin (36483384000)",57814379900; 57814185500; 57188770700; 55365461800; 57814380000; 55444721600; 57218439114; 57190415051; 55483610200; 36483384000,Electrophysiological evidence for the characteristics of implicit self-schema and other-schema in patients with major depressive disorder: An event-related potential study,2023,Frontiers in Psychiatry,14,,1131275,,,,2,10.3389/fpsyt.2023.1131275,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153531173&doi=10.3389%2ffpsyt.2023.1131275&partnerID=40&md5=7ce41948e659be287954158ad064b565,"Background: The significance of implicit self-schema and other-schema in major depressive disorder (MDD) is highlighted by both cognitive theory and attachment theory. The purpose of the current study was to investigate the behavioral and event-related potential (ERP) characteristics of implicit schemas in MDD patients. Methods: The current study recruited 40 patients with MDD and 33 healthy controls (HCs). The participants were screened for mental disorders using the Mini-International Neuropsychiatric Interview. Hamilton Depression Rating Scale-17 and Hamilton Anxiety Rating Scale-14 were employed to assess the clinical symptoms. Extrinsic Affective Simon Task (EAST) was conducted to measure the characteristics of implicit schemas. Meanwhile, reaction time and electroencephalogram data were recorded. Results: Behavioral indexes showed that HCs responded faster to positive self and positive others than negative self (t = −3.304, p = 0.002, Cohen’s d = 0.575) and negative others (t = −3.155, p = 0.003, Cohen’s d = 0.549), respectively. However, MDD did not show this pattern (p > 0.05). The difference in other-EAST effect between HCs and MDD was significant (t = 2.937, p = 0.004, Cohen’s d = 0.691). The ERP indicators of self-schema showed that under the condition of positive self, the mean amplitude of LPP in MDD was significantly smaller than that in HCs (t = −2.180, p = 0.034, Cohen’s d = 0.902). The ERP indexes of other-schema showed that HCs had a larger absolute value of N200 peak amplitude for negative others (t = 2.950, p = 0.005, Cohen’s d = 0.584) and a larger P300 peak amplitude for positive others (t = 2.185, p = 0.033, Cohen’s d = 0.433). The above patterns were not shown in MDD (p > 0.05). The comparison between groups found that under the condition of negative others, the absolute value of N200 peak amplitude in HCs was larger than that in MDD (t = 2.833, p = 0.006, Cohen’s d = 1.404); under the condition of positive others, the P300 peak amplitude (t = −2.906, p = 0.005, Cohen’s d = 1.602) and LPP amplitude (t = −2.367, p = 0.022, Cohen’s d = 1.100) in MDD were smaller than that in HCs. Conclusion: Patients with MDD lack positive self-schema and positive other-schema. Implicit other-schema might be related to abnormalities in both the early automatic processing stage and the late elaborate processing stage, while the implicit self-schema might be related only to the abnormality in the late elaborate processing stage. Copyright © 2023 Yao, Zheng, Zhang, Su, Wang, Tao, Peng, Wu, Jiang and Qiu.",event-related potential; implicit schemas; major depressive disorder (MDD); other-schema; self-schema,adult; anxiety; Article; clinical article; controlled study; depression; electroencephalogram; electroencephalography; electrophysiology; event related potential; eye movement; fatigue; female; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; human; implicit bias; major depression; male; mental disease; mini international neuropsychiatric interview; psychotherapy; Social Cognitive Theory; visual field,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85153531173,Movies / Media
Sun B.; Wang B.; Wei Z.; Feng Z.; Wu Z.-L.; Yassin W.; Stone W.S.; Lin Y.; Kong X.-J.,"Sun, Binbin (57203329231); Wang, Bryan (57220786734); Wei, Zhen (56459346600); Feng, Zhe (57693058400); Wu, Zhi-Liu (56969910400); Yassin, Walid (55650821000); Stone, William S. (7202532871); Lin, Yan (57203330591); Kong, Xue-Jun (57195760508)",57203329231; 57220786734; 56459346600; 57693058400; 56969910400; 55650821000; 7202532871; 57203330591; 57195760508,Identification of diagnostic markers for ASD: a restrictive interest analysis based on EEG combined with eye tracking,2023,Frontiers in Neuroscience,17,,1236637,,,,7,10.3389/fnins.2023.1236637,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174947520&doi=10.3389%2ffnins.2023.1236637&partnerID=40&md5=e506502b277919b542da2728bce9a84b,"Electroencephalography (EEG) functional connectivity (EFC) and eye tracking (ET) have been explored as objective screening methods for autism spectrum disorder (ASD), but no study has yet evaluated restricted and repetitive behavior (RRBs) simultaneously to infer early ASD diagnosis. Typically developing (TD) children (n = 27) and ASD (n = 32), age- and sex-matched, were evaluated with EFC and ET simultaneously, using the restricted interest stimulus paradigm. Network-based machine learning prediction (NBS-predict) was used to identify ASD. Correlations between EFC, ET, and Autism Diagnostic Observation Schedule-Second Edition (ADOS-2) were performed. The Area Under the Curve (AUC) of receiver-operating characteristics (ROC) was measured to evaluate the predictive performance. Under high restrictive interest stimuli (HRIS), ASD children have significantly higher α band connectivity and significantly more total fixation time (TFT)/pupil enlargement of ET relative to TD children (p = 0.04299). These biomarkers were not only significantly positively correlated with each other (R = 0.716, p = 8.26e−4), but also with ADOS total scores (R = 0.749, p = 34e-4) and RRBs sub-score (R = 0.770, p = 1.87e-4) for EFC (R = 0.641, p = 0.0148) for TFT. The accuracy of NBS-predict in identifying ASD was 63.4%. ROC curve demonstrated TFT with 91 and 90% sensitivity, and 78.7% and 77.4% specificity for ADOS total and RRB sub-scores, respectively. Simultaneous EFC and ET evaluation in ASD is highly correlated with RRB symptoms measured by ADOS-2. NBS-predict of EFC offered a direct prediction of ASD. The use of both EFC and ET improve early ASD diagnosis. Copyright © 2023 Sun, Wang, Wei, Feng, Wu, Yassin, Stone, Lin and Kong.",ASD biomarker; ASD early diagnosis; EEG; eye tracking; functional connectivity,biological marker; CD4 antigen; microRNA; Article; artifact; attention deficit hyperactivity disorder; autism assessment; Autism Diagnostic Observation Schedule; BOLD signal; child; connectome; controlled study; developmental delay; diagnostic test accuracy study; early diagnosis; electroencephalogram; electroencephalography; emergency ward; eye tracking; female; Fourier transform; functional connectivity; functional magnetic resonance imaging; human; machine learning; major clinical study; male; preschool child; pupil; receiver operating characteristic; sensitivity and specificity; speech perception; stereotypy; stimulus response,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85174947520,Movies / Media
Szwarc J.; Rasmus A.; Koziara J.; Matulewski J.,"Szwarc, Jakub (58851992700); Rasmus, Anna (55441300000); Koziara, Joanna (58852313900); Matulewski, Jacek (6602591861)",58851992700; 55441300000; 58852313900; 6602591861,"What is supposed to help, actually hinders: about the impact of the GUI dynamics on the efficiency of gaze text entry",2023,Procedia Computer Science,225,,,2292,2301,9.0,2,10.1016/j.procs.2023.10.220,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183573871&doi=10.1016%2fj.procs.2023.10.220&partnerID=40&md5=af0c2163d3de09b3a3129edfbc8a7b57,"The research aimed to test the influence on text entry efficiency of supporting features in gaze text entry systems (aka gaze keyboards), leading to dynamic changes in key layout and size. We examined three gaze-controlled on-screen keyboards, that differ in the degree of support, which translates into the amount of change that occurs in the arrangement of the keys and their size - three degrees of dynamism of keyboards' graphical user interface. We also attempted to examine the importance of user attention while using dynamic interface and its impact on text input performance. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)",Eye-tracking; Gaze interaction; Gaze-based games; Human-Computer interfaces,Computer games; Efficiency; Graphical user interfaces; Degree of support; Dynamic changes; Eye-tracking; Gaze interaction; Gaze-based game; Human computer interfaces; On-screen keyboard; Text entry; Text entry systems; User attention; Eye tracking,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85183573871,Movies / Media
Huang G.; Zhou L.; Chen D.; Chen W.; Liu R.,"Huang, Guan (57681945000); Zhou, Li (58821175700); Chen, Dan (57384367100); Chen, Wen (58820683200); Liu, Rui (57451015500)",57681945000; 58821175700; 57384367100; 58820683200; 57451015500,Research on the design of panoramic virtual learning environment screen elements,2023,Frontiers in Psychology,14,,1314076,,,,0,10.3389/fpsyg.2023.1314076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182654204&doi=10.3389%2ffpsyg.2023.1314076&partnerID=40&md5=d67efcfcb438214debf97704ba29e3c1,"Panoramic video and virtual reality technologies create learning environments that provide learners with an “immersive” experience. In recent years, panoramic video design to create immersive learning environments, in particular, has become an increasingly popular topic in teacher education and educational research. However, few studies have explored the elements of panoramic virtual learning environment screens regarding the design of learning environments. Therefore, this experimental study uses eye-tracking technology to investigate how learners are guided by panoramic video elements in a panoramic virtual learning environment. Participants (n = 90) were randomly assigned to one of six conditions: (1) no caption + live interpretation, (2) no caption + AI interpretation, (3) 120-degree caption + live interpretation, (4) 120-degree caption + AI interpretation, (5) static follow caption + live interpretation, and (6) static follow caption + AI interpretation. The results of the study show that when learners experience a panoramic virtual learning environment with different narration methods, the live interpretation method is more likely to attract learners’ attention and bring better emotion and experience than the AI interpretation method. When experiencing a panoramic virtual learning environment with different caption presentation methods, the caption presentation methods induced learners’ attention, learning emotions, and experiences in the order of no caption >120-degree caption > static following caption. Finally, the rules for optimizing the design of panoramic virtual learning environment screens are given based on the findings of the study, which provide new ideas for designing and developing panoramic video teaching resources. Copyright © 2024 Huang, Zhou, Chen, Chen and Liu.",caption; eye-tracking technology; interpretation method; learning effect; panoramic virtual learning environment; screen elements,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85182654204,Movies / Media
Sun Y.; Min X.; Duan H.; Zhai G.,"Sun, Yinan (58532625600); Min, Xiongkuo (56030205300); Duan, Huiyu (57195265438); Zhai, Guangtao (15847120000)",58532625600; 56030205300; 57195265438; 15847120000,The Influence of Text-guidance on Visual Attention,2023,Proceedings - IEEE International Symposium on Circuits and Systems,2023-May,,,,,,9,10.1109/ISCAS46773.2023.10182000,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167655829&doi=10.1109%2fISCAS46773.2023.10182000&partnerID=40&md5=8cb43768d7ff6c4eeaa79ab1a0967e3b,"Visual attention analysis and prediction have long been important tasks in computer vision and image processing. However, images often come along with various text descriptions in real applications, while the influence of these text-guidances on the visual saliency of corresponding images have rarely been studied. Therefore, in this paper, we mainly focus on the problem of whether and how the text-guidance influences the visual attention during image viewing, and perform subjective experiments, qualitative and quantitative comparisons as well as model evaluations on this new task. Specifically, we first conduct eye tracking experiments on 300 images under text-visual (TV) and visual (V) test conditions, respectively. Based on the subjective experiments, we perform qualitative and quantitative comparisons between the visual attention data collected under TV and V conditions, and conclude that the text-guidance can significantly influence the visual attention, especially when the text-described target is a non-salient object. Finally, we evaluate the existing saliency models on our database, and find that existing models cannot well handle this text-induced saliency prediction task. Our constructed database will be publicly available to facilitate future research. © 2023 IEEE.",image saliency; text-guidance; visual attention,Behavioral research; Computer vision; Image saliencies; Images processing; Quantitative comparison; Quantitative models; Real applications; Subjective experiments; Text-guidance; Vision processing; Visual Attention; Visual saliency; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85167655829,Movies / Media
Pochwatko G.; Cnotkowski D.; Kobyliński P.; Borkiewicz P.; Pabiś-Orzeszyna M.; Wierzbowski M.; Osęka L.,"Pochwatko, Grzegorz (55014223400); Cnotkowski, Daniel (57210804690); Kobyliński, Paweł (57194490703); Borkiewicz, Paulina (58059121600); Pabiś-Orzeszyna, Michał (57190027148); Wierzbowski, Mariusz (22434395700); Osęka, Laura (57213157282)",55014223400; 57210804690; 57194490703; 58059121600; 57190027148; 22434395700; 57213157282,Transdisciplinary Approach to Virtual Narratives - Towards Reliable Measurement Methods,2023,Lecture Notes in Networks and Systems,710 LNNS,,,202,212,10.0,1,10.1007/978-3-031-37649-8_20,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172016591&doi=10.1007%2f978-3-031-37649-8_20&partnerID=40&md5=17bfbb89ae20dd8eee338de7144c04a9,"We have recently observed intense growth in the film industry’s interest in VR creations. Cinematic VR artists encounter challenges that result from discrepancies between established techniques of storytelling, stylistic conventions, and organizational culture indicative of traditional modes of film practice and the requirements of the new medium and new audience. We propose a transdisciplinary approach to cinematic VR research. Thanks to the cooperation of art & science - a collaboration between psychologists, information technology specialists, film scholars, and filmmakers will contribute to the emergence of a new VR narrative paradigm. We use a number of quantitative and qualitative methods to study the perception of cinematic VR works, an illusion of spatial presence and copresence, attention, emotions, and arousal of its users, narrative understanding, and character engagement. We measure participants’ reactions in many independent ways: in addition to subjective assessments and declarative methods, we use more objective data: eye tracking, multi-point position skeleton tracking, and psychophysiological responses. We show the effectiveness of the adopted approach by studying three artistic cinematic VR works: narrative and non-narrative, live-action, and animated. We compare the user experience and present the possibilities of interpretation and feedback benefits for art. © 2023, The Author(s).",cinematic VR; presence; research app; usability,Behavioral research; Motion pictures; Virtual reality; Cinematic VR; Cinematics; Film industry; Measurement methods; Organizational cultures; Presence; Reliable measurement; Research app; Trans-disciplinary approaches; Usability; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85172016591,Movies / Media
Ben Itzhak N.; Kooiker M.J.G.; Pel J.J.M.; Ortibus E.,"Ben Itzhak, N. (57213605712); Kooiker, M.J.G. (56107481600); Pel, J.J.M. (7003380897); Ortibus, E. (24723149200)",57213605712; 56107481600; 7003380897; 24723149200,"Including visual orienting functions into cerebral visual impairment screening: Reliability, variability, and ecological validity",2023,Research in Developmental Disabilities,132,,104391,,,,12,10.1016/j.ridd.2022.104391,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144589943&doi=10.1016%2fj.ridd.2022.104391&partnerID=40&md5=23522347f40ea039c80a5484786b5a65,"Background: Cerebral visual impairment (CVI) is a heterogeneous brain-based visual processing disorder in which basic visual orienting functions (VOF) and higher-order perception can be impaired. Aims: To evaluate (1) the test-retest reliability and variability of an eye tracking-based VOF paradigm, and related clinical characteristics, and (2) the relations between VOF (variability) and daily visual functioning and visuoperceptual dimensions. Methods and procedures: Thirty-three children with CVI (Males=14; mean age=9 years 10 months) underwent eye tracking thrice, completed a visuoperceptual battery, and parents completed the Flemish CVI questionnaire. VOF reliability and variability of reaction time (RTF), fixation duration and accuracy were assessed with intraclass correlation coefficient (ICC), Bland-Altman plots, and coefficient of variation. Relations were analysed with linear mixed models. Outcomes and results: Highly salient visual stimuli had good RTF reliability (ICCs=0.75) and triggered less variable VOF. Intermediate and low salience stimuli had poor-to-moderate reliability and triggered more variable VOF. Younger performance age related to more VOF variability. Greater visual (dis)interest, clutter and distance viewing impairments, and a weaker visuoperceptual profile related to slower RTF. Conclusions and implications: Highly salient stimuli reveal a child's ‘optimal’ visual performance, whereas intermediate and low salience stimuli uncover VOF variability, which is a key CVI hallmark to detect. © 2022 Elsevier Ltd",Cerebral visual impairment; Remote eye tracking; Test-retest reliability; Visual orienting functions; Visual perception,"Child; Humans; Male; Reaction Time; Reproducibility of Results; Vision Disorders; Vision, Ocular; Visual Perception; vigabatrin; Article; assessment of humans; attention deficit hyperactivity disorder; autism; beery buktenica developmental test of visual motor integration test; cerebral blindness; cerebral palsy; child; clinical feature; clinical outcome; controlled study; ecological validity; epilepsy; eye tracking; female; flemish cerebral visual impairment questionnaire; gestational age; human; male; multidisciplinary team; questionnaire; reaction time; refraction index; reliability; retrospective study; school child; snijders oomen nonverbal intelligence test; statistical analysis; test retest reliability; visual acuity; visual orientation; visual perception test; visual stimulation; wechsler preschool and primary scale intelligence; reproducibility; vision; visual disorder",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85144589943,Movies / Media
Elkashef H.; Taie A.; Hamdy A.; Atia A.,"Elkashef, Habiba (59334284600); Taie, Alaa (59208807300); Hamdy, Abdalla (59208125600); Atia, Ayman (35101350300)",59334284600; 59208807300; 59208125600; 35101350300,Analyzing User Interest Detection in Web sites: A Bimodal Approach,2023,"33rd International Conference on Computer Theory and Applications, ICCTA 2023",,,,260,265,5.0,0,10.1109/ICCTA60978.2023.10969182,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004794509&doi=10.1109%2fICCTA60978.2023.10969182&partnerID=40&md5=b4b1778eaaebca0b4422bf81095997ea,"In the world of online navigation, understanding user interaction is crucial. We introduce a unique bimodal model for seeing and analyzing user interest in web adverts in this work. Our innovative method employs real-time camera data, combining face expression analysis and gaze tracking. The presented system utilizes Convolutional Neural Networks (CNNs) to understand more about user emotions while interacting with advertisements. Furthermore, we have built a gaze tracking algorithm that catches and saves gaze coordinates, as well as associated facial emotions, in a CSV file. Surprisingly, our study indicates that the upper center of the homepage receives the most visual attention, while the bottom right quadrant receives the least. With respect to Euclidean distance, the greatest distance measured was 21.4, resulting in the highest path similarity of 42.9%. Furthermore, about 18% has some common screen starting points and 22% terminate at the same screen endpoint. These findings provide an important foundation for improving advertising strategies and optimizing user experience in the changing world of web navigation.  © 2023 IEEE.",,User experience; Bimodal models; Face expressions; Gaze-tracking; Innovative method; Interest detection; On-line navigation; Real- time; User interaction; Users' interests; Web-sites; Convolutional neural networks,Conference paper,Final,,Scopus,2-s2.0-105004794509,Movies / Media
Onnasch L.; Schweidler P.; Schmidt H.,"Onnasch, Linda (35111634600); Schweidler, Paul (58062461000); Schmidt, Helena (58531015400)",35111634600; 58062461000; 58531015400,The potential of robot eyes as predictive cues in HRI—an eye-tracking study,2023,Frontiers in Robotics and AI,10,,1178433,,,,3,10.3389/frobt.2023.1178433,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167609194&doi=10.3389%2ffrobt.2023.1178433&partnerID=40&md5=b0319dc32b589c84c13c743968fba1fc,"Robots currently provide only a limited amount of information about their future movements to human collaborators. In human interaction, communication through gaze can be helpful by intuitively directing attention to specific targets. Whether and how this mechanism could benefit the interaction with robots and how a design of predictive robot eyes in general should look like is not well understood. In a between-subjects design, four different types of eyes were therefore compared with regard to their attention directing potential: a pair of arrows, human eyes, and two anthropomorphic robot eye designs. For this purpose, 39 subjects performed a novel, screen-based gaze cueing task in the laboratory. Participants’ attention was measured using manual responses and eye-tracking. Information on the perception of the tested cues was provided through additional subjective measures. All eye models were overall easy to read and were able to direct participants’ attention. The anthropomorphic robot eyes were most efficient at shifting participants’ attention which was revealed by faster manual and saccadic reaction times. In addition, a robot equipped with anthropomorphic eyes was perceived as being more competent. Abstract anthropomorphic robot eyes therefore seem to trigger a reflexive reallocation of attention. This points to a social and automatic processing of such artificial stimuli. Copyright © 2023 Onnasch, Schweidler and Schmidt.",anthropomorphism; attentional processes; human-robot interaction (HRI); joint attention; robot design,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85167609194,Movies / Media
Mora-Salinas R.J.; Perez-Rojas D.; De La Trinidad-Rendon J.S.,"Mora-Salinas, Roberto J. (57205527241); Perez-Rojas, Daniel (57218098760); De La Trinidad-Rendon, Julio S. (58162813200)",57205527241; 57218098760; 58162813200,Real-Time Sensory Adaptive Learning for Engineering Students,2023,Lecture Notes in Networks and Systems,633 LNNS,,,820,831,11.0,1,10.1007/978-3-031-26876-2_78,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151149744&doi=10.1007%2f978-3-031-26876-2_78&partnerID=40&md5=f415def674e97ff6fc0ad4cf92e5493c,"During the last two years, education has undergone a major change due to the pandemic, several problems in engineering education appeared due to the lack of face-to-face interaction. The problems in distance learning and self-study became more evident with the absence of a teacher to vary the stimulus when interacting with students. This situation caused both students and teachers to rely on distance work tools, a good Internet connection, simulation tools, and virtual laboratories. Due to the limitations of home-office, and homeschooling, it is necessary to look for alternatives such as the use of sensor technologies of different types to be able to measure students’ attention in real-time. The use of self-regulated and adaptive content in real-time, obtaining feedback from intelligent sensors, can increase the impact of the content reviewed by the student without the need to have a teacher present. This paper describes the work done in the search for alternative solutions to create self-regulating adaptive content using sensor feedback so that later warning signals can be generated to produce stimulus variations when the student is reviewing content related to a certain topic. The present work focuses on the design of an experiment, which with the help of an eye-tracking device, allows us to obtain information about the region of the screen where the student’s eyes are when reviewing material related to some subject, to analyze the characteristics that have the elements that favor the student’s attention in a scenario in which they can only interact with content on a screen and see how they react to different stimuli. This experiment intends to obtain information to improve the development of content used in flipped classroom sessions, where students are asked to review content before a synchronous session with the teacher. The positive impacts that will be reflected in the student are greater flexibility in the learning process since by designing better materials, the student can advance more at his own pace, and assimilate the contents better, reflecting this better understanding in the academic activities. A final positive impact will be that the teacher will be able to use technology in a skillful way to design new content tools for their courses and apply them to the students’ current situation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Adaptive learning; Data analytics; Educational innovation; Educational technology; Higher education,Curricula; Data Analytics; Distance education; Educational technology; Engineering education; Eye tracking; Feedback; Learning systems; Adaptive content; Adaptive learning; Data analytics; Distance-learning; Educational innovations; Face-to-face interaction; High educations; Internet connection; Real- time; Teachers'; Students,Conference paper,Final,,Scopus,2-s2.0-85151149744,Movies / Media
,,,"Medical Imaging 2023: Image Perception, Observer Performance, and Technology Assessment",2023,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,12467,,,,,362.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160951902&partnerID=40&md5=83138e1d19d8f97ba115f3b2c8d0ed56,The proceedings contain 48 papers. The topics discussed include: comparing experts to novices: reduced satisfaction of search when searching with virtual breast tomosynthesis; optimal visual search strategy with inter-saccade response correlations; challenges and solutions to processing and visualizing eye tracking data from digital pathology studies; identifying and preventing fatigue in digital breast tomosynthesis; global mammographic radiomic signature can predict radiologists’ difficult-to-interpret normal cases; a comparative study of diagnostic performance and work experience of radiologists in three countries interpreting digital breast tomosynthesis; false-negative diagnosis might occur due to absence of the global radiomic signature of malignancy on screening mammograms; investigating the error-making patterns in reading high-density screening mammograms between radiologists from two countries; developing and assessing an AI-based multi-task prediction system to assist radiologists detecting lung diseases in reading chest x-ray images; and Obuchowski-Rockette analysis for multi-reader multi-case (MRMC) readers-nested-in-test study design with unequal numbers of readers.,,,Conference review,Final,,Scopus,2-s2.0-85160951902,Movies / Media
Yang J.; Tang X.; Lin S.; Jiang L.; Wei K.; Cao X.; Wan L.; Wang J.; Ding H.; Li C.,"Yang, Junjie (57415336800); Tang, Xiaochen (57194547491); Lin, Shaohui (57218318323); Jiang, Lijuan (55653979100); Wei, Kai (56085657300); Cao, Xinyi (35975549100); Wan, Lingshan (58243877600); Wang, Jijun (59292645800); Ding, Hansheng (56597315400); Li, Chunbo (36064230700)",57415336800; 57194547491; 57218318323; 55653979100; 56085657300; 35975549100; 58243877600; 59292645800; 56597315400; 36064230700,Altered auditory processes pattern predicts cognitive decline in older adults: different modalities with aging,2023,Frontiers in Aging Neuroscience,15,,1230939,,,,1,10.3389/fnagi.2023.1230939,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171897479&doi=10.3389%2ffnagi.2023.1230939&partnerID=40&md5=3ead533a4af14017fcbc4252cda1e532,"Background: Cohort studies have shown that older adults with hearing impairment as assessed by self-report or behavioral measures are at higher risk of developing dementia many years later. A fine-grained examination of auditory processing holds promise for more effective screening of older adults at risk of cognitive decline. The auditory mismatch negativity (MMN) measure enables one to gain insights into the neurobiological substrate of central auditory processing. We hypothesized that older adults showing compromised indexes of MMN at baseline would exhibit cognitive decline at the one-year follow-up. Methods: We performed cognitive evaluations with the Repeatable Battery for the Assessment of Neuropsychological Status (RBANS; Form A and Form B) in 108 community-dwelling older adults and acquired EEG via the classic passive auditory oddball paradigm at baseline and 12-month follow-up. Results: The results showed that young-old adults with future cognitive decline showed a decrease in MMN peak amplitude, accompanied by a forward-shifting latency, whereas in older adults it showed a delay in MMN latency, and unchanged MMN peak amplitude at midline electrodes (Fz, FCz and Cz). Furthermore, the peak amplitude of the MMN decreases with age in older adults aged 70–80 years rather than 60–70 years or > 80 years. Conclusion: The altered MMN model exists in different aging stages and it’s a promising electrophysiological predictor of cognitive decline in older adults. In addition, further research is needed to determine the neural mechanisms and potential implications of the accelerated decline in MMN in older adults. Copyright © 2023 Yang, Tang, Lin, Jiang, Wei, Cao, Wan, Wang, Ding and Li.",auditory discrimination; brain aging; cognitive decline; mismatch negativity (MMN); sensory impairment,adult; aged; aging; Alzheimer disease; Article; auditory discrimination; auditory stimulation; behavior; cognition; cognitive defect; cognitive function test; community dwelling person; controlled study; depression; deterioration; electrocardiography; electroencephalogram; electroencephalography; electromyography; eye tracking; falling; female; Hamilton Depression Rating Scale; hearing impairment; human; hypertension; major clinical study; major depression; male; mental disease; micro-computed tomography; Mini Mental State Examination; mismatch negativity; Montreal cognitive assessment; multiple sclerosis; nuclear magnetic resonance imaging; social network; velocity; waist circumference,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85171897479,Movies / Media
Hamed R.; Rebello N.S.; Munsell J.,"Hamed, Razan (58688962700); Rebello, N. Sanjay (6602431152); Munsell, Jeremy (57206473203)",58688962700; 6602431152; 57206473203,Relating visual attention and learning in an online instructional physics module,2023,Physics Education Research Conference Proceedings,,,,126,131,5.0,1,10.1119/perc.2023.pr.Hamed,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176341113&doi=10.1119%2fperc.2023.pr.Hamed&partnerID=40&md5=eefaf8f6250c731f6f821e70364e3d4b,"Learning using Computer-Assisted Instruction (CAI) demands a high level of attention given the tendency to be distracted and mind-wander. How does the online STEM instructor know when learners are having attentional problems and the extent to which these problems affect learning? In the present study, the visual attentional and cognitive state of physics graduate students were probed while they went through a multimedia instructional module to refresh their knowledge of Newton’s II Law. Data from an eye tracker, webcam, egocentric glasses, screen recording, and mouse and keyboard events were integrated to record learners’ attention overt attention to the learning environment (+/-) and thinking about learning content (+/-) to analyze students’ attention spans during learning from this module. On average, learners were found to be on-task and on-screen for a vast majority of time, with evidence of mind wandering. The learning module improved the participants efficiency with which they answered the questions correctly on a post-test relative to the pre-test. Further, there is a positive albeit statistically non-significant correlation between the improvement from pre-to post-test efficiency and the time spent on-screen and on-task during the module. © 2023, American Association of Physics Teachers. All rights reserved.",,,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85176341113,Movies / Media
,,,"11th Ibero-American Conference on Applications and Usability of Interactive Digital Television, jAUTI 2022",2023,Communications in Computer and Information Science,1820 CCIS,,,,,160.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175993475&partnerID=40&md5=d45e15712ea68e6fc29ca29a1439bba1,The proceedings contain 10 papers. The special focus in this conference is on Applications and Usability of Interactive Digital Television. The topics include: MNEMOSCOPE – A Model for Digital Co-creation and Visualization of Collective Memories; dynamic Configuration of Panoramic Virtual Tours; Personalized Notifications for the TV Ecosystem: Field Trial of an iTV Solution; combining Text-to-Speech Services with Conventional Voiceover for News Oralization; iTV to Connect Generations: A Field Trial of a Solution to Send Personalized Notifications; Encryption of Messages and Additional Information in Digital Terrestrial Television’s Transport Stream Using PSI/SI Tables; on Using a Microearthquake Recognition System for an Early Warning System at Cotopaxi Volcano; Using Eye Tracking to Map Attention in an EEG-Based Brainwave Graphic Visualization System.,,,Conference review,Final,,Scopus,2-s2.0-85175993475,Movies / Media
Krauze L.; Delesa-Velina M.; Pladere T.; Krumina G.,"Krauze, Linda (57222422296); Delesa-Velina, Mara (58221038900); Pladere, Tatjana (57192594259); Krumina, Gunta (12238899900)",57222422296; 58221038900; 57192594259; 12238899900,Why 2D layout in 3D images matters: evidence from visual search and eyetracking,2023,Journal of Eye Movement Research,16,1,4,,,,0,10.16910/JEMR.16.1.4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156157374&doi=10.16910%2fJEMR.16.1.4&partnerID=40&md5=0466e1ca1276f13e854ef62ab20c238b,"Precise perception of three-dimensional (3D) images is crucial for a rewarding experience when using novel displays. However, the capability of the human visual system to perceive binocular disparities varies across the visual field meaning that depth perception might be affected by the two-dimensional (2D) layout of items on the screen. Nevertheless, potential difficulties in perceiving 3D images during free viewing have received only a little attention so far, limiting opportunities to enhance visual effectiveness of information presentation. The aim of this study was to elucidate how the 2D layout of items in 3D images impacts visual search and distribution of maintaining attention based on the analysis of the viewer’s gaze. Participants were searching for a target which was projected one plane closer to the viewer compared to distractors on a multi-plane display. The 2D layout of items was manipulated by changing the item distance from the center of the display plane from 2° to 8°. As a result, the targets were identified correctly when the items were displayed close to the center of the display plane, however, the number of errors grew with an increase in distance. Moreover, correct responses were given more often when subjects paid more attention to targets compared to other items on the screen. However, a more balanced distribution of attention over time across all items was characteristic of the incorrectly completed trials. Thus, our results suggest that items should be displayed close to each other in a 2D layout to facilitate precise perception of 3D images and considering distribution of attention maintenance based on eye-tracking might be useful in the objective assessment of user experience for novel displays © This article is licensed under a Creative Commons Attribution 4.0 International license",2D layout; 3D image; area of interest; binocular disparity; depth perception; gaze distribution; item distance,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85156157374,Movies / Media
Taib A.; Partridge G.; Darker I.; Phillips P.; Chen Y.,"Taib, Adnan (56906969100); Partridge, George (57740057500); Darker, Iain (24070033000); Phillips, Peter (57201566625); Chen, Yan (23396192500)",56906969100; 57740057500; 24070033000; 57201566625; 23396192500,Identifying and preventing fatigue in digital breast tomosynthesis,2023,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,12467,,1246707,,,,0,10.1117/12.2654936,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160913363&doi=10.1117%2f12.2654936&partnerID=40&md5=29bc84cc6d8d3e6414bec43f9f5469e2,"Digital Breast Tomosynthesis (DBT) increases breast cancer detection rates but produces a significantly greater number of images for screeners to read compared to traditional two-dimensional (2-D) mammograms. Putting screeners at risk of fatigue and therefore error in detecting cancers. The aim of this study was to explore if screeners showed differences in subjective fatigue, blink metrics and diagnostic accuracy during a DBT reading session with and without breaks. Prospective study including 45 participants from 6 different hospital sites around England between December 2020 to April 2022. Non-intrusive, screen mounted eye tracking cameras (60Hz sampling rate) were set up in the participant's natural reading environment. Forty DBT cases were read in a random order (47.5% malignant, 12.5% benign, 40% normal). Each breast was rated as normal or benign (return to screen) or indeterminate, suspicious or highly suspicious (recall). Twenty-one participants had a break at approximately 40 minutes into the session. Participants without a break showed a significantly greater difference in subjective fatigue before and after the reporting session (44% vs 33%, p=0.037). Furthermore, those without breaks exhibited significantly greater blinks per minute (15.75 vs 13.25, p<0.001) and blink duration (milliseconds) (296 vs 286, p<0.001). There was no significant difference in overall accuracy between the cohorts (p=0.921). Blink metrics have the potential to be used in identifying early onset of fatigue during reading sessions. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Diagnostic Accuracy; Digital Breast Tomosynthesis; Error; Fatigue,Diagnosis; Eye tracking; Medical imaging; Tomography; Breast cancer detection; Detection rates; Diagnostic accuracy; Digital breast tomosynthesis; England; Eye-tracking; Metric accuracy; Non-intrusive; Prospective study; Two Dimensional (2 D); Diseases,Conference paper,Final,,Scopus,2-s2.0-85160913363,Movies / Media
Pi Z.; Yang J.; Zhang X.,"Pi, Zhongling (56704731200); Yang, Jiumin (35797803600); Zhang, Xinjing (57278910800)",56704731200; 35797803600; 57278910800,Learning Analytics to Unveil Design and Learning Strategies in Video Lectures,2023,Designing Technology-Mediated Case Learning in Higher Education: A Global Perspective,,,,141,156,15.0,0,10.1007/978-981-19-5135-0_9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152346538&doi=10.1007%2f978-981-19-5135-0_9&partnerID=40&md5=05e9538cf2750675c95beaf7fe3df995,"How to effectively learn from video lectures has attracted much attention from researchers and educators. Many attempts have been made to apply design principles in creating video lectures that will maximize learning. Relatively little attention has been paid to the learning strategies students use when watching video lectures. Our studies found that learners learn better when an instructor used pointing gestures and continuous gaze guidance; they also learn better when the instructor used direct gaze with a happy facial expression. Furthermore, learners learn better when they were not exposed to others’ messages during viewing video lectures and engaged into explaining to oneself and a peer after viewing short video lectures. The main findings suggest that whether learners can effectively learn from video lectures depends on both video lectures design and their learning strategies. Our findings are discussed in terms of potential application in courses using video lectures. © Springer Nature Singapore Pte Ltd. 2022.",EEG oscillations; Eye-tracking technology; Learning strategies; Video lectures,,Book chapter,Final,,Scopus,2-s2.0-85152346538,Movies / Media
Jin P.; Ji Z.; Wang T.; Zhu X.,"Jin, Peng (57218920140); Ji, Zheqi (58706546100); Wang, Tianyi (58706103800); Zhu, Xiaomin (58705957700)",57218920140; 58706546100; 58706103800; 58705957700,Association between sports expertise and visual attention in male and female soccer players,2023,PeerJ,11,,e16286,,,,5,10.7717/peerj.16286,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177547517&doi=10.7717%2fpeerj.16286&partnerID=40&md5=5e8e795080a8ece39d2d1e6825f70649,"Background. Visual attention plays a crucial role in daily living and in sports, affecting an athlete's performance and thus, potentially, the outcome of a match. However, studies assessing the association between the level of sports expertise and visual attention have yielded mixed results. This study was conducted to examine whether visual attention could be developed with increased sports expertise, and whether visual attention differed between male athletes and female athletes. Methods. A total of 128 participants were included in this study: 64 first-level national soccer athletes recruited from college soccer teams (considered elite athletes; 32 men and 32 women with similar soccer performance requirements and training experience), and 64 physical education college students with limited soccer experience (considered novice athletes; 32 men and 32 women with matched soccer experience). To assess visual attention, we used a multiple object tracking (MOT) task with four targets among a total of 10 objects moving at a fixed speed of 10_/s in random directions across a computer monitor screen. Tracking accuracy on the MOT task was calculated for each participant as the proportion of correctly selected targets. A univariate analysis of variance was performed, with group (expert, novice) and sex (male, female) as independent variables, and tracking accuracy on the MOT task as the dependent variable to assess whether sports expertise or sex influenced visual attention. Simple effects tests followed by comparisons with Bonferroni corrections were used, and effect size calculations were performed using Cohen's f statistic. Results. Tracking accuracy on the MOT task was significantly affected by sports expertise (F(1,124) D 91.732, p < 0.001, _P 2 D 0.425), with accuracy among expert soccer athletes superior to that among novice soccer athletes. Moreover, a statistically significant interaction between sports expertise and sex was detected (F(1,124) D 7.046, p D 0.009, _P 2 D 0.054). Better tracking performance was observed for male soccer players (mean [SD], 0.39 [0.12]) than for female soccer players (mean [SD], 0.27 [0.08]); p<0:01; dD1.17; r D0:51) but only in the novice group. No significant sex difference was detected in tracking performance between elite male soccer athletes (mean [SD], 0.51 [0.09]) and elite female soccer athletes (mean [SD], 0.49 [0.11]). Conclusion. These findings confirm previous results indicating that long-term exten- sive sports training develops visual attention as assessed by MOT performance and extend previous findings to include soccer athletes. The findings of a sex difference in visual attention among novice soccer players but not among elite soccer athletes who had similar performance requirements and training experience suggest that long-term extensive training may minimize the sex difference in visual attention.  © 2023 Jin et al.",Expertise; Multiple object tracking; Sex difference; Soccer player; Visual attention,Article; eye tracking; female; human; human experiment; male; normal human; physical education; sex difference; soccer player; visual attention; visual feedback; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85177547517,Movies / Media
Ferdosi B.J.; Rahman M.; Sakib A.M.; Helaly T.,"Ferdosi, B.J. (36727490700); Rahman, M. (57706339100); Sakib, A.M. (58803789900); Helaly, T. (57220812125)",36727490700; 57706339100; 58803789900; 57220812125,Modeling and Classification of the Behavioral Patterns of Students Participating in Online Examination,2023,Human Behavior and Emerging Technologies,2023,,2613802,,,,2,10.1155/2023/2613802,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181909968&doi=10.1155%2f2023%2f2613802&partnerID=40&md5=a122cfe9ba1287c7fd9bcf7647175da0,"Online education has become an essential part of the modern education system, but keeping the integrity of the online examination remains a challenge. A significant increase in cheating in online examinations (from 29.9% before COVID-19 to 54.7% during COVID-19, as per a recent survey) points out the necessity of online exam proctoring systems. Traditionally, educational institutes utilize different questions in onsite exams: multiple-choice questions (MCQs), analytical questions, descriptive questions, etc. For online exams, form-based exams using MCQs are popular though in disciplines like math, engineering, architecture, art, or other courses, paper and pen tests are typical for proper assessment. In form-based exams, students' attention is toward display devices, and cheating behavior is identified as the deviation of head and eye gaze direction from the display device. In paper- and pen-based exams, students' main attention is on the answer script not on the device. Identifying cheating behavior in such exams is not a trivial task since complex body movements need to be observed to identify cheating. Previous research works focused on the deviation of the head and eyes from the screen which is more suited for form-based exams. Most of them are very resource-intensive; along with a webcam, they require additional hardware such as sensors, microphones, and security cameras. In this work, we propose an automated proctoring solution for paper- and pen-based online exams considering specific requirements of pen-and-paper exams. Our approach tracks head and eye orientations and lip movements in each frame and defines the movement as the change of orientation. We relate cheating with frequent coordinated movements of the head, eyes, and lips. We calculate a cheating score indicative of the frequency of movements. A case is marked as a cheating case if the cheating score is higher than the proctor-defined threshold (which may vary depending on the specific requirement of the discipline). The proposed system has five major parts: (1) identification and coordinate extraction of selected facial landmarks using MediaPipe; (2) orientation classification of the head, eye, and lips with K-NN classifier, based on the landmarks; (3) identification of abnormal movements; (4) calculation of a cheating score based on abnormal movement patterns; and (5) a visual representation of students' behavior to support the proctor for early intervention. Our system is robust since it observes the pattern of movement over a sequence of frames and considers the coordinated movement pattern of the head, eye, and lips rather than considering a single deviation as a cheating behavior which will minimize the false positive cases. Visualization of the student behavior is another strength of our system that enables the human proctor to take preventive measures rather than punishing the student for the final cheating score. We collected video data with the help of 16 student volunteers from the authors' university who participated in the two well-instructed mock exams: one with cheating and another without cheating. We achieved 100% accuracy in detecting noncheating cases and 87.5% accuracy for cheating cases when the threshold was set to 40.  © 2023 B. J. Ferdosi et al.",,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85181909968,Movies / Media
Aldossari M.; Zhang D.,"Aldossari, Marran (57202051351); Zhang, Dongsong (10042379000)",57202051351; 10042379000,D&L: A Natural Language Processing-Based Approach for Protecting Sensitive Information from Shoulder-Surfing Attacks,2023,"29th Annual Americas Conference on Information Systems, AMCIS 2023",,,,,,,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192946201&partnerID=40&md5=5cd532507cfeb8393e5655ee0dfa317e,"Despite the increasing attention and research effort, how to protect sensitive information from shoulder surfing attacks is still under studied. Existing methods for protecting sensitive textual content on users' screens from shoulder surfing attacks have various limitations, including ineffectiveness, insufficient protection of sensitive information, low usability, and high cognitive workload. To address those limitations, this paper proposes, develops, and evaluates a new solution called ""detection and labeling"" (D&L), which uses NLP techniques to automatically detect and label sensitive information in the textual content. The labeled and hidden sensitive information is then read to users through their headphones upon their clicking a label. Evaluation results demonstrate that D&L improves protection, enhances usability, reduces users’ cognitive workload, and allows faster browsing speed compared to the baseline methods. © 2023 29th Annual Americas Conference on Information Systems, AMCIS 2023. All rights reserved.",detection; labeling (D&L); Privacy; sensitive information protection; shoulder surfing,"Information use; Natural language processing systems; Cognitive workloads; Detection; Labeling (detection and labeling""); Labelings; Privacy; Sensitive information protections; Sensitive informations; Shoulder surfing; Textual content; Information systems",Conference paper,Final,,Scopus,2-s2.0-85192946201,Movies / Media
Tian B.; Rao L.; Xu W.; Cheng W.,"Tian, Bowen (57609648600); Rao, Long (58679002700); Xu, Wei (57199721022); Cheng, Wenqing (9334361500)",57609648600; 58679002700; 57199721022; 9334361500,Audio-Driven Gaze Estimation for MOOC Video,2023,"2023 6th International Conference on Big Data and Artificial Intelligence, BDAI 2023",,,,118,123,5.0,0,10.1109/BDAI59165.2023.10256826,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175649374&doi=10.1109%2fBDAI59165.2023.10256826&partnerID=40&md5=85df6059451e1956cb0c147a38e36a34,"Gaze estimation, which refers to predicting the gaze direction of human eyes, is essential in users state awareness and human attention estimation. Most existing methods only use the images of eyes or faces to obtain a good result, which is not enough in some teaching scenarios. In order to be more in line with the teaching scenarios, some additional information could have been used to correct the gaze model predictions, including the video and audio content viewed by the user. Therefore, we propose a new dataset, denoted as MOOCGaze dataset, which includes time-synchronized screen recordings, the corresponding audio, user-facing camera views, and eye gaze data. We also select a state-of-the-art model to obtain the initial Point-of-Gaze and introduce the RefineNet with an audio-video modality fusion scheme to correct the prediction results. Our final method yields significant improvements on our MOOCGaze dataset, with 26.1% improvement in the prediction of eye direction (resulting in 1.947 degrees in angular error).  © 2023 IEEE.",computer vision dataset; education; gaze estimation; multimodal representation learning,Forecasting; Attention estimations; Computer vision dataset; Gaze direction; Gaze estimation; Human attention; Human eye; Model prediction; Multi-modal; Multimodal representation learning; Video contents; Computer vision,Conference paper,Final,,Scopus,2-s2.0-85175649374,Movies / Media
Zhang Q.; Yu Z.,"Zhang, Qinghong (58192573400); Yu, Zhonggen (35975507500)",58192573400; 35975507500,A Bibliographic Review and Meta-Analysis of the Effect of Teaching Behaviors on Learners' Performance in Videotaped Lectures,2023,Education Research International,2023,,9292513,,,,1,10.1155/2023/9292513,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153175875&doi=10.1155%2f2023%2f9292513&partnerID=40&md5=fd1e4f88e275a831bb6b3e92da69ae92,"Although the discussion about the influence of the instructor-present videos has become a hot issue in recent years, the potential moderators on the effectiveness of an on-screen instructor have not been thoroughly synthesized. The present review systematically retrieves 47 empirical studies on how the instructors' behaviors moderated online education quality as measured by learning performance via a bibliographic study using VOSviewer and meta-analysis using Stata/MP 14.0. The bibliographic networks illustrate instructors' eye gaze, gestures, and facial expressions attract more researchers' attention. The meta-analysis results further reveal that better learning performance can be realized by integrating the instructor's gestures, eye guidance, and expressive faces with their speech in video lectures. Future studies can further explore the impact of instructors' other characteristics on learning perception and visual attention including voice, gender, age, etc. The underlying neural mechanism should also be considered via more objective technologies.  © 2023 Qinghong Zhang and Zhonggen Yu.",,,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85153175875,Movies / Media
Yoshida A.; Fujino H.; Yamamoto T.; Ishii A.; Mohri I.; Okuno H.,"Yoshida, Ayaka (58558658400); Fujino, Haruo (56065490900); Yamamoto, Tomoka (55561973800); Ishii, Atsuko (57216683967); Mohri, Ikuko (6602234195); Okuno, Hiroko (35786370000)",58558658400; 56065490900; 55561973800; 57216683967; 6602234195; 35786370000,Eye gaze and cerebral blood flow activation while watching social movies in children with autism spectrum disorder,2022,Journal of Brain Science,51,,,47,76,29.0,0,10.20821/jbs.51.0_47,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169433726&doi=10.20821%2fjbs.51.0_47&partnerID=40&md5=f24107adec427bdec46d1cb3f3030fc3,"Children with autism spectrum disorder (ASD) have difficulties with social cognition compared to neurotypical children. Several studies have suggested that eye gaze abnormalities characterize social cognition deficits in children with ASD, and are related to specific differences in their brain activity. To examine the characteristics of perception of social situations, we compared eye gaze, cerebral blood flow, and the understanding of the social communication movies in Japanese children with and without ASD. The participants included 20 children with ASD, 18 children without ASD, and 16 adults without ASD. Their eye gaze and cerebral blood flow responses while watching the stimuli from four social communication situations movies were measured using an eye-tracker and functional near-infrared spectroscopy. We compared the differences in social cognitive abilities between children groups using Mann–Whitney's U tests. There were no significant differences between the two groups with respect to language tasks, gaze values, or changes in cerebral blood flow after Bonferroni correction. No statistically significant correlations were observed between the variables. Further research is required to characterize behavioral and cerebral activation towards social stimuli in children with ASD. © 2022 Japan Brain Science Society. All rights reserved.",autism spectrum disorder; communication; eye movements; eye-tracking; natural scene; near-infrared spectroscopy; social interaction,adult; Article; autism; brain blood flow; child; clinical article; comprehension; controlled study; eye tracking; female; functional near-infrared spectroscopy; gaze; human; Japanese (people); language test; male; perception; social cognition; social interaction; television viewing; verbal communication,Article,Final,,Scopus,2-s2.0-85169433726,Movies / Media
Cha G.-E.; Jo W.; Min B.-C.,"Cha, Go-Eum (57219691264); Jo, Wonse (56152510500); Min, Byung-Cheol (39161762500)",57219691264; 56152510500; 39161762500,"Implications of Personality on Cognitive Workload, Affect, and Task Performance in Remote Robot Control",2023,IEEE International Conference on Intelligent Robots and Systems,,,,4153,4160,7.0,2,10.1109/IROS55552.2023.10341633,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182524255&doi=10.1109%2fIROS55552.2023.10341633&partnerID=40&md5=20e9c534c3d1033316dda61067290081,"This paper explores how the personality traits of robot operators can influence their task performance during remote control of robots. It is essential to explore the impact of personal dispositions on information processing, both directly and indirectly, when working with robots on specific tasks. To investigate this relationship, we utilize the open-access multi-modal dataset MOCAS to examine the robot operator's personality traits, affect, cognitive load, and task performance. Our objective is to confirm if personality traits have a total effect, including both direct and indirect effects, that could significantly impact the performance levels of operators. Specifically, we examine the relationship between personality traits such as extroversion, conscientiousness, and agreeableness, and task performance. We conduct a correlation analysis between cognitive load, self-ratings of workload and affect, and quantified individual personality traits along with their experimental scores. The findings show that personality traits do not have a total effect on task performance. A supplementary video can be accessed at: https://youtu.be/h3XUtVn7nzg. © 2023 IEEE.",,Robots; Cognitive loads; Cognitive task; Cognitive workloads; Personality traits; Remote robot; Robot operators; Robots control; Specific tasks; Task performance; Total effect; Remote control,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85182524255,Movies / Media
Gu Y.; Zhang C.; Ma F.; Jia X.; Ni S.,"Gu, Yating (57227020200); Zhang, Chi (58742697000); Ma, Fei (57206483659); Jia, Xiaojian (36113524100); Ni, Shiguang (55908625400)",57227020200; 58742697000; 57206483659; 36113524100; 55908625400,AI-Driven Depression Detection Algorithms from Visual and Audio Cues,2023,"Proceedings - 2023 3rd International Conference on Frontiers of Electronics, Information and Computation Technologies, ICFEICT 2023",,,,468,475,7.0,2,10.1109/ICFEICT59519.2023.00083,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172115234&doi=10.1109%2fICFEICT59519.2023.00083&partnerID=40&md5=6253e091fbbd98677a99b06af2440992,"Depression is a widespread psychiatric disorder, however, its outpatient rate remains low in many countries. To address the limitations of current depression screening methods, this study develops computer-aided algorithms for detecting depressive symptoms using a standardized depression detection dataset collected from hospitals. This study analyzes visual and audio cues of depression patients and healthy controls. Facial behavior is evaluated with a combination of visual features, including facial landmarks, action units, and eye gaze direction extracted from video frames, while verbal expressions are analyzed through a set of distinct features, such as the Mel Spectral Cepstral Coefficient (MFCC), loudness, and fundamental frequency (F0). These features are utilized to train models including random forest (RF), convolutional neural network (CNN), and recurrent neural network (RNN). Further, this paper proposes an attention-based multimodal fusion network using BiLSTM for feature representations and multi-head attention for visual-audio feature fusion. This paper achieves an F1 score of 0.8761, 0.7943, and 0.9278 for visual, audio, and visual-audio modality, respectively. By extracting easily interpretable features based on the characteristics and markers of patients with depression and applying AI algorithms, this study demonstrates the potential of AI-driven depression detection methods.  © 2023 IEEE.",artificial intelligence; audio analysis; computer vision; depression detection,Convolutional neural networks; Diagnosis; Recurrent neural networks; Signal detection; 'current; Audio analysis; Audio cues; Computer-aided; Depression detection; Depressive symptom; Detection algorithm; Psychiatric disorders; Screening methods; Visual cues; Computer vision,Conference paper,Final,,Scopus,2-s2.0-85172115234,Movies / Media
Alam M.; Alam M.S.; Siddique S.O.; Hasan N.; Hasan Tajwar M.M.; Rahman M.K.; Rahman M.,"Alam, Mahmud (59038578400); Alam, M. Shafiul (59039352900); Siddique, Saadman Omar (58942461300); Hasan, Nabil (58942543500); Hasan Tajwar, M.M. (58942267700); Rahman, Md. Khalilur (59662941300); Rahman, Mashiur (59041986100)",59038578400; 59039352900; 58942461300; 58942543500; 58942267700; 59662941300; 59041986100,Quantifying Attention Levels in Individualized Online Tutoring: A Case of One-an-One Sessions,2023,"2023 International Conference on Computational Intelligence, Networks and Security, ICCINS 2023",,,,,,,0,10.1109/ICCINS58907.2023.10450078,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187956848&doi=10.1109%2fICCINS58907.2023.10450078&partnerID=40&md5=3f4734d4debe023d7b5e0ef381895528,"After the COVID-19 pandemic, the worldwide reliance and shift towards video communication platforms have highlighted the importance of virtual learning. One major challenge in this aspect is determining the actual engagement of students during virtual sessions. To address this challenge, we present a research study that focuses on developing a system that will help evaluate participant's attentiveness in one-on-one online sessions. We propose a system that will utilize screen sharing detection, face recognition, head pose estimation, and eye gaze estimation to analyze a recorded tutoring session which will help an expert to assess the attention level of both the student and the tutor. It will provide educators valuable insights to optimize their teaching methods and adapt their strategies to boost the participation of students. As the popularity and demand of the global e-learning market continue to grow, systems such as ours can contribute to making online learning more efficient in both educational and corporate training sectors. © 2023 IEEE.",Attention; Engagement; Eye Gaze Estimation; Face Recognition; Head Position Estimation; Screen Sharing Detection; Video Communication Platform,COVID-19; E-learning; Online systems; Students; Attention; Communication platforms; Engagement; Eye gaze estimation; Eye-gaze; Gaze estimation; Head position; Head position estimation; Position estimation; Screen sharing; Screen sharing detection; Video communication platform; Video communications; Face recognition,Conference paper,Final,,Scopus,2-s2.0-85187956848,Movies / Media
Choi K.; Schlesinger M.A.; Franchak J.M.; Richert R.A.,"Choi, Koeun (57188555765); Schlesinger, Molly A. (57188652827); Franchak, John M. (36096593400); Richert, Rebekah A. (7005027946)",57188555765; 57188652827; 36096593400; 7005027946,Preschoolers’ attention to and learning from on-screen characters that vary by effort and efficiency: An eye-tracking study,2022,Frontiers in Psychology,13,,1011172,,,,1,10.3389/fpsyg.2022.1011172,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145044790&doi=10.3389%2ffpsyg.2022.1011172&partnerID=40&md5=60ace8fc56262d1e0c98e81480b3e625,"Prior findings are mixed regarding the extent to which children understand others’ effort in early childhood. Especially, little is known about how character effort impacts children’s selective attention and learning. This study examined preschoolers’ visual attention to and learning from two on-screen characters: One character exerting high effort with low efficiency and another character exerting low effort with high efficiency in solving problems successfully. Children between 3.5 and 6.5 years of age (N = 70) watched a video of the two on-screen characters successfully solving problems. Children’s eye movements were recorded during viewing. Each of the two on-screen characters consistently displayed either high effort/low efficiency or low effort/high efficiency to solve four problems (familiarization). For the final problem (testing), the two characters exerted the same level of effort as each other and used unique solutions to solve the problem. Children then solved the final problem themselves using real objects. Children could selectively use either character’s solution demonstrated in the video. Lastly, children explicitly judged how good the characters were at solving problems. Younger children were more likely to use the solution demonstrated by the character with high effort/low efficiency, whereas older children were more likely to use the solution provided by another character with low effort/high efficiency. Younger children allocated more attention to the high effort/low efficiency character than the low effort/high efficiency character, but this pattern was modified by age such that children’s gaze to the low effort/high efficiency character increased with age. Children’s explicit credibility judgments did not differ by character or child age. The findings are discussed with respect to preschoolers’ understanding of effort and implications for children’s learning from screen media. Copyright © 2022 Choi, Schlesinger, Franchak and Richert.",efficiency; effort; eye-tracking; media characters; selective social learning; visual attention,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85145044790,Movies / Media
Trbovich A.M.; Mucha A.; Eagle S.; Mehmel B.M.; Kegel N.; Sumrok V.F.; Collins M.W.; Kontos A.P.,"Trbovich, Alicia M. (57210572049); Mucha, Anne (36554720000); Eagle, Shawn (57192279814); Mehmel, Bindal Makwana (57990556500); Kegel, Nathan (36621029100); Sumrok, Vanessa Fazio (57218260296); Collins, Michael W. (35557667100); Kontos, Anthony P. (7004528698)",57210572049; 36554720000; 57192279814; 57990556500; 36621029100; 57218260296; 35557667100; 7004528698,The Vestibular/Ocular Motor Screening-Child (VOMS-C) tool for concussion evaluation in 5- to 9-year-old pediatric patients: preliminary evidence,2022,Journal of Neurosurgery: Pediatrics,30,6,,609,615,6.0,6,10.3171/2022.8.PEDS22234,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143198153&doi=10.3171%2f2022.8.PEDS22234&partnerID=40&md5=26412dc56a71d71afe328092b474aa86,"OBJECTIVE Vestibular and ocular motor dysfunction occurs in an estimated 60%-90% of concussion patients. The Vestibular/Ocular Motor Screening (VOMS) tool is validated for use in concussion patients older than 9 years. The goal of the current study was to adapt the current VOMS tool for a pediatric sample of children aged 5-9 years and establish its clinical utility in this patient population. METHODS In this case-control study, 80 symptomatic concussion patients (n = 33 [41%] female) aged 5-9 years (mean age 7.40 ± 1.09 years) and 40 (n = 18 [45%] female) age- and sex-matched uninjured controls (mean age 7.10 ± 1.26 years) completed the VOMS-Child (VOMS-C), a version of the VOMS adapted for younger patients. Differences in binary “yes” or “no” symptom provocation for headache, dizziness, and nausea/“tummy ache” across the 7 items of the VOMS-C, and near point of convergence (NPC) distance, were examined. Logistic regression (LR) models were built to classify concussion and controls. Predicted probabilities were generated from the LR model and entered into receiver operating characteristic (ROC) curve models to generate area under the curve (AUC) values. RESULTS VOMS-C item provocation ranged from 13% to 30% for concussed patients and 3% to 20% for controls. The LR model distinguished concussed participants from controls (R2 = 0.39; p < 0.001), with significant predictors being smooth pursuits, family depression history, and NPC distance. The ROC analysis had an AUC of 0.81 (95% CI 0.73-0.89; p < 0.001) in the good range. CONCLUSIONS Accurate diagnosis of concussion in the clinic setting requires comprehensive evaluation in multiple domains, including detailed clinical interview, neurocognitive testing, and vestibular/ocular motor assessment, regardless of patient age. Our results provide preliminary support for the VOMS-C as a developmentally appropriate tool for concussion management. © AANS 2022.",concussion; evaluation; screener; trauma; vestibular/ocular motor,"Athletic Injuries; Brain Concussion; Case-Control Studies; Child; Child, Preschool; Family; Female; Humans; Male; ROC Curve; anxiety; area under the curve; Article; attention deficit hyperactivity disorder; case control study; child; concussion; controlled study; depression; dizziness; false positive result; female; headache; human; intellectual impairment; learning disorder; major clinical study; male; medical history; migraine; motion sickness; motor dysfunction; motor dysfunction assessment; nausea; oculomotor nerve; outcome assessment; outpatient department; positivity rate; preschool child; provocation; receiver operating characteristic; risk factor; school child; smooth pursuit eye movement; vestibular disorder; vestibular nerve; vestibular ocular motor screening; brain concussion; family; sport injury",Article,Final,,Scopus,2-s2.0-85143198153,Movies / Media
Eijk L.; Rasenberg M.; Arnese F.; Blokpoel M.; Dingemanse M.; Doeller C.F.; Ernestus M.; Holler J.; Milivojevic B.; Özyürek A.; Pouw W.; van Rooij I.; Schriefers H.; Toni I.; Trujillo J.; Bögels S.,"Eijk, Lotte (57218953682); Rasenberg, Marlou (57209248983); Arnese, Flavia (57963042700); Blokpoel, Mark (54419526900); Dingemanse, Mark (25932093600); Doeller, Christian F. (6507122603); Ernestus, Mirjam (6506503027); Holler, Judith (22979583800); Milivojevic, Branka (8108694300); Özyürek, Asli (55967715400); Pouw, Wim (55251734900); van Rooij, Iris (6701840447); Schriefers, Herbert (7005461750); Toni, Ivan (6603768534); Trujillo, James (56517680800); Bögels, Sara (36019807300)",57218953682; 57209248983; 57963042700; 54419526900; 25932093600; 6507122603; 6506503027; 22979583800; 8108694300; 55967715400; 55251734900; 6701840447; 7005461750; 6603768534; 56517680800; 36019807300,The CABB dataset: A multimodal corpus of communicative interactions for behavioural and neural analyses,2022,NeuroImage,264,,119734,,,,11,10.1016/j.neuroimage.2022.119734,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141780012&doi=10.1016%2fj.neuroimage.2022.119734&partnerID=40&md5=dc5dfb0c4d8ad11fa6dc2cebbde3a01d,"We present a dataset of behavioural and fMRI observations acquired in the context of humans involved in multimodal referential communication. The dataset contains audio/video and motion-tracking recordings of face-to-face, task-based communicative interactions in Dutch, as well as behavioural and neural correlates of participants’ representations of dialogue referents. Seventy-one pairs of unacquainted participants performed two interleaved interactional tasks in which they described and located 16 novel geometrical objects (i.e., Fribbles) yielding spontaneous interactions of about one hour. We share high-quality video (from three cameras), audio (from head-mounted microphones), and motion-tracking (Kinect) data, as well as speech transcripts of the interactions. Before and after engaging in the face-to-face communicative interactions, participants’ individual representations of the 16 Fribbles were estimated. Behaviourally, participants provided a written description (one to three words) for each Fribble and positioned them along 29 independent conceptual dimensions (e.g., rounded, human, audible). Neurally, fMRI signal evoked by each Fribble was measured during a one-back working-memory task. To enable functional hyperalignment across participants, the dataset also includes fMRI measurements obtained during visual presentation of eight animated movies (35 min total). We present analyses for the various types of data demonstrating their quality and consistency with earlier research. Besides high-resolution multimodal interactional data, this dataset includes different correlates of communicative referents, obtained before and after face-to-face dialogue, allowing for novel investigations into the relation between communicative behaviours and the representational space shared by communicators. This unique combination of data can be used for research in neuroscience, psychology, linguistics, and beyond. © 2022",Conceptual alignment; Face-to-face interaction; fMRI; Motion tracking; Multimodal data; Referential communication,Communication; Humans; Language; Linguistics; Magnetic Resonance Imaging; Speech; glutamate sodium; adult; algorithm; aphasia; Article; behavioral science; brain surgery; clinical article; cognition; electroencephalogram; electroencephalography; emotionality; eye tracking; fatigue; female; functional magnetic resonance imaging; genetic transcription; head movement; human; human experiment; information storage; interpersonal communication; kinematics; language ability; Likert scale; linguistics; major clinical study; male; neuroscience; normal human; nuclear magnetic resonance imaging; pulse wave; speech; stimulus; task performance; videorecording; visual stimulation; white matter; working memory; interpersonal communication; language; linguistics; physiology; speech,Article,Final,,Scopus,2-s2.0-85141780012,Movies / Media
Zhang J.; Li Z.; Wu Y.; Ye A.Y.; Chen L.; Yang X.; Wu Q.; Wei L.,"Zhang, Jie (57204269060); Li, Ziyi (59291080500); Wu, Yige (57992518300); Ye, Adam Yongxin (56385241800); Chen, Lei (57992682400); Yang, Xiaoxu (56456763600); Wu, Qixi (56402182000); Wei, Liping (7402950829)",57204269060; 59291080500; 57992518300; 56385241800; 57992682400; 56456763600; 56402182000; 7402950829,RJAfinder: An automated tool for quantification of responding to joint attention behaviors in autism spectrum disorder using eye tracking data,2022,Frontiers in Neuroscience,16,,915464,,,,6,10.3389/fnins.2022.915464,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143340968&doi=10.3389%2ffnins.2022.915464&partnerID=40&md5=5a3b51ec4387606d68dd9ac74fdebf93,"Deficits in responding to joint attention (RJA) are early symptoms of autism spectrum disorder (ASD). Currently, no automated tools exist for identifying and quantifying RJA behaviors. A few eye tracking studies have investigated RJA in ASD children but have produced conflicting results. In addition, little is known about the trajectory of RJA development through developmental age. Here, a new video was designed including 12 clips of an actor pointing to or looking at an object. Eye tracking technology was used to monitor RJA in three groups: 143 ASD children assessed with the Autism Diagnostic Interview-Revised (ADI-R) and the Autism Diagnostic Observation Schedule (ADOS) (4–7 years old), 113 age- and gender-matched typically developing children (TDC), and 43 typically developing adults (TDA) (19–32 years old). RJAfinder was developed in R and MATLAB to quantify RJA events from the eye tracking data. RJA events were compared among the three groups. Spearman correlation coefficients between total number of RJA events in ASD and the Social Responsiveness Scale (SRS) scores were calculated. A logistic regression model was built using the average valid sampling rate and the total number of RJA events as two predictive variables to classify ASD and TDC groups. ASD children displayed statistically significantly less RJA events than the TDC and TDA groups with medium-to-large-sized effects. ASD and TDC children both displayed more RJA events in response to pointing stimuli than to looking stimuli. Our logistic regression model predicted ASD tendency with 0.76 accuracy in the testing set. RJA ability improved more slowly between the ages of 4–7 years old in the ASD group than in the TDC group. In ASD children, RJA ability showed negative correlation with SRS total T-score as well as the scores of five subdomains. Our study provides an automated tool for quantifying RJA and insights for the study of RJA in ASD children, which may help improve ASD screening, subtyping, and behavior interventions. Copyright © 2022 Zhang, Li, Wu, Ye, Chen, Yang, Wu and Wei.",autism spectrum disorder; automated tool; behavior assessment; eye tracking; joint attention,Article; autism; Autism Diagnostic Interview Revised; Autism Diagnostic Observation Schedule; child; controlled study; effect size; eye tracking; female; human; major clinical study; male; nervous system parameters; screening test; Social Responsiveness Scale; stimulus response,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85143340968,Movies / Media
Naples A.J.; Foss-Feig J.H.; Wolf J.M.; Srihari V.H.; McPartland J.C.,"Naples, Adam J. (15751541600); Foss-Feig, Jennifer H. (21742643000); Wolf, Julie M. (7403565218); Srihari, Vinod H. (13408378900); McPartland, James C. (7005050670)",15751541600; 21742643000; 7403565218; 13408378900; 7005050670,Predictability modulates neural response to eye contact in ASD,2022,Molecular Autism,13,1,42,,,,4,10.1186/s13229-022-00519-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141004744&doi=10.1186%2fs13229-022-00519-0&partnerID=40&md5=b4e2bbc27c46f434a750e2e1eb006fb8,"Background: Deficits in establishing and maintaining eye-contact are early and persistent vulnerabilities of autism spectrum disorder (ASD), and the neural bases of these deficits remain elusive. A promising hypothesis is that social features of autism may reflect difficulties in making predictions about the social world under conditions of uncertainty. However, no research in ASD has examined how predictability impacts the neural processing of eye-contact in naturalistic interpersonal interactions. Method: We used eye tracking to facilitate an interactive social simulation wherein onscreen faces would establish eye-contact when the participant looked at them. In Experiment One, receipt of eye-contact was unpredictable; in Experiment Two, receipt of eye-contact was predictable. Neural response to eye-contact was measured via the N170 and P300 event-related potentials (ERPs). Experiment One included 23 ASD and 46 typically developing (TD) adult participants. Experiment Two included 25 ASD and 43 TD adult participants. Results: When receipt of eye-contact was unpredictable, individuals with ASD showed increased N170 and increased, but non-specific, P300 responses. The magnitude of the N170 responses correlated with measures of sensory and anxiety symptomology, such that increased response to eye-contact was associated with increased symptomology. However, when receipt of eye-contact was predictable, individuals with ASD, relative to controls, exhibited slower N170s and no differences in the amplitude of N170 or P300. Limitations: Our ASD sample was composed of adults with IQ > 70 and included only four autistic women. Thus, further research is needed to evaluate how these results generalize across the spectrum of age, sex, and cognitive ability. Additionally, as analyses were exploratory, some findings failed to survive false-discovery rate adjustment. Conclusions: Neural response to eye-contact in ASD ranged from attenuated to hypersensitive depending on the predictability of the social context. These findings suggest that the vulnerabilities in eye-contact during social interactions in ASD may arise from differences in anticipation and expectation of eye-contact in addition to the perception of gaze alone. © 2022, The Author(s).",Autism; ERP; Eye tracking; N170; P300; Social neuroscience,Adult; Autism Spectrum Disorder; Autistic Disorder; Female; Humans; Interpersonal Relations; Nonverbal Communication; adult; anticipation; anxiety; Article; autism; clinical article; cognition; controlled study; event related potential; expectation; exploratory research; eye tracking; false discovery rate; female; gaze; human; intelligence quotient; male; nerve potential; perception; prediction; simulation; social environment; social interaction; symptomatology; vision; vulnerability; young adult; human relation; nonverbal communication,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85141004744,Movies / Media
Zhang X.; Manley C.E.; Micheletti S.; Tesic I.; Bennett C.R.; Fazzi E.M.; Merabet L.B.,"Zhang, Xin (57939877600); Manley, Claire E. (57877184300); Micheletti, Serena (41861930200); Tesic, Isidora (57939709300); Bennett, Christopher R. (55385456500); Fazzi, Elisa M. (7004236903); Merabet, Lotfi B. (6603146795)",57939877600; 57877184300; 41861930200; 57939709300; 55385456500; 7004236903; 6603146795,Assessing visuospatial processing in cerebral visual impairment using a novel and naturalistic static visual search task,2022,Research in Developmental Disabilities,131,,104364,,,,20,10.1016/j.ridd.2022.104364,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140433534&doi=10.1016%2fj.ridd.2022.104364&partnerID=40&md5=a231cc7d2af37241ba5e7d981a86eb65,"Background: Cerebral visual impairment (CVI) is a brain based visual disorder associated with the maldevelopment of central visual pathways. Individuals with CVI often report difficulties finding a target of interest in cluttered and crowded visual scenes. However, it remains unknown how manipulating task demands and other environmental factors influence visual search performance in this population. Aim: We developed a novel and naturalistic virtual reality (VR) based static visual search task combined with eye tracking called the “virtual toy box” to objectively assess visual search performance in CVI. Methods and procedures: A total of 38 individuals with CVI (mean age 13.18 years ± 3.58 SD) and 53 controls with neurotypical development (mean age 15.25 years ± 5.72 SD) participated in the study. In a first experiment, study subjects were instructed to search for a preselected toy presented among a varying number of surrounding distractor toys (set size ranging from 1 to 36 items). In a second experiment, we assessed the effects of manipulating item spacing and the size of the visual area explored (field of view; FOV). Outcomes and results: Behavioral outcomes collected were success rate, reaction time, gaze error, visual search area, and off-screen percent (an index of task compliance). Compared to age-matched controls, participants with CVI showed an overall impairment with respect to all the visual search outcomes of interest. Specifically, individuals with CVI were less likely and took longer to find the target, and search patterns were less accurate and precise compared to controls. Visual search response profiles were also comparatively less efficient and were associated with a slower initial pre-search (visual orienting) response as indexed by higher slope and intercept values derived from the analysis of reaction time × set size functions. Search performance was also more negatively affected in CVI at the smallest as well as largest spacing conditions tested, while increasing FOV was associated with greater decreased gaze accuracy and precision Conclusions and implications: These results are consistent with a general profile of impaired visual search abilities in CVI as well as worsening performance with increased visual task demands and an overall sensitivity to visual clutter and crowding. The observed profile of impaired visual search performance may be associated with dysfunctions related to how visual selective attention is deployed in individuals with CVI. © 2022 Elsevier Ltd",Attention; Cerebral visual impairment (CVI); Eye tracking; Visual perception; Visual processing deficits; Visual search,Adolescent; Attention; Brain; Humans; Reaction Time; Vision Disorders; accuracy; adolescent; adult; age; Article; behavior; cerebral blindness; child; clinical article; clinical assessment; cohort analysis; controlled study; depth perception; eye disease assessment; eye tracking; female; gaze; human; male; outcome assessment; reaction time; selective attention; static visual search task; virtual reality; visual attention; visual field; visual orientation; visual stimulation; attention; brain; visual disorder,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85140433534,Movies / Media
Chukwuorji J.C.; Allard E.S.,"Chukwuorji, JohnBosco Chika (56072105100); Allard, Eric S. (25921839800)",56072105100; 25921839800,The Age-Related Positivity Effect and Emotion Regulation: Assessing Downstream Affective Outcomes,2022,International Journal of Aging and Human Development,95,4,,455,469,14.0,4,10.1177/00914150221077954,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124913172&doi=10.1177%2f00914150221077954&partnerID=40&md5=5db68c26974fa7e8d8a6fb63e822e9a4,"While substantial literature suggests that positive preferences are in the service of emotion regulation pursuits, little evidence has directly linked positivity “processes” with well-being “outcomes.” The current study examined age-related differences in negative gaze preferences and how such preferences are related to subsequent regulatory outcomes. Participants were 79 older adults and 72 younger adults. They first provided a baseline mood assessment, which was followed by a standardized emotional video clip for three minutes during which visual fixation preferences were recorded via an eye tracker. Mood was again assessed after the film, which was followed by a standardized video recovery task, and completion of a recovery mood measure. Older adults fixated less on negative portions of the emotional video clip relative to younger adults, indicative of an age-related positivity effect. The indirect effect of age on mood recovery through fixation was not supported. © The Author(s) 2022.",adult development; attention; emotion regulation; eye tracking; socio-emotional selectivity theory,"Affect; Aged; Attention; Emotional Regulation; Emotions; Fixation, Ocular; Humans; affect; aged; attention; emotion; eye fixation; human; physiology",Article,Final,,Scopus,2-s2.0-85124913172,Movies / Media
Fang Y.; Ni G.; Gao F.; Zhang Q.; Niu M.; Ding Z.,"Fang, Yaqi (57474779100); Ni, Guodong (36572278000); Gao, Fengling (57964583000); Zhang, Qi (59447386500); Niu, Miaomiao (57960123000); Ding, Zhihua (47960938700)",57474779100; 36572278000; 57964583000; 59447386500; 57960123000; 47960938700,Influencing Mechanism of Safety Sign Features on Visual Attention of Construction Workers: A Study Based on Eye-Tracking Technology,2022,Buildings,12,11,1883,,,,10,10.3390/buildings12111883,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141864678&doi=10.3390%2fbuildings12111883&partnerID=40&md5=fe2523d8037bb91a7f11eacc80a5640f,"Visual attention of construction workers is closely related to their safety performance. Identifying and understanding safety signs on workplace effectively is beneficial to improve visual attention. This study focuses on exploring the influencing mechanism of construction safety sign features on visual attention of construction workers using the eye-tracking technology, in order to improve visual attention and workplace safety performance through optimizing the construction safety signs. A theoretical model of influencing mechanism of safety sign features on visual attention was constructed based on visual information processing theory. To verify the theoretical model, an experiment was conducted as follows: 28 pictures of safety signs including visual and cognitive features were shown on the computer screen, then eye movement data from 41 subjects was obtained using EyeLink1000 Plus. Statistical test methods were employed to analyze the relationship between safety sign features and eye-tracking metrics. The statistical results of theoretical model indicate that, among visual features, red and rectangular safety signs can reduce cognitive load of first fixation, green signs can reduce cognitive difficulties, however visual attention is not closely related to auxiliary words. Among the cognitive features, unfamiliar signs require more cognitive effort, while no significant difference exists in visual attention of different levels of concreteness and sematic closeness. This study provides theoretical and practical basis for improving construction workers’ visual attention through optimizing visual and cognitive features of construction safety signs. © 2022 by the authors.",cognitive features; construction safety signs; construction workers; eye-tracking technology; visual attention; visual features; visual information processing,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85141864678,Movies / Media
Gernert J.A.; Zimmermann H.; Oswald E.; Christmann T.; Kümpfel T.; Havla J.,"Gernert, J.A. (57208036347); Zimmermann, H. (57192430399); Oswald, E. (57226090758); Christmann, T. (57385505300); Kümpfel, T. (6603530927); Havla, J. (25824253800)",57208036347; 57192430399; 57226090758; 57385505300; 6603530927; 25824253800,Clinical onset of CNS demyelinating disease after COVID-19 vaccination: denovo disease?,2022,Multiple Sclerosis and Related Disorders,67,,104175,,,,4,10.1016/j.msard.2022.104175,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138081180&doi=10.1016%2fj.msard.2022.104175&partnerID=40&md5=521e55e1df6f3aa6a2ea6a2d8dcca689,"Background: Clinical onset of multiple sclerosis (MSpostvacc) and myelin-oligodendrocyte-glycoprotein-antibody-associated disease (MOGADpostvacc) has been reported in association with SARS-CoV-2-vaccination. There is uncertainty as to whether this is causality (denovo disease) or temporal coincidence (manifestation of a preexisting, subclinical neuroinflammation). Objectives: Comparing the clinical characteristics of MSpostvacc-patients versus patients with MS (PwMS) whose clinical onset occurred independently of vaccination (MSreference). Methods: Consecutive patients with clinical onset ≤30 days after SARS-CoV-2-vaccination were included. Clinical data, cerebrospinal fluid (CSF) parameters and magnetic resonance imaging (MRI) as well as optical coherence tomography (OCT) data were compared to an age- and sex-matched MSreference-cohort. Results: We identified 5 MSpostvacc and 1 MOGADpostvacc patients who developed their clinical onset ≤ 30 days after SARS-CoV-2-vaccination. Clinical characteristics, CSF, MRI and OCT parameters from MSpostvacc patients were comparable to the MSreference cohort and showed evidence of preexisting subclinical CNS disease. The single case with MOGADpostvacc clearly differed from PwMS in higher CSF cell counts, remission of MRI lesions during follow-up, and absence of oligoclonal bands. Conclusions: Our case series indicates that MSpostvacc patients showed a rather typical initial manifestation in temporal association with SARS-CoV-2-vaccination and harbored preexisting subclinical neuroinflammation. This argues against the denovo development of MS in this cohort. © 2022",Demyelinating disease; Multiple Sclerosis (MS); Myelin oligodendrocyte glycoprotein antibody-related disease (MOGAD); SARS-CoV-2- (COVID-19) vaccination,Autoantibodies; COVID-19; COVID-19 Vaccines; Demyelinating Diseases; Humans; Multiple Sclerosis; SARS-CoV-2; Vaccination; albumin; chadox1; immunoglobulin A; immunoglobulin G; immunoglobulin M; oligoclonal band; tozinameran; vaxzevria; autoantibody; adult; Article; bladder dysfunction; case report; central nervous system disease; cerebrospinal fluid analysis; cerebrospinal fluid cytology; clinical article; cohort analysis; controlled study; coronavirus disease 2019; demyelinating disease; depression; diplopia; Expanded Disability Status Scale; eye movement disorder; fatigue; female; follow up; headache; human; malaise; male; multiple sclerosis; nervous system inflammation; nuclear magnetic resonance imaging; optic neuritis; optical coherence tomography; paresthesia; pleocytosis; relapsing remitting multiple sclerosis; retinal inner plexiform layer; retinal nerve fiber layer thickness; vaccination; adverse event; cerebrospinal fluid; complication; diagnostic imaging; prevention and control; vaccination,Article,Final,,Scopus,2-s2.0-85138081180,Movies / Media
Donuk K.; Ari A.; Hanbay D.,"Donuk, Kenan (57207452614); Ari, Ali (56463872400); Hanbay, Davut (15834365300)",57207452614; 56463872400; 15834365300,A CNN based real-time eye tracker for web mining applications,2022,Multimedia Tools and Applications,81,27,,39103,39120,17.0,13,10.1007/s11042-022-13085-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128909145&doi=10.1007%2fs11042-022-13085-7&partnerID=40&md5=3c975006986992d89d183563e6594c26,"Eye gaze tracking is an increasingly important technology in the field of human-computer interaction. Individuals’ preferences, tendencies, and attention can be measured by processing the data obtained from face and eye images. This technology is used in advertising, market research, web page design, education, learning methods, and various neurological-psychiatric studies of medical research. Many different methods have been used in eye gaze tracking tasks. Today, commonly model-shape and appearance-based methods are used. Model-shape based methods require less workload than appearance-based methods. But it is more sensitive to environmental conditions. Appearance-based methods require powerful hardware, but they are less susceptible to environmental conditions. Developments in technology have paved the way for applying appearance-based models in eye gaze tracking. In this paper, a CNN-based real-time eye tracking system was designed to overcome environmental problems in eye gaze tracking. The designed system is used to determine the areas of interest of the user in web pages. The performance of the designed CNN-based system is evaluated during the training and testing phases. In the training phase, the difference between the desired and determined points on the screen is 32 pixels and in testing phase, the difference between the desired and determined points on the screen is 53 pixels. The results of the test trials have shown that the proposed system could be used successfully in eye tracking studies on web pages. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",CNNs; Deep learning; Eye gaze tracking; Web data mining,Data handling; Data mining; Deep learning; Eye tracking; Human computer interaction; Market Research; Websites; Appearance-based methods; Deep learning; Environmental conditions; Eye gaze tracking; Real- time; Shape based; Testing phase; Training phasis; Web data mining; Web-page; Pixels,Article,Final,,Scopus,2-s2.0-85128909145,Movies / Media
Da Silva T.H.C.T.; Cavalcanti M.D.; De Sá F.M.F.; Marinho I.N.; Cavalcanti D.D.Q.; Becker V.,"Da Silva, Thiago Henrique Coelho Tavares (57926153000); Cavalcanti, Matheus Dantas (57773369000); De Sá, Felipe Melo Feliciano (57773196100); Marinho, Isaac Nóbrega (57926600700); Cavalcanti, Daniel De Queiroz (57925998900); Becker, Valdecir (56372303300)",57926153000; 57773369000; 57773196100; 57926600700; 57925998900; 56372303300,Visualization of brainwaves using EEG to map emotions with eye tracking to identify attention in audiovisual workpieces,2022,ACM International Conference Proceeding Series,,,,381,389,8.0,2,10.1145/3539637.3557055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139789498&doi=10.1145%2f3539637.3557055&partnerID=40&md5=4edb4cde55be3b23d8415bb5ff5dbf6e,"This article describes a brainwave visualization system using EEG and Eye Tracking in order to map the emotional relationship of individuals with audiovisual workpieces, especially attention and taste. Using the Design Science Research method, the artifact was specified, implemented and tested with 10 subjects, using a horror movie trailer. A preliminary and a post-Test questionnaire was presented to the participants. The results indicate patterns of emotional identification with the film, which can be interpreted as an inclination to watch the film in movie theaters or a repulsion to the theme/genre of the film. In conclusion, this research points to an advance in evaluation of audiovisual workpieces, contemplating unconscious emotional elements of subjective perceptions about the watched content.  © 2022 ACM.",Brain-Computer Interfaces; EEG; emotions; Eye Tracking; Human-Computer interaction,Behavioral research; Eye movements; Eye tracking; Visualization; Brain wave; Design-science researches; Emotion; Eye-tracking; Post test; Research method; Subjective perceptions; Visualization system; Workpiece; Brain computer interface,Conference paper,Final,,Scopus,2-s2.0-85139789498,Movies / Media
Polzer L.; Freitag C.M.; Bast N.,"Polzer, Leonie (57212460992); Freitag, Christine M. (7003868143); Bast, Nico (57200231841)",57212460992; 7003868143; 57200231841,Pupillometric measures of altered stimulus-evoked locus coeruleus-norepinephrine activity explain attenuated social attention in preschoolers with autism spectrum disorder,2022,Autism Research,15,11,,2167,2180,13.0,11,10.1002/aur.2818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138198053&doi=10.1002%2faur.2818&partnerID=40&md5=4a05bbed3f683b3a2b4ac8eb28193b4f,"Attenuated social attention has been described as a reduced preference for social compared to geometric motion in preschoolers with autism spectrum disorder (ASD). The locus coeruleus-norpinephrine (LC-NE) system modulates sensory reactivity and is a promising underlying mechanism. LC-NE activity is indexed by a stimulus-evoked pupillary response (SEPR) and partially by a luminance-adaptation pupillary response (LAPR), which were both shown to be aberrant in ASD. We examined whether SEPR and LAPR explain an attenuated social motion preference. We applied pupillometry via video-based eye tracking in young children (18–65 months) with ASD (n = 57) and typically developing (TD) children (n = 39) during a preferential looking paradigm of competing social and geometric motion and a changing light condition paradigm. We found an attenuated social motion preference in the ASD compared to the TD group. This was accompanied by atypical pupillometry showing a smaller SEPR to social motion, a larger SEPR to geometric motion and a reduced LAPR to a dark screen. SEPR but not LAPR explained the group difference in social motion preference. An ASD diagnosis was statistically predicted by the social motion preference, while this effect was mediated by the inclusion of SEPR to geometric and social motion. Our findings suggest a decreased sensory reactivity to social and increased reactivity to non-social motion in ASD, which may concurrently contribute to an attenuated social attention. The LC-NE system is supported as a promising underlying mechanism of altered social attention in young children with ASD, while the specificity of findings remains to be addressed. © 2022 The Authors. Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.",attention; child; eye-tracking technology; locus coeruleus; preschool; pupil,"Attention; Autism Spectrum Disorder; Child; Child, Preschool; Humans; Locus Coeruleus; Norepinephrine; Pupil; noradrenalin; noradrenalin; Article; attention; autism; Autism Diagnostic Observation Schedule; brain depth stimulation; child; controlled study; empirical research; eye tracking; female; gaze; human; locus ceruleus; luminance; luminance adaptation pupillary response; major clinical study; male; motion; preschool child; pupil; pupillometry; Social Responsiveness Scale; stimulus evoked pupillary response; visual evoked potential; attention; locus ceruleus; physiology",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85138198053,Movies / Media
Grynszpan O.; Bouteiller J.; Grynszpan S.; Martin J.-C.; Nadel J.,"Grynszpan, Ouriel (22034481500); Bouteiller, Julie (57211385295); Grynszpan, Séverine (57211384555); Martin, Jean-Claude (55727532000); Nadel, Jacqueline (56357082600)",22034481500; 57211385295; 57211384555; 55727532000; 56357082600,Social gaze training for Autism Spectrum Disorder using eye-tracking and virtual humans,2022,Interaction Studies,23,1,,89,115,26.0,3,10.1075/is.21022.gry,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140976918&doi=10.1075%2fis.21022.gry&partnerID=40&md5=e13bf39df81f34862f79a414a27523a2,"Background: Individuals with Autism Spectrum Disorder (ASD) have pronounced difficulties in attending to relevant visual information during social interactions. Method: We designed and evaluated the feasibility of a novel method to train this ability, by exposing participants to virtual human characters displayed on a screen which was entirely blurred, except for a gaze-contingent viewing window that followed participants’ eyes direction. The goal was to incite participants to direct their gaze towards the facial expressions of the virtual characters. Twenty-one adolescents with ASD who attended ordinary school were randomized to either an experimental group, who was trained during a month and a half, or to a control group. Social communicative abilities were assessed during pre, post and follow-up tests. Results: After training, the experimental group showed significantly more interest in facial expressions on a test which involved understanding a dialogue. Significant differences were not found for the other tests used. Conclusions: This outcome suggests that the training method fostered participants’ awareness of the relevance of facial expressions. © John Benjamins Publishing Company.",Autism; Eye-tracking; Gaze-contingent; Social cognition; Training,,Article,Final,,Scopus,2-s2.0-85140976918,Movies / Media
Gerlofs D.J.; Roberts K.H.; Anderson N.C.; Kingstone A.,"Gerlofs, D. Jacob (57222281181); Roberts, Kevin H. (57192588534); Anderson, Nicola C. (50461074200); Kingstone, Alan (7006826868)",57222281181; 57192588534; 50461074200; 7006826868,Eye spy: Gaze communication and deception during hide-and-seek,2022,Cognition,227,,105209,,,,0,10.1016/j.cognition.2022.105209,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132899806&doi=10.1016%2fj.cognition.2022.105209&partnerID=40&md5=380a278226d76c2db5b5387f78209cfc,"Gaze behaviour is an important component of successful social interactions. Existing research on social gaze and attention has largely focused on gaze detection and following, rather than the two-way communicative component of gaze that operates between individuals. The present study sought to address this in two experiments. First, “hiders” were eye-tracked while they selected hiding places among a grid of boxes on a computer screen; these boxes were either homogeneous or contained a visually unique pop-out item. Importantly, sometimes hiders believed that their gaze would be seen by hypothetical “seekers” who they might wish to deceive or communicate truthful information to; and sometime hiders believed that their gaze would be concealed. In a second experiment, seekers were asked to select the hiders' locations after viewing the hiders' gaze behaviour, including the eye movements that hiders had been (falsely) told would be concealed. Results indicate that seekers are most accurate when hiders use their gaze to truthfully communicate their selected locations and least accurate when hiders aim to deceive. Notably, both communication and interpretation strategies were affected by the visual display type (e.g., hiders looked to and preferentially selected pop-out items when communicating truthfully while seekers interpreted gaze differently when allocated to these pop-out items), indicating that the visual context can be integrated with gaze to facilitate mis/communication. Our study illuminates how the gaze of an individual acquires and signals information, and that individuals will spontaneously adjust the balance between these two functions based on their current goal and visual environment. © 2022 Elsevier B.V.",Cognition; Eye movements; Perspective taking; Social attention; Theory of mind,"Attention; Communication; Deception; Eye Movements; Fixation, Ocular; Humans; adult; Article; behavior control; comparative study; deception; eye tracking; female; game; gaze; head movement; human; information; interpersonal communication; latent period; male; saccadic eye movement; self concept; social interaction; spatiotemporal analysis; attention; deception; eye fixation; eye movement",Article,Final,,Scopus,2-s2.0-85132899806,Movies / Media
van Marlen T.; van Wermeskerken M.; Jarodzka H.; Raijmakers M.; van Gog T.,"van Marlen, Tim (57191630222); van Wermeskerken, Margot (26434933600); Jarodzka, Halszka (26321686500); Raijmakers, Maartje (7004134241); van Gog, Tamara (56779822700)",57191630222; 26434933600; 26321686500; 7004134241; 56779822700,Looking through Sherlock's eyes: Effects of eye movement modelling examples with and without verbal explanations on deductive reasoning,2022,Journal of Computer Assisted Learning,38,5,,1497,1506,9.0,7,10.1111/jcal.12712,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135036540&doi=10.1111%2fjcal.12712&partnerID=40&md5=744ab3e05fd987055acd6601f3a846c3,"Background: Eye movement modelling examples (EMME) are demonstrations in which learners' not only see a model's (e.g., a teacher's) task performance on a computer screen (as in regular video examples) but also the model's eye movements (represented as moving coloured dots overlaid on the screen). Thereby EMME help guide learners' attention towards the relevant information and can model cognitive strategies which are otherwise unobservable for learners. Objectives: This study investigated whether EMME can help to learn deductive reasoning strategies and how the presence/absence of a teacher's verbal explanation affects learning from EMME. Methods: Secondary education students (N = 137) were randomly assigned to study video examples under one of four conditions in a 2 (EMME: yes/no) x 2 (verbal explanations: yes/no) between-subjects design. Results and Conclusions: Results revealed only a beneficial effect of the presence of verbal explanations on performance on the practice problems, but no pretest-to-posttest learning gains. Implications: Seeing the teacher's eye movements does not appear to enhance learning of deductive reasoning. The presence/absence of the teacher's verbal explanation does not seem to affect learning deductive reasoning. © 2022 John Wiley & Sons Ltd.",attention cueing; example-based learning; eye movement modelling examples; eye tracking,,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85135036540,Movies / Media
Barrett R.C.A.; Poe R.; O’Camb J.W.; Woodruff C.; Harrison S.M.; Dolguikh K.; Chuong C.; Klassen A.D.; Zhang R.; Joseph R.B.; Blair M.R.,"Barrett, Robin Colin Alexander (57195065710); Poe, Rollin (57216635915); O’Camb, Justin William (57930054900); Woodruff, Cal (57216632526); Harrison, Scott Marcus (57216633401); Dolguikh, Katerina (57216634971); Chuong, Christine (57917651800); Klassen, Amanda Dawn (57917633800); Zhang, Ruilin (57216635351); Joseph, Rohan Ben (57917633900); Blair, Mark Randall (7102440319)",57195065710; 57216635915; 57930054900; 57216632526; 57216633401; 57216634971; 57917651800; 57917633800; 57216635351; 57917633900; 7102440319,"Comparing virtual reality, desktop-based 3D, and 2D versions of a category learning experiment",2022,PLoS ONE,17,10-Oct,e0275119,,,,31,10.1371/journal.pone.0275119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139376588&doi=10.1371%2fjournal.pone.0275119&partnerID=40&md5=e7d2ead0753d21ad275eaee5183b249b,"Virtual reality (VR) has seen increasing application in cognitive psychology in recent years. There is some debate about the impact of VR on both learning outcomes and on patterns of information access behaviors. In this study we compare performance on a category learning task between three groups: one presented with three-dimensional (3D) stimuli while immersed in the HTC Vive VR system (n = 26), another presented with the same 3D stimuli while using a flat-screen desktop computer (n = 26), and a third presented with a two-dimensional projection of the stimuli on a desktop computer while their eye movements were tracked (n = 8). In the VR and 3D conditions, features of the object to be categorized had to be revealed by rotating the object. In the eye tracking control condition (2D), all object features were visible, and participants’ gaze was tracked as they examined each feature. Over 240 trials we measured accuracy, reaction times, attentional optimization, time spent on feedback, fixation durations, and fixation counts for each participant as they learned to correctly categorize the stimuli. In the VR condition, participants had increased fixation counts compared to the 3D and 2D conditions. Reaction times for the 2D condition were significantly faster and fixation durations were lower compared to the VR and 3D conditions. We found no significant differences in learning accuracy between the VR, 3D, and 2D conditions. We discuss implications for both researchers interested in using VR to study cognition, and VR developers hoping to use non-VR research to guide their designs and applications. © 2022 Barrett et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Attention; Cognition; Humans; Learning; User-Computer Interface; Virtual Reality; accuracy; Article; behavior; category learning task; cognition assessment; cognitive processing therapy; cybersickness; eye movement; eye tracking; functional magnetic resonance imaging; gaze; information access behavior; learning; learning outcome; outcome variable; stimulation; stimulus; stimulus response; three-dimensional stimuli; two-dimensional stimuli; virtual reality; attention; cognition; computer interface; human,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85139376588,Movies / Media
Hartmann M.,"Hartmann, Matthias (55174904500)",55174904500,Summing up: A functional role of eye movements along the mental number line for arithmetic,2022,Acta Psychologica,230,,103770,,,,7,10.1016/j.actpsy.2022.103770,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140256576&doi=10.1016%2fj.actpsy.2022.103770&partnerID=40&md5=e0f3990f367658f0b99ca00734fc9493,"In Western cultures, small-left and large-right spatial-numerical associations are constantly found in various simple number processing tasks. It has recently been suggested that spatial associations are also involved in more complex number processing, for example that individuals make rightward or upward “mental” movements along the number line during addition, and leftward or downward movements during subtraction. In line with this, it has been shown that participants' spontaneous eye movements on a blank screen during upward and downward counting follow such associations. The present research investigated whether eye movements along the number line are simply an epiphenomenon of the recruitment of a spatial reference frame, or whether they play a functional role for the arithmetic computation. This question was addressed by using multi-step problems (e.g., 59 + 5 + 4 + 3) that show a larger proportion of computation (vs. retrieval) when compared to single-step problems (e.g., 59 + 5), as confirmed in Pretest 1. Moreover, the question was addressed only for addition problems and vertical eye movements, because spatial-arithmetic associations were not found in the other conditions (subtraction, horizontal eye movements) in Pretest 2. In the main experiment, participants (n = 29) solved addition problems while following a moving dot with their eyes (smooth pursuit) either in a congruent (upward) or incongruent (downward) direction, or while keeping their eyes fixated on to the center of the screen, or while moving their eyes freely on a blank screen. Arithmetic performance was faster in the congruent condition (upward eye movements) when compared to the other conditions (downward eye movements, central fixation, free viewing). These results suggest that vertical shifts in spatial attention along the mental number line are functionally involved in addition. The results support the view of shared mechanisms for directing spatial attention in external (visual) and representational (number space). Implications for embodied views of number processing are discussed. © 2022 The Author",Eye movements; SNARC; Spatial attention; Spatial-arithmetic associations,Attention; Eye Movements; Humans; Mathematics; Movement; attention; eye movement; human; mathematics; movement (physiology),Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85140256576,Movies / Media
Almeida N.L.; Silva J.B.S.; Oliveira M.E.C.; Fernandes T.P.; Santos N.A.,"Almeida, Natalia L. (57194206276); Silva, Jessica B. S. (57191251681); Oliveira, Milena E. C. (57219141408); Fernandes, Thiago P. (57193858482); Santos, Natanael A. (57201308822)",57194206276; 57191251681; 57219141408; 57193858482; 57201308822,Eye movement impairments in children with malnutrition,2022,International Journal of Psychology,57,5,,644,651,7.0,3,10.1002/ijop.12838,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126056316&doi=10.1002%2fijop.12838&partnerID=40&md5=097e165ee6848267b42fdb5376f18c39,"Malnutrition is characterised by deficient nutrient ingestion and absorption and is still one of the most important causes of morbidity and mortality in children worldwide. Our main rationale was that protein-energy malnutrition (PEM) may affect eye movement in children with malnutrition. Twenty children without PEM (mean age = 10.8; SD = 1.0 years) and 18 children with PEM (mean age = 10.9; SD = 1.2 years) were included in the present study. We applied three types of tests: one that consisted of a maze and two versions of the Spot the Seven Errors test using boats and elephants. Our results indicated that children with PEM exhibited performance deficits in the maze test (p <.001) and Spot the Seven Errors test for both boats (p <.001) and elephants (p <.001). These data suggest that nutritional impairments during the first year of life (i.e., a critical period) can directly impact eye movement. Eye tracking is a reliable technique to investigate higher-order processes, but our results should be interpreted with caution. Our findings highlight the relevance of cognitive development in malnourished children, which can negatively affect their development. Screening, assessment and rehabilitation strategies are essential in this at-risk population. © 2022 International Union of Psychological Science.",Cognition; Eye movement; Eye tracking; Malnutrition; Protein-energy malnutrition,Animals; Elephants; Eye Movements; Humans; Protein-Energy Malnutrition; animal; elephant; eye movement; human; protein calorie malnutrition,Article,Final,,Scopus,2-s2.0-85126056316,Movies / Media
Nair V.; Suchan J.; Bhatt M.; Hemeren P.,"Nair, Vipul (57218620747); Suchan, Jakob (55767093900); Bhatt, Mehul (8925250400); Hemeren, Paul (7801589389)",57218620747; 55767093900; 8925250400; 7801589389,Attentional synchrony in films: A window to visuospatial characterization of events,2022,Proceedings - SAP 2022: ACM Symposium on Applied Perception,,,8,,,,1,10.1145/3548814.3551466,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139425610&doi=10.1145%2f3548814.3551466&partnerID=40&md5=62f89a10b318b5d349e937d05c2d15fd,"The study of event perception emphasizes the importance of visuospatial attributes in everyday human activities and how they influence event segmentation, prediction and retrieval. Attending to these visuospatial attributes is the first step toward event understanding, and therefore correlating attentional measures to such attributes would help to further our understanding of event comprehension. In this study, we focus on attentional synchrony amongst other attentional measures and analyze select film scenes through the lens of a visuospatial event model. Here we present the first results of an in-depth multimodal (such as head-turn, hand-action etc.) visuospatial analysis of 10 movie scenes correlated with visual attention (eye-tracking 32 participants per scene). With the results, we tease apart event segments of high and low attentional synchrony and describe the distribution of attention in relation to the visuospatial features. This analysis gives us an indirect measure of attentional saliency for a scene with a particular visuospatial complexity, ultimately directing the attentional selection of the observers in a given context.  © 2022 Owner/Author.",Attention; Eye-tracking; Human-interaction; Visuoauditory cues,Behavioral research; Attention; Event model; Event segmentation; Eye-tracking; Human activities; Humaninteraction; Movie scenes; Multi-modal; Through the lens; Visuoauditory cue; Eye tracking,Conference paper,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85139425610,Movies / Media
Rutherford A.V.; Raila H.; Blicher A.; Vanderlind W.M.; Joormann J.,"Rutherford, Ashleigh V. (57205623824); Raila, Hannah (55552946600); Blicher, Andreas (33067619800); Vanderlind, W. Michael (55734522200); Joormann, Jutta (6602734156)",57205623824; 55552946600; 33067619800; 55734522200; 6602734156,Seeing Red: Distraction Influences Visual Attention for Anger but Not for Other Negative Emotions,2022,Emotion,23,5,,1224,1235,11.0,1,10.1037/emo0001136,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139279586&doi=10.1037%2femo0001136&partnerID=40&md5=2075b50b684beb2f0de3ccac92571aee,"Emotion regulation is a vital skill that improves psychological well-being and overall functioning. Distraction (the purposeful internal disengagement from an emotional stimulus) and cognitive reappraisal (the process of changing one’s thoughts about an emotional event/stimulus) are two well-established regulation strategies that can effectively decrease negative affect. Less understood, however, are the attention allocation strategies that occur when engaging in these emotion regulation strategies—specifically, do people visually scan emotional information differently when distracting vs. reappraising? In the current study, community participants were randomly assigned to either distract, reappraise, or view naturally while watching four emotional film clips that each elicited a different negative emotional state: anger, fear, sadness, and disgust. Eye tracking was used to record total time spent gazing (“dwell time”) at faces within the emotion-eliciting film clips. An effect of condition was found for anger-eliciting material only: participants in the distraction condition exhibited shorter dwell times compared with reappraisal and natural viewing. Importantly, this effect was moderated by state anxiety, such that it was found at low but not high levels of state anxiety. These results show that emotion regulation strategies differentially affect attention to emotion-eliciting stimuli and points to the role of current affective states in impacting how distraction is used. © 2022 American Psychological Association",anger; distraction; emotion regulation; eye-tracking; reappraisal,Anger; Anxiety; Cognition; Emotions; Fear; Humans; adult; anger; anxiety; article; attention; controlled study; disgust; dwell time; emotion; emotion regulation; eye tracking; fear; female; human; male; randomized controlled trial; sadness; visual attention; anger; cognition; physiology; psychology,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85139279586,Movies / Media
Marzi C.; Narzisi A.; Milone A.; Masi G.; Pirrelli V.,"Marzi, Claudia (36621334800); Narzisi, Antonio (43961521900); Milone, Annarita (7004113345); Masi, Gabriele (7005105897); Pirrelli, Vito (14833305800)",36621334800; 43961521900; 7004113345; 7005105897; 14833305800,Reading Behaviors through Patterns of Finger-Tracking in Italian Children with Autism Spectrum Disorder,2022,Brain Sciences,12,10,1316,,,,2,10.3390/brainsci12101316,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140654256&doi=10.3390%2fbrainsci12101316&partnerID=40&md5=8999a73178faf636eb66d3534ae2f551,"The paper proposes an ecological and portable protocol for the large-scale collection of reading data in high-functioning autism spectrum disorder (ASD) children based on recording the finger movements of a subject reading a text displayed on a tablet touchscreen. By capitalizing on recent evidence that movements of a finger that points to a scene or text during visual exploration or reading may approximate eye fixations, we focus on recognition of written content and function words, pace of reading, and accuracy in reading comprehension. The analysis showed significant differences between typically developing and ASD children, with the latter group exhibiting greater variation in levels of reading ability, slower developmental pace in reading speed, less accurate comprehension, greater dependency on word length and word frequency, less significant prediction-based processing, as well as a monotonous, steady reading pace with reduced attention to weak punctuation. Finger-tracking patterns provides evidence that ASD readers may fail to integrate single word processing into major syntactic structures and lends support to the hypothesis of an impaired use of contextual information to predict upcoming stimuli, suggesting that difficulties in perception may arise as difficulties in prediction. © 2022 by the authors.",autism; developing readers; finger-tracking; prediction-driven processing; reading,lamotrigine; valproic acid; aphasia; Article; Asperger syndrome; attention; attention deficit hyperactivity disorder; autism; behavior; binge eating disorder; child; cognitive defect; comprehension; data analysis; depth perception; electroencephalography; emotionality; eye fixation; eye tracking; female; finger tracking; human; hypothesis; karyotyping; male; perception; phobia; prediction; procedures; psychometry; questionnaire; reading; velocity; word processing; work environment,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85140654256,Movies / Media
Zhang J.; Liu W.; Guo Z.; Rong D.; Li J.; Xu P.,"Zhang, Jie (58396146700); Liu, Weiguo (57208760612); Guo, Zhiying (57567498000); Rong, Danyan (57211433150); Li, Jimin (59790599500); Xu, Pingyi (7202215735)",58396146700; 57208760612; 57567498000; 57211433150; 59790599500; 7202215735,Analysis of clinical features of mild motor symptoms in prodromal Parkinson′s disease; [帕金森病前驱期轻微运动症状临床特征分析],2022,Chinese Journal of Neurology,55,9,,960,967,7.0,0,10.3760/cma.j.cn113694-20220317-00204,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148304380&doi=10.3760%2fcma.j.cn113694-20220317-00204&partnerID=40&md5=fb44b5c8ada4d2c385ee88475a7161c5,"Objective To investigate the characteristics and evolution of mild motor symptoms (MMS) in patients with prodromal Parkinson′s disease (pPD). Methods Based on the pPD cohort screened by Parkinson′s Disease Prodromal Clinical Assessment Scale in Nanjing community from July 2018 to December 2020, the clinical data of 30 patients with pPD who completed the baseline assessment and were followed up for at least 1 year were analyzed. According to the Unified Parkinson Diease Rating Scale Ⅲ (UPDRS‐Ⅲ) score, the patients were divided into MMS group (UPDRS‐Ⅲ score>3) and non‐MMS group (NMMS group, UPDRS‐Ⅲ score≤ 3). The differences and evolution characteristics of clinical characteristics between the 2 groups were compared. Multivariate linear regression was used to analyze the risk factors of motor symptom progression in pPD patients. Results Among the 30 patients with pPD, 7 of 23 patients in the MMS group were converted to PD at the end of follow‐up, 1 of 7 patients in the NMMS group were converted to PD at the end of follow‐up. The UPDRS‐Ⅲ score [10.00 (7.00, 17.00)], Montreal Cognitive Assessment Scale (MoCA) score [25.50 (24.75, 28.00)] and the Hamilton Anxiety Scale (HAMA) score [9.00 (5.00, 13.00)] at the end of follow‐up of pPD patients were significantly higher than those at baseline [7.00 (4.00, 12.00), 24.00 (22.75, 25.25) and 8.00 (2.00, 11.00)], and the differences were statistically significant (Z=-3.505, P<0.001; Z=-2.956, P=0.003; Z=-2.427, P=0.015). Subgroup analysis showed that UPDRS‐Ⅲ score [11.00 (7.00, 18.00)], MoCA score [25.00 (24.00, 27.00)] and HAMA score [9.00 (6.00, 15.00)] at the end of follow‐up in the MMS group were higher than those at baseline [8.00 (6.00, 12.00), 24.00 (22.00, 25.00) and 9.00 (3.00, 11.00)], and the difference was statistically significant (Z=-2.768, P=0.006; Z=-2.457, P=0.014; Z=-2.250, P=0.024). The Non‐Motor Symptoms Questionnaire score at the end of follow‐up in the MMS group (8.96± 5.20) was significantly lower than that in the baseline (11.04±4.41), and the difference was statistically significant (t=2.441, P=0.023).There was no significant difference in Mini‐Mental State Examination (MMSE), Hamilton Depression Scale (HAMD), Rapid Eyes Movement Sleep Behavior Disorder Questionnaire‐Hong Kong (RBDQ‐HK) and Sniffin′ sticks olfactory test score at the end of follow‐up in the MMS group. Only UPDRS‐Ⅲ score in the NMMS group was increased at the end of follow‐up [7.00 (5.00, 8.00)] compared with the baseline [4.00 (1.00, 4.00)], and the difference was statistically significant (Z=-2.375, P=0.018). There was no significant difference in MoCA, MMSE, HAMA, HAMD, RBDQ‐HK, and Sniffin′ sticks olfactory test score between the NMMS group and the baseline at the end of follow‐up. Conclusion The clinical conversion rate of pPD patients with MMS is high,and screening of this population should be paid attention. © 2022 Authors. All rights reserved.",Mild motor symptoms; Non‐motor symptoms; Parkinson disease; Prodromal stage,Article; clinical article; clinical feature; clinical study; cohort analysis; controlled study; follow up; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; human; mental health; Montreal cognitive assessment; motor dysfunction; nonmotor symptoms questionnaire; Parkinson disease; parkinson disease prodromal clinical assessment scale; prodromal symptom; questionnaire; rapid eyes movement sleep behavior disorder questionnaire; risk factor; scoring system; sniffin sticks olfactory test; Unified Parkinson Disease Rating Scale; Unified Parkinson Disease Rating Scale iii,Article,Final,,Scopus,2-s2.0-85148304380,Movies / Media
Imaoka Y.; Hauri L.; Flury A.; de Bruin E.D.,"Imaoka, Yu (57219250601); Hauri, Laura (57222154102); Flury, Andri (57219253115); de Bruin, Eling D. (7004058816)",57219250601; 57222154102; 57219253115; 7004058816,Linking cognitive functioning and postural balance control through virtual reality environmental manipulations,2022,Frontiers in Aging Neuroscience,14,,954050,,,,5,10.3389/fnagi.2022.954050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138200572&doi=10.3389%2ffnagi.2022.954050&partnerID=40&md5=79172c41505b65e6ecc168a45f2d5ed0,"Background: Dementia is becoming a relevant problem worldwide. A simple screening at an early stage will be important to detect the risk of developing dementia. Vestibular dysfunction is likely to be associated with cognitive impairment. Since head-mounted display (HMD) virtual reality (VR) technology has the potential to activate the vestibular function, assessing postural sway with visual stimulation using HMD VR technology could be potentially useful for dementia screening. Objective: The purpose of this study is to evaluate the effect of HMD-based VR visual stimuli on posture in older adults and the relationship between the stimulated body sway behaviors and cognitive performance. Method: Using a cross-sectional study design, we investigated the effect of an optokinetic design-based room with stripes (OKR) VR environment oscillating forwards and backwards at 23/60Hz. Center of pressure (COP) displacement was measured in older adults aged 65 years and over in the OKR VR environment. The frequency response of COP was compared to the cognitive performance of the Montreal Cognitive Assessment (MoCA). Results: 20 healthy older adults (70.4 ± 4.9 years; 27.2 ± 1.6 MoCA score) and 3 people with mild cognitive impairment (74.7 ± 4.0 years; 20.3 ± 2.1 MoCA score) were assessed. The results reveal that the oscillating OKR VR environment induced different postural sway in the anterior-posterior direction in the real world. Correlation analysis shows that the cognitive test score was associated with the frequency response of stimulated postural sway in the anterior-posterior direction (frequency Band 1 of 0−0.5Hz related to the visual and vestibular systems: rs = 0.45, P = 0.03). Conclusion: Outcomes would suggest that a potential link may emerge between cognition and posture when the HMD-based VR visual stimuli are applied. The simple screening of stimulated postural sway could explain cognitive functioning. Further studies are warranted to clarify the vestibular system and spatial cognitive function more specifically in the proposed assessment system. Copyright © 2022 Imaoka, Hauri, Flury and de Bruin.",cognitive function; cognitive impairment; dementia; dual task; head-mounted display virtual reality technology; posture; saccade; vestibular,aged; Article; body equilibrium; body movement; clinical article; cognition; cohort analysis; controlled study; correlation analysis; cross-sectional study; dementia; disease association; eye tracking; female; human; male; mental performance; mild cognitive impairment; Montreal cognitive assessment; optokinetic stimulation; oscillation; proprioception; saccadic eye movement; spatial memory; vestibular disorder; vestibular function; vestibular system; virtual reality; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85138200572,Movies / Media
Nassif L.; Huntley E.; Mohamed A.,"Nassif, Lama (55786692600); Huntley, Elizabeth (57371317700); Mohamed, Ayman (57194398502)",55786692600; 57371317700; 57194398502,Attention to verbal morphology in L2 Arabic reading: An eye-movement study,2022,Foreign Language Annals,55,3,,769,792,23.0,4,10.1111/flan.12644,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135947077&doi=10.1111%2fflan.12644&partnerID=40&md5=2cfb05af1f913fefaaea93ab1a16b075,"Attention is believed to help facilitate learning. Godfroid and Uggen found that attention to irregular verb morphology motivated the learning of novel second language (L2) German forms. The current study explored the generalizability of these findings to geminate and sound verbs in Arabic, a typologically different language with a novel writing system. Eleven fourth-semester learners of Arabic participated in the experiment. Participants completed a language learning background survey, took a fill-in-the blank pretest, read 20 sentence pairs while an Eyelink 1000 recorded their eye movements, and answered true/false comprehension questions that appeared on-screen following each sentence. A posttest, identical to the pretest, and a prior vocabulary knowledge scale task were then conducted. Learners' reflections were recorded in a subsequent recall task and a follow-up semistructured interview. Descriptive analyses of the eye-tracking metrics reveal generally equivalent reading times between verb types, although participants made more direct visual comparisons between geminate- than between sound-verb conjugations. Participants did not report awareness of geminate verbs, but noticed other aspects of input, and, on average, improved their written productive knowledge by 2% after only one exposure. Pedagogical implications are discussed in terms of input enhancement in a communicative L2 classroom. © 2022 ACTFL.",acquisition of L2 verbal morphology; attention in L2 learning; L2 Arabic learning; L2 reading,,Article,Final,,Scopus,2-s2.0-85135947077,Movies / Media
Zhu H.; Salcudean S.; Rohling R.,"Zhu, Hongzhi (57208316327); Salcudean, Septimiu (7005922122); Rohling, Robert (7004322927)",57208316327; 7005922122; 7004322927,Gaze-Guided Class Activation Mapping: Leverage Human Visual Attention for Network Attention in Chest X-rays Classification,2022,ACM International Conference Proceeding Series,,,5,,,,0,10.1145/3554944.3554952,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142093447&doi=10.1145%2f3554944.3554952&partnerID=40&md5=fbc7fc0da6f4cf5b3eca103dd6d5cc61,"The attention mechanism in artificial neural networks is conceptually interlinked with human visual attention, and studies have shown that either artificial or human attention can facilitate computer vision tasks. However, little research has investigated the visual interpretation of neural network's attention with the help of human visual attention. This paper describes a novel eye gaze-guided class activation mapping (GG-CAM) method that augments deep convolutional neural network (CNN) attention with human attention for improved chest X-ray (CXR) pathology classification and CNN's visual interpretability. A loss function designed for attention supervision and an improved multi-task learning scheme are developed to achieve the primary classification task and the auxiliary attention supervision task. The GG-CAM is a generic and light-weight method, with only 3 additional trainable parameters, and can be applied to many classification CNNs. GG-CAM-modified CNNs do not require human attention as an input when fully trained. Experimental results show that GG-CAM modified ResNet50 and EfficientNetV2 (S) outperform state-of-the-art CNNs for CXR pathology classification, and demonstrate better visual interpretability on CNN's classification decisions. Code used for this paper is available at https://github.com/hz-zhu/GG-CAM.  © 2022 ACM.",Deep learning; Explainable artificial intelligence; Multitask learning; Network attention; Visual attention,Behavioral research; Chemical activation; Convolutional neural networks; Deep neural networks; Learning systems; Activation mapping; Attention mechanisms; Deep learning; Explainable artificial intelligence; Human attention; Human visual attention; Interpretability; Multitask learning; Network attention; Visual Attention; Mapping,Conference paper,Final,,Scopus,2-s2.0-85142093447,Movies / Media
Dou K.; Ma J.; Zhang X.; Shi W.; Tao M.; Xie A.,"Dou, Kaixin (57205238670); Ma, Jiangnan (57200938766); Zhang, Xue (57202589573); Shi, Wanda (57223255585); Tao, Mingzhu (57891661500); Xie, Anmu (36873744600)",57205238670; 57200938766; 57202589573; 57223255585; 57891661500; 36873744600,Multi-predictor modeling for predicting early Parkinson’s disease and non-motor symptoms progression,2022,Frontiers in Aging Neuroscience,14,,977985,,,,5,10.3389/fnagi.2022.977985,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138048282&doi=10.3389%2ffnagi.2022.977985&partnerID=40&md5=16f04083ac71fc8af1a407fe46617476,"Background: Identifying individuals with high-risk Parkinson’s disease (PD) at earlier stages is an urgent priority to delay disease onset and progression. In the present study, we aimed to develop and validate clinical risk models using non-motor predictors to distinguish between early PD and healthy individuals. In addition, we constructed prognostic models for predicting the progression of non-motor symptoms [cognitive impairment, Rapid-eye-movement sleep Behavior Disorder (RBD), and depression] in de novo PD patients at 5 years of follow-up. Methods: We retrieved the data from the Parkinson’s Progression Markers Initiative (PPMI) database. After a backward variable selection approach to identify predictors, logistic regression analyses were applied for diagnosis model construction, and cox proportional-hazards models were used to predict non-motor symptom progression. The predictive models were internally validated by correcting measures of predictive performance for “optimism” or overfitting with the bootstrap resampling approach. Results: For constructing diagnostic models, the final model reached a high accuracy with an area under the curve (AUC) of 0.93 (95% CI: 0.91–0.96), which included eight variables (age, gender, family history, University of Pennsylvania Smell Inventory Test score, Montreal Cognitive Assessment score, RBD Screening Questionnaire score, levels of cerebrospinal fluid α-synuclein, and SNCA rs356181 polymorphism). For the construction of prognostic models, our results showed that the AUC of the three prognostic models improved slightly with increasing follow-up time. The overall AUCs fluctuated around 0.70. The model validation established good discrimination and calibration for predicting PD onset and progression of non-motor symptoms. Conclusion: The findings of our study facilitate predicting the individual risk at an early stage based on the predictors derived from these models. These predictive models provide relatively reliable information to prevent PD onset and progression. However, future validation analysis is still needed to clarify these findings and provide more insight into the predictive models over more extended periods of disease progression in more diverse samples. Copyright © 2022 Dou, Ma, Zhang, Shi, Tao and Xie.",diagnosis; non-motor symptoms; Parkinson’s disease; predictive model; progression,alpha synuclein; dopamine; dopamine transporter; adult; area under the curve; Article; biochemical analysis; bootstrapping; bradykinesia; cerebrospinal fluid; cognition; controlled study; disease exacerbation; DNA polymorphism; female; Geriatric Depression Scale; hormone substitution; human; Impulsive Compulsive Disorders in Parkinson Disease score; major clinical study; male; middle aged; Montreal cognitive assessment; motor dysfunction; motor performance; multicenter study; Parkinson disease; predictive model; prospective study; RBD Screening Questionnaire score; rigidity; scoring system; sensitivity and specificity; tremor; Unified Parkinson Disease Rating Scale; University of Pennsylvania Smell Inventory Test score,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85138048282,Movies / Media
Kirsh I.,"Kirsh, Ilan (55268400400)",55268400400,Virtual Finger-Point Reading Behaviors: A Case Study of Mouse Cursor Movements on a Website,2022,Big Data Research,29,,100328,,,,4,10.1016/j.bdr.2022.100328,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133872483&doi=10.1016%2fj.bdr.2022.100328&partnerID=40&md5=9246897e265149433addb04271c8ec5b,"Web analytics has changed significantly in recent years. As part of the big data revolution, frequent low-level user actions, such as mouse movements and clicks, are often used in modern web analytics. Various studies show that when a user moves or clicks the mouse, the position of the mouse cursor is relatively close to the position of the eye gaze on the screen. Accordingly, mouse cursor positions can indicate user attention and interest in specific areas of web pages. This study focuses on mouse movement directions and speeds rather than on mouse cursor positions. A statistical analysis of mouse movements on an online learning website, which was selected for this study, sheds light on several interesting patterns. For example, most mouse movements in the examined usage data are either approximately horizontal or approximately vertical, and horizontal mouse movements are more frequent than vertical mouse movements. Besides, horizontal movements to the left are not equivalent to horizontal movements to the right, in terms of moving time and speed. As this study shows, these statistical findings are related to Pointer Assisted Reading (PAR), a reading behavior consisting of moving the mouse cursor (also known as the mouse pointer) along sentences, marking the reading position, similarly to finger-pointing when reading a book. Associating mouse movements with text reading may potentially highlight content that most users tend to skip, and therefore, might not interest the website's audience, as well as content that many readers read more than once or slowly, suggesting a lack of clarity or ambiguity. As discussed in this paper, this could be useful in locating issues in the textual content of websites and especially in online learning and educational technology applications. © 2022 Elsevier Inc.",Big data analysis; Mouse cursor; Online learning; Pointer Assisted Reading (PAR); Reading patterns and behaviors; Web analytics,,Article,Final,,Scopus,2-s2.0-85133872483,Movies / Media
Riddiford J.A.; Enticott P.G.; Lavale A.; Gurvich C.,"Riddiford, Jacqueline A. (56803962500); Enticott, Peter G. (11641162100); Lavale, Alex (57219892160); Gurvich, Caroline (19337094200)",56803962500; 11641162100; 57219892160; 19337094200,Gaze and social functioning associations in autism spectrum disorder: A systematic review and meta-analysis,2022,Autism Research,15,8,,1380,1446,66.0,30,10.1002/aur.2729,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130234199&doi=10.1002%2faur.2729&partnerID=40&md5=0c1e8114b7cc887098040c5c50d21269,"Autism spectrum disorder (ASD) is characterized by significant social functioning impairments, including (but not limited to) emotion recognition, mentalizing, and joint attention. Despite extensive investigation into the correlates of social functioning in ASD, only recently has there been focus on the role of low-level sensory input, particularly visual processing. Extensive gaze deficits have been described in ASD, from basic saccadic function through to social attention and the processing of complex biological motion. Given that social functioning often relies on accurately processing visual information, inefficient visual processing may contribute to the emergence and sustainment of social functioning difficulties in ASD. To explore the association between measures of gaze and social functioning in ASD, a systematic review and meta-analysis was conducted. A total of 95 studies were identified from a search of CINAHL Plus, Embase, OVID Medline, and psycINFO databases in July 2021. Findings support associations between increased gaze to the face/head and eye regions with improved social functioning and reduced autism symptom severity. However, gaze allocation to the mouth appears dependent on social and emotional content of scenes and the cognitive profile of participants. This review supports the investigation of gaze variables as potential biomarkers of ASD, although future longitudinal studies are required to investigate the developmental progression of this relationship and to explore the influence of heterogeneity in ASD clinical characteristics. Lay Summary: This review explored how eye gaze (e.g., where a person looks when watching a movie) is associated with social functioning in autism spectrum disorder (ASD). We found evidence that better social functioning in ASD was associated with increased eye gaze toward faces/head and eye regions. Individual characteristics (e.g., intelligence) and the complexity of the social scene also influenced eye gaze. Future research including large longitudinal studies and studies investigating the influence of differing presentations of ASD are recommended. © 2022 The Authors. Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.",attention; autism spectrum disorder; cognition; eye gaze; motivation; social functioning; visual processing,"Attention; Autism Spectrum Disorder; Fixation, Ocular; Humans; Social Interaction; Visual Perception; autism; clinical feature; cognition; disease association; disease course; disease severity; emotion; evidence based practice; gaze; human; intelligence; meta analysis; patient participation; quantitative study; Review; saccadic eye movement; sample size; sensitivity analysis; social environment; social interaction; systematic review; attention; eye fixation; social interaction; vision",Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85130234199,Movies / Media
Addleman D.A.; Lee V.G.,"Addleman, Douglas A. (57195384649); Lee, Vanessa G. (35279609200)",57195384649; 35279609200,Simulated central vision loss does not impair implicit location probability learning when participants search through simple displays,2022,"Attention, Perception, and Psychophysics",84,6,,1901,1912,11.0,7,10.3758/s13414-021-02416-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121343871&doi=10.3758%2fs13414-021-02416-9&partnerID=40&md5=e799da21d3e0a9c754c6480d2643f5ef,"Central vision loss disrupts voluntary shifts of spatial attention during visual search. Recently, we reported that a simulated scotoma impaired learned spatial attention towards regions likely to contain search targets. In that task, search items were overlaid on natural scenes. Because natural scenes can induce explicit awareness of learned biases leading to voluntary shifts of attention, here we used a search display with a blank background less likely to induce awareness of target location probabilities. Participants searched both with and without a simulated central scotoma: a training phase contained targets more often in one screen quadrant and a testing phase contained targets equally often in all quadrants. In Experiment 1, training used no scotoma, while testing alternated between blocks of scotoma and no-scotoma search. Experiment 2 training included the scotoma and testing again alternated between scotoma and no-scotoma search. Response times and saccadic behaviors in both experiments showed attentional biases towards the high-probability target quadrant during scotoma and no-scotoma search. Whereas simulated central vision loss impairs learned spatial attention in the context of natural scenes, our results show that this may not arise from impairments to the basic mechanisms of attentional learning indexed by visual search tasks without scenes. © 2021, The Psychonomic Society, Inc.",central vision loss; selection history; visual attention; visual search,Attention; Humans; Probability Learning; Reaction Time; Saccades; Scotoma; attention; human; physiology; probability learning; reaction time; saccadic eye movement; scotoma,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85121343871,Movies / Media
Loaiza V.M.; Souza A.S.,"Loaiza, Vanessa M. (50461781000); Souza, Alessandra S. (55436300200)",50461781000; 55436300200,The eyes don’t have it: Eye movements are unlikely to reflect refreshing in working memory,2022,PLoS ONE,17,7-Jul,e0271116,,,,11,10.1371/journal.pone.0271116,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134187233&doi=10.1371%2fjournal.pone.0271116&partnerID=40&md5=4481cb7d7bb1083e948f288a5af13f66,"There is a growing interest in specifying the mechanisms underlying refreshing, i.e., the use of attention to keep working memory (WM) contents accessible. Here, we examined whether participants’ visual fixations during the retention interval of a WM task indicate the current focus of internal attention, thereby serving as an online measure of refreshing. Eye movements were recorded while participants studied and maintained an array of colored dots followed by probed recall of one (Experiments 1A and 1B) or all (Experiment 2) of the memoranda via a continuous color wheel. Experiments 1A and 2 entailed an unfilled retention interval in which refreshing is assumed to occur spontaneously, and Experiment 1B entailed a retention interval embedded with cues prompting the sequential refreshment of a subset of the memoranda. During the retention interval, fixations revisited the locations occupied by the memoranda, consistent with a looking-at-nothing phenomenon in WM, but the pattern was only evident when placeholders were onscreen in Experiment 2, indicating that most of these fixations may largely reflect random gaze. Furthermore, spontaneous fixations did not predict recall precision (Experiments 1A and 2), even when ensuring that they did not reflect random gaze (Experiment 2). In Experiment 1B, refreshing cues increased fixations to the eventually tested target and predicted better recall precision, which interacted with an overall benefit of target fixations, such that the benefit of fixations decreased as the number of refreshing cues increased. Thus, fixations under spontaneous conditions had no credible effect on recall precision, whereas the beneficial effect of fixations under instructed refreshing conditions may indicate situations in which cues were disregarded. Consequently, we conclude that eye movements do not seem suitable as an online measure of refreshing. © 2022 Loaiza, Souza.",,"Cues; Eye Movements; Fixation, Ocular; Humans; Memory, Short-Term; Mental Recall; Polyvinyl Alcohol; polyvinyl alcohol; adult; article; attention; controlled study; eye movement; female; gaze; human; human experiment; male; recall; working memory; association; eye fixation; short term memory",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85134187233,Movies / Media
Chen J.; Yang Y.; Liu B.; Xie X.; Li W.,"Chen, Jun (57217374825); Yang, Yifan (57826383900); Liu, Binjie (27168338400); Xie, Xiaoli (57211576181); Li, Wenjie (57207915765)",57217374825; 57826383900; 27168338400; 57211576181; 57207915765,Hermansky-Pudlak syndrome type 2: A rare cause of severe periodontitis in adolescents—A case study,2022,Frontiers in Pediatrics,10,,914243,,,,0,10.3389/fped.2022.914243,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135249472&doi=10.3389%2ffped.2022.914243&partnerID=40&md5=d0ce30212eb3ee6a3a7d96e218905383,"Background and aims: Hermansky-Pudlak syndrome (HPS) is an autosomal recessive disorder characterized by oculocutaneous albinism (OCA) and platelet storage pool deficiency. The HPS-2 subtype is distinguished by neutropenia, and little is known about its periodontal phenotype in adolescents. AP3B1 is the causative gene for HPS-2. A 13-year-old Chinese girl presented to our department suffering from gingival bleeding and tooth mobility. Her dental history was otherwise unremarkable. Suspecting some systemic diseases as the underlying cause, the patient was referred for medical consultation, a series of blood tests, and genetic tests. In this case study, periodontal status and mutation screening of one HPS-2 case are presented. Methods: Blood analysis including a complete blood count (CBC) and glycated hemoglobin levels were measured. Platelet transmission electron microscopy (PTEM) was performed to observe the dense granules in platelets. Whole-exome sequencing (WES) and Sanger sequencing were performed to confirm the pathogenic variants. Results: A medical diagnosis of HPS-2 was assigned to the patient. Following the medical diagnosis, a periodontal diagnosis of “periodontitis as a manifestation of systemic disease” was assigned to the patient. We identified novel compound heterozygous variants in AP3B1 (NM_003664.4: exon7: c.763C>T: p.Q255*) and (NM_003664.4: exon1: c.53_56dup: p.E19Dfs*21) in this Chinese pedigree with HPS-2. Conclusion: This case study indicates the importance of periodontitis as a possible indicator of underlying systemic disease. Systemic disease screening is needed when a young patient presents with unusual, severe periodontitis, as the oral condition may be the first of a systemic abnormality. Our work also expands the spectrum of AP3B1 mutations and further provides additional genetic testing information for other HPS-2 patients. Copyright © 2022 Chen, Yang, Liu, Xie and Li.",adaptor protein complex 3 (AP3B1); genetics; Hermansky-Pudlak syndrome type 2 (HPS-2); juvenile; periodontitis,adaptor protein; absolute neutrophil count; adolescent; alveolar bone; Article; bleeding on probing; case report; clinical article; clinical attachment level; cone beam computed tomography; eye movement; eye surgery; female; gene mutation; gingiva bleeding; Hermansky Pudlak syndrome type 2; heterozygote; human; leukocyte count; lung edema; maternal inheritance; mouth hygiene; neutropenia; neutrophil count; nystagmus; ocular albinism; oculocutaneous albinism; oral hygiene index; osteolysis; panoramic radiography; paternal inheritance; periodontal pocket depth; periodontitis; photophobia; Sanger sequencing; single nucleotide polymorphism; transmission electron microscopy; visual attention; whole exome sequencing,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85135249472,Movies / Media
Zhu L.; Cui G.; Li Y.; Zhang J.; Kong W.; Cichocki A.; Li J.,"Zhu, Li (57206724818); Cui, Gaochao (55657626300); Li, Yan (57384784700); Zhang, Jianhai (36717145000); Kong, Wanzeng (12804023400); Cichocki, Andrzej (7103098626); Li, Junhua (36184673200)",57206724818; 55657626300; 57384784700; 36717145000; 12804023400; 7103098626; 36184673200,Attention allocation on mobile app interfaces when human interacts with them,2022,Cognitive Neurodynamics,16,4,,859,870,11.0,4,10.1007/s11571-021-09760-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121758277&doi=10.1007%2fs11571-021-09760-4&partnerID=40&md5=28886e54072548d80559424c4fcc4505,"With the popularity of smartphones and the pervasion of mobile apps, people spend more and more time to interact with a diversity of apps on their smartphones, especially for young population. This raises a question: how people allocate attention to interfaces of apps during using them. To address this question, we, in this study, designed an experiment with two sessions (i.e., Session1: browsing original interfaces; Session 2: browsing interfaces after removal of colors and background) integrating with an eyetracking system. Attention fixation durations were recorded by an eye-tracker while participants browsed app interfaces. The whole screen of smartphone was divided into four even regions to explore fixation durations. The results revealed that participants gave significantly longer total fixation duration on the bottom left region compared to other regions in the session (1) Longer total fixation duration on the bottom was preserved, but there is no significant difference between left side and right side in the session2. Similar to the finding of total fixation duration, first fixation duration is also predominantly paid on the bottom area of the interface. Moreover, the skill in the use of mobile phone was quantified by assessing familiarity and accuracy of phone operation and was investigated in the association with the fixation durations. We found that first fixation duration of the bottom left region is significantly negatively correlated with the smartphone operation level in the session 1, but there is no significant correlation between them in the session (2) According to the results of ratio exploration, the ratio of the first fixation duration to the total fixation duration is not significantly different between areas of interest for both sessions. The findings of this study provide insights into the attention allocation during browsing app interfaces and are of implications on the design of app interfaces and advertisements as layout can be optimized according to the attention allocation to maximally deliver information. © 2021, The Author(s).",Advertising region; Attention allocation; Eye-tracking; Mobile app interfaces,accuracy; adult; advertising; Article; attention; cell phone use; clinical article; controlled study; female; human; human experiment; male; normal human,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85121758277,Movies / Media
Behler A.; Müller H.-P.; Del Tredici K.; Braak H.; Ludolph A.C.; Lulé D.; Kassubek J.,"Behler, Anna (57222325711); Müller, Hans-Peter (58603535800); Del Tredici, Kelly (6601996139); Braak, Heiko (35431706300); Ludolph, Albert C. (26643359400); Lulé, Dorothée (10141622200); Kassubek, Jan (7003511907)",57222325711; 58603535800; 6601996139; 35431706300; 26643359400; 10141622200; 7003511907,Multimodal in vivo staging in amyotrophic lateral sclerosis using artificial intelligence,2022,Annals of Clinical and Translational Neurology,9,7,,1069,1079,10.0,10,10.1002/acn3.51601,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131517413&doi=10.1002%2facn3.51601&partnerID=40&md5=ca51e607419709fa6225493863f99c5c,"Background: The underlying neuropathological process of amyotrophic lateral sclerosis (ALS) can be classified in a four-stage sequential pTDP-43 cerebral propagation scheme. Using diffusion tensor imaging (DTI), in vivo imaging of these stages has already been shown to be feasible for the specific corticoefferent tract systems. Because both cognitive and oculomotor dysfunctions are associated with microstructural changes at the brain level in ALS, a cognitive and an oculomotor staging classification were developed, respectively. The association of these different in vivo staging schemes has not been attempted to date. Methods: A total of 245 patients with ALS underwent DTI, video-oculography, and cognitive testing using Edinburgh Cognitive and Behavioral ALS Screen (ECAS). A set of tract-related diffusion metrics, cognitive, and oculomotor parameters was selected for further analysis. Hierarchical and k-means clustering algorithms were used to obtain an optimal cluster solution. Results: According to cluster analysis, differentiation of patients with ALS into four clusters resulted: Cluster A showed the highest fractional anisotropy (FA) values and thereby the best performances in executive oculomotor tasks and cognitive tests, whereas cluster D showed the lowest FA values, the lowest ECAS scores, and the worst executive oculomotor performance across all clusters. Clusters B and C showed intermediate results regarding parameter values. Discussion: In a multimodal dataset of technical assessments of brain structure and function in ALS, an artificial intelligence-based cluster analysis showed high congruence of DTI, executive oculomotor function, and neuropsychological performance for mapping in vivo correlates of neuropathological spreading. © 2022 The Authors. Annals of Clinical and Translational Neurology published by Wiley Periodicals LLC on behalf of American Neurological Association.",,Amyotrophic Lateral Sclerosis; Anisotropy; Artificial Intelligence; Brain; Diffusion Tensor Imaging; Humans; adult; aged; amyotrophic lateral sclerosis; Amyotrophic Lateral Sclerosis Functional Rating Scale; Article; artificial intelligence; central nervous system; cluster analysis; clustering algorithm; cognition; cognitive function test; corticopontine tract; corticorubral tract; diffusion; diffusion tensor imaging; edinburgh cognitive and behavioral ALS screen; eye movement; eye movement control; female; fractional anisotropy; hierarchical clustering; human; imaging; k means clustering; major clinical study; male; nervous system parameters; neuropsychological test; normal human; nuclear magnetic resonance imaging; principal component analysis; pyramidal tract; scoring system; T1 weighted imaging; videooculography; anisotropy; artificial intelligence; brain; pathology; procedures,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131517413,Movies / Media
Price A.M.; Knell G.; Caze T.J.; Abt J.P.; Loveland D.; Burkhart S.O.,"Price, August M. (57772075300); Knell, Gregory (56862156400); Caze, Todd J. (56188385800); Abt, John P. (6603044433); Loveland, Dustin (23970943300); Burkhart, Scott O. (55508630200)",57772075300; 56862156400; 56188385800; 6603044433; 23970943300; 55508630200,Exploring Vestibular/Ocular and Cognitive Dysfunction as Prognostic Factors for Protracted Recovery in Sports-Related Concussion Patients Aged 8 to 12 Years,2022,Clinical Journal of Sport Medicine,32,4,,408,414,6.0,7,10.1097/JSM.0000000000000975,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133144462&doi=10.1097%2fJSM.0000000000000975&partnerID=40&md5=785b4921be9f21124557213a9751e599,"Objective: To explore the prognostic ability of the vestibular/ocular motor screening (VOMS), King-Devick (K-D) Test, and C3 Logix Trails A and B to identify protracted recovery from sports-related concussion (SRC) in patients aged 8 to 12 years.Design: Retrospective cohort analysis.Setting: Specialty pediatric sports concussion clinic.Participants: A total of 114 youth athletes aged 8 to 12 years who were diagnosed with an SRC within 7 days of injury.Independent Variables: A positive screen on the VOMS, K-D, and C3 Logix Trails A and Trails B. Combined positive screens on multiple tests (ie, 2, 3, or all 4 positive screens of 4 possible).Main Outcome Measures: Recovery time in days and protracted recovery (recovery time ≥30-days) were the primary outcomes of interest.Results: A positive VOMS screen was associated with 1.31 greater days to SRC recovery (P = 0.02) than a negative VOMS screen. The K-D and C3 Logix tests were not significantly associated with recovery time, nor were any combinations of tests (P > 0.05). The VOMS demonstrated moderate prognostic ability to predict normal recovery (negative predictive value = 80.78% [95% CI = 63.73-90.95]). Overall predictive accuracy of normal versus protracted recovery was strongest when a participant screened positive on all 4 tests (Accuracy = 76.32% [95% CI = 67.45-83.78]).Conclusions: The VOMS was associated with overall recovery time and proved to be a useful test to identify those who would experience a normal recovery time. Combining the 4 tests improved the prognostic accuracy of the protocol in predicting protracted versus normal recovery. These findings suggest that combining multiple, varied assessments of cognition and vestibular/ocular functions may better explain factors contributing to protracted recovery.  © 2021 Wolters Kluwer Health, Inc.",ocular motor; protracted recovery; sports-related concussion; vestibular; youth athletes,Adolescent; Athletic Injuries; Brain Concussion; Child; Cognitive Dysfunction; Humans; Prognosis; Retrospective Studies; Article; brain injury assessment; child; cohort analysis; concussion; diagnostic accuracy; diagnostic value; female; human; major clinical study; male; outcome assessment; predictive value; prognosis; prognostic assessment; retrospective study; saccadic eye movement; sport injury; trail making test; validity; visual system examination; youth sport; adolescent; brain concussion; cognitive defect; complication; sport injury,Article,Final,,Scopus,2-s2.0-85133144462,Movies / Media
Mendonça R.; Garrido M.V.; Semin G.R.,"Mendonça, Rita (57183843000); Garrido, Margarida V. (36443467600); Semin, Gün R. (7006221548)",57183843000; 36443467600; 7006221548,Two Cultural Processing Asymmetries Drive Spatial Attention,2022,Cognitive Science,46,8,e13185,,,,1,10.1111/cogs.13185,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136506097&doi=10.1111%2fcogs.13185&partnerID=40&md5=459aa6ead4c6b8c9c63f17b5902e0ffd,"Cultural routines, such as reading and writing direction (script direction), channel attention orientation. Depending on one's native language habit, attention is biased from left-to-right (LR) or from right-to-left (RL). Here, we further document this bias, as it interacts with the spatial directionality that grounds time concepts. We used a spatial cueing task to test whether script direction and the grounding of time in Portuguese (LR, Exp. 1) and Arabic (RL, Exp. 2) shape visuomotor performance in target discrimination. Temporal words (e.g., tomorrow, yesterday) were presented as cues in two modalities: visual (Exp. 1–2) and auditory (Exp. 1). Gaze movement (Exp. 1) and speed of discrimination decisions (Exp. 1–2) of targets presented to the left or right sides of the screen were assessed. As predicted, the interaction between target location and time concepts was significant across both modalities and linguistic communities. Additionally, LR participants detected the target on the right side of the screen faster after a future word than the target on the left side of the screen after a past word cue. In contrast, RL participants detected the target on the left side of the screen faster when the cue word was a future word than the target on the right side of the screen cued by a past word. In both modalities, the initial eye-gaze movement (Exp. 1) was responsive to the cue's time referent, further confirming that time orients attention. An additional bias was observed for the first fixation onset, which landed earlier on the target set that matched habitualized spatial routines. We conclude that scanning regularities are shaped by writing habits and bodily grounded categorical features. © 2022 Cognitive Science Society LLC.",Eye-tracking; Language script; Spatial bias; Time; Visual attention,"Attention; Cues; Fixation, Ocular; Humans; Language; Reaction Time; Reading; association; attention; eye fixation; human; language; reaction time; reading",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85136506097,Movies / Media
Zhang Y.; Yang J.,"Zhang, Yuyang (57849341200); Yang, Jing (41862756700)",57849341200; 41862756700,Exploring Gender Differences in the Instructor Presence Effect in Video Lectures: An Eye-Tracking Study,2022,Brain Sciences,12,7,946,,,,9,10.3390/brainsci12070946,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136163094&doi=10.3390%2fbrainsci12070946&partnerID=40&md5=e6e9982838caec6b3b4892105fcf8786,"The instructor’s presence on the screen has become a popular feature in the video lectures of online learning and has drawn increasing research interest. Studies on the instructor presence effect of video lectures mainly focused on the features of the instructor, and few have taken learners’ differences, such as gender, into consideration. The current study examined whether male and female learners differed in their learning performance and eye movement features when learning video lectures with and without the instructor’s presence. All participants (N = 64) were asked to watch three different types of video lectures: audio-video without instructor presence (AV), picture-video with instructor presence (PV), and video-video with instructor presence (VV). They watched nine videos, three of each condition, and completed a reading comprehension test after each video. Their eye movement data were simultaneously collected when they watched these videos. Results showed that learners gained better outcomes after watching the videos with a talking instructor (VV) than those with the instructor’s picture (PV) or without the instructor (AV). This finding suggests that the dynamic presence of the instructor in video lectures could enhance learning through increased social presence and agency. Gender differences were found in their attention allocation, but not behavioral learning performance. When watching the videos with a talking instructor (VV), female learners dwelt longer on the instructor, while males transited more between the instructor and the text. Our results highlight the value of instructor presence in video lectures and call for more comprehensive explorations of gender differences in online learning outcomes and attention distribution. © 2022 by the authors.",eye-tracking; gender differences; instructor presence; social presence; video lecture,adult; article; attention; e-learning; eye movement; eye tracking; female; human; human experiment; learning; major clinical study; male; outcome assessment; reading; sex difference; videorecording,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85136163094,Movies / Media
Soares J.D.C.A.; Barros M.C.D.M.; da Silva G.V.T.; Carlini L.P.; Heiderich T.M.; Orsi R.N.; Balda R.D.C.X.; Silva P.A.S.O.; Thomaz C.E.; Guinsburg R.,"Soares, Juliana do Carmo Azevedo (57376340200); Barros, Marina Carvalho de Moraes (55423333100); da Silva, Giselle Valério Teixeira (57226130716); Carlini, Lucas Pereira (57217701010); Heiderich, Tatiany Marcondes (56458763600); Orsi, Rafael Nobre (57212513779); Balda, Rita de Cássia Xavier (11839554200); Silva, Pedro Augusto Santos Orona (57226100635); Thomaz, Carlos Eduardo (16023624400); Guinsburg, Ruth (6602113035)",57376340200; 55423333100; 57226130716; 57217701010; 56458763600; 57212513779; 11839554200; 57226100635; 16023624400; 6602113035,Looking at neonatal facial features of pain: do health and non-health professionals differ?,2022,Jornal de Pediatria,98,4,,406,412,6.0,6,10.1016/j.jped.2021.10.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121361159&doi=10.1016%2fj.jped.2021.10.006&partnerID=40&md5=3a3c146ba99378e2e1c77154b024af99,"Objective: To analyze the regions that trigger the attention of adults’ gaze when assessing pain in newborn infants’ pictures and to verify if there are differences between health and non-health professionals. Method: Experimental study with 84 health professionals and 59 non-health professionals, who evaluated two images of 10 neonates, one at rest and the other during a painful procedure. Each image was shown for 7 seconds on a computer screen, while eye movements were tracked by the Tobii TX300 EyeTracker. After evaluating each image, participants gave a score from 0 (absent pain) to 10 (maximum pain), according to their perception of neonatal pain. For each image, the number and total time of gaze fixations in the forehead, eyes, nasolabial furrow, and mouth were studied. Comparisons between both groups of adults were made by an intraclass correlation coefficient, Student's t-test, and Bland Altman graphic. Results: Health professionals (93% female; 34 ± 9 years old), compared to non-health professionals (64% female; 35 ± 11 years old), gave lower scores for images at rest (0.81 ± 0.50 vs. 1.59 ± 0.76; p = 0.010), with no difference for those obtained during the painful procedure (6.98 ± 1.08 vs. 6.73 ± 0.82). There was a strong or almost perfect correlation for the number of fixations in the mouth, eyes, forehead, and for the total fixation time in the eyes and forehead. Conclusions: Adults, irrespective of their profession, showed a homogeneous gaze pattern when evaluating pictures of neonates at rest or during a painful procedures. © 2021 Sociedade Brasileira de Pediatria",Eye-tracking technology; Facial expression; Health personnel; Infant; newborn; Pain perception,"Adult; Female; Fixation, Ocular; Health Personnel; Humans; Infant; Infant, Newborn; Male; Middle Aged; Pain; Young Adult; Apgar score; Article; clinical article; controlled study; eye movement; eye tracking; eye-tracking technology; facial expression; facies; female; forehead; gaze; health care personnel; health practitioner; human; image analysis; male; mouth; newborn; newborn intensive care; nociception; nurse; pediatric patient; pediatrician; physiotherapist; social class; speech language pathologist; adult; eye fixation; infant; middle aged; pain; young adult",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85121361159,Movies / Media
Hui B.; Wong S.S.Y.; Au R.K.C.,"Hui, Bronson (57215870950); Wong, Sharon Sin Ying (57763224300); Au, Ricky K.C. (37074077700)",57215870950; 57763224300; 37074077700,"Reading aloud listening test items to young learners: Attention, item understanding, and test performance",2022,System,108,,102831,,,,3,10.1016/j.system.2022.102831,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132782055&doi=10.1016%2fj.system.2022.102831&partnerID=40&md5=be655ff93ee0c10776eb4cdde5c7f5e9,"In second language (L2) listening assessment for young learners, test items are often read aloud by the narrator or by the teacher administering the test. Although read-alouds seem to be a special test feature for children, a solid empirical basis of this practice has not been established in the literature. In this article, we examine the relationship between read-alouds, test takers' attention, perceived item understanding, and test performance. We report an experiment where non-native English-speaking children completed a baseline reading test before taking a sample TOEFL Primary listening test on an eye tracker in two conditions: items fully read aloud (FRA) and items partially read aloud (PRA). After each item, test takers also rated their understanding of the item. We found that the read-alouds helped in drawing test takers’ attention to the corresponding written information on the screen. However, no robust differences were found in perceived item understanding, and test performance was equivalent between the two conditions. We discuss the implications for test administrators on assessment design for this population. © 2022 Elsevier Ltd",,,Article,Final,,Scopus,2-s2.0-85132782055,Movies / Media
Sharma M.; Vemuri K.,"Sharma, Medha (57923403100); Vemuri, Kavita (55490496400)",57923403100; 55490496400,Accepting Human-like Avatars in Social and Professional Roles,2022,ACM Transactions on Human-Robot Interaction,11,3,28,,,,8,10.1145/3526026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139593674&doi=10.1145%2f3526026&partnerID=40&md5=14b9e5b4ec0e3c62ec3982746ec8d0ac,"Humans report perceptions of unease or eeriness as humanoid/android robots and digital avatars approach human-like physical resemblance, a phenomenon alluded by the Uncanny Valley theory. This study extends the discussions on interactions and acceptance of digital avatars with findings from three experiments. In the first, perceptive evaluation of actors in clips from computer-generated animation and a live-action version of the same movie was examined. In the second experiment, we considered short clips with highly realistic digital avatars to measure recognition ability, the extent of eeriness, and specific physical features identified as unreal. The fixation area and pupil size variation recorded using an eye tracker were analyzed to infer attention to the body, face, and emotional response, respectively. Building on these findings, the third experiment looked at acceptance in roles requiring human skill, empathy, and cognitive ability. The results show that based on perceptions from physical attributes, the eeriness scores diverge from the uncanny valley theory as human-likeness increases. The realistic CGI and mocap technology could have helped cross the valley. Visual attention inferred from gaze behavior was similar for live-action and CGI. At the same time, we observe pupil size changes reflecting emotions like eeriness when the avatars either talked or smiled. Proficiency and acceptance scores were lower for roles requiring complex social cognition processes, such as friends and judicial decision-making. Interestingly, real-life stereotypes of gender roles were transferred to digital avatars too. The findings suggest an ambiguity in accepting human-like avatars in social and professional interactions, emphasizing the need for a multi-dimensional approach when applying the uncanny valley theory. A detailed and contextual examination is imperative as technological advancements have placed humans closer to co-existing with digital or physical android/humanoid robots.  © 2022 Association for Computing Machinery.",acceptance; animation; digital human; eeriness; human-computer interaction; motions capture techniques; Uncanny valley,Behavioral research; Computation theory; Decision making; Emotion Recognition; Eye movements; Eye tracking; Human computer interaction; Landforms; Acceptance; Digital humans; Eeriness; Human like; Live actions; Motion capture; Motion capture technique; Pupil size; Social roles; Uncanny valley; Animation,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85139593674,Movies / Media
Sauter M.; Wagner T.; Huckauf A.,"Sauter, Marian (56763649100); Wagner, Tobias (57215298980); Huckauf, Anke (6701503895)",56763649100; 57215298980; 6701503895,Distance between gaze and laser pointer predicts performance in video-based e-learning independent of the presence of an on-screen instructor,2022,Eye Tracking Research and Applications Symposium (ETRA),,,7,,,,6,10.1145/3517031.3529620,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132417363&doi=10.1145%2f3517031.3529620&partnerID=40&md5=97bb6c11d62c3a367ef9689e08b8a463,"In online lectures, showing an on-screen instructor gained popularity amidst the Covid-19 pandemic. However, evidence in favor of this is mixed: They draw attention and may distract from the content. In contrast, using signaling (e.g., with a digital pointer) provides known benefits for learners. But effects of signaling were only researched in absence of an on-screen instructor. In the present explorative study, we investigated effects of an on-screen instructor on the division of learnerś attention; specifically, on following a digital pointer signal with their gaze. The presence of an instructor led to an increased number of fixations in the presenter area. This did neither affect learning outcomes nor gaze patterns following the pointer. The average distance between the learner's gaze and the pointer position predicts the student's quiz performance, independent of the presence of an on-screen instructor. This can also help in creating automated immediate-feedback systems for educational videos. © 2022 Owner/Author.",e-learning; eye tracking; regression analysis; test performance,E-learning; Regression analysis; Average Distance; E - learning; Eye-tracking; Feedback systems; Immediate feedbacks; Laser pointer; Learning outcome; Number of fixations; Performance; Test performance; Eye tracking,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85132417363,Movies / Media
,,,"MMVE 2022 - Proceedings of the 2022 International Workshop on Immersive Mixed and Virtual Environment Systems, Part of MMSys 2022",2022,"MMVE 2022 - Proceedings of the 2022 International Workshop on Immersive Mixed and Virtual Environment Systems, Part of MMSys 2022",,,,,,55.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135406859&partnerID=40&md5=9aa9b20c95d0b90a5f0e37d641a3c9bf,The proceedings contain 9 papers. The topics discussed include: does having a virtual body make a difference during cinematic VR experiences?; rhythmic stimuli effects on subjective time perception in immersive virtual environments; real-time gaze prediction in virtual reality; the development of a machine learning/augmented reality immersive training system for performance monitoring in athletes; subjective evaluation of group user QoE in collaborative virtual environment (CVE); perceptually enhanced shadows for OST AR; the development of a glove-like controller interface for VR applications; and exploring non-verbal cues and user attention in IVR with eye tracking technologies.,,,Conference review,Final,,Scopus,2-s2.0-85135406859,Movies / Media
Zermiani F.; Bulling A.; Wirzberger M.,"Zermiani, Francesca (57552130100); Bulling, Andreas (6505807414); Wirzberger, Maria (57189259048)",57552130100; 6505807414; 57189259048,Mind Wandering Trait-level Tendencies during Lecture Viewing: A Pilot Study,2022,Eye Tracking Research and Applications Symposium (ETRA),,,49,,,,2,10.1145/3517031.3529241,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132417961&doi=10.1145%2f3517031.3529241&partnerID=40&md5=2819d5d4ade99013aefa48aa080f6e36,"Mind wandering (MW) is defined as a shift of attention to task-unrelated internal thoughts that is pervasive and disruptive for learning performance. Current state-of-The-Art gaze-based attention-Aware intelligent systems are capable of detecting MW from eye movements and delivering interventions to mitigate its negative effects. However, the beneficial functions of MW and its trait-level tendency, defined as the content of MW experience, are still largely neglected by these systems. In this pilot study, we address the questions of whether different MW trait-level tendencies can be detected through off-screen fixations' frequency and duration and blink rate during a lecture viewing task. We focus on prospective planning and creative problem-solving as two of the main MW trait-level tendencies. Despite the non-significance, the descriptive values show a higher frequency and duration of off-screen fixations, but lower blink rate, in the creative problem-solving MW condition. Interestingly, we do find a highly significant correlation between MW level and engagement scores in the prospective planning MW group. Potential explanations for the observed results are discussed. Overall, these findings represent a preliminary step towards the development of more accurate and adaptive learning technologies, and call for further studies on MW trait-level tendency detection. © 2022 ACM.",education; eye-movements; learning; mind-wandering,Intelligent systems; 'current; Blink rates; Creative problem-solving; Functions of minds; Learning; Learning performance; Mind-wandering; Pilot studies; Prospectives; State of the art; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85132417961,Movies / Media
Cui Y.; Zheng B.,"Cui, Yixiao (57216853232); Zheng, Binghan (55512006100)",57216853232; 55512006100,Extralinguistic Consultation in English–Chinese Translation: A Study Drawing on Eye-Tracking and Screen-Recording Data,2022,Frontiers in Psychology,13,,891997,,,,2,10.3389/fpsyg.2022.891997,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133666673&doi=10.3389%2ffpsyg.2022.891997&partnerID=40&md5=077c15cadb6aeb6f8e6957c6df22b3ce,"Both linguistic and extralinguistic consultations are essential in translation practice and have been commonly investigated as an integral topic in previous studies. However, since extralinguistic information is usually longer in extent and not specifically designed for a linguistic purpose, extralinguistic consultations involve different search strategies compared with linguistic consultations. Drawing on eye-tracking and screen-recording data, this study compares linguistic and extralinguistic consultations in terms of cognitive resources allocation and information processing patterns in English–Chinese translation. It also explores the differences among 17 language learners, 20 student translators, and 21 professional translators, and the effect of extralinguistic consultation on their translation quality. The findings are as follows: (1) all participants allocate more attention and lower cognitive load to extralinguistic consultations than to linguistic consultations; (2) participants’ translation experience levels and their attention allocated to extralinguistic consultation show an inverted U-shaped relationship; and (3) participants who consult extralinguistic information before drafting or devote more attention to extralinguistic consultation produce target texts with significantly higher scores. Copyright © 2022 Cui and Zheng.",English–Chinese translation; extralinguistic information; eye-tracking; online consultation; translation experience; translation product,,Article,Final,,Scopus,2-s2.0-85133666673,Movies / Media
Raffi M.; Trofè A.; Meoni A.; Gallelli L.; Piras A.,"Raffi, Milena (6603459027); Trofè, Aurelio (57214938898); Meoni, Andrea (57221080822); Gallelli, Luca (6602177838); Piras, Alessandro (36089214500)",6603459027; 57214938898; 57221080822; 6602177838; 36089214500,Optic Flow Speed and Retinal Stimulation Influence Microsaccades,2022,International Journal of Environmental Research and Public Health,19,11,6765,,,,2,10.3390/ijerph19116765,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131087372&doi=10.3390%2fijerph19116765&partnerID=40&md5=7bb8539a032f147cb0397f31f59aa76e,"Microsaccades are linked with extraretinal mechanisms that significantly alter spatial perception before the onset of eye movements. We sought to investigate whether microsaccadic activity is modulated by the speed of radial optic flow stimuli. Experiments were performed in the dark on 19 subjects who stood in front of a screen covering 135 × 107◦ of the visual field. Subjects were instructed to fixate on a central fixation point while optic flow stimuli were presented in full field, in the foveal, and in the peripheral visual field at different dot speeds (8, 11, 14, 17, and 20◦/s). Fixation in the dark was used as a control stimulus. For almost all tested speeds, the stimulation of the peripheral retina evoked the highest microsaccade rate. We also found combined effects of optic flow speed and the stimulated retinal region (foveal, peripheral, and full field) for microsaccade latency. These results show that optic flow speed modulates microsaccadic activity when presented in specific retinal portions, suggesting that eye movement generation is strictly dependent on the stimulated retinal regions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",attention; eye movements; eye position; self-motion perception; sensorimotor control; visual perception; visual processing; visual system,"Fixation, Ocular; Humans; Optic Flow; Photic Stimulation; Retina; Saccades; Visual Perception; experimental study; eye; perception; sensory system; vision; adult; article; attention; clinical article; controlled study; eye movement; eye position; female; flow rate; human; human experiment; male; movement perception; optic flow; peripheral retina; retina fovea; velocity; vision; visual field; visual system; eye fixation; photostimulation; physiology; procedures; retina; saccadic eye movement; vision",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131087372,Movies / Media
Saaty M.; Hashemi M.R.,"Saaty, Morva (57219112423); Hashemi, Mahmoud Reza (7005774450)",57219112423; 7005774450,"Game Audio Impacts on Players' Visual Attention, Model Performance for Cloud Gaming",2022,Eye Tracking Research and Applications Symposium (ETRA),,,25,,,,3,10.1145/3517031.3529621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132387836&doi=10.1145%2f3517031.3529621&partnerID=40&md5=0ebb9682de45a527a724dcecdf8e3cef,"Cloud gaming (CG) is a new approach to deliver a high-quality gaming experience to gamers anywhere, anytime, and on any device. To achieve this goal, CG requires a high bandwidth, which is still a major challenge. Many existing research pieces have focused on modeling or predicting the players' Visual Attention Map (VAM) and allocating bitrate accordingly. Although studies indicate that both modalities of audio and video influence human perception, a few studies considered audio impacts in the cloud-based attention models. This paper demonstrates that the audio features in video games change the players' VAMs in various game scenarios. Our findings indicated that incorporating game audio improves the accuracy of the predicted attention maps by 13% on average compared to the previous VAMs generated based on visual saliency by Game Attention Model for CG. The audio impact is more evident in video games with fewer visual components or indicators on the screen. © 2022 Owner/Author.",Attention Model; Cloud Gaming; Eye Movements; Eye Tracking; Game audio; Visual attention,Behavioral research; Eye movements; Human computer interaction; Interactive computer graphics; Attention model; Cloud gamings; Eye-tracking; Game audio; High quality; Modeling performance; New approaches; Video-games; Visual Attention; Visual attention model; Eye tracking,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85132387836,Movies / Media
Hynes E.; Flynn R.; Lee B.; Murray N.,"Hynes, Eoghan (57212020953); Flynn, Ronan (24376317500); Lee, Brian (55913808300); Murray, Niall (7201513152)",57212020953; 24376317500; 55913808300; 7201513152,A QoE evaluation of procedural and example instruction formats for procedure training in augmented reality,2022,MMSys 2022 - Proceedings of the 13th ACM Multimedia Systems Conference,,,,287,292,5.0,1,10.1145/3524273.3532899,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137142093&doi=10.1145%2f3524273.3532899&partnerID=40&md5=61165972c0fc6612194ab3e6172a9b7b,"Augmented reality (AR) has significant potential as a training platform. The pedagogical purpose of training is learning or transfer. Learning is the acquisition of an ability to perform a procedure as taught while transfer involves generalising that knowledge to similar procedures in the same domain. Quality of experience (QoE) concerns the fulfilment of the application, system or service user's pragmatic and hedonic needs and expectations. Learning or transfer fulfil the AR trainee's pragmatic needs. Training instructions can be presented in procedural, and example formats. Procedural instructions tell the trainee what to do while examples show the trainee how to do it. These two different instruction formats can influence learning, transfer, and hardware resource availability differently. The AR trainee's hedonic needs and expectations may be influenced by the impact of instruction format resource consumption on system performance. Efficient training efficacy is a design concern for mobile AR training applications. This work aims to inform AR training application design by evaluating the influence of procedural and example instruction formats on AR trainee QoE. In this demo, an AR GoCube™ solver training application will be exhibited on the state-of-the-art Hololens 2 (HL2) mixed reality (MR) headset. This AR training app is part of a test framework that will be used in a between groups study to evaluate the influence of text-based and animated 3D model instruction formats on AR trainee QoE. This framework will record the trainee's physiological ratings, eye gaze features and facial expressions. Learning will be evaluated in a post-training recall phase while transfer will be evaluated using a pre and post training comparison of mental rotation skills. Application profiling code will monitor AR headset resource consumption. © 2022 ACM.",Augmented reality; cognitive load; eye gaze; learning; memory; micro facial expressions; quality of experience; training,3D modeling; Mixed reality; Quality control; Quality of service; Cognitive loads; Experience evaluation; Eye-gaze; Facial Expressions; Learning; Micro facial expression; Quality of experience; Resources consumption; Training applications; Training platform; Augmented reality,Conference paper,Final,,Scopus,2-s2.0-85137142093,Movies / Media
Wright A.M.; Salas J.A.; Carter K.E.; Levin D.T.,"Wright, Anna M. (57224904540); Salas, Jorge A. (57219433500); Carter, Kelly E. (57211023305); Levin, Daniel T. (7202969153)",57224904540; 57219433500; 57211023305; 7202969153,Eye Movement Modeling Examples guide viewer eye movements but do not improve learning,2022,Learning and Instruction,79,,101601,,,,9,10.1016/j.learninstruc.2022.101601,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125452507&doi=10.1016%2fj.learninstruc.2022.101601&partnerID=40&md5=70b8d8b7f5e27ee5e14543ee519f3cf9,"Recent research has tested whether Eye Movement Modeling Examples (EMMEs) can effectively cue attention and improve learning. However, the effects of EMMEs are variable, and the degree to which viewers follow these cues remains unclear. In the current paper, we compared screen-captured instructional videos that included an EMME in the form of a transparent circular overlay depicting the instructor's gaze location with identical videos that lacked this cue. We observed that EMMEs drove viewer saccades to cued locations and resulted in shorter distances between viewer gaze and the EMME, but learning performance and video preference were unaffected by the presence of an EMME. We argue that EMMEs can effectively guide attention, but the range of circumstances under which they improve learning may be limited. © 2022 Elsevier Ltd",Attention cueing; Eye movement modeling examples; Eye tracking; Instructional videos; Multimedia learning,,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85125452507,Movies / Media
Jernajczyk W.; Litwin T.; Członkowska A.; Bembenek J.P.,"Jernajczyk, Wojciech (6602543297); Litwin, Tomasz (57213096808); Członkowska, Anna (7102938849); Bembenek, Jan P. (26654781100)",6602543297; 57213096808; 7102938849; 26654781100,Sleep disturbances in newly diagnosed treatment-naïve patients with Wilson’s disease,2022,Acta Neurologica Belgica,122,3,,745,751,6.0,5,10.1007/s13760-022-01915-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127121852&doi=10.1007%2fs13760-022-01915-2&partnerID=40&md5=b9b59479472f770a0f4366722b65adfc,"Introduction: Most neurodegenerative and chronic liver disorders are associated with sleep disturbances (SD). SD may be expected to occur in patients with Wilson’s disease (WD), an inherited disorder of copper metabolism that mostly affects the liver and brain; however, there is a lack of observations, particularly in treatment-naïve WD patients. Methods: We evaluated SD in 19 newly diagnosed treatment-naïve WD patients. All patients completed the Beck Depression Inventory (BDI), the Athens Insomnia Scale (AIS) and the Epworth Sleepiness Scale (ESS), and underwent nightlong video polysomnography (vPSG). Results of vPSG in WD patients were compared with results from 19 sex- and age-matched healthy controls. Results: Depressive symptoms were not reported by patients on routine examination although three patients were diagnosed with mild depression. No patients reported SD during routine examination; three patients had insomnia according to the AIS and all patients scored 0 on the ESS. Despite the lack of reporting of SD by patients, significant differences were observed between WD patients and controls following vPSG analysis: WD patients had shorter mean total sleeping time (366.2 vs. 451.7 min), a lower percentage of rapid-eye movement (15.4 vs. 20.6%), longer sleep latency (36.7 vs. 10.4 min) and lower sleep efficiency (76.2 vs. 93.8%) (all P ≤ 0.01). SD tended to be worse in patients with neurological WD compared with hepatic WD. Conclusions: As SD may precede depression and severely affect quality of life, our findings suggest that patients with WD should be screened for SD with suitable methods. © 2022, The Author(s) under exclusive licence to Belgian Neurological Society.","Copper; Depression, polysomnography; Sleep disorders",Hepatolenticular Degeneration; Humans; Quality of Life; Sleep; Sleep Initiation and Maintenance Disorders; Sleep Wake Disorders; copper; adult; Article; Athens Insomnia Scale; Beck Depression Inventory; bipolar disorder; brain; brain atrophy; clinical article; cognition; controlled study; copper metabolism; daily life activity; depression; electroencephalography; Epworth sleepiness scale; female; fibromyalgia; globus pallidus; hepatic encephalopathy; human; insomnia; liver; liver biopsy; liver cirrhosis; male; neuropsychological test; nuclear magnetic resonance imaging; percentage of REM sleep; polysomnography; putamen; quality of life; REM sleep; sleep disorder; sleep disordered breathing; sleep efficiency; sleep latency; sleep quality; sleep time; Unified Parkinson Disease Rating Scale; Wilson disease; complication; insomnia; sleep; sleep disorder,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85127121852,Movies / Media
Zhou H.-Y.; Yang H.-X.; Wei Z.; Wan G.-B.; Lui S.S.Y.; Chan R.C.K.,"Zhou, Han-yu (57195413365); Yang, Han-xue (57211211809); Wei, Zhen (56459346600); Wan, Guo-bin (56258026300); Lui, Simon S. Y. (35292835200); Chan, Raymond C. K. (55708154200)",57195413365; 57211211809; 56459346600; 56258026300; 35292835200; 55708154200,Audiovisual synchrony detection for fluent speech in early childhood: An eye-tracking study,2022,PsyCh Journal,11,3,,409,418,9.0,4,10.1002/pchj.538,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127253611&doi=10.1002%2fpchj.538&partnerID=40&md5=7beeb3a1a52961e7eb3ed695be3448ce,"During childhood, the ability to detect audiovisual synchrony gradually sharpens for simple stimuli such as flashbeeps and single syllables. However, little is known about how children perceive synchrony for natural and continuous speech. This study investigated young children's gaze patterns while they were watching movies of two identical speakers telling stories side by side. Only one speaker's lip movements matched the voices and the other one either led or lagged behind the soundtrack by 600 ms. Children aged 3–6 years (n = 94, 52.13% males) showed an overall preference for the synchronous speaker, with no age-related changes in synchrony-detection sensitivity as indicated by similar gaze patterns across ages. However, viewing time to the synchronous speech was significantly longer in the auditory-leading (AL) condition compared with that in the visual-leading (VL) condition, suggesting asymmetric sensitivities for AL versus VL asynchrony have already been established in early childhood. When further examining gaze patterns on dynamic faces, we found that more attention focused on the mouth region was an adaptive strategy to read visual speech signals and thus associated with increased viewing time of the synchronous videos. Attention to detail, one dimension of autistic traits featured by local processing, has been found to be correlated with worse performances in speech synchrony processing. These findings extended previous research by showing the development of speech synchrony perception in young children, and may have implications for clinical populations (e.g., autism) with impaired multisensory integration. © 2022 Institute of Psychology, Chinese Academy of Sciences and John Wiley & Sons Australia, Ltd.",audiovisual; autistic traits; eye-tracking; speech; synchrony detection,"Auditory Perception; Autistic Disorder; Child; Child, Preschool; Eye-Tracking Technology; Female; Humans; Male; Speech; Speech Perception; Visual Perception; autism; child; female; hearing; human; male; preschool child; speech; speech perception; vision",Article,Final,,Scopus,2-s2.0-85127253611,Movies / Media
Kong P.; Mancas M.; Gosselin B.; Po K.,"Kong, Phutphalla (55929232800); Mancas, Matei (8569088000); Gosselin, Bernard (57162610800); Po, Kimtho (24829726600)",55929232800; 8569088000; 57162610800; 24829726600,DeepRare: Generic Unsupervised Visual Attention Models,2022,Electronics (Switzerland),11,11,1696,,,,1,10.3390/electronics11111696,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131010726&doi=10.3390%2felectronics11111696&partnerID=40&md5=a32255a522338b9960595662bb98f5e4,"Visual attention selects data considered as “interesting” by humans, and it is modeled in the field of engineering by feature-engineered methods finding contrasted/surprising/unusual image data. Deep learning drastically improved the models efficiency on the main benchmark datasets. However, Deep Neural Networks-based (DNN-based) models are counterintuitive: surprising or unusual data are by definition difficult to learn because of their low occurrence probability. In reality, DNN-based models mainly learn top-down features such as faces, text, people, or animals which usually attract human attention, but they have low efficiency in extracting surprising or unusual data in the images. In this article, we propose a new family of visual attention models called DeepRare and especially DeepRare2021 (DR21), which uses the power of DNNs’ feature extraction and the genericity of feature-engineered algorithms. This algorithm is an evolution of a previous version called DeepRare2019 (DR19) based on this common framework. DR21 (1) does not need any additional training other than the default ImageNet training, (2) is fast even on CPU, (3) is tested on four very different eye-tracking datasets showing that DR21 is generic and is always within the top models on all datasets and metrics while no other model exhibits such a regularity and genericity. Finally, DR21 (4) is tested with several network architectures such as VGG16 (V16), VGG19 (V19), and MobileNetV2 (MN2), and (5) it provides explanation and transparency on which parts of the image are the most surprising at different levels despite the use of a DNN-based feature extractor. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",deep features; eye tracking; odd one out; rarity; saliency; visibility; visual attention prediction,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131010726,Movies / Media
Chong-Wen W.; Sha-Sha L.; Xu E.,"Chong-Wen, Wu (57747949500); Sha-Sha, Li (57203978015); Xu, E. (59819406200)",57747949500; 57203978015; 59819406200,Predictors of rapid eye movement sleep behavior disorder in patients with Parkinson’s disease based on random forest and decision tree,2022,PLoS ONE,17,6 6,e0269392,,,,9,10.1371/journal.pone.0269392,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132188557&doi=10.1371%2fjournal.pone.0269392&partnerID=40&md5=17eed0f0aac302c9db0fe6eff2fe77ba,"Background and objectives Sleep disorders related to Parkinson’s disease (PD) have recently attracted increasing attention, but there are few clinical reports on the correlation of Parkinson’s disease patients with rapid eye movement (REM) sleep behavior disorder (RBD). Therefore, this study conducted a cognitive function examination for Parkinson’s disease patients and discussed the application effect of three algorithms in the screening of influencing factors and risk prediction effects. Methods Three algorithms (logistic regression, machine learning-based regression trees and random forest) were used to establish a prediction model for PD-RBD patients, and the application effects of the three algorithms in the screening of influencing factors and the risk prediction of PD-RBD were discussed. Results The subjects included 169 patients with Parkinson’s disease (Parkinson’s disease with RBD [PD-RBD] = 69 subjects; Parkinson’s disease without RBD [PD-nRBD] = 100 subjects). This study compared the predictive performance of RF, decision tree and logistic regression, selected a final model with the best model performance and proposed the importance of variables in the final model. After the analysis, the accuracy of RF (83.05%) was better than that of the other models (decision tree = 75.10%, logistic regression = 71.62%). PQSI, Scopa-AUT score, MoCA score, MMSE score, AGE, LEDD, PD-course, UPDRS total score, ESS score, NMSQ, disease type, RLSRS, HAMD, UPDRS III and PDOnsetage are the main variables for predicting RBD, along with increased weight. Among them, PQSI is the most important factor. The prediction model of Parkinson’s disease RBD that was established in this study will help in screening out predictive factors and in providing a reference for the prognosis and preventive treatment of PD-RBD patients. Conclusions The random forest model had good performance in the prediction and evaluation of PD-RBD influencing factors and was superior to decision tree and traditional logistic regression models in many aspects, which can provide a reference for the prognosis and preventive treatment of PD-RBD patients. © 2022 Chong-Wen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Decision Trees; Disease Progression; Humans; Mental Status and Dementia Tests; Parkinson Disease; REM Sleep Behavior Disorder; levodopa; Article; behavior disorder; cognition; controlled study; decision tree; human; machine learning; major clinical study; Mini Mental State Examination; Montreal cognitive assessment; Parkinson disease; random forest; REM sleep; complication; decision tree; dementia assessment; disease exacerbation; parasomnia; Parkinson disease,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85132188557,Movies / Media
Rubies E.; Palacín J.; Clotet E.,"Rubies, Elena (57216591924); Palacín, Jordi (6701716085); Clotet, Eduard (56326361400)",57216591924; 6701716085; 56326361400,Enhancing the Sense of Attention from an Assistance Mobile Robot by Improving Eye-Gaze Contact from Its Iconic Face Displayed on a Flat Screen,2022,Sensors,22,11,4282,,,,14,10.3390/s22114282,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131156804&doi=10.3390%2fs22114282&partnerID=40&md5=2b529b71b7853a91070f925f7a793bed,"One direct way to express the sense of attention in a human interaction is through the gaze. This paper presents the enhancement of the sense of attention from the face of a human-sized mobile robot during an interaction. This mobile robot was designed as an assistance mobile robot and uses a flat screen at the top of the robot to display an iconic (simplified) face with big round eyes and a single line as a mouth. The implementation of eye-gaze contact from this iconic face is a problem because of the difficulty of simulating real 3D spherical eyes in a 2D image considering the perspective of the person interacting with the mobile robot. The perception of eye-gaze contact has been improved by manually calibrating the gaze of the robot relative to the location of the face of the person interacting with the robot. The sense of attention has been further enhanced by imple-menting cyclic face explorations with saccades in the gaze and by performing blinking and small movements of the mouth. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",assistance robot; big eyes; eye-gaze; iconic face; sense of attention,"Eye Movements; Fixation, Ocular; Humans; Mouth; Robotics; Saccades; Eye movements; Human robot interaction; 2D images; Assistance robot; Big eye; Eye-gaze; Flat-screens; Humaninteraction; Iconic face; Iconics; Sense of attention; eye fixation; eye movement; human; mouth; robotics; saccadic eye movement; Mobile robots",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131156804,Movies / Media
Desai I.; Gupta R.; Kumar M.; Tiwari A.; Kumar N.,"Desai, Ishita (57221941839); Gupta, Ravi (7501324271); Kumar, Mritunjai (57191341809); Tiwari, Ashutosh (56902182600); Kumar, Niraj (57200896396)",57221941839; 7501324271; 57191341809; 56902182600; 57200896396,Sleep Disorders in Patients with Parkinson’s Disease during COVID-19 Pandemic: A Case–Control Study,2022,Annals of Indian Academy of Neurology,25,3,,394,400,6.0,2,10.4103/aian.aian_255_22,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183996751&doi=10.4103%2faian.aian_255_22&partnerID=40&md5=8ab7c21cde8327dc9364057180ea5963,"Objective: To assess the impact of coronavirus disease 2019 (COVID‑19) pandemic on sleep disorders among Parkinson’s disease (PD) patients using validated questionnaires. Materials and Methods: This prospective study involved 50 PD patients and 50 age, gender, and body mass index‑matched controls. All participants underwent assessment of cognition using Montreal Cognitive Assessment scale, sleep quality using Parkinson’s disease sleep scale‑2 (PDSS‑2; for PD patients) and Pittsburgh Sleep Quality Index (PSQI; for PD patients and healthy controls), excessive daytime sleepiness (EDS) using Epworth sleepiness scale (ESS), insomnia symptoms and severity using insomnia severity index (ISI), restless legs syndrome (RLS) using International RLS Study Group criteria, rapid eye movement sleep behavior disorder (RBD) using RBD Single‑Question Screen (RBD1Q), and depression using Patient Health Questionnaire‑9 scale. Results: Eighty‑eight percent of PD patients reported one or more sleep disorders, compared to 28% controls. While 72% of PD patients reported poor sleep quality (PDSS‑2 ≥15, PSQI >5), 60% had insomnia, 58% reported RBD, 50% had EDS, and 36% reported RLS. Depressive symptoms were reported by 70% patients. PD patients with and without poor sleep quality were comparable with regards to demographic and clinical variables, except for depressive symptoms (P < 0.001). Depressive symptoms showed a significant association with EDS (P = 0.008), RBD (P < 0.001), and insomnia (P = 0.001). Conclusion: Prevalence of sleep disorders increased in PD patients during the COVID‑19 pandemic. Prevalence of EDS, RBD, and RLS in PD patients was higher compared to that reported in studies during the pre‑COVID‑19 times. Presence of depressive symptoms was a significant correlate of presence of sleep disorders in PD patients. © 2022 Annals of Indian Academy of Neurology.",Excessive Daytime Somnolence; Parkinson’s disease; rapid eye movement sleep behavior disorder; restless legs syndrome; sleep quality,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85183996751,Movies / Media
Meirinhos G.; Mendes T.; Rêgo R.; Oliveira M.; Rodrigues M.; Silva R.,"Meirinhos, Galvão (57197843128); Mendes, Tiago (57711438400); Rêgo, Reiville (57711184100); Oliveira, Márcio (57211295011); Rodrigues, Margarida (57194551205); Silva, Rui (16550689000)",57197843128; 57711438400; 57711184100; 57211295011; 57194551205; 16550689000,The Communicative Effectiveness of Branding at Sports Press Conferences,2022,Behavioral Sciences,12,5,151,,,,1,10.3390/bs12050151,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130764591&doi=10.3390%2fbs12050151&partnerID=40&md5=7b6a5799ec4baea80f8a880d0163e779,"This scientific work studies brand placement in the press conferences of soccer coaches and evaluates their communicative effectiveness through the measurement of their cognitive and affective effects on the viewers. In this research, we established the following objectives: (1) to examine the characteristics of the practice of brand placement in football press conferences: the diffusion times of brands, space occupied on the screen, and categories of brands placed; (2) to evaluate the behaviour of the human eye when viewing press conferences, in terms of continuous movements (saccades) and fixations (fixations) on brands; (3) to gauge the spontaneous and assisted recall of brands by subjects; (4) to verify the correlation between the persistence of visual fixations and recall/recognition; (5) to investigate the changes in subjects’ attitudes towards brands viewed in the experimental context. An exploratory observation was made that enabled a more in-depth knowledge and implementation of brand placement at sports conferences. For the experimental observation, a 2 × 2 factorial design of independent groups with total randomization was defined in order to perceive the influence of the variables “time” and “quantity” on the communicative effectiveness of the placed tags. In order to collect the data, a combination of several tested and validated tools was used, namely the screen division grid in surface units, as advocated by Bravo (1995); the technology of eye-tracking as an instrument for the recognition of the ocular movements of subjects in the observation space; surveys tested for cognitive gauging; and a semantic differential scale to assess attitudes toward the brand. The results indicate that the subjects recall in a spontaneous and suggested way the brands placed at the press conferences and develop positive attitudes about them. The recall is influenced by the diffusion time of the stimulus, and above all, the type of placement on the screen is decisive. It was not found that the brands to which subjects develop more positive attitudes were the most remembered. Finally, the face of the soccer coach is the main focus of attention of the subjects, and the areas surrounding this interlocutor are the ones that arouse the most interest in terms of the placement of brands. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",branding; communication; sport press conferences,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85130764591,Movies / Media
Shi C.; Rothrock L.,"Shi, Chao (57196019445); Rothrock, Ling (6603284989)",57196019445; 6603284989,Validating an abnormal situation prediction model for smart manufacturing in the oil refining industry,2022,Applied Ergonomics,101,,103697,,,,6,10.1016/j.apergo.2022.103697,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123629732&doi=10.1016%2fj.apergo.2022.103697&partnerID=40&md5=053500a07a9d2c22635d6183b5700c33,"Human beings play an important role in a smart manufacturing economy. The repetitive and cognitive demanding task operations of smart manufacturing require the development of system models for measuring and predicting human performance, including oil refinery monitoring tasks. The main objective of this research was to validate the generalizability of a mathematical model for the prediction of refinery operators' detection of abnormal events. Moreover, we examined operators' visual behaviors in response to abnormal situations at different ages and with different task loads, task complexities, and input devices. We found that participants had lower mean fixation durations, total fixation numbers, and fixation/saccade ratios when they were in the condition of a touchscreen device. Moreover, we found that older adults had higher mean saccade durations and saccade amplitudes when they were in the condition of a touchscreen device. Finally, the statistical model borrowed from our prior paper was found to be generalizable to different task loads and age groups for the prediction of operators’ detection of abnormal events. Our results showed that visual behaviors can indicate specific internal states of participants, including their cognitive workload, attention, and situation awareness in a real-time manner. The findings provide additional support for the value of using visual behavior to predict responsiveness of oil refinery operators and for future applications of smart manufacturing monitoring systems. © 2022 Elsevier Ltd",Control room; Eye-tracking; Interactive devices; Statistical modeling prediction,Aged; Attention; Awareness; Humans; Saccades; Task Performance and Analysis; Workload; Eye movements; Forecasting; Mathematical operators; Refining; Condition; Control room; Eye-tracking; Model prediction; Oil refineries; Situation prediction; Smart manufacturing; Statistic modeling; Statistical modeling prediction; Visual behavior; adolescent; adult; aged; Article; cognition; controlled study; eye fixation; eye tracking; groups by age; human; human experiment; industry and industrial phenomena; job performance; mathematical model; normal human; occupation and occupation related phenomena; occupational accident; occupational safety; oil industry; prediction; saccadic eye movement; smart manufacturing; statistical model; task performance; validation study; workload; attention; awareness; physiology; task performance; Eye tracking,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85123629732,Movies / Media
Jiang T.; Fu S.; Erdelez S.; Guo Q.,"Jiang, Tingting (7402148747); Fu, Shiting (57203964713); Erdelez, Sanda (6602970875); Guo, Qian (57203954920)",7402148747; 57203964713; 6602970875; 57203954920,Understanding the seeking-encountering tension: Roles of foreground and background task urgency,2022,Information Processing and Management,59,3,102910,,,,8,10.1016/j.ipm.2022.102910,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126065588&doi=10.1016%2fj.ipm.2022.102910&partnerID=40&md5=4ad97cdc0231103eab075325d9bb92a6,"Echoing the urge for in-depth research on the mechanisms of the seeking-encountering tension, i.e., foreground and background tasks co-exist and switch between each other, this study conducted a true experiment based on 2*2 factorial design to examine the roles of task urgency in such tension. The experiment used an eye tracker and the build-in screen recorder to capture 39 participants’ eye movements and clicking behavior when they performed foreground search tasks in the laboratory, while the information related to the background task assigned in advance as coursework was embedded in the search results. It was found that the information seeking and encountering processes were interwoven and competed persistently with each other for users’ attention and actions, and the seeking-encountering tension led to a lose-lose outcome. While there existed negative relationships between foreground task urgency and multiple search measures, positive relationships were revealed between background task urgency and the examining of the encountered information. In particular, the high foreground task urgency suppressed the noticing of the stimulus related to the background task. The results not only enrich the understanding of multitasking in human information acquisition, but also generate useful practical implications for the design of search engines. © 2022 Elsevier Ltd",Background task; Eye tracking; Foreground task; Information encountering; Seeking-encountering tension; Task urgency,Eye movements; Search engines; Background tasks; Courseworks; Eye trackers; Eye-tracking; Factorial design; Foreground task; Information encountering; Search tasks; Seeking-encountering tension; Task urgency; Eye tracking,Article,Final,,Scopus,2-s2.0-85126065588,Movies / Media
Vernet M.; Jover M.; Bellocchi S.; Maziero S.; Jucla M.; Tallet J.; Danna J.; Chaix Y.; Ducrot S.,"Vernet, Marie (57222493147); Jover, Marianne (9841519100); Bellocchi, Stéphanie (37090282600); Maziero, Stéphanie (57210061965); Jucla, Mélanie (36461263200); Tallet, Jessica (23991539600); Danna, Jérémy (16490504400); Chaix, Yves (6701396382); Ducrot, Stéphanie (6603173091)",57222493147; 9841519100; 37090282600; 57210061965; 36461263200; 23991539600; 16490504400; 6701396382; 6603173091,Visual-processing deficits in children with neurofibromatosis type 1: A clinical marker of reading difficulties: Vision and reading in NF1 children,2022,European Journal of Paediatric Neurology,38,,,25,32,7.0,9,10.1016/j.ejpn.2022.03.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127336351&doi=10.1016%2fj.ejpn.2022.03.009&partnerID=40&md5=35960ad68f36480722b63b08015645f9,"Today's estimates indicate that nearly 50% of children with Neurofibromatosis type 1 (NF1) suffer from reading disabilities, with a high impact on their academic achievement. In addition to the well-documented importance of phonological skills in reading acquisition and neurodevelopmental disorders, visual-attention processes also appear as important factors in learning to read. The present study aimed at assessing the role of visual-processing dysfunction in the high prevalence of reading disabilities in NF1 children and providing a useful tool for clinician in the early detection of reading impairment in this neurogenetic disorder. Forty-two children with NF1 and 42 typically developing children (TD) participated in the study. All were right-handed and did not present intellectual disability or attention deficit hyperactivity disorder. Visual-attention processes were assessed with the Developmental Eye Movement (DEM) test, together with the NF1 children's reading level. NF1 children with and without reading disabilities were then compared. The results showed that visual-processing deficits were highly present among the NF1 children included in our study. Furthermore, poor readers with NF1 presented an increased risk of visual-processing deficits compared to peers. This finding supports the role of visual-processing deficits in the reading difficulties encountered in nearly half of children with NF1. Finally, in NF1 children without intellectual or attention disability, visual-processing deficits emerge as one of the clinical markers of reading disabilities. The study holds important clinical implications both for the identification, by providing a useful screening tool, and the management of reading disabilities in NF1 children. © 2022",DEM-Test; Neurofibromatosis type 1; Reading; Screening tool; Visual information processing,Biomarkers; Child; Cognition; Dyslexia; Humans; Learning Disabilities; Neurofibromatosis 1; biological marker; Article; attention deficit hyperactivity disorder; case report; child; clinical article; clinician; demographics; dyslexia; eye movement; female; human; intellectual impairment; male; neurofibromatosis type 1; neuropsychological test; pediatric patient; physician; processing; sensitivity and specificity; vision; visual attention; visual disorder; visual information; cognition; complication; dyslexia; learning disorder,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85127336351,Movies / Media
Khushnood K.; Sultan N.; Awan M.M.A.,"Khushnood, Kiran (57217230141); Sultan, Nasir (57219446287); Awan, Malik Muhammad Ali (57193863285)",57217230141; 57219446287; 57193863285,Eye Muscle Exercises; Solution to Rising Screen Exposure,2022,Journal of the College of Physicians and Surgeons Pakistan,32,5,,694,,,0,10.29271/jcpsp.2022.05.694,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130196692&doi=10.29271%2fjcpsp.2022.05.694&partnerID=40&md5=bbf28e23535536cb8818ff78265d5555,[No abstract available],,"Electromyography; Exercise; Exercise Therapy; Humans; Muscle, Skeletal; Oculomotor Muscles; blinking; extraocular muscle; eye disease; eye movement; eye muscle exercise; gaze; human; Letter; mental performance; muscle exercise; muscle fatigue; quality of life; screen time; visual fatigue; visuomotor coordination; electromyography; exercise; kinesiotherapy; skeletal muscle",Letter,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85130196692,Movies / Media
Liu Y.; Tan H.; Zeng Y.; Xiao L.,"Liu, Yishu (57218772619); Tan, Huiwen (57218762026); Zeng, Yin (57218768469); Xiao, Li (57218396540)",57218772619; 57218762026; 57218768469; 57218396540,Relationship of Cognitive Function with Emotion and Sleep Architecture in Patients with OSAHS; [阻塞性睡眠呼吸暂停低通气综合征患者认知功能与情绪及睡眠结构的关系研究],2022,Chinese General Practice,25,11,,1340,1345and1350,13450010.0,2,10.12114/j.issn.1007-9572.2022.01.603,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128692406&doi=10.12114%2fj.issn.1007-9572.2022.01.603&partnerID=40&md5=0f182762df3b626b879868b178825bd1,"Background: Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a sleep-related breathing disease, which influences patients' sleep quality and emotion regulation due to long-term intermittent hypoxemia and sleep fragmentation. It has a close relationship with cognitive function. Objective: To explore the relationship of cognitive function with emotion and sleep architecture in patients with OSAHS. Methods: A retrospective analysis was conducted. Participants were 116 cases of OSAHS diagnosed by polysomnography(PSG) recruited from Sleep Medical Center, Shengjing Hospital of China Medical University from September 2019 to December 2020. Clinical data were collected, including results of PSG and questionnaires before PSG〔including Generalized Anxiety Disorder(GAD-7), Patient Health Questionnaire-9(PHQ-9), Montreal Cognitive Assessment(MoCA), Mean Memory and Executive Screening(MES), Insomnia Severity Index(ISI), Epworth Sleepiness Scale(ESS)〕. According to the total score of MoCA, participants were divided into normal cognition group(≥26 points, n=79) and abnormal cognition group (< 26 points, n=37). Pearson and Spearman correlation analyses were used to study the correlation of cognitive function with PSG indicators. Multiple linear regression analysisi was used to explore the factors associated with cognitive function. Results: There were no significant differences in emotion functions between normal cognition group and abnormal cognition group. Both groups had significant differences in mean age, sex ratio, MES score, total arousals, arousals in non-rapid eye movement(NREM), arousals in rapid eye movement(REM), total sleep time(TST), wake after sleep onset(WASO), sleep efficiency, percentage of stage N3 sleep(N3/TST%) and percentage of REM(REM/TST%) (P< 0.05). Correlation analyses showed that MoCA score was negatively correlated with age, apnea hypopnea index(AHI), and WASO(P< 0.05), and positively correlated with TST, sleep efficiency, REM/TST%, total arousals and arousals in REM(P< 0.05). The score of delayed recall in the MoCA scale was negatively correlated with age and WASO(P< 0.05), and positively correlated with sleep efficiency, REM/TST%, total arousals and arousals in REM(P< 0.05).The total score of MES was negatively correlated with age(P< 0.05), and positively correlated with REM/TST%, total arousals, and arousals in NREM and REM(P< 0.05). Multiple linear regression analysis showed that age, AHI and REM/TST% were associated with MoCA score(P< 0.05), and age was associated with delayed recall score and MES score(P< 0.05). The final regression model established using stepwise regression revealed that the MoCA score had a stronger correlation with age and REM/TST%, and MoCA score was negatively correlated with age(P< 0.05), and positively correlated with REM/TST%(P< 0.05). Conclusion: The decline of cognitive function in OSAHS patients was significantly correlated with the reduction of REM. No obvious abnormality in emotion was found in these patients with cognitive dysfunction. The relationship between cognitive function and sleep architecture in OSAHS patients can be further clarified in future research. Copyright © 2022 by the Chinese General Practice.","Cognitive function; Emotion; Root cause analysis; Sleep apnea, obstructive; Sleep architecture",,Article,Final,,Scopus,2-s2.0-85128692406,Movies / Media
Opwonya J.; Wang C.; Jang K.-M.; Lee K.; Kim J.I.; Kim J.U.,"Opwonya, Julius (57223292646); Wang, Changwon (57639564000); Jang, Kyoung-Mi (26638248500); Lee, Kunho (7409693862); Kim, Joong Il (23667374600); Kim, Jaeuk U. (35760349400)",57223292646; 57639564000; 26638248500; 7409693862; 23667374600; 35760349400,Inhibitory Control of Saccadic Eye Movements and Cognitive Impairment in Mild Cognitive Impairment,2022,Frontiers in Aging Neuroscience,14,,871432,,,,23,10.3389/fnagi.2022.871432,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128842402&doi=10.3389%2ffnagi.2022.871432&partnerID=40&md5=9732e6ad55e1b10d032e6b30520d6cc4,"Background: Mild cognitive impairment (MCI) may occur due to several forms of neurodegenerative diseases and non-degenerative conditions and is associated with cognitive impairment that does not affect everyday activities. For a timely diagnosis of MCI to prevent progression to dementia, a screening tool of fast, low-cost and easy access is needed. Recent research on eye movement hints it a potential application for the MCI screening. However, the precise extent of cognitive function decline and eye-movement control alterations in patients with MCI is still unclear. Objective: This study examined executive control deficits and saccade behavioral changes in patients with MCI using comprehensive neuropsychological assessment and interleaved saccade paradigms. Methods: Patients with MCI (n = 79) and age-matched cognitively healthy controls (HC) (n = 170) completed four saccadic eye-movement paradigms: prosaccade (PS)/antisaccade (AS), Go/No-go, and a battery of neuropsychological tests. Results: The findings revealed significantly longer latency in patients with MCI than in HC during the PS task. Additionally, patients with MCI had a lower proportion of correct responses and a marked increase in inhibition errors for both PS/AS and Go/No-go tasks. Furthermore, when patients with MCI made errors, they failed to self-correct many of these inhibition errors. In addition to the increase in inhibition errors and uncorrected inhibition errors, patients with MCI demonstrated a trend toward increased correction latencies. We also showed a relationship between neuropsychological scores and correct and error saccade responses. Conclusion: Our results demonstrate that, similar to patients with Alzheimer’s dementia (AD), patients with MCI generate a high proportion of erroneous saccades toward the prepotent target and fail to self-correct many of these errors, which is consistent with an impairment of inhibitory control and error monitoring. Significance: The interleaved PS/AS and Go/No-go paradigms are sensitive and objective at detecting subtle cognitive deficits and saccade changes in MCI, indicating that these saccadic eye movement paradigms have clinical potential as a screening tool for MCI. Copyright © 2022 Opwonya, Wang, Jang, Lee, Kim and Kim.",frontal/executive function; Go/No-go; inhibitory control; mild cognitive impairment; prosaccade/antisaccade; self-monitoring,aged; Alzheimer disease; antisaccade test; Article; clinical dementia rating scale; cognition; cognitive defect; controlled study; dementia; ethnicity; eye movement control; eye tracking; female; gaze; Go No Go task; human; major clinical study; male; mild cognitive impairment; Mini Mental State Examination; neuropsychological test; nuclear magnetic resonance imaging; prosaccade test; saccadic eye movement; scoring system; Seoul Neuropsychological Screening Battery; task performance,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128842402,Movies / Media
Johnson K.A.; Pontvianne A.; Ly V.; Jin R.; Januar J.H.; Machida K.; Sargent L.D.; Lee K.E.; Williams N.S.G.; Williams K.J.H.,"Johnson, Katherine A. (55697125600); Pontvianne, Annabelle (57670725500); Ly, Vi (57671327300); Jin, Rui (59586975700); Januar, Jonathan Haris (57671327500); Machida, Keitaro (57202948047); Sargent, Leisa D. (7005543100); Lee, Kate E. (55937971700); Williams, Nicholas S. G. (16148052800); Williams, Kathryn J. H. (56691900200)",55697125600; 57670725500; 57671327300; 59586975700; 57671327500; 57202948047; 7005543100; 55937971700; 16148052800; 56691900200,Water and Meadow Views Both Afford Perceived but Not Performance-Based Attention Restoration: Results From Two Experimental Studies,2022,Frontiers in Psychology,13,,809629,,,,10,10.3389/fpsyg.2022.809629,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129585044&doi=10.3389%2ffpsyg.2022.809629&partnerID=40&md5=f673de4a5945860eb49515b1039da800,"Attention Restoration Theory proposes that exposure to natural environments helps to restore attention. For sustained attention—the ongoing application of focus to a task, the effect appears to be modest, and the underlying mechanisms of attention restoration remain unclear. Exposure to nature may improve attention performance through many means: modulation of alertness and one’s connection to nature were investigated here, in two separate studies. In both studies, participants performed the Sustained Attention to Response Task (SART) before and immediately after viewing a meadow, ocean, or urban image for 40 s, and then completed the Perceived Restorativeness Scale. In Study 1 (n = 68), an eye-tracker recorded the participants’ tonic pupil diameter during the SARTs, providing a measure of alertness. In Study 2 (n = 186), the effects of connectedness to nature on SART performance and perceived restoration were studied. In both studies, the image viewed was not associated with participants’ sustained attention performance; both nature images were perceived as equally restorative, and more restorative than the urban image. The image viewed was not associated with changes in alertness. Connectedness to nature was not associated with sustained attention performance, but it did moderate the relation between viewing the natural images and perceived restorativeness; participants reporting a higher connection to nature also reported feeling more restored after viewing the nature, but not the urban, images. Dissociation was found between the physiological and behavioral measures and the perceived restorativeness of the images. The results suggest that restoration associated with nature exposure is not associated with modulation of alertness but is associated with connectedness with nature. Copyright © 2022 Johnson, Pontvianne, Ly, Jin, Januar, Machida, Sargent, Lee, Williams and Williams.",alertness; attention restoration theory; connectedness to nature; meadow; pupillometry; SART; sustained attention; waterscape,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85129585044,Movies / Media
Gowrishankar D.; Sathyasaravanan S.; Karthik V.; Kumar D.A.; Sankar U.G.,"Gowrishankar, Dhyaneshwar (57226893473); Sathyasaravanan, Shivani (57573738600); Karthik, Varshini (57081911600); Kumar, D. Ashok (58091021800); Sankar, U. Ganapathy (59663240200)",57226893473; 57573738600; 57081911600; 58091021800; 59663240200,Eye tracking to study eye gaze in juveniles with autism,2022,AIP Conference Proceedings,2405,,20009,,,,0,10.1063/5.0072445,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128080292&doi=10.1063%2f5.0072445&partnerID=40&md5=ebb742a66294afd5fc6154b5b0aabd60,"Eye contact is the first step to understand visual focus in a subject. However, in juveniles diagnosed with autism spectrum disorder, it has been observed that visual focus is not very thorough due to their increased sensory seeking impulsiveness. Eye tracking has been in use previously to determine the Visual Focus of Attention to understand eye gaze of the subject. The proposed system is an objective test for eye gaze tracking, while the juvenile is subjected to visual prompts on the screen. Using this method of study, it is possible to maintain a continued track of the subject's visual focus. We aim to observe the improvement in visual focus after the prescribed Sensory Seeking Intervention Therapy. The accuracy and response latency of the subjects are studied before and after intervention therapy, over a period of 2 weeks. The study includes n=6 autistic juveniles, with varying levels of gaze aversion, (male n=5 and female n=1) and severity of autism ranges from moderate to severe. The mean age of the subjects being 5 years. The progress in the participants‟ eye gaze showed significant improvement with sensory seeking therapy.  © 2022 Author(s).",,,Conference paper,Final,,Scopus,2-s2.0-85128080292,Movies / Media
David E.J.; Lebranchu P.; Da Silva M.P.; Callet P.L.,"David, Erwan Joël (57202111778); Lebranchu, Pierre (36128539400); Da Silva, Matthieu Perreira (24337440300); Callet, Patrick Le (57203923621)",57202111778; 36128539400; 24337440300; 57203923621,What are the visuo-motor tendencies of omnidirectional scene free-viewing in virtual reality?,2022,Journal of Vision,22,4,12,,,,9,10.1167/jov.22.4.12,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128000725&doi=10.1167%2fjov.22.4.12&partnerID=40&md5=7c61cac4dedda930d2fcab51eb80d3ea,"Central and peripheral vision during visual tasks have been extensively studied on two-dimensional screens, highlighting their perceptual and functional disparities. This study has two objectives: replicating on-screen gaze-contingent experiments removing central or peripheral field of view in virtual reality, and identifying visuo-motor biases specific to the exploration of 360 scenes with a wide field of view. Our results are useful for vision modelling, with applications in gaze position prediction (e.g., content compression and streaming). We ask how previous on-screen findings translate to conditions where observers can use their head to explore stimuli. We implemented a gaze-contingent paradigm to simulate loss of vision in virtual reality, participants could freely view omnidirectional natural scenes. This protocol allows the simulation of vision loss with an extended field of view (>80°) and studying the head's contributions to visual attention. The time-course of visuo-motor variables in our pure free-viewing task reveals long fixations and short saccades during first seconds of exploration, contrary to literature in visual tasks guided by instructions. We show that the effect of vision loss is reflected primarily on eye movements, in a manner consistent with two-dimensional screens literature. We hypothesize that head movements mainly serve to explore the scenes during free-viewing, the presence of masks did not significantly impact head scanning behaviours. We present new fixational and saccadic visuo-motor tendencies in a 360° context that we hope will help in the creation of gaze prediction models dedicated to virtual reality. © 2022. All Rights Reserved.",artificial vision loss; eye-movements; gaze-contingent paradigm; time-dynamics; virtual reality,"Eye Movements; Fixation, Ocular; Humans; Saccades; Virtual Reality; Visual Perception; eye fixation; eye movement; human; saccadic eye movement; virtual reality; vision",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128000725,Movies / Media
Cioana M.; Ranalli P.J.; Micieli J.A.,"Cioana, Milena (57215578869); Ranalli, Paul J. (16198761100); Micieli, Jonathan A. (35170784300)",57215578869; 16198761100; 35170784300,Transient Visual Obscurations as the Presenting Symptom of Papilledema from COVID-19-Related Cerebral Venous Sinus Thrombosis,2022,Case Reports in Ophthalmology,13,1,,185,190,5.0,0,10.1159/000522637,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127836000&doi=10.1159%2f000522637&partnerID=40&md5=969bcf45b2b03536c8cc32f339f66f4d,"Coronavirus disease-19 (COVID-19) patients are at an increased risk of cerebral venous sinus thrombosis (CVST). Rapid diagnosis and treatment are vital to ensure a favorable outcome for CVST, so clinicians need to be aware of all its potential presentations. We describe a unique case where transient visual obscurations (TVOs) from papilledema were the presenting symptoms of COVID-19-related CVST. A 43-year-old woman, who had tested positive for severe acute respiratory syndrome coronavirus-2 1 month earlier, developed holocephalic headache, TVOs, and bilateral disc edema. She did not seek medical attention until she developed TVOs. Visual acuity was 20/20 and Humphrey visual field testing showed enlarged blind spots in both eyes. She was diagnosed with papilledema and underwent magnetic resonance imaging and magnetic resonance venography of the brain, which revealed right transverse sinus thrombosis. Lumbar puncture was performed, showing elevated opening pressure and normal cerebrospinal fluid contents. Her optic disc edema resolved and visual function remained normal 6 weeks following warfarin and topiramate therapy. Recanalization of the right transverse sinus occurred after 3 months. Although rare, TVOs are important presenting symptoms of COVID-19-related CVST. Ophthalmologists, who may be the first physicians to assess patients with this presentation, should be aware of TVOs as potential presenting symptoms of CVST, so diagnoses can be made in a timely manner.  © 2022 Authors",Cerebral venous sinus thrombosis; Coronavirus diseae-19; Papilledema; Transient visual obscurations,acetazolamide; dipeptidyl carboxypeptidase; ferritin; hemoglobin; topiramate; warfarin; adult; afferent pupillary defect; Article; case report; cerebral sinus thrombosis; cerebrospinal fluid; clinical article; coronavirus disease 2019; drug substitution; emergency ward; eye examination; eye movement; female; fever; follow up; headache; human; lateral sinus thrombosis; lumbar puncture; magnetic resonance venography; neuroimaging; neuroophthalmology; nuclear magnetic resonance imaging; ophthalmologist; optometrist; papilledema; physician; rhinorrhea; transitional blindness; transverse sinus; Varicella zoster virus; venereal disease reaction test; visual acuity,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85127836000,Movies / Media
Ozdemir S.; Akin-Bulbul I.; Kok I.; Ozdemir S.,"Ozdemir, Selda (23985940600); Akin-Bulbul, Isik (57421376900); Kok, Ibrahim (57200283688); Ozdemir, Suat (23467461900)",23985940600; 57421376900; 57200283688; 23467461900,Development of a visual attention based decision support system for autism spectrum disorder screening,2022,International Journal of Psychophysiology,173,,,69,81,12.0,14,10.1016/j.ijpsycho.2022.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123262355&doi=10.1016%2fj.ijpsycho.2022.01.004&partnerID=40&md5=a5f804754e711ed4b57275f53b7f78dc,"Visual attention of young children with autism spectrum disorder (ASD) has been well documented in the literature for the past 20 years. In this study, we developed a Decision Support System (DSS) that uses machine learning (ML) techniques to identify young children with ASD from typically developing (TD) children. Study participants included 26 to 36 months old young children with ASD (n = 61) and TD children (n = 72). The results showed that the proposed DSS achieved up to 87.5% success rate in the early assessment of ASD in young children. Findings suggested that visual attention is a unique, promising biomarker for early assessment of ASD. Study results were discussed, and suggestions for future research were provided. © 2022 Elsevier B.V.",Autism spectrum disorders; Biomarker; Eye tracking; Machine learning; Screening; Visual attention,"Autism Spectrum Disorder; Biomarkers; Child; Child, Preschool; Humans; Machine Learning; biological marker; Article; autism; autism assessment; Bayley Scales of Infant Development; child; clinical feature; controlled study; decision support system; diagnostic accuracy; diagnostic test accuracy study; emotional disorder; empirical research; eye movement; eye tracking; feature selection; female; first-degree relative; hearing impairment; human; internal consistency; language processing; machine learning; major clinical study; male; preschool child; risk assessment; second-degree relative; social interaction; task performance; visual attention; visual impairment; machine learning",Article,Final,,Scopus,2-s2.0-85123262355,Movies / Media
Vortmann L.-M.; Schult M.; Putze F.,"Vortmann, Lisa-Marie (57211492447); Schult, Moritz (57211501519); Putze, Felix (22036416700)",57211492447; 57211501519; 22036416700,Differentiating Endogenous and Exogenous Attention Shifts Based on Fixation-Related Potentials,2022,"International Conference on Intelligent User Interfaces, Proceedings IUI",,,,243,257,14.0,0,10.1145/3490099.3511149,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127776312&doi=10.1145%2f3490099.3511149&partnerID=40&md5=abf345d6de25edec2e4342cd38772f2c,"Attentional shifts can occur voluntarily (endogenous control) or reflexively (exogenous control). Previous studies have shown that the neural mechanisms underlying these shifts produce different activity patterns in the brain. Changes in visual-spatial attention are usually accompanied by eye movements and a fixation on the new center of attention. In this study, we analyze the fixation-related potentials in electroencephalographic recordings of 10 participants during computer screen-based viewing tasks. During task performance, we presented salient visual distractors to evoke reflexive attention shifts. Surrounding each fixation, 0.7-second data windows were extracted and labeled as ""endogenous""or ""exogenous"". Averaged over all participants, the balanced classification accuracy using a person-dependent Linear Discriminant Analysis reached 59.84%. In a leave-one-participant-out approach, the average classification accuracy reached 58.48%. Differentiating attention shifts, based on fixation-related potentials, could be used to deepen the understanding of human viewing behavior or as a Brain-Computer Interface for attention-aware user interface adaptations.  © 2022 ACM.",Attention; EEG; endogenous; exogenous; fixation related potential; gaze detection; linear discriminant analysis,Behavioral research; Brain; Brain computer interface; Discriminant analysis; Eye movements; User interfaces; Attention; Attention shifts; Attentional shift; Classification accuracy; Endogenous; Exogenous; Fixation related potential; Gaze detection; Linear discriminant analyze; Neural mechanisms; Electroencephalography,Conference paper,Final,,Scopus,2-s2.0-85127776312,Movies / Media
Cavadini T.; Courbois Y.; Gentaz E.,"Cavadini, Thalia (57223026777); Courbois, Yannick (22034531800); Gentaz, Edouard (55917486200)",57223026777; 22034531800; 55917486200,Eye-tracking-based experimental paradigm to assess social-emotional abilities in young individuals with profound intellectual and multiple disabilities,2022,PLoS ONE,17,4-Apr,e0266176,,,,3,10.1371/journal.pone.0266176,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128318762&doi=10.1371%2fjournal.pone.0266176&partnerID=40&md5=87aaa73c183a71ad56f0c1a2f24992d6,"Individuals with Profound Intellectual and Multiple Disabilities (PIMD) experience a combination of severe cognitive and motor impairments frequently associated with additional sensory deficits and numerous medical disorders. The purpose of the present study was to propose an experimental paradigm based on eye-tracking that combines various pre-existing tasks from infancy research as an assessment tool. This would enable the investigation of social-emotional abilities in nine young individuals with PIMD through their visual preferences for different types of stimuli. The first objective was to test the feasibility of this paradigm, by expecting individuals to look more at the tasks’ presentation screen than elsewhere during its implementation. The second objective was to investigate whether PIMD individuals exhibit visual preferences for (a) biological (vs. non-biological) motion, (b) socially salient (vs. non-social) scenes, (c) the facial area of the eyes (vs. the mouth), (d) happy (vs. angry) faces, (e) objects of joint attention (vs. non-looked at ones), and for (f) prosocial (vs. anti-social) behaviors similar to those of a control group of typically developing children aged two years on average. Overall, the feasibility of this paradigm proved to be good, resulting in high individual looking rates that were not affected by the presentation or the content of the tasks. Analyses of individual social-emotional abilities, supported by the visual preference patterns of each PIMD individual, firstly revealed strong—but expected—variability both within and between subjects, and secondly highlighted some individual task-specific abilities although few similarities between these individual results and those of the control group were found. These findings underline the great relevance of using this type of paradigm for assessing PIMD individuals and thus contribute to a better understanding of their social and emotional development. Copyright: © 2022 Cavadini et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Attention; Blindness; Child; Disabled Persons; Emotions; Eye-Tracking Technology; Humans; Intellectual Disability; adolescent; anger; antisocial behavior; Article; attention; child; childhood; clinical article; controlled study; emotion; eye tracking; facial expression; female; happiness; human; intellectual impairment; male; motion; motor dysfunction; profound intellectual and multiple disability; prosocial behavior; psychosocial development; social behavior; visual stimulation; blindness; disabled person; emotion; psychology,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128318762,Movies / Media
Afzal U.; Prouzeau A.; Lawrence L.; Dwyer T.; Bichinepally S.; Liebman A.; Goodwin S.,"Afzal, Umair (57579357700); Prouzeau, Arnaud (57188737259); Lawrence, Lee (55920958800); Dwyer, Tim (13905632400); Bichinepally, Saikiranrao (57579357800); Liebman, Ariel (6701578250); Goodwin, Sarah (55570921400)",57579357700; 57188737259; 55920958800; 13905632400; 57579357800; 6701578250; 55570921400,Investigating Cognitive Load in Energy Network Control Rooms: Recommendations for Future Designs,2022,Frontiers in Psychology,13,,812677,,,,8,10.3389/fpsyg.2022.812677,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128421253&doi=10.3389%2ffpsyg.2022.812677&partnerID=40&md5=88ed0aacacb30a3edea6614d8b369e77,"This study analyzed and explored the cognitive load of Australian energy market operators managing one of the longest inter-connected electrical networks in the world. Each operator uses a workstation with seven screens in an active control room environment, with a large coordination screen to show information and enable collaboration between different control centers. Cognitive load was assessed during both training scenarios and regular control room operations via the integration of subjective and physiological measures. Eye-tracking glasses were also used to analyze the operators gaze behavior. Our results indicate that different events (normal or unexpected), different participants for the same session, and different periods of one session all have varying degrees of cognitive load. The system design was observed to be inefficient in some situations and to have an adverse affect on cognitive load. In critical situations for instance, operator collaboration was high and the coordination screen was used heavily when collaborating between two control centers, yet integration with the system could be improved. Eye tracking data analysis showed that the layout of applications across the seven screens was not optimal for many tasks. Improved layout strategies, potential combination of applications, redesigning of certain applications, and linked views are all recommended for further exploration in addition to improved integration of procedures and linking alarms to visual cues. Copyright © 2022 Afzal, Prouzeau, Lawrence, Dwyer, Bichinepally, Liebman and Goodwin.",cognitive load; control room; energy market operators; eye tracking; situational awareness,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128421253,Movies / Media
Doherty S.; Martschuk N.; Goodman-Delahunty J.; Hale S.,"Doherty, Stephen (56137159600); Martschuk, Natalie (56565641500); Goodman-Delahunty, Jane (6603176622); Hale, Sandra (7102877058)",56137159600; 56565641500; 6603176622; 7102877058,An Eye-Movement Analysis of Overt Visual Attention During Consecutive and Simultaneous Interpreting Modes in a Remotely Interpreted Investigative Interview,2022,Frontiers in Psychology,13,,764460,,,,6,10.3389/fpsyg.2022.764460,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128305433&doi=10.3389%2ffpsyg.2022.764460&partnerID=40&md5=cfcdce318cbd1fd82248097a0092c377,"Remote interpreting via video-link is increasingly being employed in investigative interviews chiefly due to its apparent increased accessibility and efficiency. However, risks of miscommunication have been shown to be magnified in remote interpreting and empirical research specifically on video-link remote interpreting is in its infancy which greatly limits the evidence base available to inform and direct evidence-based policy and best practice, particularly in the identification of the optimal mode(s) of interpreting to be used, namely consecutive and simultaneous. Consecutive interpreting refers to a process in which the interpreter transfers short segments of speech from one language into the other as each person speaks in managed turn-taking, while simultaneous interpreting refers to the transfer of natural speech from one language into another in a concurrent manner without the need for speakers to segment their speech. This study provides novel empirical evidence by using eye tracking to compare the overt visual attention of interpreters working in a remote setting in which an English-speaking Interviewer interacts with a non-English-speaking Suspect in person, for whom interpretation is provided via video-link in real time. Using a within-subject design, we analyze eye-movement data from 28 professionally accredited interpreters who interpreted via video-link an investigative interview in which consecutive and simultaneous interpreting modes were counterbalanced. Taking interpreting performance into account, our results showed that, the consecutive mode yielded significantly less gaze time and therefore significantly less on-screen overt visual attention due to off-screen notetaking, an essential component of the consecutive interpreting mode. Relative to gaze time, the consecutive mode also resulted in significantly more and longer fixations and shifts of attention. Participants also allocated significantly more overt visual attention to the Interviewer than the Suspect, particularly in the consecutive mode. Furthermore, we found informative significant correlations between eye tracking measures and interpreting performance: accuracy, verbal rapport, and management. Finally, we found no significant differences between the three language pairs tested. We conclude with a discussion of limitations and the contributions of the study and an outline for future work on this topic of growing importance. Copyright © 2022 Doherty, Martschuk, Goodman-Delahunty and Hale.",consecutive interpreting; interpreting mode; investigative interview; remote interpreting; simultaneous interpreting,,Article,Final,,Scopus,2-s2.0-85128305433,Movies / Media
Děchtěrenko F.; Jakubková D.; Lukavský J.; Howard C.J.,"Děchtěrenko, Filip (55987134200); Jakubková, Daniela (57491289400); Lukavský, Jiří (23091670300); Howard, Christina J. (23978102100)",55987134200; 57491289400; 23091670300; 23978102100,Tracking multiple fish,2022,PeerJ,10,,e13031,,,,2,10.7717/peerj.13031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126512632&doi=10.7717%2fpeerj.13031&partnerID=40&md5=1426f4694de1decbf45cd88f1b6130c4,"Although the Multiple Object Tracking (MOT) task is a widely used experimental method for studying divided attention, tracking objects in the real world usually looks different. For example, in the real world, objects are usually clearly distinguishable from each other and also possess different movement patterns. One such case is tracking groups of creatures, such as tracking fish in an aquarium. We used movies of fish in an aquarium and measured general tracking performance in this task (Experiment 1). In Experiment 2, we compared tracking accuracy within-subjects in fish tracking, tracking typical MOT stimuli, and in a third condition using standard MOT uniform objects which possessed movement patterns similar to the real fish. This third condition was added to further examine the impact of different motion characteristics on tracking performance. Results within a Bayesian framework showed that tracking real fish shares similarities with tracking simple objects in a typical laboratory MOT task. Furthermore, we observed a close relationship between performance in both laboratory MOT tasks (typical and fish-like) and real fish tracking, suggesting that the commonly used laboratory MOT task possesses a good level of ecological validity. © 2022 Děchtěrenko et al.",Attention; Ecological validity; Fish; Modelling; Multiple object tracking,accuracy; adult; Article; attention; Bayes theorem; data analysis; ecological validity; eye tracking; female; fish; human; multiple object tracking; nonhuman; stimulus; task performance; taxonomy; videorecording; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85126512632,Movies / Media
Burris J.L.; Reider L.B.; Oleas D.S.; Gunther K.E.; Buss K.A.; Pérez-Edgar K.; Field A.P.; LoBue V.,"Burris, Jessica L. (57547657400); Reider, Lori B. (57211440339); Oleas, Denise S. (57211444487); Gunther, Kelley E. (57223359431); Buss, Kristin A. (6603842341); Pérez-Edgar, Koraly (8768724000); Field, Andy P. (7102408715); LoBue, Vanessa (23968071200)",57547657400; 57211440339; 57211444487; 57223359431; 6603842341; 8768724000; 7102408715; 23968071200,Moderating effects of environmental stressors on the development of attention to threat in infancy,2022,Developmental Psychobiology,64,3,e22241,,,,6,10.1002/dev.22241,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126814971&doi=10.1002%2fdev.22241&partnerID=40&md5=b110e832973e4ab0d9a1436abde3d7d5,"An attention bias to threat has been linked to psychosocial outcomes across development, including anxiety (Pérez-Edgar, K., Bar-Haim, Y., McDermott, J. M., Chronis-Tuscano, A., Pine, D. S., & Fox, N. A. (2010). Attention biases to threat and behavioral inhibition in early childhood shape adolescent social withdrawal. Emotion (Washington, D.C.), 10(3), 349). Although some attention biases to threat are normative, it remains unclear how these biases diverge into maladaptive patterns of emotion processing for some infants. Here, we examined the relation between household stress, maternal anxiety, and attention bias to threat in a longitudinal sample of infants tested at 4, 8, and 12 months. Infants were presented with a passive viewing eye-tracking task in which angry, happy, or neutral facial configurations appeared in one of the four corners of a screen. We measured infants’ latency to fixate each target image and collected measures of parental anxiety and daily hassles at each timepoint. Intensity of daily parenting hassles moderated patterns of attention bias to threat in infants over time. Infants exposed to heightened levels of parental hassles became slower to detect angry (but not happy) facial configurations compared with neutral faces between 4 and 12 months of age, regardless of parental anxiety. Our findings highlight the potential impact of the environment on the development of infants’ early threat processing and the need to further investigate how early environmental factors shape the development of infant emotion processing. © 2022 Wiley Periodicals LLC",anxiety; biased attention; infant attention; parenting hassles; threat detection,"Adolescent; Anxiety; Anxiety Disorders; Attentional Bias; Child, Preschool; Emotions; Happiness; Humans; Infant; adolescent; anxiety; anxiety disorder; attentional bias; emotion; happiness; human; infant; physiology; preschool child; psychology",Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85126814971,Movies / Media
Feng D.; Lu C.; Cai Q.; Lu J.,"Feng, Di (57203685643); Lu, Chunfu (56174621500); Cai, Qingli (57427663600); Lu, Jun (57580301800)",57203685643; 56174621500; 57427663600; 57580301800,A Study on the Design of Vision Protection Products Based on Children’s Visual Fatigue under Online Learning Scenarios,2022,Healthcare (Switzerland),10,4,621,,,,4,10.3390/healthcare10040621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128398538&doi=10.3390%2fhealthcare10040621&partnerID=40&md5=8f53a6c786f4e73441741c7b33d3f8db,"The rate of myopia in children is increasing rapidly under online learning scenarios. One of the important reasons for this is incorrect reading and writing posture. Three screen view parameters (viewing angle, viewing height, and viewing distance) are selected as significant influencing factors and blink rating is used as a sign of visual fatigue through literature analysis to study the influence factors of myopia in children, and their correlation. Children’s visual fatigue is evaluated by subjective evaluation and is recording using an eye tracker for changes in the three factors through online learning scenario simulation experiment. An optimal regression model is constructed that illustrates the relationship between the three variables and the visual fatigue levels. The aim of this study is to confirm the quantitative relationship between the screen view parameters and visual fatigue, and to design a child vision protection product on this basis. The test results show there is a linear positive correlation between the viewing angle, viewing height, and viewing distance. A vision protection device has been designed based on this model and was verified through function prototype testing. The result of this study quantified the relationship among screen view parameters and children’s visual fatigue, which provides a theoretical basis for the design of a children’s visual protection device. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",children’s visual fatigue; online learning; screen view parameters; vision protection product,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128398538,Movies / Media
Cheng D.; Miao X.; Wu H.; Chen C.; Chen Q.; Zhou X.,"Cheng, Dazhi (55352855300); Miao, Xinyang (57225980718); Wu, Haiyan (55703718500); Chen, Chuansheng (8555006800); Chen, Qian (56609483900); Zhou, Xinlin (14025132500)",55352855300; 57225980718; 55703718500; 8555006800; 56609483900; 14025132500,"Dyscalculia and dyslexia in Chinese children with idiopathic epilepsy: Different patterns of prevalence, comorbidity, and gender differences",2022,Epilepsia Open,7,1,,160,169,9.0,9,10.1002/epi4.12577,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123712273&doi=10.1002%2fepi4.12577&partnerID=40&md5=3aab897094fa78a1676fbb9649885a1f,"Objective: The present study aimed to examine the prevalence of dyscalculia, dyslexia, and their comorbidity rates in a large population-based sample of children with idiopathic epilepsy (N = 2282) and a comparison sample of typically developing schoolchildren (N = 2371). Methods: Both groups of children were screened using an arithmetic fluency test for dyscalculia and a reading fluency test for dyslexia. Their comorbidity rates were assessed. The prevalence rates of dyscalculia, dyslexia, comorbidity, and isolated dyscalculia/dyslexia (ie, participants with comorbid dyslexia and dyscalculia were excluded) were analyzed. Results: In both −1.5 SD and −1 SD cutoff criterion, the prevalence rates were about two times higher in children with idiopathic epilepsy than in other schoolchildren; the prevalence rates of isolated dyslexia were higher in children with idiopathic epilepsy than in other schoolchildren (−1 SD: 10.9% vs 8.6%; −1.5 SD: 6.5% vs 4.7%). Meanwhile, comorbidity rates of dyscalculia and dyslexia were higher in children with idiopathic epilepsy than in other schoolchildren (32.7% vs 26.6%; 38.3% vs 23.5%, respectively). Overall, patterns of prevalence rates were different for children with idiopathic epilepsy and schoolchildren, in which children with idiopathic epilepsy had a higher prevalence rate of dyscalculia than dyslexia, while schoolchildren had a higher prevalence of dyslexia than dyscalculia, regardless of cutoff criteria. Interestingly, gender differences in the prevalence rates of all types of learning disabilities were found in schoolchildren, but there were only gender differences in the prevalence rates of dyslexia in children with idiopathic epilepsy. Significance: The results highlight the vulnerability of children with idiopathic epilepsy for learning disabilities and a differential pattern of gender differences in dyslexia. Moreover, different patterns of prevalence rates suggest that children with idiopathic epilepsy and schoolchildren are more prone to different types of learning disabilities. The findings suggest needs for special interventions of learning disabilities for children with idiopathic epilepsy. © 2022 The Authors. Epilepsia Open published by Wiley Periodicals LLC on behalf of International League Against Epilepsy.",dyscalculia; dyslexia; idiopathic epilepsy; prevalence; school children,Child; China; Comorbidity; Dyscalculia; Dyslexia; Epilepsy; Humans; Prevalence; Sex Factors; adolescent; arithmetic fluency test; Article; autism; benign childhood epilepsy with centrotemporal spikes; child; childhood absence epilepsy; China; cognition assessment; comorbidity; dyscalculia; dyslexia; electroencephalogram; electroencephalography; executive function test; eye movement; female; frontal lobe epilepsy; generalized epilepsy; generalized tonic clonic seizures; human; learning disorder; Lennox Gastaut syndrome; major clinical study; male; math fluency test; mental deficiency; myoclonus epilepsy; nonrapid eye movement; nonverbal matrices reasoning test; nuclear magnetic resonance imaging; panayiotopoulos syndrome; parietal lobe epilepsy; prevalence; Raven's Progressive Matrices test; reading fluency test; school child; seizure; sex difference; sleep discharge index; temporal lobe epilepsy; comorbidity; epilepsy; prevalence; sex factor,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85123712273,Movies / Media
Ha J.; Park S.; Im C.-H.,"Ha, Jisoo (57223105668); Park, Seonghun (57209980475); Im, Chang-Hwan (7005671177)",57223105668; 57209980475; 7005671177,Novel Hybrid Brain-Computer Interface for Virtual Reality Applications Using Steady-State Visual-Evoked Potential-Based Brain–Computer Interface and Electrooculogram-Based Eye Tracking for Increased Information Transfer Rate,2022,Frontiers in Neuroinformatics,16,,758537,,,,17,10.3389/fninf.2022.758537,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126250305&doi=10.3389%2ffninf.2022.758537&partnerID=40&md5=3f0ebf124eb8c34fc17dbe7eda0f252a,"Brain–computer interfaces (BCIs) based on electroencephalogram (EEG) have recently attracted increasing attention in virtual reality (VR) applications as a promising tool for controlling virtual objects or generating commands in a “hands-free” manner. Video-oculography (VOG) has been frequently used as a tool to improve BCI performance by identifying the gaze location on the screen, however, current VOG devices are generally too expensive to be embedded in practical low-cost VR head-mounted display (HMD) systems. In this study, we proposed a novel calibration-free hybrid BCI system combining steady-state visual-evoked potential (SSVEP)-based BCI and electrooculogram (EOG)-based eye tracking to increase the information transfer rate (ITR) of a nine-target SSVEP-based BCI in VR environment. Experiments were repeated on three different frequency configurations of pattern-reversal checkerboard stimuli arranged in a 3 × 3 matrix. When a user was staring at one of the nine visual stimuli, the column containing the target stimulus was first identified based on the user’s horizontal eye movement direction (left, middle, or right) classified using horizontal EOG recorded from a pair of electrodes that can be readily incorporated with any existing VR-HMD systems. Note that the EOG can be recorded using the same amplifier for recording SSVEP, unlike the VOG system. Then, the target visual stimulus was identified among the three visual stimuli vertically arranged in the selected column using the extension of multivariate synchronization index (EMSI) algorithm, one of the widely used SSVEP detection algorithms. In our experiments with 20 participants wearing a commercial VR-HMD system, it was shown that both the accuracy and ITR of the proposed hybrid BCI were significantly increased compared to those of the traditional SSVEP-based BCI in VR environment. Copyright © 2022 Ha, Park and Im.",brain-computer interface; electroencephalogram; electrooculogram; steady state visual evoked potential; virtual reality,accuracy; Article; clinical article; detection algorithm; electroencephalogram; electrooculogram; eye movement; eye tracking; female; head movement; human; human experiment; male; normal human; steady state; videooculography; virtual reality; visual evoked potential; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85126250305,Movies / Media
Ba F.; Sang T.T.; He W.; Fatehi J.; Mostofi E.; Zheng B.,"Ba, Fang (6603835734); Sang, Tina T. (57248283900); He, Wenjing (55945245700); Fatehi, Jaleh (57070161200); Mostofi, Emanuel (57203084121); Zheng, Bin (35294347300)",6603835734; 57248283900; 55945245700; 57070161200; 57203084121; 35294347300,Stereopsis and Eye Movement Abnormalities in Parkinson’s Disease and Their Clinical Implications,2022,Frontiers in Aging Neuroscience,14,,783773,,,,15,10.3389/fnagi.2022.783773,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125082480&doi=10.3389%2ffnagi.2022.783773&partnerID=40&md5=8294e6a0cb9e90339b488327621aed77,"Background: Parkinson’s disease (PD) is not exclusively a motor disorder. Among non-motor features, patients with PD possess sensory visual dysfunctions. Depth perception and oculomotor deficits can significantly impact patients’ motor performance. Stereopsis and eye behavioral study using 3D stimuli may help determine their implications in disease status. Objective: The objective of this study is to investigate stereopsis and eye movement abnormalities in PD with reliable tools and their correlation with indicators of PD severity. We hypothesize that patients with PD exhibit different eye behaviors and that these differences may correlate to the severity of motor symptoms and cognitive status. Methods: Control and PD participants were first evaluated for visual acuity, visual field, contrast acuity, and stereo perception with 2D and Titmus stereotests, followed by the assessment with a 3D active shutter system. Eye movement behaviors were assessed by a Tobii X2-60 eye tracker. Results: Screening visual tests did not reveal any differences between the PD and control groups. With the 3D active shutter system, the PD group demonstrated significantly worse stereopsis. The preserved cognitive function was correlated to a more intact stereo function. Patients with PD had longer visual response times, with a higher number of fixations and bigger saccade amplitude, suggesting fixation stabilization difficulties. Such changes showed a positive correlation with the severity of motor symptoms and a negative correlation with normal cognitive status. Conclusion: We assessed stereopsis with a 3D active shutter system and oculomotor behaviors with the Tobii eye tracker. Patients with PD exhibit poorer stereopsis and impaired oculomotor behaviors during response time. These deficits were correlated with PD motor and cognitive status. The visual parameters may potentially serve as the clinical biomarkers for PD. Copyright © 2022 Ba, Sang, He, Fatehi, Mostofi and Zheng.",biomarker; cognition; extraocular movements; Parkinson’s disease; stereopsis,biological marker; levodopa; Article; clinical feature; comparative study; control group; demography; depth perception; device comparison; disease duration; disease severity assessment; eye movement disorder; geriatric patient; health status; human; mental disease assessment; Montreal cognitive assessment; motor dysfunction; Parkinson disease; saccadic eye movement; stereoscopic vision; vision test; visual acuity; visual disorder; visual field; visual reaction time,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85125082480,Movies / Media
Leppänen J.M.; Butcher J.W.; Godbout C.; Stephenson K.; Taylor Hendrixson D.; Griswold S.; Rogers B.L.; Webb P.; Koroma A.S.; Manary M.J.,"Leppänen, Jukka M (36777388300); Butcher, Julius Walker (57456488500); Godbout, Claire (57216152962); Stephenson, Kevin (35743932100); Taylor Hendrixson, D. (57200446592); Griswold, Stacy (57226159031); Rogers, Beatrice Lorge (7202486872); Webb, Patrick (7202522327); Koroma, Aminata S. (57212306299); Manary, Mark J (7004540804)",36777388300; 57456488500; 57216152962; 35743932100; 57200446592; 57226159031; 7202486872; 7202522327; 57212306299; 7004540804,Assessing infant cognition in field settings using eye-tracking: A pilot cohort trial in Sierra Leone,2022,BMJ Open,12,2,e049783,,,,7,10.1136/bmjopen-2021-049783,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124776902&doi=10.1136%2fbmjopen-2021-049783&partnerID=40&md5=1f25cc640075dca5679b94cec8d53417,"Objectives To investigate the feasibility of eye-tracking-based testing of the speed of visual orienting in malnourished young children at rural clinics in Sierra Leone. Design Prospective dual cohort study nested in a cluster-randomised trial. Setting 8 sites participating in a cluster-randomised trial of supplementary feeding for moderate acute malnutrition (MAM). Participants For the MAM cohort, all infants aged 7-11 months at the eight sites were enrolled, 138 altogether. For controls, a convenience sample of all non-malnourished infants aged 7-11 months at the same sites were eligible, 60 altogether. A sample of 30 adults at the sites also underwent eye-tracking tests as a further control. Interventions Infants with MAM were provided with supplementary feeding. Outcome measures The primary outcomes were feasibility and reliability of eye-tracking-based testing of saccadic reaction time (SRT). Feasibility was assessed by the percent of successful tests in the infants. Reliability was measured with intraclass correlation coefficients (ICCs). Secondary outcomes were mean SRT based on nutritional state as well as and changes in mean SRT after supplementary feeding of MAM children. Results Infants exhibited consistent orienting to targets on a computer screen (>95% of valid trials). Mean SRTs had moderate stability within visits (ICCs 0.60-0.69) and across the 4-week test-retest interval (0.53) in infants; the adult control group had greater SRT stability (within visit ICC=0.92). MAM infants had a trend toward higher adjusted SRT at baseline (difference=12.4 ms, 95% CI -2 to 26.9, p=0.09) and improvement in SRT 4 weeks thereafter (difference=-14 ms, 95% CI -26.2 to -1.7, p=0.025) compared with age-matched controls. Conclusions The results demonstrate the feasibility of eye-tracking-based testing in a resource-poor field setting and suggest eye-tracking measures have utility in the detection of group level effects of supplementary feeding.  © ",developmental neurology & neurodisability; nutrition; paediatric neurology,"Adult; Child; Child, Preschool; Cognition; Cohort Studies; Eye-Tracking Technology; Humans; Infant; Prospective Studies; Reproducibility of Results; Sierra Leone; amylase; vegetable oil; anthropometry; arm circumference; Article; clinical article; cognition; cohort analysis; comparative study; controlled study; cost effectiveness analysis; eye tracking; feasibility study; female; fortified food; human; infant; infant feeding; intervention study; male; malnutrition; nutritional status; pilot study; prospective study; pupil diameter; randomized controlled trial; ready to use supplementary food; saccadic eye movement; Sierra Leone; smooth pursuit eye movement; social problem; vision; visual reaction time; adult; child; preschool child; reproducibility",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85124776902,Movies / Media
Wang Y.; Wang Y.; Huo L.; Li Q.; Chen J.; Wang H.,"Wang, Yumin (57768358100); Wang, Yanchao (57238113400); Huo, Liang (55496661600); Li, Qiang (57248362700); Chen, Jichao (57771945300); Wang, Hongquan (35184438800)",57768358100; 57238113400; 55496661600; 57248362700; 57771945300; 35184438800,SARS-CoV-2-associated acute disseminated encephalomyelitis: a systematic review of the literature,2022,Journal of Neurology,269,3,,1071,1092,21.0,36,10.1007/s00415-021-10771-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113862406&doi=10.1007%2fs00415-021-10771-8&partnerID=40&md5=8710bcbc4791f30536cb030e72f361bd,"The literature on cases of acute disseminated encephalomyelitis (ADEM) associated with SARS-CoV-2 infection has been rapidly increasing. However, the specific clinical features of ADEM associated with SARS-CoV-2 (SARS-CoV-2-ADEM) have not been previously evaluated. We screened all articles resulting from a search of PubMed and Web of Science databases looking for reports of ADEM published between December 01, 2019, and June 5, 2021. Of the 48 ADEM cases identified from 37 studies, 34 (71%) had ADEM while 14 (29%) were of AHLE. RT-PCR for SARS-CoV-2 was positive in 83% (n = 19) of patients. 26 patients (54%) were male, and 18 patients (38%) were female, with a male to female sex ratio of 1.4:1; median age was 44 (1.4–71) years. 9 patients (19%, 9/48) were children. Of the 9 children patients, their median age was 9 years (range 1.4–13 years), 6 patients (67%) were female, and 2 patients (22%) were male, with a female to male sex ratio of 3:1.39 patients (81%) was performed CSF analysis. PCR for SARS-CoV-2 tested positive in 3 patients (14%, 3/22) on CSF sample. 31 (64%) of patients had a poor outcome on discharge from hospital. Five (10%) patients died in hospital. Compared to classic ADEM, SARS-CoV-2-ADEM have a more longer duration between the onset of the antecedent infective symptoms and the start of ADEM symptoms, the older age distribution of the patients, relatively poor outcome, a lower full recovery rate, a more frequently brain lesions involved the periventricular white matter and corpus callosum, and less frequently affected the deep gray matter. Taken together, the present comprehensive review reveals that although rare, ADEM can be associated with SARS-CoV-2 infection. SARS-CoV-2-ADEM seems to share most features of classic ADEM, with moderate discrepancies from the classical ADEM. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.",Acute disseminated encephalomyelitis; Clinical features; COVID-19; SARS-CoV-2,"Adolescent; Adult; Child; Child, Preschool; Corpus Callosum; COVID-19; Encephalomyelitis, Acute Disseminated; Female; Humans; Infant; Male; Nervous System Diseases; SARS-CoV-2; aciclovir; anakinra; antibiotic agent; aquaporin 4 antibody; azithromycin; dexamethasone; glucose; hydroxychloroquine; hypertensive factor; immunoglobulin; immunoglobulin G; lopinavir plus ritonavir; methylprednisolone; prednisolone; remdesivir; rituximab; steroid; virus RNA; acute disseminated encephalomyelitis; acute hemorrhagic leukoencephalitis; acute respiratory failure; adolescent; adult; age distribution; aged; ageusia; agitation; altered state of consciousness; anosmia; antibody detection; aphasia; areflexia; arm weakness; ataxia; Babinski reflex; backache; behavior disorder; brain damage; brain disease; brain radiography; brain stem injury; cerebellum disease; cerebrospinal fluid analysis; child; clinical feature; clonus; confusion; consciousness disorder; contrast enhancement; convalescence; convalescent plasma therapy; cornea disease; coronavirus disease 2019; corpus callosum; coughing; COVID-19 nucleic acid testing; COVID-19 serological testing; cubital tunnel syndrome; decreased appetite; diarrhea; disease association; disease duration; drowsiness; dry cough; dyspnea; erythema; erythrocyte count; eye movement disorder; face disorder; fatigue; female; fever; flu like syndrome; gait disorder; geographic distribution; glucose level; gray matter; headache; hemiparesis; hemiplegia; hospital discharge; human; hyperreflexia; hyporeflexia; hyposmia; hypoxia; immunotherapy; in-hospital mortality; incontinence; lethargy; leukocyte count; limb weakness; loss of appetite; lung congestion; lymphocyte count; malaise; male; Medline; meningoencephalitis; middle aged; motor dysfunction; muscle hypotonia; muscle weakness; myalgia; nasopharyngeal swab; neck swelling; nuclear magnetic resonance imaging; ophthalmoplegia; paraplegia; paresthesia; plasma exchange; pleocytosis; positivity rate; preschool child; protein cerebrospinal fluid level; pupil disease; pyramidal sign; quadriplegia; rash; real time polymerase chain reaction; respiratory distress; respiratory failure; Review; school child; seizure; sensory dysfunction; sex ratio; speech disorder; spine radiography; sputum analysis; stiff neck; systematic review; thorax pain; tonic clonic seizure; unsteadiness; unsteady gait; urine incontinence; urine retention; visual impairment; vomiting; walking difficulty; weakness; Web of Science; white matter lesion; young adult; acute disseminated encephalomyelitis; infant; neurologic disease; pathology",Review,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85113862406,Movies / Media
Martinez-Levy A.C.; Rossi D.; Cartocci G.; Mancini M.; Di Flumeri G.; Trettel A.; Babiloni F.; Cherubino P.,"Martinez-Levy, Ana C. (57204218022); Rossi, Dario (57201867718); Cartocci, Giulia (52263349900); Mancini, Marco (57193548664); Di Flumeri, Gianluca (56647980200); Trettel, Arianna (55936931600); Babiloni, Fabio (7006787992); Cherubino, Patrizia (54894299700)",57204218022; 57201867718; 52263349900; 57193548664; 56647980200; 55936931600; 7006787992; 54894299700,"Message framing, non-conscious perception and effectiveness in non-profit advertising. Contribution by neuromarketing research",2022,International Review on Public and Nonprofit Marketing,19,1,,53,75,22.0,20,10.1007/s12208-021-00289-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107412250&doi=10.1007%2fs12208-021-00289-0&partnerID=40&md5=faa4963d76a91d3d74b27d47955fb9c1,"Advertising for non-profit organizations through television commercials is a valuable means of communication to raise awareness and receive donations. When it comes to social aspects, personal attitudes such as empathy are significant for reinforcing the intention to donate; and the study of eliciting emotions has critical attention in the literature, especially some types of emotion, such as guilt which mediates empathy. Different methodologies have been used to measure consumer emotions when faced with TV ads stimuli: mainly traditional techniques such as interviews or questionnaires after the ads viewing. In the last ten years, there has also been a great interest in new neuroscience techniques applied to measure emotional and cognitive reactions by physiological signals, frame by frame. Our research has applied neuromarketing technologies during the observation of a UNHCR commercial promoting legacy calls. The objective was to study cognitive and emotional reactions in order to increase the effectiveness whilst having the possibility to verify the results by measuring the benefits in terms of calls from contributors. The purpose of this research is to empirically prove the impact in calls thanks to changes in the message framing strategy in non-profit advertising suggested and measured by neuromarketing techniques. Particularly we measured the cerebral activity through an electroencephalogram to obtain an Approach-Withdrawal Index (AW); the heart rate and galvanic skin response through different sensors in the palm of one hand, to obtain an Emotional Index (EI), and finally, eye fixations through an eye tracker device to obtain the visual attention on key visual areas of the ads. After these indicators’ recordings on a sample of subjects, some suggestions to modify the advertising were made to create a more effective campaign. The results compared, those elicited by the first version of the spot (LVE) and those by the second version (HVE), confirmed that (1) the number of sellable and legacy calls increased with the message framing strategy modified in the second spot (HVE), (2) a lower cognitive and emotional reactions have been obtained in the final section of HVE, (3) the visual attention on the key information of the phone number to call, in the final call to action frames(CTA), was higher in HVE than in the first version of the spot (LVE), (4) the cognitive approach increased during the same CTA frames in HVE. © 2021, The Author(s).",Call to action; Effectiveness; Emotion; Neuromarketing; Non-Profit Advertising,,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85107412250,Movies / Media
D'Anselmo A.; Pisani A.; Brancucci A.,"D'Anselmo, Anita (57226817694); Pisani, Angelo (57453777300); Brancucci, Alfredo (6602326908)",57226817694; 57453777300; 6602326908,A tentative I/O curve with consciousness: Effects of multiple simultaneous ambiguous figures presentation on perceptual reversals and time estimation,2022,Consciousness and Cognition,99,,103300,,,,2,10.1016/j.concog.2022.103300,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124656349&doi=10.1016%2fj.concog.2022.103300&partnerID=40&md5=044c3c2f93247b4018b21d1f4934846b,"This study was aimed at investigating mechanisms of consciousness using bistable perception. In 4 experimental conditions, 1, 2, 4 or 8 Rubin's face-vase ambiguous figures were presented for 3 min. In Experiment 1, 40 subjects looked at the center of the screen and pressed a specific key correspondent to the figure where they perceived a reversal. In Experiment 2, 32 subjects controlled with eye-tracker performed a similar task in which they pressed the spacebar whenever they perceived a reversal in any of the figures. At the end of each condition subjects estimated its duration. Results showed that changing the number of figures does not alter the number of reversals, producing a flat I/O curve between the two parameters. Estimated time lapse showed a negative correlation with the number of reversals. These findings are discussed considering the relationships between bistable perception, attention, and consciousness, as well as the time perception literature. © 2022 Elsevier Inc.",Attention; Bistable perception; Consciousness; Time perception,Attention; Consciousness; Humans; Photic Stimulation; Visual Perception; adult; Article; attention; consciousness; female; human; male; perception; time perception; attention; photostimulation; procedures; vision,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85124656349,Movies / Media
Lev A.; Braw Y.; Elbaum T.; Wagner M.; Rassovsky Y.,"Lev, Astar (57210336427); Braw, Yoram (8539894400); Elbaum, Tomer (57119933100); Wagner, Michael (57118771600); Rassovsky, Yuri (57203179107)",57210336427; 8539894400; 57119933100; 57118771600; 57203179107,Eye Tracking During a Continuous Performance Test: Utility for Assessing ADHD Patients,2022,Journal of Attention Disorders,26,2,,245,255,10.0,35,10.1177/1087054720972786,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096798567&doi=10.1177%2f1087054720972786&partnerID=40&md5=3d6bec5dcf016d45c0f539ffd615d5db,"Objective: The use of continuous performance tests (CPTs) for assessing ADHD related cognitive impairment is ubiquitous. Novel psychophysiological measures may enhance the data that is derived from CPTs and thereby improve clinical decision-making regarding diagnosis and treatment. As part of the current study, we integrated an eye tracker with the MOXO-dCPT and assessed the utility of eye movement measures to differentiate ADHD patients and healthy controls. Method: Adult ADHD patients and gender/age-matched healthy controls performed the MOXO-dCPT while their eye movements were monitored (n = 33 per group). Results: ADHD patients spent significantly more time gazing at irrelevant regions, both on the screen and outside of it, than healthy controls. The eye movement measures showed adequate ability to classify ADHD patients. Moreover, a scale that combined eye movement measures enhanced group prediction, compared to the sole use of conventional MOXO-dCPT indices. Conclusions: Integrating an eye tracker with CPTs is a feasible way of enhancing diagnostic precision and shows initial promise for clarifying the cognitive profile of ADHD patients. Pending replication, these findings point toward a promising path for the evolution of existing CPTs. © ©The Author(s) 2020.",ADHD; continuous performance tests; eye movements; MOXO-dCPT,Adult; Attention Deficit Disorder with Hyperactivity; Eye Movements; Eye-Tracking Technology; Humans; Neuropsychological Tests; adult; attention deficit hyperactivity disorder; eye movement; human; neuropsychological test; psychology,Article,Final,,Scopus,2-s2.0-85096798567,Movies / Media
Yang Y.; Gao Q.; Song Y.; Song X.; Mao Z.; Liu J.,"Yang, Yi (57217078240); Gao, Qiang (56486664800); Song, Yu (57191511945); Song, Xiaolin (57201767441); Mao, Zemin (57204600538); Liu, Junjie (59266827000)",57217078240; 56486664800; 57191511945; 57201767441; 57204600538; 59266827000,Investigating of Deaf Emotion Cognition Pattern by EEG and Facial Expression Combination,2022,IEEE Journal of Biomedical and Health Informatics,26,2,,589,599,10.0,38,10.1109/JBHI.2021.3092412,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113226248&doi=10.1109%2fJBHI.2021.3092412&partnerID=40&md5=2026238a071ab761dbc4c770503ba4f1,"With the development of sensor technology and learning algorithms, multimodal emotion recognition has attracted widespread attention. Many existing studies on emotion recognition mainly focused on normal people. Besides, due to hearing loss, deaf people cannot express emotions by words, which may have a greater need for emotion recognition. In this paper, the deep belief network (DBN) was utilized to classify three category emotions through the electroencephalograph (EEG) and facial expressions. Signals from 15 deaf subjects were recorded when they watched the emotional movie clips. Our system uses a 1-s window without overlap to segment the EEG signals in five frequency bands, then the differential entropy (DE) feature is extracted. The DE feature of EEG and facial expression images plays as multimodal input for subject-dependent emotion recognition. To avoid feature redundancy, the top 12 major EEG electrode channels (FP2, FP1, FT7, FPZ, F7, T8, F8, CB2, CB1, FT8, T7, TP8) in the gamma band and 30 facial expression features (the areas around the eyes and eyebrow) which are selected by the largest weight values. The results show that the classification accuracy is 99.92% by feature selection in deaf emotion reignition. Moreover, investigations on brain activities reveal deaf brain activity changes mainly in the beta and gamma bands, and the brain regions that are affected by emotions are mainly distributed in the prefrontal and outer temporal lobes.  © 2013 IEEE.",deaf; EEG; Emotion recognition; facial expression,Brain; Cognition; Electroencephalography; Emotions; Facial Expression; Humans; Audition; Brain; Electroencephalography; Learning algorithms; Neurophysiology; Speech recognition; Classification accuracy; Deep belief network (DBN); Differential entropy; Emotion recognition; Facial Expressions; Feature redundancy; Multimodal emotion recognition; Sensor technologies; accuracy; adult; algorithm; Article; artificial intelligence; artificial neural network; brain depth stimulation; brain region; classification algorithm; cognition; deep belief network; disgust; electrodermal response; electroencephalogram; electroencephalography; emotion; entropy; eye movement; eyebrow; facial expression; facial recognition; feature extraction; feature selection; female; functional magnetic resonance imaging; hearing impaired person; hearing impairment; heart rate variability; hip; human; human experiment; imagery; learning algorithm; machine learning; male; physical activity; sensitivity and specificity; skin conductance; speech intelligibility; support vector machine; task performance; temporal lobe; training; brain; cognition; electroencephalography; emotion; procedures; Biomedical signal processing,Article,Final,,Scopus,2-s2.0-85113226248,Movies / Media
Kanhirakadavath M.R.; Chandran M.S.M.,"Kanhirakadavath, Mujeeb Rahman (56900722400); Chandran, Monica Subashini Mohan (57028259700)",56900722400; 57028259700,Investigation of Eye-Tracking Scan Path as a Biomarker for Autism Screening Using Machine Learning Algorithms,2022,Diagnostics,12,2,518,,,,60,10.3390/diagnostics12020518,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125580765&doi=10.3390%2fdiagnostics12020518&partnerID=40&md5=0dc40cd2487b31749509ac7aef7db945,"Autism spectrum disorder is a group of disorders marked by difficulties with social skills, repetitive activities, speech, and nonverbal communication. Deficits in paying attention to, and processing, social stimuli are common for children with autism spectrum disorders. It is uncertain whether eye-tracking technologies can assist in establishing an early biomarker of autism based on the children’s atypical visual preference patterns. In this study, we used machine learning methods to test the applicability of eye-tracking data in children to aid in the early screening of autism. We looked into the effectiveness of various machine learning techniques to discover the best model for predicting autism using visualized eye-tracking scan path images. We adopted three traditional machine learning models and a deep neural network classifier to run experimental trials. This study employed a publicly available dataset of 547 graphical eye-tracking scan paths from 328 typically developing and 219 autistic children. We used image augmentation to populate the dataset to prevent the model from overfitting. The deep neural network model outperformed typical machine learning approaches on the populated dataset, with 97% AUC, 93.28% sensitivity, 91.38% specificity, 94.46% NPV, and 90.06% PPV (fivefold cross-validated). The findings strongly suggest that eye-tracking data help clinicians for a quick and reliable autism screening. © 2022 by the author. Licensee MDPI, Basel, Switzerland.",ASD screening; Autism spectrum disorder; Convolutional neural network (CNN); Eye-tracking scan path images; Machine learning,adolescent; area under the curve; Article; autism screening; boosted decision tree; child; classification algorithm; controlled study; convolutional neural network; decision jungle; decision tree; deep neural network; deep support vector machine; diagnostic test accuracy study; eye tracking; eye tracking scan path; female; human; image analysis; image augmentation; learning algorithm; machine learning; male; predictive value; principal component analysis; random forest; receiver operating characteristic; screening; sensitivity and specificity; support vector machine; visualized eye tracking scan path images,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85125580765,Movies / Media
Van Patten R.; Mahmood Z.; Pickell D.; Maye J.E.; Roesch S.; Twamley E.W.; Vincent Filoteo J.; Schiehser D.M.,"Van Patten, Ryan (55940238200); Mahmood, Zanjbeel (57016403300); Pickell, Delaney (57430262900); Maye, Jacqueline E. (41261634700); Roesch, Scott (7003754594); Twamley, Elizabeth W (6602326616); Vincent Filoteo, J. (6701397710); Schiehser, Dawn M (9336782100)",55940238200; 57016403300; 57430262900; 41261634700; 7003754594; 6602326616; 6701397710; 9336782100,"REM Sleep Behavior Disorder in Parkinson's Disease: Change in Cognitive, Psychiatric, and Functional Outcomes from Baseline to 16-47-Month Follow-Up",2022,Archives of Clinical Neuropsychology,37,1,,1,11,10.0,4,10.1093/arclin/acab037,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123647913&doi=10.1093%2farclin%2facab037&partnerID=40&md5=6b5ba598956fd13b571a925c7ac2bd85,"Objective: Rapid Eye Movement Sleep Behavior Disorder (RBD) is common in Parkinson's Disease (PD) and is associated with cognitive impairment; however, the majority of the evidence on the impact of RBD on multidomain cognitive batteries in PD is cross-sectional. This study evaluated the longitudinal impact of probable RBD (pRBD) on cognitive, psychiatric, and functional outcomes in people with PD. Method: Case-control study. A total of 65 people with PD completed the study protocol at baseline and 16-to-47-month follow-up. Participants were classified as pRBD+ (n = 25) or pRBD- (n = 40) based on an established cutoff of 6 on the RBD Sleep Questionnaire (RBDSQ). Participants also completed a) comprehensive cognitive testing, b) self-report measures of depression, anxiety, and apathy, and c) performance-based and other-report forms of instrumental activities of daily living. Results: Baseline mean age was 67.8 (SD = 8.1; range = 45-86) and baseline mean years of education was 16.4 (SD = 2.1; range = 12-20). The two groups did not differ on measured demographic characteristics. Baseline mean T-scores for cognitive tests were in the average range (46-55). Hierarchical linear models tested group differences in cognitive and functional decline from baseline to follow-up, controlling for appropriate demographic and psychiatric variables. Compared to the pRBD- group, pRBD+ participants showed greater decline in attention/working memory (r = -0.31; p = 0.01) and UPSA financial skills (r = -0.31; p = 0.01). No other group differences approached significance. Conclusions: RBD may differentially affect attention/working memory and financial abilities in PD. Results underscore the importance of regular RBD screening in older adults with PD in order to triage symptomatic patients to appropriate cognitive and medical interventions. © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved.",Activities of daily living; Movement disorders; Neurodegeneration; Neuropsychology; Sleep,"Activities of Daily Living; Aged; Aged, 80 and over; Case-Control Studies; Cognition; Cross-Sectional Studies; Follow-Up Studies; Humans; Middle Aged; Neuropsychological Tests; Parkinson Disease; REM Sleep Behavior Disorder; aged; case control study; cognition; complication; cross-sectional study; daily life activity; follow up; human; middle aged; neuropsychological test; parasomnia; Parkinson disease; very elderly",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85123647913,Movies / Media
Conklin K.; Pellicer-Sánchez A.,"Conklin, Kathy (23967922100); Pellicer-Sánchez, Ana (55387804200)",23967922100; 55387804200,EYE-TRACKING,2022,The Routledge Handbook of Second Language Acquisition and Individual Differences,,,,441,453,12.0,1,10.4324/9781003270546-35,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140158994&doi=10.4324%2f9781003270546-35&partnerID=40&md5=54ea39c89c8de3645ee44b06d42bc3bd,"Eye-tracking technology monitors participants’ eye movements to different types of verbal and non-verbal stimuli presented on a computer screen, e.g., written texts, computer-based tests, images or scenes, video content and subtitles, and written production tasks. Participants can engage as they normally would with these computer-based activities while their eye movements are monitored. Where participants look on the screen indicates what they are attending to and for how long. Thus, attention, or processing effort, can be inferred from eye movements. Such eye movement behavior can be explored in relation to individual differences. In this chapter, we first discuss eye-tracking technology to understand how it might be used in individual differences research. Then, recent research that has explored the role of individual differences, in particular cognitive differences (e.g., executive control and working memory), on eye movement patterns is examined. Finally, the potential of eye-tracking data to be used as a proxy for individual differences and/or as a diagnostic tool is considered. © 2022 Taylor and Francis.",,,Book chapter,Final,,Scopus,2-s2.0-85140158994,Movies / Media
Dalmaso M.; Petri L.; Patron E.; Spoto A.; Vicovaro M.,"Dalmaso, Mario (52363482800); Petri, Lara (57559960300); Patron, Elisabetta (55216824500); Spoto, Andrea (23398508300); Vicovaro, Michele (55346965600)",52363482800; 57559960300; 55216824500; 23398508300; 55346965600,"Direct Gaze Holds Attention, but Not in Individuals with Obsessive-Compulsive Disorder",2022,Brain Sciences,12,2,288,,,,4,10.3390/brainsci12020288,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127535392&doi=10.3390%2fbrainsci12020288&partnerID=40&md5=41f228d53fa7d48cb55115622e564545,"The attentional response to eye-gaze stimuli is still largely unexplored in individuals with obsessive-compulsive disorder (OCD). Here, we focused on an attentional phenomenon according to which a direct-gaze face can hold attention in a perceiver. Individuals with OCD and a group of matched healthy controls were asked to discriminate, through a speeded manual response, a peripheral target. Meanwhile, a task-irrelevant face displaying either direct gaze (in the eye-contact condition) or averted gaze (in the no-eye-contact condition) was also presented at the centre of the screen. Overall, the latencies were slower for faces with direct gaze than for faces with averted gaze; however, this difference was reliable in the healthy control group but not in the OCD group. This suggests the presence of an unusual attentional response to direct gaze in this clinical population. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Eye contact; Obsessive-compulsive disorder; Social attention; Social cognition,adult; Article; attention test; clinical article; controlled study; education; facial expression; facial recognition; female; gaze; handedness; human; ICD-10; interrater reliability; male; obsessive compulsive disorder; photography; psychotherapy; social interaction; visual attention; visual feedback; visual stimulation,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85127535392,Movies / Media
Liu F.; Zhao J.; Han T.; Shen Y.; Li M.; Liu J.; Yang D.; Fang Y.; Yan L.; Zhou X.,"Liu, Fang (59666034000); Zhao, Jing (57144952600); Han, Tian (57190967186); Shen, Yang (57307974600); Li, Meng (57190261275); Liu, Jingrong (57437736700); Yang, Dong (57194614157); Fang, Yong (59044959600); Yan, Li (57198311523); Zhou, Xingtao (7410090610)",59666034000; 57144952600; 57190967186; 57307974600; 57190261275; 57437736700; 57194614157; 59044959600; 57198311523; 7410090610,Screening for Stereopsis Using an Eye-Tracking Glasses-Free Display in Adults: A Pilot Study,2022,Frontiers in Medicine,8,,814908,,,,4,10.3389/fmed.2021.814908,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123932740&doi=10.3389%2ffmed.2021.814908&partnerID=40&md5=94b48bef82b1ac0c725ae22149f6fcca,"Purpose: To explore the feasibility and repeatability of a novel glasses-free display combined with random-dot stimulus and eye-tracking technology for screening stereopsis in adults. Methods: A total of 74 patients aged 18–44 years were recruited in this study (male: female, 32:42), including 33 patients with high myopia [≤ -6.0 diopters (D)] and 41 patients with moderate-to-low myopia (>-6.0 D). Stereopsis was measured using glasses-free, polarized, and Titmus stereotests. All patients completed a visual fatigue questionnaire after the polarized stereotest and glasses-free test. Kendall's W and Cohen's Kappa tests were used to evaluate repeatability and consistency of the glasses-free stereotest. Results: The stereotest results using the glasses-free monitor showed strong repeatability in the three consecutive tests (W = 0.968, P < 0.01) and good consistency with the polarized stereotest and Titmus test results (vs. polarization: Kappa = 0.910, P < 0.001; vs. Titmus: Kappa = 0.493, P < 0.001). Stereopsis levels of the high myopia group were significantly poorer than those of the moderate-to-low myopia group in three stereotest monitors (all P < 0.05). There was no significant difference in visual fatigue level between the polarized and the glasses-free display test (P = 0.72). Compared with the polarized test, 56.76% of patients preferred the glasses-free display and found it more comfortable, 20.27% reported both tests to be acceptable. Conclusions: In our adult patients, the new eye-tracking glasses-free display system feasibly screened stereopsis with good repeatability, consistency, and patient acceptance. Copyright © 2022 Liu, Zhao, Han, Shen, Li, Liu, Yang, Fang, Yan and Zhou.",eye-tracking; feasibility; glasses-free display; random-dot; stereopsis screening,adult; Article; controlled study; eye disease assessment; eye-tracking technology; feasibility study; female; high myopia; human; major clinical study; male; measurement repeatability; pilot study; polarization; screening; stereoscopic vision; vision test,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85123932740,Movies / Media
Zhang L.; Liu X.; Chen Q.; Zhou Y.; Xu T.,"Zhang, Ling (57748286600); Liu, Xiao (57670313300); Chen, Qian (57669986900); Zhou, Yun (42962905800); Xu, Tao (55264204500)",57748286600; 57670313300; 57669986900; 42962905800; 55264204500,EyeBox: A Toolbox based on Python3 for Eye Movement Analysis,2022,Procedia Computer Science,201,C,,166,173,7.0,3,10.1016/j.procs.2022.03.024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132160989&doi=10.1016%2fj.procs.2022.03.024&partnerID=40&md5=1ea6d811ee9ac86d9306927de8b4382a,"Eye tracking technology can reflect human attention and cognition, widely used as a research tool. To analyze eye movement data, users need to determine a specific area known as areas of interests (AOIs). Although existing tools offer dynamic AOIs functions to process visual behavior on moving stimuli, they may ask users to use markers to specify contours of moving stimuli in the physical environment or define AOIs manually on screen. This paper proposes a toolbox named Eyebox to 1) recognize dynamic AOIs automatically based on SIFT and extract eye movement indicators, as well as 2) draw fixations. We also design a user-friendly interface for this toolbox. Eyebox currently supports processing data recorded from the Pupil Core device. We compared results processed by manual with by Eyebox in a custom eye-tracking dataset to evaluate this toolbox. The accuracy of 3/4 data for AOI1 is above 90%, and the accuracy of 4/5 data for AOI2 is higher than 90%. Finally, we conducted a user study to test the usability and user experience of EyeBox. © 2022 Elsevier B.V.. All rights reserved.",Dynamic Area-of-Interest; Eye Tracking; Pupil Core,Data handling; Eye movements; Area of interest; Dynamic area-of-interest; Eye movement analysis; Eye movement datum; Eye tracking technologies; Eye-tracking; Human attention; Human cognition; Pupil core; Research tools; Eye tracking,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85132160989,Movies / Media
Wang W.; Chen T.; Indulska M.; Sadiq S.; Weber B.,"Wang, Wei (57148988700); Chen, Tianwa (57203919585); Indulska, Marta (8366424900); Sadiq, Shazia (7006420326); Weber, Barbara (7401435414)",57148988700; 57203919585; 8366424900; 7006420326; 7401435414,Business process and rule integration approaches—An empirical analysis of model understanding,2022,Information Systems,104,,101901,,,,18,10.1016/j.is.2021.101901,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117118263&doi=10.1016%2fj.is.2021.101901&partnerID=40&md5=cfdcf54cdb92f1b461ed6e85be0fc884,"Business process models are widely used in organizations by information systems analysts to represent complex business requirements. They are also used by business users to understand business operations and constraints. This understanding is extracted from graphical process models as well as business rules. Prior research advocated integrating business rules and business process models to improve the effectiveness of various organizational activities, such as developing a shared understanding of practices, process improvement, and mitigating risks of compliance and policy breaches. However, whether such integrated modeling can improve the understanding of business processes, which is a fundamental benefit of integrated modeling, has not been empirically evaluated. In this paper, first, we report on an experiment investigating whether rule linking, a representative integrated modeling method, can improve understanding performance. We use eye tracking technology to understand the cognitive process by which model readers use models to perform understanding tasks. Our results show that rule linking outperforms separated modeling in terms of understanding effectiveness, efficiency, perceived mental effort, and visual attention. Further, cognitive process analysis reveals that the form of rule representation does not affect the extent of deep processing, but rule linking significantly decreases the occurrence of rule scanning and screening processes. Moreover, our results show that rule linking leads to an increase of visual association suggesting improved information integration, leading to improved task performance. © 2021 Elsevier Ltd",Business process modeling; Business rule modeling; Cognitive process; Controlled experiment; Eye-tracking; Model understanding,Behavioral research; Cognitive systems; Systems engineering; Business Process; Business process modeling; Business rule modeling; Business rules; Cognitive process; Controlled experiment; Eye-tracking; Integrated modeling; Model understanding; Rule modeling; Eye tracking,Article,Final,,Scopus,2-s2.0-85117118263,Movies / Media
Schmitz‐peiffer H.; Aust E.; Linse K.; Rueger W.; Joos M.; Löhle M.; Storch A.; Hermann A.,"Schmitz‐peiffer, Henning (56491356400); Aust, Elisa (57195774840); Linse, Katharina (57189362089); Rueger, Wolfgang (57436206500); Joos, Markus (14048196500); Löhle, Matthias (14050515700); Storch, Alexander (7003359751); Hermann, Andreas (8790108900)",56491356400; 57195774840; 57189362089; 57436206500; 14048196500; 14050515700; 7003359751; 8790108900,Motor‐Independent Cognitive Testing in Motor Degenerative Diseases,2022,Journal of Clinical Medicine,11,3,814,,,,4,10.3390/jcm11030814,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123887016&doi=10.3390%2fjcm11030814&partnerID=40&md5=12b18bb9e0861a23f8a02537047f19bc,"Cognitive function is tested through speech‐ or writing‐based neuropsychological instruments. The application and validity of those tests is impeded for patients with diseases that affect speech and hand motor skills. We therefore developed a “motor‐free” gaze‐controlled version of the Trail Making Test (TMT), including a calibration task to assess gaze accuracy, for completion by means of an eye‐tracking computer system (ETCS). This electronic TMT version (eTMT) was evaluated for two paradigmatic “motor‐neurodegenerative” diseases, Parkinson’s disease (PD) and amyotrophic lateral sclerosis (ALS). We screened 146 subjects, of whom 44 were excluded, e.g., because of vision deficits. Patients were dichotomized into subgroups with less (ALS−, PD−) or severe motor affection (ALS+, PD+). All 66 patients and all 36 healthy controls (HC) completed the eTMT. Patients with sufficient hand motor control (ALS−, PD−, PD+) and all HC additionally completed the original paper–pencil‐based version of the TMT. Sufficient and comparable gaze fixation accuracy across all groups and the correlations of the eTMT results with the TMT results supported the reliability and validity of the eTMT. PD+ patients made significantly more errors than HC in the eTMT‐B. We hereby proved the good applicability of a motor‐free cognitive test. Error rates could be a particularly sensitive marker of executive dysfunction. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Amyotrophic lateral sclerosis; Cognition; Executive functions; Eye tracking; Neuromuscular diseases; Neuropsychological tests; Parkinson’s disease; Trail Making Test,adult; amyotrophic lateral sclerosis; Article; calibration; cognition assessment; controlled study; degenerative disease; executive function; eye tracking; eye-tracking technology; female; gaze; human; intermethod comparison; major clinical study; male; middle aged; motor control; motor dysfunction; Parkinson disease; trail making test; usability testing; validity,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85123887016,Movies / Media
Jayes L.T.; Fitzsimmons G.; Weal M.J.; Kaakinen J.K.; Drieghe D.,"Jayes, Lewis T. (57194828425); Fitzsimmons, Gemma (42261301100); Weal, Mark J. (6602832776); Kaakinen, Johanna K. (55917360500); Drieghe, Denis (6603086900)",57194828425; 42261301100; 6602832776; 55917360500; 6603086900,"The impact of hyperlinks, skim reading and perceived importance when reading on the Web",2022,PLoS ONE,17,2-Feb,e0263669,,,,6,10.1371/journal.pone.0263669,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124286437&doi=10.1371%2fjournal.pone.0263669&partnerID=40&md5=4fb4f6d2633e8327206ca2d572736a20,"It has previously been shown that readers spend a great deal of time skim reading on the Web and that this type of reading can affect comprehension of text. Across two experiments, we examine how hyperlinks influence perceived importance of sentences and how perceived importance in turn affects reading behaviour. In Experiment 1, participants rated the importance of sentences across passages of Wikipedia text. In Experiment 2, a different set of participants read these passages while their eye movements were tracked, with the task being either reading for comprehension or skim reading. Reading times of sentences were analysed in relation to the type of task and the importance ratings from Experiment 1. Results from Experiment 1 show readers rated sentences without hyperlinks as being of less importance than sentences that did feature hyperlinks, and this effect is larger when sentences are lower on the page. It was also found that short sentences with more links were rated as more important, but only when they were presented at the top of the page. Long sentences with more links were rated as more important regardless of their position on the page. In Experiment 2, higher importance scores resulted in longer sentence reading times, measured as fixation durations. When skim reading, however, importance ratings had a lesser impact on online reading behaviour than when reading for comprehension. We suggest readers are less able to establish the importance of a sentence when skim reading, even though importance could have been assessed by information that would be fairly easy to extract (i.e. presence of hyperlinks, length of sentences, and position on the screen). Copyright: © 2022 Jayes et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Adolescent; Adult; Attention; Behavior Control; Comprehension; Computer Graphics; Discrimination Learning; Eye Movements; Female; Humans; Internet; Judgment; Male; Perception; Persuasive Communication; Photic Stimulation; Reading; Young Adult; adult; article; comprehension; eye movement; female; human; human experiment; male; reading; adolescent; attention; behavior control; computer graphics; decision making; discrimination learning; ethics; Internet; organization and management; perception; persuasive communication; photostimulation; physiology; procedures; reading; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85124286437,Movies / Media
Pradhan G.N.; Hagen K.M.; Cevette M.J.; Stepanek J.,"Pradhan, Gaurav N. (8228556100); Hagen, Kate M. (57910943400); Cevette, Michael J. (6603047461); Stepanek, Jan (7102104737)",8228556100; 57910943400; 6603047461; 7102104737,Oculo-Cognitive Addition Test: Quantifying Cognitive Performance During Variable Cognitive Workload Through Eye Movement Features,2022,"Proceedings - 2022 IEEE 10th International Conference on Healthcare Informatics, ICHI 2022",,,,422,430,8.0,4,10.1109/ICHI54592.2022.00064,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139036326&doi=10.1109%2fICHI54592.2022.00064&partnerID=40&md5=5599dc7e6e092666a220727af47210cf,"The need exists for a device that can rapidly and accurately assess cognitive impairment. Because the link between oculometrics (i.e., eye movements) and cognition is well-documented, the Oculo-Cognitive Addition Test (OCAT) was developed which tracks eye movements as the user completes a simple mental addition test. OCAT consists of 12 trials of summing three consecutive single-digit numbers, shown separately on three consecutive screens. The first, second, and third screens in each trial correspond to low, medium, and high cognitive workloads. Using an infinity-loop pattern of 24 symmetrical positions not evident to the subject, eye movements were captured systematically in horizontal, vertical, and diagonal directions. Cognitive impairment was simulated by exposing subjects to 5 minutes of a hypoxic gas mixture (8% O2 + 92% N2). 20 subjects completed OCAT at baseline (i.e., normal room air), hypoxia, and post-baseline (i.e., breathing 20 minutes of room air) conditions. Raw scan-paths were collected with an eye-tracking device. Oculometrics pertaining to fixations and saccades were extracted. OCAT completion time significantly increased from baseline to hypoxia, which corresponded to a significant decrease in cerebral oxygenation from baseline to hypoxia. From baseline to hypoxia, saccadic latency significantly increased while saccadic velocity significantly decreased in the diagonal direction. However, results in the horizontal and vertical directions were not significant. Fixation time significantly increased from baseline to hypoxia at medium and high cognitive workloads but did not significantly change at the low cognitive workload. From baseline to hypoxia, fixation size did not significantly change in any cognitive workload, however, the fluctuation in fixation size significantly increased at the medium cognitive workload. From baseline to hypoxia, the fixation area significantly increased in low cognitive workload, and the fluctuation in fixation area significantly increased at the high cognitive workload. OCAT can detect subtle changes in oculometrics that correlate with cognitive impairment. This study provides a rationale for providing varying cognitive loads to elucidate subtle changes in oculometrics that may otherwise go undetected in neurocognitive tests that do not vary the cognitive load.  © 2022 IEEE.",Cognitive impairment; Cognitive Performance; Cognitive Workload; Eye-tracking; Oculo-Cognitive Addition Test; Oculometrics,Eye tracking; Cognitive impairment; Cognitive loads; Cognitive performance; Cognitive workloads; Eye-tracking; Low-high; Oculo-cognitive addition test; Oculometric; Room air; Simple++; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85139036326,Movies / Media
Gao J.; Li C.; He Z.; Wei Y.; Guo L.; Han J.; Zhang S.; Zhang T.,"Gao, Jiaxing (57671814700); Li, Changhe (57669997400); He, Zhibin (57209242288); Wei, Yaonai (57671201500); Guo, Lei (56428255600); Han, Junwei (24450644400); Zhang, Shu (55363657100); Zhang, Tuo (35191407900)",57671814700; 57669997400; 57209242288; 57671201500; 56428255600; 24450644400; 55363657100; 35191407900,Prediction of Cognitive Scores by Movie-Watching FMRI Connectivity and Eye Movement Via Spectral Graph Convolutions,2022,Proceedings - International Symposium on Biomedical Imaging,2022-March,,,,,,3,10.1109/ISBI52829.2022.9761565,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129638733&doi=10.1109%2fISBI52829.2022.9761565&partnerID=40&md5=5bac309de2584859bf40fd2ec4d8b098,"Brain functional connectivity has been demonstrated to serve as a ""fingerprint""to predict individual behaviors and phenotypes. A precise mapping between them could provide insightful clues to brain architectures and the generation of cognition. In this context, the naturalistic paradigm provides more engaging conditions and richer fMRI information, and both preserves or even enhances individual features and increases sensitivity to phenotypic measures, compared with other functional MRI modalities including resting-state and task paradigms. However, to the best of our knowledge, only linear methods were developed for predicting phenotypic measures from brain activity under naturalistic stimulus, while the brain activity is highly dynamic and nonlinear. Hence, we adopted the nonlinear graph convolutional network (GCN) to predict cognition-related phenotypic score from brain functional connectivity under naturalistic stimulus, where subjects are the nodes and functional connectivity is node feature. The behavior patterns of eye movement were integrated into this method to estimate similarity across subjects and define the graph edges. A few nodes are labeled by their phenotypic score, and the model is trained to predict the scores of those unlabeled nodes. The prediction accuracy of this method outperforms those from the linear classification method, resting-state based functional node feature and random edge tests. © 2022 IEEE.",eye movement trajectory; Functional connectivity; GCN; naturalistic stimulus,Brain mapping; Convolution; Convolutional neural networks; Eye movements; Forecasting; Graph theory; Neurophysiology; Brain activity; Brain architecture; Convolutional networks; Eye movement trajectory; Functional connectivity; Graph convolutional network; Individual behavior; Movement trajectories; Naturalistic stimulus; Resting state; Brain,Conference paper,Final,,Scopus,2-s2.0-85129638733,Movies / Media
Fraser C.L.; Mobbs R.,"Fraser, Clare L. (12139611300); Mobbs, Rowena (56715102700)",12139611300; 56715102700,Visual effects of concussion: A review,2022,Clinical and Experimental Ophthalmology,50,1,,104,109,5.0,13,10.1111/ceo.13987,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113870828&doi=10.1111%2fceo.13987&partnerID=40&md5=be1694a27e25ed8de85677fa5a30d35f,"A concussion occurs when a direct or indirect force is transmitted to the brain, causing a change in brain function. Given that approximately half the brain circuits are involved in vision and the control of eye movements, a concussion frequently results in visual symptoms. Ophthalmic abnormalities are helpful in the assessment of acute concussion, identified by rapid automized naming tasks and eye movement assessments. In particular, convergence, eye-tracking and the vestibular-ocular motor screening tool may be used. For patients suffering from post-concussion syndrome more than 3 months from the original injury, abnormalities may be found in convergence, accommodation and smooth pursuit. Orthoptic exercises are useful rehabilitation tools to allow patients to return to school, work and recreation. This article provides a brief overview of concussion as it relates to vision and ophthalmic practice. © 2021 Royal Australian and New Zealand College of Ophthalmologists.",accommodation; concussion; convergence; post-concussion; vision,Brain Concussion; Eye Movements; Humans; Vision Disorders; binocular convergence; blurred vision; chronic traumatic encephalopathy; cognition; disease association; disease burden; dizziness; eye movement; eye tracking; gold standard; headache; human; near point of convergence; optical coherence tomography; photosensitivity; postconcussion syndrome; practice guideline; rapid automatized naming task; Review; task performance; traumatic brain injury; United States; vision; visual stimulation; brain concussion; complication; visual disorder,Review,Final,,Scopus,2-s2.0-85113870828,Movies / Media
Lewandowska A.; Rejer I.; Bortko K.; Jankowski J.,"Lewandowska, Anna (57195332084); Rejer, Izabela (14045884300); Bortko, Kamil (57204818517); Jankowski, Jarosław (38961526700)",57195332084; 14045884300; 57204818517; 38961526700,Eye-Tracker Study of Influence of Affective Disruptive Content on User’s Visual Attention and Emotional State,2022,Sensors,22,2,547,,,,10,10.3390/s22020547,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122684847&doi=10.3390%2fs22020547&partnerID=40&md5=0357f11d9b96f142690d4356bf2cade2,"When reading interesting content or searching for information on a website, the appearance of a pop-up advertisement in the middle of the screen is perceived as irritating by a recipient. Interrupted cognitive processes are considered unwanted by the user but desired by advertising providers. Diverting visual attention away from the main content is intended to focus the user on the appeared disruptive content. Is the attempt to reach the user by any means justified? In this study, we examined the impact of pop-up emotional content on user reactions. For this purpose, a cognitive experiment was designed where a text-reading task was interrupted by two types of affective pictures: positive and negative ones. To measure the changes in user reactions, an eye-tracker (for analysis of eye movements and changes in gaze points) and an iMotion Platform (for analysis of face muscles’ movements) were used. The results confirm the impact of the type of emotional content on users’ reactions during cognitive process interruptions and indicate that the negative impact of cognitive process interruptions on the user can be reduced. The negative content evoked lower cognitive load, narrower visual attention, and lower irritation compared to positive content. These results offer insight on how to provide more efficient Internet advertising. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Advertisements; Affective pictures; Emotions; Eye-tracking; Face emotion recognition,Behavioral research; Cognitive systems; Eye movements; Face recognition; Marketing; Advertisement; Affective picture; Cognitive process; Emotion; Emotional state; Eye trackers; Eye-tracking; Face emotion recognition; Searching for informations; Visual Attention; Eye tracking,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85122684847,Movies / Media
Foster N.L.; Harriman G.,"Foster, Nathaniel L. (26431972800); Harriman, Grace (57736001100)",26431972800; 57736001100,Instructions to shift eyes do not increase item-method directed forgetting,2022,Memory,30,9,,1118,1129,11.0,0,10.1080/09658211.2022.2085302,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131765855&doi=10.1080%2f09658211.2022.2085302&partnerID=40&md5=3c3933635284fb89f5ac01d83313c787,"Successful forgetting of recently-studied information has been shown to be positively correlated with eye movements [Lee, Y. (2018). Withdrawal of spatial overt attention following intentional forgetting: Evidence from eye movements. Memory (Hove, England), 26(4), 503–513. https://doi.org/10.1080/09658211.2017.1378360]. We tested whether eye movements caused forgetting by manipulating instructions to move eyes following forget and remember cues in item-method directed forgetting. In Experiment 1, participants were instructed to move eyes to the periphery after TBF trials or to focus on the centre where the TBF word and cue had been presented. In Experiment 2, we manipulated eye movement instructions within participants such that on half of the TBR and TBF trials participants shifted their eyes to the periphery, and on the other half of the trials, participants focused on the centre of the screen. Experiment 3 replicated Experiment 2 with an added probe task which ensured participants were moving their eyes as instructed. Results overall showed eye movements did not increase directed forgetting. Instructing participants to shift or focus eyes did not interact with the effectiveness of directed forgetting. Furthermore, metacognitive measures collected during study indicated that participants are sensitive to the significant effects of directed forgetting, but–like recall–judgments were not affected by eye movement instructions. From these findings, we concluded that eye movements do not promote intentional forgetting. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",attentional control; Directed forgetting; eye movements; metacognition,Attention; Cues; Humans; Judgment; Memory; Mental Recall; association; attention; decision making; human; memory; recall,Article,Final,,Scopus,2-s2.0-85131765855,Movies / Media
Franchak J.M.; Yu C.,"Franchak, John M. (36096593400); Yu, Chen (16032623800)",36096593400; 16032623800,Beyond screen time: Using head-mounted eye tracking to study natural behavior,2022,Advances in Child Development and Behavior,62,,,61,91,30.0,19,10.1016/bs.acdb.2021.11.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123238079&doi=10.1016%2fbs.acdb.2021.11.001&partnerID=40&md5=e3975795a16ba933133e295f0681efee,"Head-mounted eye tracking is a new method that allows researchers to catch a glimpse of what infants and children see during naturalistic activities. In this chapter, we review how mobile, wearable eye trackers improve the construct validity of important developmental constructs, such as visual object experiences and social attention, in ways that would be impossible using screen-based eye tracking. Head-mounted eye tracking improves ecological validity by allowing researchers to present more realistic and complex visual scenes, create more interactive experimental situations, and examine how the body influences what infants and children see. As with any new method, there are difficulties to overcome. Accordingly, we identify what aspects of head-mounted eye-tracking study design affect the measurement quality, interpretability of the results, and efficiency of gathering data. Moreover, we provide a summary of best practices aimed at allowing researchers to make well-informed decisions about whether and how to apply head-mounted eye tracking to their own research questions. © 2022 Elsevier Inc.",Computer vision; Ecological validity; Eye movements; Head-mounted eye tracking; Joint attention; Language development; Mobile eye tracking; Perceptual-motor development; Social attention,Attention; Child; Eye Movements; Eye-Tracking Technology; Head; Humans; Infant; Screen Time; article; attention; computer vision; ecological validity; eye tracking; human; infant; language development; motor development; screen time; attention; child; eye movement; head,Book chapter,Final,,Scopus,2-s2.0-85123238079,Movies / Media
Arjun S.; Kothari B.; Shah N.K.; Biswas P.,"Arjun, Somnath (57193513088); Kothari, Brij (24166823600); Shah, Nirav Kumar (58081194500); Biswas, Pradipta (14007579800)",57193513088; 24166823600; 58081194500; 14007579800,Do weak readers in rural India automatically read same language subtitles on Bollywood films? An eye gaze analysis,2022,Journal of Eye Movement Research,15,5,4,,,,1,10.16910/jemr.15.5.4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147011854&doi=10.16910%2fjemr.15.5.4&partnerID=40&md5=4e24e1d3290d45d9f75345ee656b9af5,"Same Language Subtitling (SLS) of audio-visual content on mainstream TV entertainment to improve mass reading literacy was first conceived and piloted in India. SLS is now being scaled up nationally to ensure that the reading skills of one billion TV viewers, including 600 million weak readers, remain on a lifelong pathway to practice, progress, and proficiency. Will weak readers ignore or try to read along with SLS? Our eye-tracking study investigates this question with 136 weak readers drawn from a remote village in Rajasthan state by showing them popular Hindi film clips of dialog and songs, with and without SLS. We developed an interactive web-based visual analytics tool for exploring eye-tracking data. Based on an analysis of fixations, saccades, and time spent in the subtitle and non-subtitle areas, our main finding is that 70 percent of weak readers engaged in unprompted reading while watching film clips with SLS. We observed that saccadic eye movement is a good indicator to quantify the amount of reading with SLS, and saccadic regression can further differentiate weak readers. Eye-tracking studies of weak readers watching subtitles are rare, and ours may be the first with subjects from rural India © This article is licensed under a Creative Commons Attribution 4.0 International license",Attention; Eye movements; Eye-tracking; Literacy; Reading; Same language subtitling,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85147011854,Movies / Media
Thentu S.; Attar N.,"Thentu, Siddartha (57218290774); Attar, Nada (57189853430)",57218290774; 57189853430,Investigating Classification Methods using Fixation Patterns to Predict Visual Tasks,2022,IFAC-PapersOnLine,55,29,,19,24,5.0,0,10.1016/j.ifacol.2022.10.225,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144283501&doi=10.1016%2fj.ifacol.2022.10.225&partnerID=40&md5=9a6780d28c24636b5375a6c61aebc6b6,"Studies have shown the possibility to classify user tasks from eye-movement data. We present a new way to determine the optimal model for different visual cognitive tasks using data that includes two types of visual search tasks, a visual exploration task, a blank screen task, and a task where a user needs to fixate at the center of any scene. We used CNN and SVM models on RGB images generated from fixation scan paths from these tasks. We also used AdaBoost on filtered eye movement data as a baseline. Our study shows that deep learning gives the best accuracy for classifying between visual search tasks but misclassified between visual search and visual exploration tasks. Machine learning-based methods performed with high accuracy classifying tasks that involve minimal visual search. Our study gives insight on the best model to choose by type of visual task using eye movement data. Copyright © 2022 The Authors. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/)",attention; classifications; CNN; Eye-movement; visual search,Adaptive boosting; Deep learning; Support vector machines; Attention; Classification methods; Cognitive task; Exploration tasks; Eye movement datum; Optimal model; Search tasks; Visual exploration; Visual search; Visual tasks; Eye movements,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85144283501,Movies / Media
Wen M.; Dong Z.; Zhang L.; Li B.; Zhang Y.; Li K.,"Wen, Min (58081228100); Dong, Zhen (57311655100); Zhang, Lili (58437323900); Li, Bing (58081401200); Zhang, Yunshu (57201501190); Li, Keqing (55487989400)",58081228100; 57311655100; 58437323900; 58081401200; 57201501190; 55487989400,Depression and Cognitive Impairment: Current Understanding of Its Neurobiology and Diagnosis,2022,Neuropsychiatric Disease and Treatment,18,,,2783,2794,11.0,10,10.2147/NDT.S383093,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146989148&doi=10.2147%2fNDT.S383093&partnerID=40&md5=ed50cbc701d903c8f56608f889811239,"Background: Eye movement is critical for obtaining precise visual information and providing sensorimotor processes and advanced cognitive functions to the brain behavioral indicator. Methods: In this article, we present a narrative review of the eye-movement paradigms (such as fixation, smooth pursuit eye movements, and memory-guided saccade tasks) in major depression. Results: Characteristics of eye movement are considered to reflect several aspects of cognitive deficits regarded as an aid to diagnosis. Findings regarding depressive disorders showed differences from the healthy population in paradigms, the characteristics of eye movement may reflect cognitive deficits in depression. Neuroimaging studies have demonstrated the effectiveness of different eye movement paradigms for MDD screening. Conclusion: Depression can be distinguished from other mental illnesses based on eye movements. Eye movement reflects cognitive deficits that can help diagnose depression, and it can make the entire diagnostic process more accurate. © 2022 Wen et al.",biological marker; cognitive impairment; depressive disorder; eye movement; neurology,clinical feature; cognitive defect; depression assessment; disease association; emotionality; event related potential; eye fixation; facial expression; functional connectivity; human; major depression; memory guided saccade task eye movement; neurobiology; neuroimaging; nonhuman; Review; saccadic eye movement; smooth pursuit eye movement; social cognition; spatial memory; task performance; working memory,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85146989148,Movies / Media
Zhang Y.; Xu K.; Pi Z.; Yang J.,"Zhang, Yi (57190298579); Xu, Ke (57204140926); Pi, Zhongling (56704731200); Yang, Jiumin (35797803600)",57190298579; 57204140926; 56704731200; 35797803600,Instructor’s position affects learning from video lectures in Chinese context: an eye-tracking study,2022,Behaviour and Information Technology,41,9,,1988,1997,9.0,25,10.1080/0144929X.2021.1910731,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103621870&doi=10.1080%2f0144929X.2021.1910731&partnerID=40&md5=0ceb087c7bd4ffcf33371d85f65d62ec,"Although more and more online courses use video lectures that feature an instructor and slides, there are few specific guidelines for designing these video lectures. This experiment tested whether the instructor should appear on the screen and whether her position on the screen (left, middle, right of the content on the slides) influenced students. Students were randomly assigned to watch one of four video lectures on the topic of sleep. The results showed that the video lectures with an instructor’s presence (regardless of position) motivated students more than the video lecture without an instructor presence did. Learning performance and satisfaction were highest when the instructor appeared on the right side of the screen. Furthermore, eye movement data showed that compared to students in all other conditions, students in the middle condition paid more attention to the instructor and less attention to the learning content, and switched more between instructor and learning content. The findings highlight the positive effects of the instructor appearing on the right side of the screen in video lectures with slides. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",attention allocation; Instructor position; learning performance; split attention; video lectures,Distance education; Eye movements; Students; Chinese context; Eye movement datum; Eye-tracking studies; Learning contents; Learning from videos; Learning performance; Online course; Video lectures; article; attention; controlled study; eye tracking; female; human; human experiment; learning; randomized controlled trial; satisfaction; sleep; videorecording; Eye tracking,Article,Final,,Scopus,2-s2.0-85103621870,Movies / Media
Rosner A.; Schaffner M.; von Helversen B.,"Rosner, Agnes (57208692837); Schaffner, Michael (57226494673); von Helversen, Bettina (57203177455)",57208692837; 57226494673; 57203177455,When the Eyes Have It and When Not: How Multiple Sources of Activation Combine to Guide Eye Movements During Multiattribute Decision Making,2022,Journal of Experimental Psychology: General,151,6,,1394,1418,24.0,6,10.1037/xge0000833,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119272155&doi=10.1037%2fxge0000833&partnerID=40&md5=6789df8c429589ea4ad37e5462d21f41,"Memory plays a major but underexplored role in judgment and decision making (JDM). Studying eye movements—especially how people look at empty spatial locations when retrieving from memory information previously associated with those locations—provides useful information about how memory influences JDM. This so-called looking-at-nothing behavior is thought to reflect memory-driven allocation of attention. However, eye movements are also guided toward salient visual stimuli, such as test items presented on a screen. It is unclear how these multiple sources of activation combine to guide looking-at-nothing in JDM. We investigated this question in two experiments in which participants solved multiattribute categorization tasks using an exemplar-based decision strategy. In the first experiment, we tested how the occurrence and the strength of looking-at-nothing vary with the presentation format and the amount of training participants received. Looking-at-nothing occurred during categorizations when test-item information was presented auditorily and visually, but for the latter only after visual information was removed from the screen. It occurred both when training items were learned by heart and when they were presented 10 times on the screen. A second experiment revealed that an explicit instruction to imagine retrieval-relevant information during categorizations increased looking-at-nothing but did not change the decision-making process. The results shed light on the interaction between eye movements and attention to information in memory during JDM that can be explained in light of a shared priority map in memory. A detailed understanding of this interaction forms the basis for using eye movements to study memory processes in JDM. © 2021. American Psychological Association",Attention; Decision making; Eye movements; Memory; Similarity,,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119272155,Movies / Media
Kühnlenz K.; Kühnlenz B.,"Kühnlenz, Kolja (8611373500); Kühnlenz, Barbara (55909854300)",8611373500; 55909854300,Towards the Influence of Human Observer Eye-Movements on Discriminating Between Perceived Sociability of Different Robots,2022,"54th International Symposium on Robotics, ISR Europe 2022",,,,88,93,5.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137146532&partnerID=40&md5=85fbdf3c029a25fdde4e4757545ce006,"Results from a study on Perceived Sociability of a robot dependent on different gaze behaviors of human observers are presented. A 2x2 between-subjects design is used with independent variables’gaze-behavior’ (static/dynamic) and’robot’ (appearance) of a displayed robot head. Participants are told to fixate a point on a screen, which is either static or moving linearly, while a picture of one of two robot heads is shown in the covert visual attention region of the human observer. The robots differ in the level of human-likeness (mechanistic vs. anthropomorphic). Significant results show, that Perceived Sociability depends on the interaction of gaze-behavior and robot appearance. The findings show, that eye-movements influence covert perception of robot attributes and contribute to a better understanding of gaze dependent perception of robot appearance with potential practical implications of situational perception of anthropomorphic attributes like sociability situationally impacting interaction with the robot. © VDE VERLAG GMBH ∙ Berlin ∙ Offenbach.",,Anthropomorphic robots; Behavioral research; Machine design; Gaze behaviours; Human likeness; Human observers; Independent variables; Mechanistics; Robot appearance; Robot head; Static dynamics; Visual Attention; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85137146532,Movies / Media
Portengen B.L.; Naber M.; Jansen D.; van den Boomen C.; Imhof S.M.; Porro G.L.,"Portengen, Brendan L. (57218162199); Naber, Marnix (24577145000); Jansen, Demi (7103097209); van den Boomen, Carlijn (55369928500); Imhof, Saskia M. (7003870021); Porro, Giorgio L. (7102552140)",57218162199; 24577145000; 7103097209; 55369928500; 7003870021; 7102552140,Maintaining fixation by children in a virtual reality version of pupil perimetry,2022,Journal of Eye Movement Research,15,3,2,,,,7,10.16910/JEMR.15.3.2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143860612&doi=10.16910%2fJEMR.15.3.2&partnerID=40&md5=6f38893ddac675815be8b377af5b5e36,"The assessment of the visual field in young children continues to be a challenge. Children often do not sit still, fail to fixate stimuli for longer durations, and have limited verbal capacity to report visibility. Therefore, we introduced a head-mounted VR display with gazecontingent flicker pupil perimetry (VRgcFPP). We presented large flickering patches at different eccentricities and angles in the periphery to evoke pupillary oscillations, and three fixation stimulus conditions to determine best practices for optimal fixation and pupil response quality. A total of twenty children (3-11y) passively fixated a dot, counted the repeated appearance of an animated character (counting task), and watched an animated movie in separate trials of 80s each (20 patch locations, 4s per location). The results showed that gaze precision and accuracy did not differ significantly across the fixation conditions but pupil amplitudes were strongest for the dot and count task. The VR set-up appears to be an ideal apparatus for children to allow free range of movement, an engaging visual task, and reliable eye measurements. We recommend the use of the fixation counting task for pupil perimetry because children enjoyed it the most and it achieved strongest pupil responses. © This article is licensed under a Creative Commons Attribution 4.0 International license.",Attention; Eye movement; Eye tracking; Pupillometry; Saccades; Virtual reality,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85143860612,Movies / Media
Gannon E.T.; Grubb M.A.,"Gannon, Erin T. (57217230669); Grubb, Michael A. (55667892800)",57217230669; 55667892800,How Filmmakers Guide the Eye: The Effect of Average Shot Length on Intersubject Attentional Synchrony,2022,"Psychology of Aesthetics, Creativity, and the Arts",16,1,,125,134,9.0,1,10.1037/aca0000315,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086871674&doi=10.1037%2faca0000315&partnerID=40&md5=322934948be08edc77baa47e992faeed,"As editing technology has advanced, filmmakers have become increasingly skilled at manipulating overt attention such that eye movements are highly synchronized during film viewing. Average shot length (ASL; film length/number of shots) is a quantitative metric in film studies that may help us understand this perceptual phenomenon. Since shorter shots give viewers less time to voluntarily scan images, we predicted that shorter ASLs would yield greater attentional synchrony across viewers. We recorded participants’ eye movements as they viewed clips from commercially produced films with varying ASLs, and in line with our hypothesis, we found that ASL and attentional synchrony were negatively related. These findings were replicated in an independent sample of participants who viewed a different set of clips from the same films used in Experiment 1. Comparing across experiments, we found that within the same films, clips with shorter ASLs synchronized eye movements to a greater extent than did clips with longer ASLs. Studies of film perception have long implied that ASL modulates eye movements across viewers, and this study provides robust empirical evidence to support that claim. © 2020. American Psychological Association",Attention; Average shot length; Continuity editing; Eye movements; Film,,Article,Final,,Scopus,2-s2.0-85086871674,Movies / Media
Gokcen C.; Yilmaz G.; Karadag M.,"Gokcen, Cem (36186815300); Yilmaz, Gizem (58730767300); Karadag, Mehmet (6601970351)",36186815300; 58730767300; 6601970351,ADHD symptoms persist even when PTSD symptoms progress: An EMDR case report,2022,Dusunen Adam - The Journal of Psychiatry and Neurological Sciences,35,1,,64,68,4.0,1,10.14744/DAJPNS.2022.00174,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128942503&doi=10.14744%2fDAJPNS.2022.00174&partnerID=40&md5=56aa9a81e55486e8bb25d4314f1328c1,"Although many studies report that attention deficit and hyperactivity disorder (ADHD) symptoms will improve after eye movement desensitization and reprocessing (EMDR), it is thought that the symptoms of ADHD, which is an organic disease, will not improve with psychotherapy. In this case report, significant improvements were reported in post-traumatic stress disorder (PTSD) symptoms with EMDR therapy in a 9-year-old boy, who was previously followed up with the diagnosis of ADHD and who was sexually abused by his cousin at the age of 7 years. A total of 5 EMDR sessions that lasted for an average of 45 min were applied to the patient. The symptoms of the case were followed up with Atilla Turgay Screening and Evaluation Scale that is based on the DSM-IV and with Post-traumatic Stress Index for Conduct Disorders in Children and Adolescents. At the end of the therapy and after the 4-week follow-up, the ADHD symptoms continued at the same level as they were before the traumatic event, and the symptoms of the oppositional defiant disorder (ODD) improved more when compared with the period before the event, and significant improvements were also detected in PTSD symptoms. However, ODD symptoms can mimic PTSD symptoms; EMDR may therefore be good. It was also observed that the bilateral stimulation types that were employed during EMDR should be changed more frequently than normal. As a conclusion, it was found that EMDR can be used as an effective psychotherapy method in children with ADHD and PTSD for PTSD and ODD symptoms except for ADHD symptoms. © 2022 Yerkure Tanitim ve Yayincilik Hizmetleri A.S.. All rights reserved.",ADHD; EMDR; PTSD; trauma,aripiprazole; atomoxetine; methylphenidate; risperidone; anger; Article; attention deficit hyperactivity disorder; avoidance behavior; case report; child; child sexual abuse; clinical article; communication skill; comorbidity; disease exacerbation; drug withdrawal; DSM-IV; eye movement desensitization and reprocessing; follow up; high risk behavior; human; intelligence quotient; male; nocturnal enuresis; oppositional defiant disorder; physical violence; posttraumatic stress disorder; psychoeducation; school child; therapy effect; Wechsler intelligence scale for children,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85128942503,Movies / Media
Toba A.; Ishikawa J.; Harada K.,"Toba, Ayumi (36960489700); Ishikawa, Joji (7202941463); Harada, Kazumasa (7402731181)",36960489700; 7202941463; 7402731181,Increased blood pressure variability is associated with probable rapid eye movement sleep behaviour disorder in elderly hypertensive patients,2022,Blood Pressure,31,1,,40,46,6.0,2,10.1080/08037051.2022.2055531,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128297008&doi=10.1080%2f08037051.2022.2055531&partnerID=40&md5=d711b1a54b3dfc9be338c7bc9f83a4c9,"Purpose: An increased blood pressure variability (BPV) has been reported to be associated with older age and cognitive dysfunction; however, associations between increased BPV and rapid eye movement sleep behaviour disorder (RBD) has not been thoroughly investigated in patients without clinical Lewy body diseases. Materials and methods: In frailty outpatient clinic, we evaluated ambulatory BP, RBD screening questionnaire (RBDSQ), and beat-to-beat heart rate variability during positional change from sitting to standing in 112 elderly hypertensive patients. Results: The mean age was 81.2 ± 6.3 years (68% male). There were 15 patients who had probable RBD (RBDSQ scores ≥ 5). Patients with RBD had a greater body mass index, coefficient of variation (CV) in 24-h diastolic BP (23.5 ± 6.1 versus 18.7 ± 5.8, p = 0.005), awake diastolic BP (23.0 ± 7.7 versus 18.6 ± 6.2, p = 0.017), and nocturnal systolic BP (14.9 ± 5.5 versus 12.0 ± 4.4, p = 0.025) compared with those without RBD, while systolic BP, diastolic BP, and cognitive function did not differ significantly between patients with and without RBD. Patients with RBD exhibited larger orthostatic BP fall compared with patients without RBD (−4.9 ± 11.0 versus 7.5 ± 11.8, p = 0.009) and lower CV of R–R intervals while standing (1.3 ± 0.6 versus 2.4 ± 1.5, p = 0.039). Multiple regression analysis revealed that patients with RBD had significantly greater CV of nocturnal systolic BP independent of age, sex, BMI, history of diabetes and dyslipidaemia, and use of antihypertensive drugs (p = 0.008). Conclusion: An increased BPV in ambulatory BP, associated with autonomic dysfunction, can be observed in patients with probable RBD even in elderly patients without clinical presentation of Lewy body diseases. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",autonomic dysfunction; Blood pressure variability; elderly; rapid eye movement sleep behaviour disorder,"Aged; Aged, 80 and over; Antihypertensive Agents; Blood Pressure; Blood Pressure Monitoring, Ambulatory; Female; Humans; Hypertension; Male; REM Sleep Behavior Disorder; antihypertensive agent; antihypertensive agent; aged; antihypertensive therapy; Article; blood pressure monitoring; blood pressure variability; body mass; cognition; controlled study; diabetes mellitus; diastolic blood pressure; dyslipidemia; female; frailty; geriatric hospital; geriatric patient; heart rate variability; human; hypertension; hypertensive patient; major clinical study; male; medical history; orthostatic blood pressure; outpatient; outpatient department; parasomnia; screening; sitting; standing; systolic blood pressure; very elderly; wakefulness; blood pressure; complication; hypertension; physiology; psychology",Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85128297008,Movies / Media
Li W.-C.; Liang Y.-H.; Korek W.T.; Lin J.J.H.,"Li, Wen-Chin (36064620900); Liang, Yung-Hsiang (57768278800); Korek, Wojciech Tomasz (57218262943); Lin, John J. H. (57194606885)",36064620900; 57768278800; 57218262943; 57194606885,Assessments on Human-Computer Interaction Using Touchscreen as Control Inputs in Flight Operations,2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13307 LNAI,,,326,338,12.0,6,10.1007/978-3-031-06086-1_25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132969829&doi=10.1007%2f978-3-031-06086-1_25&partnerID=40&md5=83549f555921158f5edcd9fef7ea6c9d,"The developing technology on innovative touchscreen applied in the cockpit can integrate control inputs and outputs on the same display in flight operations. Flight systems could be updated by modifying the touchscreen user interface without the complicated processes on reconfiguring cockpit panels. There is a potential risk on touchscreen components constrained by the issues associated with inadvertent touch, which may be defined as any system detectable touch issued to the touch sensors without the pilot’s operational consent. Pilots’ visual behaviours can be explored by using eye trackers to analyze the relationship between eye scan patterns and attention shifts while conducting monitoring tasks in flight operations. This research aims to evaluate human-computer interactions using eye tracker to investigate the safety concerns on implementation of touchscreen in flight operations. The scenario was set to conduct an instrument landing on the final approach using future system simulator. Participants were required to interact with all the control surfaces and checklists using the touchscreens located on different areas in the cockpit. Each participant performed landing scenario as pilot-flying (PF) and pilot-monitoring (PM) in random sequence. Currently PF and PM perform different tasks related to control inputs and control outputs monitoring in the flight deck. The PF’s primary obligation is to fly the aircraft’s flight path, and the PM’s main responsibility is to monitor the aircraft’s flight path and cross-check to the PF’s operational behaviours. By analyzing participants’ visual behaviours and scanning patterns, the findings on HCI related to applying touchscreen for future flight deck design would be applicable. There are some benefits on the implementation touchscreen for future flight deck design if the human-centred design principle can be integrated in the early stage. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Attention distribution; Flight deck touchscreen; Human-computer interactions; System usability; Visual behaviours,Air traffic control; Aircraft; Behavioral research; Eye movements; Eye tracking; Flight paths; User interfaces; Attention distribution; Control inputs; Eye trackers; Flight deck design; Flight deck touchscreen; Flight decks; Flight operation; Input and outputs; System usability; Visual behavior; Human computer interaction,Conference paper,Final,,Scopus,2-s2.0-85132969829,Movies / Media
Bould J.; Hepworth L.; Howard C.; Currie J.; Rowe F.,"Bould, James (57788927900); Hepworth, Lauren (56845569500); Howard, Claire (57193559042); Currie, Jim (56602378600); Rowe, Fiona (7003681030)",57788927900; 56845569500; 57193559042; 56602378600; 7003681030,The Impact of Visual Impairment on Completion of Cognitive Screening Assessments: A Post-Hoc Analysis from the IVIS Study,2022,British and Irish Orthoptic Journal,18,1,,65,75,10.0,2,10.22599/bioj.263,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133693322&doi=10.22599%2fbioj.263&partnerID=40&md5=9af957a7c9f9278dd56a840a6a2c7cfc,"Aim: The aim of this study was to evaluate completed cognitive screens in stroke survivors with and without visual impairment to explore whether the presence of visual impairment impacts on completion of cognitive screening. Materials and methods: Cognitive screening assessment was undertaken using the Oxford Cognitive Screen (OCS). Data from visual function assessments (inclusive of visual acuity, visual fields, eye movements and visual perception evaluation) were analysed to determine whether presence and/or type of visual impairment impacted on cognitive screening scores achieved. Covariates, including glasses use, gender, age at stroke onset and stroke type, were used to assess confounding impacts on scores attained during cognitive screening. Results: 1500 stroke admissions were recruited. One hundred ninety-seven who completed the OCS, were identified from the IVIS study database. Those who reported visual symptoms performed worse statistically on all cognitive tasks except the recall recognition (p = 0.232) and executive tasks (p = 0.967). Visual symptoms did not prevent participants from completing every section of the OCS (p = 0.095). In certain tasks, those not wearing their required glasses performed worse, including the executive function (p = 0.012), broken hearts and sentence reading tasks. Conclusions: Many tasks within cognitive screening assessment are impacted by presence of visual deficits, and adjustments, where possible (e.g. good lighting, large print) should be used to facilitate completion of cognitive screening. It is important to ensure required reading correction is worn during screening. © 2022 The Author(s).",Cognition; Cognitive; OCS; Refractive Error; Stroke; Vision; Visual impairment; Visual symptoms,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85133693322,Movies / Media
Liu D.; Zhang J.,"Liu, Dashuai (58040143600); Zhang, Jie (57206850097)",58040143600; 57206850097,Research on Kansei Image Modeling Design of Nail Gun Products Based on Kansei Engineering,2022,"2022 3rd International Conference on Intelligent Design, ICID 2022",,,,1,6,5.0,1,10.1109/ICID57362.2022.9969757,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145436031&doi=10.1109%2fICID57362.2022.9969757&partnerID=40&md5=b24d7e8b3c4c285bfa6bdf889183c29f,"In order to solve the problem that existing nail gun products' modeling can't meet the perceptual image needs of users, Kansei engineering (KE) is used to quantify the perceptual cognitive factors of consumers on nail gun products' modeling. And the corresponding relationship model between perceptual image cognition and modeling characteristics of nail gun products is established. Firstly, the samples of nail gun products and their Kansei image vocabulary are collected. Secondly, cluster analysis and KJ method are used to screen out representative samples. And then factor analysis and semantic difference method are used to screen out representative Kansei image vocabulary. Thirdly, the shape analysis method and the eye movement equipment are used to extract the shape design elements of the side profile of nail gun products. Finally, the correlation between linear design elements and perceptual image vocabulary is analyzed by using quantitative theory I, and their corresponding mathematical model for perceptual image prediction is constructed. So it provides theoretical methods and design reference for perceptual image form design of nail gun products.  © 2022 IEEE.",industrial design; Kansei engineering; Kansei image cognition of products' modeling; nail gun products; quantitative theory class I,Cluster analysis; Engineering education; Eye movements; Image analysis; Industrial research; Semantics; Class I; Design elements; Image modeling; Kansei Engineering; Kansei image cognition of product' modeling; Kansei images; Nail gun product; Product models; Quantitative theory; Quantitative theory class I; Product design,Conference paper,Final,,Scopus,2-s2.0-85145436031,Movies / Media
Xue C.; Tang Y.; Wang C.; Yang H.; Li L.,"Xue, Chuanwei (57219440251); Tang, Yi (57221071526); Wang, Changming (56527531200); Yang, Haibo (36618479600); Li, Liang (56480382000)",57219440251; 57221071526; 56527531200; 36618479600; 56480382000,"The Effects of Normal Aging, Subjective Cognitive Decline, Mild Cognitive Impairment, or Alzheimer's Disease on Visual Search",2022,Journal of Alzheimer's Disease,88,4,,1639,1650,11.0,4,10.3233/JAD-220209,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137008614&doi=10.3233%2fJAD-220209&partnerID=40&md5=f47308275e898b2661f7779181d39fb0,"Background: Alzheimer's disease (AD) has been confirmed as an influencing factor of visual impairment, but potential concomitant effects on visual and cognitive performance are not well understood. Objective: To provide a new method for early screening of Alzheimer's disease and further explore the theoretical mechanism of the decline of whole visual and cognitive performance in AD. Methods: We studied 60 individuals without dementia as normal control (NC), 74 individuals with subjective cognitive decline (SCD), 60 individuals with amnesia mild cognitive impairment (aMCI), and 75 patients with AD on a battery of tests designed to measure multiple aspects of basic and higher-order visual perception and cognition. All subjects performed on same visual and cognitive test batteries. Results: The results showed both of four groups, with the stimulus-presentation time being longer, the visual-search performance improved, and both the eye interest-area first fixation duration and the interest-area-fixation count increased. Particularly under the noise-masking condition, the AD group performed the worst at stimulus-presentation times between 300 and 900 ms. The aMCI group, but not the SCD group, performed worse than the NC group at the stimulus-presentation time of either 300 or 500 ms. The interest-area-fixation count was higher in all the patient groups than that in the NC group, and distinguishable between participants with AD and those with SCD or aMCI. Conclusion: The visual-search performance combined with eye-movement tracking under the noise-masking condition can be used for distinguishing AD from normal aging, SCD, and aMCI.  © 2022 - IOS Press. All rights reserved.",Alzheimer's disease; attention allocation; cognitive load; eye movement tracking; visual search,Aging; Alzheimer Disease; Amnesia; Cognitive Dysfunction; Humans; Neuropsychological Tests; aged; aging; Alzheimer disease; amnesia; Article; cerebrospinal fluid; clinical dementia rating scale; cognitive defect; controlled study; energy consumption; eye tracking; female; human; infrared radiation; major clinical study; male; mathematical parameters; mental performance; mild cognitive impairment; Mini Mental State Examination; questionnaire; screening test; stimulus; subjective cognitive decline questionnaire; vision; aging; amnesia; neuropsychological test; psychology,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85137008614,Movies / Media
Blekic W.; Bellaert N.; Lecomte N.; Kandana Arachchige K.; Melot H.; Rossignol M.,"Blekic, Wivine (57202892290); Bellaert, Nellia (57439305600); Lecomte, Nicolas (57454600500); Kandana Arachchige, Kendra (57195997249); Melot, Hadrien (8925424300); Rossignol, Mandy (56156449300)",57202892290; 57439305600; 57454600500; 57195997249; 8925424300; 56156449300,Cognitive flexibility and attentional patterns among trauma survivors: preliminary evidence from an eye-tracking study; [创伤幸存者的认知灵活性和注意模式：眼动追踪研究的初步证据]; [Flexibilidad cognitiva y patrones atencionales entre sobrevivientes de trauma. Evidencia preliminar de un estudio de seguimiento ocular],2022,European Journal of Psychotraumatology,13,1,2055296,,,,2,10.1080/20008198.2022.2055296,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128657594&doi=10.1080%2f20008198.2022.2055296&partnerID=40&md5=da7cb2a584b0a8fbfff87dc145639b23,"Background: Executive functioning has been linked to both the development of post-traumatic symptoms and the efficiency of therapy. Specifically, flexibility processes seem to play a major role in the use of efficient coping strategies after a traumatic event. However, only a few studies have focused on the links between flexibility, resilience, and concrete behaviours displayed by individuals. Objective: The aim of this study was to investigate the influence of emotional content on the efficiency of cognitive flexibility among trauma-exposed individuals. Method: Twenty-eight trauma-exposed (TE) and 27 non-trauma-exposed (NTE) individuals performed an overlap task in which neutral, positive, and negative pictures appeared in the centre of the screen. Participants were required to disengage their attentional focus from this picture to identify a peripheral target. Analyses included eye movements during the presentation of the scenes and the response times associated with target localization. Results: TE individuals initially presented a rapid overt disengagement from both neutral and negative emotional information. In other words, TE participants moved their gaze away from the central picture towards the target more rapidly than NTE participants. However, TE participants then displayed longer reaction times to identify the target in comparison with NTE participants. Discussion: This study presents preliminary evidence that cognitive flexibility may be relevant when considering the impact of trauma. The developed task could provide a novel way to assess this flexibility within an emotional context. HIGHLIGHTS: • This study developed an original assessment of cognitive flexibility processes in an emotional context. • Cognitive flexibility was assessed using an overlap task and eye-tracking technology. • Cognitive flexibility may be relevant when considering the impact of a trauma. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",attention; executive processes; eye-tracking; Flexibility; PTSD; resilience; trauma,Attention; Cognition; Eye-Tracking Technology; Humans; Reaction Time; Survivors; attention; cognition; human; physiology; reaction time; survivor,Letter,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128657594,Movies / Media
Varshney M.; Goyal T.; Dey P.; Nath Singh P.,"Varshney, Mehul (58039000700); Goyal, Tushar (58031909700); Dey, Prateek (58038755500); Nath Singh, Paras (57223019615)",58039000700; 58031909700; 58038755500; 57223019615,Flipping of Computer Pages Using Eye Blinks,2022,MysuruCon 2022 - 2022 IEEE 2nd Mysore Sub Section International Conference,,,,,,,1,10.1109/MysuruCon55714.2022.9972369,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145349835&doi=10.1109%2fMysuruCon55714.2022.9972369&partnerID=40&md5=9fc8c569e4543d442b8bb4d9316436ed,"As computer vision technology has advanced quickly in recent years, 3D eyeball tracking and its movement have drawn the greatest attention from researchers because of its demand in screen handling and running the applications by eye blinks or moving the eye lids. The Physically Challenged People Suffering with NO limbs or Diplegia Paralysis of Symmetrical Body Parts like Hands and for one step towards a more comfortable life of Human civilization. In this research paper flipping and scrolling of pages on computer screen using eye blinks has been proposed and implemented successfully. The extraction of the face structure points that refers to the eyes using the Haar-Cascade faces dataset points. These extracted parts are matched up with the Eye-aspect-ratio for measuring the threshold values affirmation of the voluntary eye blinks. The 'Divyang' disadvantageous people with no hands can use this tool for scrolling and flipping the pages of the screen. The OpenCV tools have used with Python for implementation. © 2022 IEEE.",electroencephalogram; Eye Aspect Ratio; Facial Structure Positioning; Haar Cascade; OpenCV tools; Threshold value; Voluntary Eye Blinks,Eye movements; Aspect-ratio; Computer vision technology; Eye aspect ratio; Eye blink; Facial structure; Facial structure positioning; Haar cascade; Opencv tool; Threshold-value; Voluntary eye blink; Aspect ratio,Conference paper,Final,,Scopus,2-s2.0-85145349835,Movies / Media
Jayanath S.; Hamzah N.; Ahmad Fauzi A.; Ahmad Adlan A.S.; Muhamad N.A.; Zainal A.Z.; Mohri I.; Tachibana M.,"Jayanath, Subhashini (56578557500); Hamzah, Norhamizan (55496611300); Ahmad Fauzi, Aishah (54784229700); Ahmad Adlan, Aida Syarinaz (58036859300); Muhamad, Nor Asiah (57221113926); Zainal, Azlin Zaiti (56890923300); Mohri, Ikuko (6602234195); Tachibana, Masaya (37666244500)",56578557500; 55496611300; 54784229700; 58036859300; 57221113926; 56890923300; 6602234195; 37666244500,The Japanese Sleep Questionnaire for preschoolers within a Malaysian context,2022,Pediatrics International,64,1,e15123,,,,6,10.1111/ped.15123,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133998362&doi=10.1111%2fped.15123&partnerID=40&md5=1ef419cf20915a0cd15d342dc5858e44,"Background: Childhood sleep practices impact growth, development, and long-term health. There is a paucity of sleep data pertaining to preschool children in Asia, especially South-East Asia. Methods: This cross-sectional study involved parents of well siblings, aged 2–6 years. It aimed to: (i) test the reliability of the English version of the Japanese Sleep Questionnaire for Preschoolers (JSQ-P), and (ii) obtain the prevalence, as well as describe, sleep-related issues. Ninety-one (91) parents (74.7%; mothers) self-administered the questionnaire in the pediatric clinic waiting area of a Malaysian tertiary hospital. Recruitment was from August to November 2020. Results: The English version of the JSQ-P has good internal consistency (Cronbach alpha = 0.85). Range of Cronbach alpha values for each item: 0.36–0.87. Many (77%) children slept at 10:00 p.m. or later, similar to parents' late bedtimes. One-third had difficulty waking up in the morning. There were significant strong positive correlations between some features of restless leg syndrome, daytime tiredness, morning symptoms, and obstructive sleep apnea symptoms. Co-sleeping was prevalent (97.9%). Mean screen time for those who had set time limits was 2.35 ± 1.68 h. Conclusions: The English-language translation of the JSQ-P is a questionnaire with good internal consistency that can be used in non-Japanese speaking countries. Parents need to be educated on healthy sleep and screen time practices to optimize children's sleep quality and quantity. © 2022 Japan Pediatric Society.",Japanese; Malaysia; preschool; sleep; sleep wake disorder,"Child; Child, Preschool; Cross-Sectional Studies; Female; Humans; Reproducibility of Results; Sleep; Sleep Wake Disorders; Surveys and Questionnaires; Article; child; cross-sectional study; fatigue; female; follow up; habit; human; insomnia; internal consistency; Likert scale; major clinical study; male; parasomnia; parental age; polysomnography; preschool child; prevalence; questionnaire; rapid eye movement sleep behavior disorder; reliability; REM sleep; restless legs syndrome; screen time; sleep disorder assessment; sleep disordered breathing; sleep hygiene; sleep latency; sleep quality; sleep time; sleep waking cycle; wakefulness; questionnaire; reproducibility; sleep; sleep disorder",Article,Final,,Scopus,2-s2.0-85133998362,Movies / Media
Shi Y.; Du J.,"Shi, Yangming (57189999728); Du, Jing (57219889677)",57189999728; 57219889677,3D-DesktopEye: A Desktop-Based Eye-Tracking System for Facility Management,2022,"Construction Research Congress 2022: Computer Applications, Automation, and Data Analytics - Selected Papers from Construction Research Congress 2022",2-B,,,1033,1041,8.0,1,10.1061/9780784483961.108,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128896760&doi=10.1061%2f9780784483961.108&partnerID=40&md5=f466692695c6bd773470936af3d39fd4,"Understanding the attentional patterns of construction professionals in design, construction, and facilities management processes is critical to identifying the performance bottlenecks and improving the current workflow designs in the Architecture, Engineering, Construction, and Facility Management (AEC/FM) industry. Recent developments in eye-tracking technologies have attracted an increasing attention of construction scholars as it is an effective tool for attentional analysis. However, the existing monitor-mounted eye trackers are designed for tracking gaze focus on 2D screens (such as attentions during a 2D drawing review) and thus are limited for understanding attentional patterns in 3D model reviews. To track gaze focus in 3D environments, scholars have to use expensive eye trackers integrated with glasses or headset displays such as Virtual Reality headsets. As an alternative, this paper proposes an effective solution for tracking gaze focus in 3D model reviews on 2D screens using the regular monitor-mounted eye trackers. The proposed 3D Desktop-Based Eye-Tracking System called ""3D-DesktopEye"" leverages the eye-tracking function of the Unity Game engine and a set of geometric conversations to project the 2D eye-tracking points into virtual 3D models. As a result, it can track the focus points of a user looking at a 3D model on a 2D screen. We tested the 3D-DesktopEye system in a facility management scenario - a pipe maintenance task. We also compared the effectiveness of the proposed 3D-DesktopEye system with the traditional 2D eye-tracking system. The results confirmed the usability and feasibility of the 3D-DesktopEye, and the proposed 3D-DesktopEye can help the user achieve better task performance. © 2022 ASCE.",,3D modeling; Helmet mounted displays; Office buildings; Three dimensional computer graphics; Virtual reality; 3D models; 3d-modeling; Construction professionals; Design construction; Design facilities; Eye trackers; Eye tracking systems; Eye-tracking; Facilities management; Model reviews; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85128896760,Movies / Media
Xue W.; Lo C.-H.,"Xue, Wenbai (57772835900); Lo, Cheng-Hung (27967790600)",57772835900; 27967790600,Sound-Guided Framing in Cinematic Virtual Reality – an Eye-Tracking Study,2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13312 LNCS,,,520,535,15.0,3,10.1007/978-3-031-06047-2_39,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133163984&doi=10.1007%2f978-3-031-06047-2_39&partnerID=40&md5=389776610693ff43a26c7123c97d28fb,"When watching films made and displayed with Virtual Reality approaches, the viewers can freely move the visual field, resulting in possible disruptions in the narratives designed by the directors. This phenomenon demands novel narrative strategies in Cinematic Virtual Reality (CVR) to effectively guide a viewer’s attention in following important plots. In this study, we evaluate the effect of using sound as a guiding mechanism in CVR. We conduct experiments to analyze the participants’ responses to the sound cues outside the field of view with the eye-tracking technique. Statistical methods are then used to infer the significance of the differences among the responses. The experiments are conducted in a virtual scene with low complexity, reducing the possible confounding effects of the variety of visual elements. The results show that the viewer's visual attention can be guided by sounds sourced at the range outside the field of view. More specifically, the viewers react significantly better to sound stimuli varying in horizontal directions than those in vertical directions. Furthermore, different types of sounds also significantly affect the viewers’ attention in the virtual scene. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",3D sound; Cinematic virtual reality; Eye-tracking; Sound-guided framing; Visual attention,Behavioral research; Eye tracking; 3D sound; Cinematic virtual reality; Cinematics; Eye-tracking; Eye-tracking studies; Field of views; Sound-guided framing; Virtual scenes; Visual Attention; Visual fields; Virtual reality,Conference paper,Final,,Scopus,2-s2.0-85133163984,Movies / Media
Hwang Y.M.; Lee K.C.,"Hwang, Yoon Min (35435393400); Lee, Kun Chang (35330125000)",35435393400; 35330125000,An eye-tracking paradigm to explore the effect of online consumers’ emotion on their visual behaviour between desktop screen and mobile screen,2022,Behaviour and Information Technology,41,3,,535,546,11.0,22,10.1080/0144929X.2020.1813330,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090240516&doi=10.1080%2f0144929X.2020.1813330&partnerID=40&md5=08c2093c644fe6d892625a33476c2205,"With the exponential growth of mobile smartphones, shopping through them has received considerable attention from online retailers, who wish to offer an interactive and personalised online shopping marketing. However, interactive mobile shopping marketing is still in the early stages of development, and the impact of individual shopping context, such as emotional state of online shoppers’ visual behaviour, is unexplored yet. To address this question, this study adopted the eye-tracking paradigm to examine the ways in which consumers’ pattern of visual attention varies according to their emotional states (positive vs. negative) in mobile screen compared with desktop screen. Results revealed that those with negative emotion paid greater visual attention to online shopping information presented on the mobile and desktop screen than with positive emotion consumers. The gap of the impact of emotional state on consumers’ visual behaviour was more evident in the case of the small screen of mobile device. Regardless of emotional status, visual attention was more highly appeared in mobile screen than desktop screen. © 2020 Informa UK Limited, trading as Taylor & Francis Group.",consumers’ emotion; eye-tracking; Mobile commerce; online shopping marketing; visual behaviour,Behavioral research; Mobile commerce; Consumer’ emotion; Emotional state; Exponential growth; Eye-tracking; Mobile screens; Online consumers; Online shopping; Online shopping marketing; Visual Attention; Visual behavior; article; consumer; controlled study; emotion; eye tracking; human; human experiment; marketing; shopping; visual attention; Eye tracking,Article,Final,,Scopus,2-s2.0-85090240516,Movies / Media
Malavolta M.; De Gobbis A.; Trimarco E.; Benavente-Fernández I.; Lubián-López S.P.; Groznik V.; Sadikov A.,"Malavolta, Marta (57202403100); De Gobbis, Andrea (57820834400); Trimarco, Emiliano (57821100100); Benavente-Fernández, Isabel (57193162448); Lubián-López, Simón Pedro (6507742356); Groznik, Vida (52463560700); Sadikov, Aleksander (55883901600)",57202403100; 57820834400; 57821100100; 57193162448; 6507742356; 52463560700; 55883901600,Eye-tracking test battery for newborns: A pilot feasibility study,2022,CEUR Workshop Proceedings,3363,,,39,48,9.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151623820&partnerID=40&md5=77be1f0d53dba13d158cb17edef98b1d,"Preterm birth is one of the leading causes of neurodevelopmental disabilities. Many efforts have been made to improve the well-being and quality of life of preterm infants and their families, especially during the first months of life. Several authors investigated cognitive impairments in children, such as social disorders or attention deficit, using various remote eye-tracking techniques. However, this tool remains poorly used in newborn infants, particularly in the first three months old children. Therefore, we aim to create a neuropsychological test battery using screen-based eye-tracking that can also be used on the above-mentioned population. The aim of this study is to analyse the feasibility of the created pilot eye-tracking test battery and the suitability of the different stimuli used. We also investigate how the current paradigm evolved based on observations made during data acquisition, and how it was modified to achieve an appropriate test in terms of composition and length to keep children’s attention. © 2022 Copyright for this paper by its authors.",Cognitive Impairments; Eye-tracking test battery; Feasibility Study; Premature Children,Data acquisition; Electric batteries; Cognitive impairment; Eye-tracking; Eye-tracking test battery; Feasibility studies; Premature child; Preterm birth; Quality of life; Test batteries; Tracking tests; Well being; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85151623820,Movies / Media
Ha J.; Choi K.-M.; Im C.-H.,"Ha, Jisoo (57223105668); Choi, Kang-Min (57329678600); Im, Chang-Hwan (7005671177)",57223105668; 57329678600; 7005671177,Feasibility of Using Electrooculography-Based Eye-Trackers for Neuromarketing Applications,2022,IEEE Transactions on Instrumentation and Measurement,71,,6503310,,,,9,10.1109/TIM.2022.3217849,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141452809&doi=10.1109%2fTIM.2022.3217849&partnerID=40&md5=e3baea508e329ff0d7aec9a1262628dc,"Eye-tracking has been increasingly utilized in neuromarketing applications to quantitatively investigate consumers' subliminal attention and preferences. Eye-tracking technology in neuromarketing has been developed mainly using camera-based methods; however, camera-based eye-trackers are generally expensive for some customers, hindering widespread use of eye-tracking technology. Electrooculography (EOG)-based eye-tracking could be a promising alternative because it can be implemented at a relatively lower cost even less than 100 USD; however, EOG-based eye-tracking has not yet been employed in neuromarketing applications. In this study, we developed a method to estimate the absolute coordinates of eye gaze from EOG and investigated its reliability over time. The EOG signals were acquired in three separate experimental sessions: calibration, instructed eye-tracking test, and free eye-tracking test (FET) sessions. A linear regression model was constructed using the calibration data to estimate the absolute coordinates on the screen. The reconstructed eye-gaze results were visualized in the form of a heat map to be applied to practical neuromarketing scenarios. The results of the instructed eye-tracker test session revealed that the reliability of the eye-tracking results gradually decreased over time but did not drop drastically for up to 8 s. Moreover, the results of the neuromarketing test session analyzed with 6-s-EOG-data revealed clear gender differences among the heat maps of six advertisement pictures, coinciding with previous camera-based study results. Our results suggest that the proposed EOG-based eye-tracker has great potential to be utilized in practical neuromarketing applications.  © 1963-2012 IEEE.",Electrooculography (EOG); eye-tracking; gaze reconstruction; gender difference; neuromarketing,Cameras; Eye tracking; Linear regression; Reliability; Absolute coordinate; Camera-based; Electrooculography; Eye trackers; Eye tracking technologies; Eye-tracking; Gaze reconstruction; Gender-differences; Neuromarketing; Calibration,Article,Final,,Scopus,2-s2.0-85141452809,Movies / Media
Jeon Y.A.,"Jeon, Yongwoog Andy (57202281484)",57202281484,Reading Social Media Marketing Messages as Simulated Self Within a Metaverse: An Analysis of Gaze and Social Media Engagement Behaviors within a Metaverse Platform,2022,"Proceedings - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2022",,,,301,303,2.0,15,10.1109/VRW55335.2022.00068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129632993&doi=10.1109%2fVRW55335.2022.00068&partnerID=40&md5=5e81c220b4a2119c389060c280a96f1c,"The current paper discusses how individuals will process social media content within the metaverse world. Also, the current paper will propose an exploratory study that is designed to provide preliminary evidence regarding how individuals cognitively and emotionally process social media posts embedded in a metaverse platform where they experience the simulation of becoming their desired or positive 'future self'. From data obtained from the gaze tracking and social media engagement metrics that measure users' simulated attentional and engagement behaviors, the author will examine to what extent the different temporal distances of virtual or simulated self (present vs near-vs far-future self) and the actual self (lowly vs highly conscientious self) interactively influences the durations of attention (duration of viewing the posts) to and the engagement (i.e., clicking 'like' button for the posts) in different social media posts (e.g., news feeds, positive vs negative dog pictures in native adverts, a health marketing post) seen in the virtual computer screen within the virtual room. In general, it is expected that the father the temporal distance, the longer the duration of the attention to the social media posts. This effect can be moderated by the actual self-views. That is, for participants with negative self-views, the farther the simulated temporal distance, the shorter the duration of attention to the social media posts relevant for the positive self within the metaverse environment. The opposite results are expected to be observed from individuals with positive self-views: the farther the simulated temporal distance, the longer the duration of attention to the social media posts seen within the non-real or metaverse world. The analysis and the plan for the presentation at 2022 IEEE VR workshop is provided in this paper. © 2022 IEEE.",Identity; Information Processing; Metaverse; Time Travel,Commerce; Eye tracking; Marketing; Simulation platform; Virtual reality; 'current; Identity; Information processing; Marketing message; Media content; Metaverses; Social media; Social media marketings; Temporal distance; Time travel; Social networking (online),Conference paper,Final,,Scopus,2-s2.0-85129632993,Movies / Media
Gaprielian P.; Scott S.H.; Levy R.,"Gaprielian, Pauline (56829389600); Scott, Stephen H. (7401506040); Levy, Ron (7404060690)",56829389600; 7401506040; 7404060690,Reverse Visually Guided Reaching in Patients with Parkinson's Disease,2022,Parkinson's Disease,2022,,8132923,,,,2,10.1155/2022/8132923,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128386711&doi=10.1155%2f2022%2f8132923&partnerID=40&md5=9a53b268ec698966cdfcb33606403ade,"In addition to motor symptoms such as difficulty in movement initiation and bradykinesia, patients with Parkinson's disease (PD) display nonmotor executive cognitive dysfunction with deficits in inhibitory control. Preoperative psychological assessments are used to screen for impulsivity that may be worsened by deep brain stimulation (DBS) of the subthalamic nucleus (STN). However, it is unclear whether anti-Parkinson's therapy, such as dopamine replacement therapy (DRT) or DBS, which has beneficial effects on motor function, adversely affects inhibitory control or its domains. The detrimental effects of STN-DBS are more apparent when tasks test the inhibition of habitual prepotent responses or involve complex cognitive loads. Our goal was to use a reverse visually guided reaching (RVGR) task, a hand-based version of the antisaccade task, to simultaneously measure motor performance and response inhibition in subjects with PD. We recruited 55 healthy control subjects, 26 PD subjects receiving treatment with DRTs, and 7 PD subjects receiving treatment with STN-DBS and DRTs. In the RVGR task, a cursor moved opposite to the subject's hand movement. This was compared to visually guided reaching (VGR) where the cursor moved in the same direction as the subject's hand movement. Reaction time, mean speed, and direction errors (in RVGR) were assessed. Reaction times were longer, and mean speeds were slower during RVGR compared to VGR in all three groups but worse in untreated subjects with PD. Treatment with DRTs, DBS, or DBS + DRT improved the reaction time and speed on the RVGR task to a greater extent than VGR. Additionally, DBS or DBS + DRT demonstrated an increase in direction errors, which was correlated with decreased reaction time. These results show that the RVGR task quantifies the benefit of STN-DBS on bradykinesia and the concomitant reduction of proactive inhibitory control. The RVGR task has the potential to be used to rapidly screen for preoperative deficits in inhibitory control and to titrate STN-DBS, to maximize the therapeutic benefits on movement, and minimize impaired inhibitory control.  © 2022 Pauline Gaprielian et al.",,amantadine; carbidopa plus entacapone plus levodopa; levodopa; pramipexole; rasagiline; ropinirole; rotigotine; adult; aged; arm movement; Article; bradykinesia; brain depth stimulation; choice reaction time; clinical article; controlled study; degree of freedom; female; hand movement; human; male; middle aged; motor function test; motor performance; motor reaction time; Parkinson disease; proactive inhibition; reverse visually guided reaching task; saccadic eye movement; substitution therapy; subthalamic nucleus; task performance,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85128386711,Movies / Media
Wang Y.-P.; Chao Y.-P.,"Wang, Yu-Pei (58099187400); Chao, Yi-Ping (15843250800)",58099187400; 15843250800,"To evaluate the learning attention and effectiveness in three remote learning approaches using EEG, eyetracking and traditional exam",2022,"Proceedings - 2022 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2022",,,,255,259,4.0,1,10.1109/AIVR56993.2022.00054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147850955&doi=10.1109%2fAIVR56993.2022.00054&partnerID=40&md5=f707e562c25087d93c542b5f30a73688,"In past three years, many schools have switched to remote learning in response to the new pneumonia epidemic, but remote learning may be less effective due to unsupervised learning or the surrounding environment. This study investigated the impact of three remote learning methods, including (1) 2D video without face (slide + teacher's lecture); (2) 2D video with face (slide + teacher's lecture + showing face); and (3) immersive virtual reality (VR) using 360-degree video. Total 17 students were recruited in our experiment. Based on the grade point average (GPA) in last semester, all participants were divided into two groups: higher GPA and lower GPA first, and then subdivided into three groups with different remote learning method. In order to realize the degree of attention for each participant during the experiment, electroencephalography (EEG) and eye tracking data were collected simultaneously. Moreover, the exam after experiment was also applied to each participant for realizing the learning effectiveness. The results showed that no significant difference exists in the the exam score after watching video between three remote learning methods. The reason might be that the discrimination index of exam were less to distinguish the learning effectiveness. From the EEG scores, the VR group shows higher attention level. However, the VR group shows the worst eye tracking attention score. It might be caused by that the VR content is relatively rich than 2D video. Moreover, for the EEG analysis, we used two different machine learning models for the attention classification, and the final results showed that logistic regression had better classification results. In the future, we would like to use EEG combined with VR for real-time attention alerts to give immediate alerts when students are not concentrating in order to obtain better learning results.  © 2022 IEEE.",EEG; Eye Tracking; logistic regression; VR,"Electroencephalography; Electrophysiology; Learning systems; Logistic regression; Virtual reality; 2D video; Experiment, electroencephalography; Eye-tracking; Grade point average; Learning approach; Learning effectiveness; Learning methods; Logistics regressions; Remote learning; Teachers'; Eye tracking",Conference paper,Final,,Scopus,2-s2.0-85147850955,Movies / Media
Toki E.I.; Tatsis G.; Pange J.; Plachouras K.; Christodoulides P.; Kosma E.I.; Chronopoulos S.K.; Zakopoulou V.,"Toki, Eugenia I. (36544342700); Tatsis, Giorgos (35488955700); Pange, Jenny (6507161641); Plachouras, Konstantinos (57200880847); Christodoulides, Pavlos (53986072200); Kosma, Evangelia I. (57193411500); Chronopoulos, Spyridon K. (35486875600); Zakopoulou, Victoria (37666375900)",36544342700; 35488955700; 6507161641; 57200880847; 53986072200; 57193411500; 35486875600; 37666375900,Can Eye Tracking Identify Prognostic Markers for Learning Disabilities? a Preliminary Study,2022,Lecture Notes in Networks and Systems,411 LNNS,,,1032,1039,7.0,6,10.1007/978-3-030-96296-8_94,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128783389&doi=10.1007%2f978-3-030-96296-8_94&partnerID=40&md5=730ce61b6aec4d579f8119bf01b4a030,"Eye tracking is a promising technology offering objective metrics quantifying visual attention in various application fields. The employment in people with specific learning disabilities (SLDs), who reportedly manifest long-term functional social, emotional, and behavioral difficulties, provided well understandings of their visual attention, detecting cognitive processing mechanisms regarding specific SLD patterns. This study focuses on investigating and reporting the potential of eye tracking technology to identify multifaceted prognostic markers for SLDs. 30 adults (M: 16, F: 14) aged 29.8 ± 13.35 years old were presented with audiovisual stimuli in ordered digital tasks targeted to take real time metrics on (i) emotions, (ii) body scheme perception, and (iii) digital reading out loud. All digital visual stimuli consisted of still images accompanied by audio instructions. Cluster analysis indicated the presence of a variation between groups according to metrics and tasks. Descriptive statistics, gaze heatmaps and cluster diagrams give insights of this study, indicating that reading fixations provide the potential of promising metrics in the current classification. The development of eye tracking digital innovative systems may prove to be a valuable tool for early identification of SLDs, employing learning mobile technology to (i) reduce screening and diagnostic costs and (ii) enhance clinician’s efficiency. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Eye tracking; Prognostic markers; Specific learning disabilities,,Conference paper,Final,,Scopus,2-s2.0-85128783389,Movies / Media
Seeber B.U.; Wackler T.,"Seeber, Bernhard U. (57205697939); Wackler, Tim (58199219600)",57205697939; 58199219600,Measuring auditory attention effort in virtual audio-visual environments using pupillometry,2022,Proceedings of the International Congress on Acoustics,,,,,,,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162293857&partnerID=40&md5=adf4329a1648434b90b8a89ed1b0dfb3,"Pupillometry is a common approach to measure cognitive effort due to attending auditory targets in noise. The enhanced attention to sound sources required in difficult listening situations is associated with cognitive effort, which is linked with an increased pupil diameter. However, pupil diameter is far more affected by the luminance of the focused visual object. Hence, pupillometry is done with low illumination or by focusing on a region with constant luminance. In ecologically valid audio-visual environments, visual objects appear interactively, dynamically in view and luminance changes constantly. We present a method that compensates for these 'environmental luminance effects' such that the measurement of attention through pupil dilation is possible. Using a head-mounted world-camera and an eye-tracker, luminance in the focused area is measured. A system of differential equations is solved to dynamically predict a baseline pupil diameter as a function of momentary luminance. The approach is verified in a listening experiment with cued attention to one of two spatialized talkers and varying difficulty, while luminance on a video projection screen is varied. Results show that the large effect of luminance on pupil diameter can predicted with sufficient accuracy in order to measure the residual small effect of attentional effort. This paves the way for dynamic attention measurements in virtual communication scenarios. © ICA 2022.All rights reserved",communication; eye-tracking; Spatial attention,Differential equations; Luminance; Audio-visual; Auditory attention; Cognitive efforts; Eye-tracking; Pupil diameter; Pupillometry; Sound source; Spatial attention; Visual environments; Visual objects; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85162293857,Movies / Media
Yörük A.; Cangöz-Tavat B.,"Yörük, Aslı (58029226600); Cangöz-Tavat, Banu (57302897100)",58029226600; 57302897100,AGING EFFECT IN PROSPECTIVE MEMORY MONITORING: AN EYE-TRACKING STUDY,2022,Turk Geriatri Dergisi,25,4,,640,649,9.0,2,10.31086/tjgeri.2022.323,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144732780&doi=10.31086%2ftjgeri.2022.323&partnerID=40&md5=e2cb89725b1c7d992966dd678daf4e40,"Introduction: Prospective memory is a robust predictor of functional capacity among older adults. Studies examining prospective memory and aging have suggested that prospective memory deficits are associated with aging. Although the impairment of prospective memory processes is mostly attributed to the impairment of the monitoring process, contradictory findings have been reported in the literature. This study aimed to determine the main factors underlying the negative effects of aging on prospective memory. To this end, we compared the monitoring performances of older and younger adults in time-and event-based prospective memory tasks using the eye-tracking method. Materials and Method: A total of 88 healthy and voluntary participants participated in the experiment. The time-and event-based prospective memory tasks were presented on a computer-screen. Participants were instructed to count the living/non-living objects, and when they saw the prospective memory target on the right corner of the screen, they were asked to press the spacebar on the keyboard. Results: A 2×2 analysis of variance was conducted. We found an age-related decline in event-and time-based prospective memory. In addition, the aging effect was greater in the time-based prospective Memory task, which requires more executive function than the event-based prospective memory task. The eye-tracking findings suggest that there is no monitoring deficit among older adults in either prospective memory task. Conclusion: We conclude that aging deficits in prospective memory tasks may not be due to monitoring deficits. Instead, executive functions other than monitoring are discussed as possible mechanisms underlying older adults’ reduced prospective memory performance. © 2022, Geriatrics Society. All rights reserved.",Aged; Executive Function; Eye-Tracking Technology; Memory; Young Adult,accuracy; adult; aging; analysis of variance; anesthesia; Article; Beck Depression Inventory; behavior; cognition; controlled study; executive function; eye tracking; eye-tracking technology; female; functional status; Geriatric Depression Scale; human; human experiment; information; major clinical study; male; mental disease; Mini Mental State Examination; monitoring; Montreal cognitive assessment; neuropsychological test; normal human; polysomnography; prospective memory; questionnaire; training; validity; Wechsler adult intelligence scale; working memory,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85144732780,Movies / Media
Bauer T.; Hantel V.,"Bauer, Thomas (59850226300); Hantel, Vera (57298213700)",59850226300; 57298213700,Built to attract: Evaluating trade show booth designs using attention analysis in a live communication context,2022,Journal of Convention and Event Tourism,23,3,,240,268,28.0,5,10.1080/15470148.2021.1988022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117170145&doi=10.1080%2f15470148.2021.1988022&partnerID=40&md5=13b3f19bff6688573c444e69c59253cf,"Trade show booths are focal points in exhibitors’ trade show marketing, as well as platforms for meeting different target groups, most important new and existing customers. Booth designs thus need to attract trade show attendees’ attention; this study explores which design elements are most effective for doing so. Using eye-tracking technology, it reveals which design elements attract visitors’ visual gaze, using both and comparing a two-dimensional photographic artwork based laboratory study to an actual three-dimensional visual live experience context. The results indicate comparable gaze patterns and relative importance of design elements in both research settings, such that the same design elements attract the most attention in lab and live communication environments. Distraction and sensory overload result in considerably fewer absolute gaze contacts on trade show floors though. Furthermore, the results show that visually outstanding components such as towers, canopies, furniture, or interaction elements compel more attention than wallpaper or screens. This study validates the use of eye-tracking tools in three-dimensional contexts. It also offers managerial recommendations to exhibitors to include visually remarkable elements in their booths and to rely on eye-tracking techniques to evaluate available design options. © 2021 Taylor & Francis Group, LLC.",attention research; B2B; booth design; eye tracking; trade show,,Review,Final,,Scopus,2-s2.0-85117170145,Movies / Media
Arnaldi D.; Mattioli P.; Famà F.; Girtler N.; Brugnolo A.; Pardini M.; Donniaquio A.; Massa F.; Orso B.; Raffa S.; Bauckneht M.; Morbelli S.; Nobili F.,"Arnaldi, Dario (35809752900); Mattioli, Pietro (57216360491); Famà, Francesco (57076226000); Girtler, Nicola (6602982284); Brugnolo, Andrea (16306634100); Pardini, Matteo (23493507300); Donniaquio, Andrea (57216364713); Massa, Federico (57196120473); Orso, Beatrice (57213192590); Raffa, Stefano (57212192056); Bauckneht, Matteo (55617887700); Morbelli, Silvia (24471961700); Nobili, Flavio (57206948479)",35809752900; 57216360491; 57076226000; 6602982284; 16306634100; 23493507300; 57216364713; 57196120473; 57213192590; 57212192056; 55617887700; 24471961700; 57206948479,Stratification Tools for Disease-Modifying Trials in Prodromal Synucleinopathy,2022,Movement Disorders,37,1,,52,61,9.0,11,10.1002/mds.28785,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115004515&doi=10.1002%2fmds.28785&partnerID=40&md5=83d05c115fe52bc8d036b851fbb0991c,"Background: Dopamine transporter single photon-emission computed tomography (DAT-SPECT) is the strongest risk factor for phenoconversion in patients with idiopathic rapid eye movement (REM)-sleep behavior disorder (iRBD). However, it might be used as a second-line stratification tool in clinical trials, because it is expensive and mini-invasive. Objective: Aim of the study is to investigate whether other cost-effective and non-invasive biomarkers may be proposed as first-line stratification tools. Methods: Forty-seven consecutive iRBD patients (68.53 ± 7.16 years, 40 males) underwent baseline clinical and neuropsychological assessment, olfaction test, resting electroencephalogram (EEG), and DAT-SPECT. All patients underwent 6 month-based clinical follow-up to investigate the emergence of parkinsonism and/or dementia. Survival analysis and Cox regression were used to estimate conversion risk. Results: Seventeen patients developed an overt synucleinopathy (eight Parkinsonism and nine dementia) 32.8 ± 22 months after diagnosis. The strongest risk factors were putamen specific to non-displaceable binding ratio (SBR) (hazard ratio [HR], 7.3), attention/working memory cognitive function (NPS-AT/WM) (HR, 5.9), EEG occipital mean frequency (HR, 2.7) and clinical motor assessment (HR, 2.3). On multivariate Cox-regression analysis, only putamen SBR and NPS-AT/WM significantly contributed to the model (HR, 6.2, 95% confidence interval [CI], 1.9–19.8). At post-hoc analysis, the trail-making test B (TMT-B) was the single most efficient first-line stratification tool that allowed to reduce the number of eligible subjects to 76.6% (sensitivity 1, specificity 0.37). Combining TMT-B and DAT-SPECT further reduced the sample to 66% (sensitivity 0.88, specificity 0.47). Conclusion: The TMT-B seems to be a cost-effective and efficient first-line screening tool, to be used to select patients that deserve DAT-SPECT as second-line screening tool for disease-modifying clinical trials. © 2021 The Authors. Movement Disorders published by Wiley Periodicals LLC on behalf of International Parkinson and Movement Disorder Society. © 2021 The Authors. Movement Disorders published by Wiley Periodicals LLC on behalf of International Parkinson and Movement Disorder Society",,"Humans; Male; Parkinsonian Disorders; Putamen; REM Sleep Behavior Disorder; Synucleinopathies; Tomography, Emission-Computed, Single-Photon; biological marker; ioflupane i 123; aged; Article; attention; caudate nucleus; clinical article; clinical examination; cognition; controlled study; cost effectiveness analysis; dementia; diagnostic test accuracy study; disease risk assessment; electroencephalogram; female; follow up; functional neuroimaging; human; hyposmia; male; neuropsychological test; occipital lobe; parasomnia; Parkinson disease; parkinsonism; prodromal symptom; prospective study; putamen; sensitivity and specificity; single photon emission computed tomography; smelling; survival analysis; synucleinopathy; trail making test; working memory; metabolism; parkinsonism; synucleinopathy",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85115004515,Movies / Media
Ren X.; Duan H.; Min X.; Zhu Y.; Shen W.; Wang L.; Shi F.; Fan L.; Yang X.; Zhai G.,"Ren, Xiaoyu (58102623600); Duan, Huiyu (57195265438); Min, Xiongkuo (56030205300); Zhu, Yucheng (57189598758); Shen, Wei (55574196461); Wang, Linlin (58851948300); Shi, Fangyu (57208839344); Fan, Lei (58466260700); Yang, Xiaokang (7406503333); Zhai, Guangtao (15847120000)",58102623600; 57195265438; 56030205300; 57189598758; 55574196461; 58851948300; 57208839344; 58466260700; 7406503333; 15847120000,Where are the Children with Autism Looking in Reality?,2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13605 LNAI,,,588,600,12.0,5,10.1007/978-3-031-20500-2_48,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148048763&doi=10.1007%2f978-3-031-20500-2_48&partnerID=40&md5=9677595f194b377e5b760ae956cfc853,"Social difficulties are hallmarks of individuals with autism spectrum disorder (ASD), of which atypical visual attention is one of the most important characteristics. Learning and modeling the atypical visual attention of individuals with ASD have particularly important significance to related research in the fields of medical science, psychology, education etc., and many studies have been conducted in the literature. However, previous studies have two weaknesses. First, all stimuli in the conducted experiments are selected by the researchers, which are not only restricted by the objective and intention of the researchers, but also limited by the subjective cognition of the photographers. Secondly, most of these stimuli are displayed on screens with restricted and relatively small field-of-view (FOV) compared with the real world. Therefore, in this paper, we conduct the first large-scale study towards better understanding and modeling the atypical visual attention of individuals with ASD in real world. To overcome the two weaknesses mentioned above, a large-scale dataset is established which includes 300 omnidirectional images with the corresponding eye tracking data collected under virtual reality (VR) environment among 15 children with ASD and 16 typically developing (TD) controls. Moreover, a vector quantized saliency prediction model (VQSAL) is applied to better learn the visual attention patterns of both ASD and TD people under the omnidirectional condition. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Atypical visual attention; Autism spectrum disorder (ASD); Virtual reality (VR),Behavioral research; Diseases; Large dataset; Virtual reality; Atypical visual attention; Atypicals; Autism spectrum disorder; Autism spectrum disorders; Children with autisms; Medical science; Psychology educations; Real-world; Virtual reality; Visual Attention; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85148048763,Movies / Media
Thang S.M.; Priyadarshini M.; Tan J.P.S.; Wong H.K.; Iman A.N.; Sue C.H.,"Thang, Siew Ming (8438412000); Priyadarshini, Muthukrishnan (57208128575); Tan, Jennifer Poh Sim (57900148200); Wong, Hoo Keat (57210927948); Iman, Arshad Nurul (57900393900); Sue, Chee Hao (57899994900)",8438412000; 57208128575; 57900148200; 57210927948; 57900393900; 57899994900,Is There a Relationship between Prereaders’ Visual Attention and Their Storytelling Performance? Evidence from Eye-Tracking and Qualitative Data,2022,CALL-EJ,23,4,,219,239,20.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138565086&partnerID=40&md5=d62dd4645606ce1551cdc7deb6fde3d8,"In the Malaysian context, numerous studies explored young learners’ literacy skills but none uses the eye-tracking device to track the cognitive processes of prereaders when they are reading picture storybooks. For this project 22 prereaders (4-5 years old) listened to brief stories in four conditions: (a) only static text with narration (text condition), (b) oral narration, and a picture that was congruent with the narration (congruent condition), (c) oral narration and an incongruent picture (incongruent condition), and (d) only picture with text but no oral narration (control condition). Inferential statistics were used to analyse the relationship between eye fixation, gender, and story-telling performance. The quantitative analysis revealed that the prereaders’ story-telling performance did not depend on treatment conditions, gender, or fixation patterns on the predefined areas of interest (AOI). To further understand this phenomenon a qualitative analysis was undertaken to explore the patterns of the prereaders’ storytelling performance (STP). The qualitative analysis suggested affective factors such as the prereaders’ state of mind and their level of attentiveness could have affected their STP. Hence, they may appear to be focusing on the screen but their attention could have been somewhere else or they could have been confused. In addition, their lack of proficiency in a language that was not their first/native language and their general inability to communicate well verbally could have been contributory factors. © 2022, The Pacific Association for Computer Assisted Language Learning (PacCALL). All rights reserved.",,,Article,Final,,Scopus,2-s2.0-85138565086,Movies / Media
Partridge G.; Phillips P.; Darker I.; Chen Y.,"Partridge, George (57740057500); Phillips, Peter (57201566625); Darker, Iain (24070033000); Chen, Yan (23396192500)",57740057500; 57201566625; 24070033000; 23396192500,Investigating reading strategies and eye behaviours associated with high diagnostic performance when reading digital breast tomosynthesis (DBT) images,2022,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,12035,,1203508,,,,3,10.1117/12.2611388,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131890086&doi=10.1117%2f12.2611388&partnerID=40&md5=fc7c371a310b25920c3778e0e5efcb41,"Purpose Digital breast tomosynthesis (DBT) exhibits increased sensitivity and specificity compared to 2D mammography (DM), but DBT images are complex and interpretation takes longer. Clinicians may fatigue or hit a cognitive limit sooner when reading DBT, potentially reducing diagnostic accuracy. Eye blink behaviour was investigated to explore fatigue and cognitive load. Methods Screeners (N=47) from five UK breast screening centres were eye tracked as they read 40 DBT cases (15 normal, 6 benign and 19 malignant), from November 2019-July 2021. Differences in diagnostic accuracy and blink behaviour were analysed over the course of the reading session. Blink rates and case durations were investigated by case malignancy and outcome using T-Tests and ANOVAs (α=0.05). Results Blink rates were higher on malignant cases than on normal cases (p=0.004), and blink rates were higher for cases with true positive outcomes than for cases with true negative outcomes (p=0.013). Participants spent less time on malignant cases than normal or benign cases (ps=<0.0001), whilst spending more time on cases with a false positive outcome than on cases with a true negative or true positive outcome (ps<0.0001). No significant difference in blink rate or diagnostic performance by time through reporting session. Conclusion Differences in blink rate and time on case are associated with case malignancy and outcome, potentially reflecting varying cognitive demand and interpretation strategies. Further investigation into blinking during medical image interpretation may identify robust signals of cognition and fatigue that could be used for education and training purposes, whilst indicating optimal screening session duration. 2022 SPIE. © 2022 SPIE. All rights reserved.",Case Interpretation Time; Cognitive Load; Diagnostic Accuracy; Digital Breast Tomosynthesis (DBT); Eye Blink; Eye Tracking; Fatigue,Eye tracking; Optical tomography; Blink rates; Case interpretation time; Cognitive loads; Diagnostic accuracy; Diagnostic performance; Digital breast tomosynthesis; Eye blink; Eye-tracking; True positive; Mammography,Conference paper,Final,,Scopus,2-s2.0-85131890086,Movies / Media
Dawson J.; Foulsham T.,"Dawson, Jessica (57226456999); Foulsham, Tom (8983741300)",57226456999; 8983741300,Your turn to speak? Audiovisual social attention in the lab and in the wild,2022,Visual Cognition,30,2-Jan,,116,134,18.0,8,10.1080/13506285.2021.1958038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111667996&doi=10.1080%2f13506285.2021.1958038&partnerID=40&md5=da6afb20bf39d5c6c37074e8bd74c832,"In everyday group conversations, we must decide whom to pay attention to and when. This process of dynamic social attention is important for goals both perceptual and social. The present study investigated gaze during a conversation in a realistic group and in a controlled laboratory study where third-party observers watched videos of the same group. In both contexts, we explore how gaze allocation is related to turn-taking in speech. Experimental video clips were edited to either remove the sound, freeze the video, or transition to a blank screen, allowing us to determine how shifts in attention between speakers depend on visual or auditory cues. Gaze behaviour in the real, interactive situation was similar to the fixations made by observers watching a video. Eyetracked participants often fixated the person speaking and shifted gaze in response to changes in speaker, even when sound was removed or the video freeze-framed. These findings suggest we sometimes fixate the location of speakers even when no additional visual information can be gained. Our novel approach offers both a comparison of interactive and third-party viewing and the opportunity for controlled experimental manipulations. This delivers a rich understanding of gaze behaviour and multimodal attention during a conversation following. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",audiovisual; conversation; eye tracking; Interaction; signalling,adult; article; attention; auditory stimulation; controlled study; conversation; eye tracking; female; gaze; human; human experiment; male; speech; videorecording; visual information,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85111667996,Movies / Media
Martínez-Rojas A.; Jiménez-Ramírez A.; Enríquez J.G.; Lizcano-Casas D.,"Martínez-Rojas, A. (57211522155); Jiménez-Ramírez, A. (53979785300); Enríquez, J.G. (56203929000); Lizcano-Casas, D. (57209566261)",57211522155; 53979785300; 56203929000; 57209566261,Incorporating the User Attention in User Interface Logs,2022,"International Conference on Web Information Systems and Technologies, WEBIST - Proceedings",2022-October,,,415,421,6.0,3,10.5220/0011568000003318,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146200948&doi=10.5220%2f0011568000003318&partnerID=40&md5=6ec88f1203684a654e3693a5bd1bd623,"Business process analysis is a key factor in the lifecycle of Robotic Process Automation. Currently, task mining techniques provide mechanisms to analyze information about the process tasks to be automated, e.g., identify repetitive tasks or process variations. Existing proposals mainly rely on the user interactions with the UIs of the system (i.e., keyboard and mouse level) and information that can be gathered from them (e.g., the window name) which is stored in a UI event log. In some contexts, the latter information is limited because the system is accessed through virtualized environments (e.g., Citrix or Teamviewer). Other approaches extend the UI Log, including screenshots to address this issue. Regardless of the context, the aim is to store as much information as possible in the UI Log so that is can be analyzed later on, e.g., by extracting features from the screenshots. This amount of information can introduce much noise in the log that messes up what is relevant to the process. To amend this, the current approach proposes a method to include a gaze analyzer, which helps to identify which is process-relevant information between all the information. More precisely, the proposal extends the UI Log definition with the attention change level, which records when the user’s attention changes from one element on the screen to another. This paper sets the research settings for the approach and enumerates the future steps to conduct it. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Eye Tracker; Feature Extraction; Gaze Analysis; Human-Computer Interaction; Noise Filtering; Robotic Process Automation,Computer vision; Eye tracking; Human computer interaction; Life cycle; Mammals; Process control; User interfaces; Virtual reality; Business process analysis; Eye trackers; Features extraction; Gaze analysis; Key factors; Noise filtering; Process automation; Robotic process automation; Screenshots; User attention; Robotics,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85146200948,Movies / Media
Fernández M.R.; Martín L.S.; Tiralaso H.C.,"Fernández, Mario Rajas (56712232500); Martín, Lucía Sutil (57927459900); Tiralaso, Héctor Canorea (57218899048)",56712232500; 57927459900; 57218899048,Neuroscientific techniques applied to audiovisual stimuli: cognitive-emotional analysis of Heineken commercials during COVID-19; [Técnicas neurocientíficas aplicadas a estímulos audiovisuales: análisis cognitivoemocional de anuncios de Heineken durante la COVID-19],2022,Icono14,20,2,,,,,0,10.7195/ri14.v20i2.1836,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139817470&doi=10.7195%2fri14.v20i2.1836&partnerID=40&md5=cd96a194db5c6cf56076d0ebbcb5c6d4,"Using neuroscience techniques applied to the analysis of audiovisual content, four Heineken advertisements produced during the COVID-19 pandemic are studied. The main objective is to detect what cognitive and emotional responses the different stimuli elicit in thirty subjects and to evaluate whether the narrative construction of the advertisements works when conveying their advertising messages in images and sounds. For this purpose, after a preliminary textual analysis, tools for recording facial microexpressions and eye tracking are used, and the research is completed with a recall test. The results indicate the predominance of the emotions of joy and surprise, as well as the presence of other emotions (disgust, contempt, sadness) at specific moments. At the same time, it was found that the types of images that most captured the viewer's attention were those that included eye-catching, exciting, illustrative actions of the pandemic (mask, distance greeting, etc.) or that introduced written text on the screen. Likewise, it is observed that the Heineken product in its various materialisations (bottle, tap, logo, etc.) is only perceived prominently in the frame if there is a dramatic action that accompanies or underlines it. In contrast, the human figure (especially the eyes) is the visual component on which the subjects' gaze is predominantly focused. Finally, the results of the memory test coincide with the rest of the analyses with respect to the intensity of the emotions produced by the stimuli. © 2022 Scientific Association Icono14. All rights reserved.",Advertising; Audiovisual Narrative; COVID-19; Eye Tracking; Facial Coding; Neuroscience,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85139817470,Movies / Media
Moreno J.; Jurado J.M.; Callejas-Aguilera J.E.; Jiménez-Pérez J.R.,"Moreno, Jesús (58784420900); Jurado, Juan M. (57200367247); Callejas-Aguilera, José E. (14014216600); Jiménez-Pérez, J. Roberto (55420831700)",58784420900; 57200367247; 14014216600; 55420831700,A Preliminary Development of the Morris Maze Procedure in Virtual Reality,2022,"Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",1,,,260,267,7.0,0,10.5220/0010897500003124,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180816544&doi=10.5220%2f0010897500003124&partnerID=40&md5=f9c3c7b1d74775683ba37d15a8682a52,"The Morris Water Maze (MWM) has become one of the most widely used laboratory tools in behavioural neuroscience. It has been used in some of the most sophisticated experiments in the study of spatial learning and memory with animals. However, human-based studies have been very limited due to the use of unrealistic scenarios, usually presented on a computer screen where participants' attention is poorly controlled. Recent advances in virtual reality (VR) enable the generation of 3D environments with a high level of realism and user's immersion. The user's attention plays a key role in spatial learning. Current VR systems integrate eye-tracking devices to measure the user's attention over virtual entities. In this paper, we present an easy-to-use game-based simulator of the MWM, using eye-tracking VR technology to extract information about the user's attention. This research still in progress has achieved important hints according to the design of the virtual scenario, user interaction and experimentation. The study conducted in this paper validates the technology as a novel way to perform MWM focused on spatial learning and memory with human participants. © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved",Human-centered Computing; Psychology and Graphic Input Devices; Virtual Reality,,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85180816544,Movies / Media
Wang K.; Julier S.J.; Cho Y.,"Wang, Katherine (57218764149); Julier, Simon J. (7003972937); Cho, Youngjun (57196019045)",57218764149; 7003972937; 57196019045,Attention-Based Applications in Extended Reality to Support Autistic Users: A Systematic Review,2022,IEEE Access,10,,,15574,15593,19.0,12,10.1109/ACCESS.2022.3147726,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124180617&doi=10.1109%2fACCESS.2022.3147726&partnerID=40&md5=8255e5d95746b7812d3cdce4ec80113d,"With the rising prevalence of autism diagnoses, it is essential for research to understand how to leverage technology to support the diverse nature of autistic traits. While traditional interventions focused on technology for medical cure and rehabilitation, recent research aims to understand how technology can accommodate each unique situation in an efficient and engaging way. Extended reality (XR) technology has been shown to be effective in improving attention in autistic users given that it is more engaging and motivating than other traditional mediums. Here, we conducted a systematic review of 59 research articles that explored the role of attention in XR interventions for autistic users. We systematically analyzed demographics, study design and findings, including autism screening and attention measurement methods. Furthermore, given methodological inconsistencies in the literature, we systematically synthesize methods and protocols including screening tools, physiological and behavioral cues of autism and XR tasks. While there is substantial evidence for the effectiveness of using XR in attention-based interventions for autism to support autistic traits, we have identified three principal research gaps that provide promising research directions to examine how autistic populations interact with XR. First, our findings highlight the disproportionate geographic locations of autism studies and underrepresentation of autistic adults, evidence of gender disparity, and presence of individuals diagnosed with co-occurring conditions across studies. Second, many studies used an assortment of standardized and novel tasks and self-report assessments with limited tested reliability. Lastly, the research lacks evidence of performance maintenance and transferability. Based on these challenges, this paper discusses inclusive future research directions considering greater diversification of participant recruitment, robust objective evaluations using physiological measurements (e.g., eye-tracking), and follow-up maintenance sessions that promote transferrable skills. Pursuing these opportunities would lead to more effective therapy solutions, improved accessible interfaces, and engaging interactions. © 2013 IEEE.",assistive technology; attention; autism spectrum disorder; Extended reality,Diagnosis; Eye tracking; Job analysis; Maintenance; Physiology; Assistive technology; Attention; Autism spectrum disorders; Extended reality; Medical cures; Recent researches; Systematic; Systematic Review; Task analysis; X reality; Diseases,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85124180617,Movies / Media
Dal Ben R.; Killam H.; Pour Iliaei S.; Byers-Heinlein K.,"Dal Ben, Rodrigo (57222341099); Killam, Hilary (57223978451); Pour Iliaei, Sadaf (57220206375); Byers-Heinlein, Krista (21933333000)",57222341099; 57223978451; 57220206375; 21933333000,Bilingualism Affects Infant Cognition: Insights From New and Open Data,2022,Open Mind,6,,,88,117,29.0,4,10.1162/opmi_a_00057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149301053&doi=10.1162%2fopmi_a_00057&partnerID=40&md5=70d00afa66b72ca324786b82d3e52a20,"Bilingualism has been hypothesized to shape cognitive abilities across the lifespan. Here, we examined the replicability of a seminal study that showed monolingual–bilingual differences in infancy (Kovács & Mehler, 2009a) by collecting new data from 7-month-olds and 20-month-olds and reanalyzing three open datasets from 7-to 9-month-olds (D’Souza et al., 2020; Kalashnikova et al., 2020, 2021). Infants from all studies (N = 222) were tested in an anticipatory eye-tracking paradigm, where they learned to use a cue to anticipate a reward presented on one side of a screen during Training, and the opposite side at Test. To correctly anticipate the reward at Test, infants had to update their previously learned behavior. Across four out of five studies, a fine-grained analysis of infants’ anticipations showed that bilinguals were better able to update the previously learned response at Test, which could be related to bilinguals’ weaker initial learning during Training. However, in one study of 7-month-olds, we observed the opposite pattern: bilinguals performed better during Training, and monolinguals performed better at Test. These results show that bilingualism affects how infants process information during learning. We also highlight the potential of open science to advance our understanding of language development. © 2022 Massachusetts Institute of Technology.",anticipatory looking; bilingualism; cognitive control; infancy; inhibitory control,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85149301053,Movies / Media
Zhang X.; Zhang X.; Wu L.; Li C.; Chen X.; Chen X.,"Zhang, Xuan (57774133700); Zhang, Xu (36007982800); Wu, Le (57856066100); Li, Chang (56718731300); Chen, Xiang (59343087200); Chen, Xun (36456894700)",57774133700; 36007982800; 57856066100; 56718731300; 59343087200; 36456894700,Domain Adaptation With Self-Guided Adaptive Sampling Strategy: Feature Alignment for Cross-User Myoelectric Pattern Recognition,2022,IEEE Transactions on Neural Systems and Rehabilitation Engineering,30,,,1374,1383,9.0,30,10.1109/TNSRE.2022.3173946,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131216537&doi=10.1109%2fTNSRE.2022.3173946&partnerID=40&md5=d338061d91bbecf40675dce486140c8b,"Gestural interfaces based on surface electromyographic (sEMG) signal have been widely explored. Nevertheless, due to the individual differences in the sEMG signals, it is very challenging for a myoelectric pattern recognition control system to adapt cross-user variability. Unsupervised domain adaptation (UDA) has achieved unprecedented success in improving the cross-domain robustness, and it is a promising approach to solve the cross-user challenge. Existing UDA methods largely ignore the instantaneous data distribution during model updating, thus deteriorating the feature representation given a large domain shift. To address this issue, a novel method is proposed based on a UDA model incorporated with a self-guided adaptive sampling (SGAS) strategy. This strategy is designed to utilize the domain distance in a kernel space as an indicator to screen out reliable instantaneous samples for updating the classifier. Thus, it enables improved alignment of feature representations of myoelectric patterns across users. To evaluate the performance of the proposed method, sEMG data were recorded from forearm muscles of nine subjects performing six finger and wrist gestures. Experiment results show that the UDA method with the SGAS strategy achieved a mean accuracy of 90.41% ± 14.44% in a cross-user classification manner, outperformed the state-of-the-art methods with statistical significance (p < 0.05). This study demonstrates the effectiveness of the proposed UDA framework and offers a novel tool for implementing cross-user myoelectric pattern recognition towards a multi-user and user-independent control.  © 2001-2011 IEEE.",cross-user variability; domain adaptation; Electromyography (EMG); gestural interfaces; myoelectric control,"Algorithms; Electromyography; Gestures; Humans; Muscle, Skeletal; Pattern Recognition, Automated; Biomedical signal processing; Electromyography; Feature extraction; Adaptation methods; Adaptation models; Adaptive sampling strategies; Cross-user variability; Domain adaptation; Electromyography; Features extraction; Finger; Gestural interfaces; Myoelectric control; adult; Article; clinical article; control system; electromyography; emotion; eye tracking; fatigue; female; finger; functional magnetic resonance imaging; gesture; human; human experiment; male; myoelectric control; nerve block; principal component analysis; recognition; sensitivity analysis; signal processing; speech intelligibility; statistical significance; support vector machine; surface property; task performance; working memory; algorithm; automated pattern recognition; physiology; procedures; skeletal muscle; Muscle",Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85131216537,Movies / Media
Schmidt L.L.; Maier E.,"Schmidt, Lennard L. (57209217409); Maier, Erik (55363235000)",57209217409; 55363235000,Interactive Ad Avoidance on Mobile Phones,2022,Journal of Advertising,51,4,,440,449,9.0,15,10.1080/00913367.2022.2077266,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133023731&doi=10.1080%2f00913367.2022.2077266&partnerID=40&md5=dc1380b8ba401158e789b292514769de,"Ad avoidance (e.g., “blinding out” digital ads) is a substantial problem for advertisers. Avoiding mobile banner ads differs from active ad avoidance in nonmobile (desktop) settings, because mobile phone users interact with ads to avoid them: (1) They classify new content at the bottom of their screens; if they see an ad, they (2) scroll so that it is out of the locus of attention and (3) position it at a peripheral location at the top of the screen while focusing their attention on the (non-ad) content in the screen center. Introducing viewport logging to marketing research, we capture granular ad-viewing patterns from users’ screens (i.e., viewports). While mobile users’ ad-viewing patterns are concave over the viewport (with more time at the periphery than in the screen center), viewing patterns on desktop computers are convex (most time in the screen center). Consequently, we show that the effect of viewing time on recall depends on the position of an ad in interaction with the device. An eye-tracking study and an experiment show that 43% to 46% of embedded mobile banner ads are likely to suffer from ad avoidance, and that ad recall is 6 to 7 percentage points lower on mobile phones (versus desktop). © Copyright © 2022, American Academy of Advertising.",,,Article,Final,,Scopus,2-s2.0-85133023731,Movies / Media
Lauer T.; Võ M.L.-H.,"Lauer, Tim (57204038899); Võ, Melissa L.-H. (9634349400)",57204038899; 9634349400,The ingredients of scenes that affect object search and perception,2022,Human Perception of Visual Information: Psychological and Computational Perspectives,,,,1,32,31.0,8,10.1007/978-3-030-81465-6_1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135741593&doi=10.1007%2f978-3-030-81465-6_1&partnerID=40&md5=097d20d115522f0493bef8919ec07cff,"Humans search for, identify, and interact with objects efficiently, utilizing not only the visual characteristics of the object itself but also contextual information to generate optimal predictions about objects in scenes. Over the course of our lives, we have acquired knowledge regarding co-occurring local objects as well as the global scene contexts in which they are usually encountered, creating strong predictions regarding what objects are typically found where in our environment. A number of studies from the last decades have characterized how such knowledge may guide attention in scene viewing and modulate object perception, using diverse methodologies like psychophysics, eye tracking, and neurophysiology, with various degrees of realism ranging from on-screen experiments via virtual reality to real-world studies. Some recent work has focused on investigating what ""ingredients"" of scenes actually influence object search and perception. Scenes tend to be hierarchically organized with some objects-so-called ""anchor objects""-holding stronger predictions than others. Apart from meaningful objects, global scene properties (e.g., spatial layout or texture) have been shown to predict object identity. In order to tease apart the influence of such ingredients, large-scale databases and machine learning techniques have become increasingly popular. Here, we review recent advances in the field that help to better capture human efficiency in real-world scene and object perception, particularly focusing on which contextual information we take advantage of most and when. Further, we explore how these findings could be useful in pushing computer vision further ahead and how computer vision could mutually further our understanding of human visual perception. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.",Contextual modulation; Object recognition; Scene perception; Visual search,,Book chapter,Final,,Scopus,2-s2.0-85135741593,Movies / Media
Flores R.; Tlachac M.L.; Toto E.; Rundensteiner E.,"Flores, Ricardo (57479121800); Tlachac, M.L. (57203187245); Toto, Ermal (36440224800); Rundensteiner, Elke (7005195084)",57479121800; 57203187245; 36440224800; 7005195084,AudiFace: Multimodal Deep Learning for Depression Screening,2022,Proceedings of Machine Learning Research,182,,,609,630,21.0,13,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164540455&partnerID=40&md5=f8c754f77e1c90ffb51fd492f4b48372,"Depression is a very common mental health disorder with a devastating social and economic impact. It can be costly and difficult to detect, traditionally requiring a significant number of hours by a trained mental health professional. Recently, machine learning and deep learning models have been trained for depression screening using modalities extracted from videos of clinical interviews conducted by a virtual agent. This complex task is challenging for deep learning models because of the multiple modalities and limited number of participants in the dataset. To address these challenges we propose AudiFace, a multimodal deep learning model that inputs temporal facial features, audio, and transcripts to screen for depression. To incorporate all three modalities, AudiFace combines multiple pre-trained transfer learning models and bidirectional LSTM with self-Attention. When compared with the state-of-the-art models, AudiFace achieves the highest F1 scores for thirteen of the fifteen different datasets. AudiFace notably improves the depression screening capabilities of general wellbeing questions. Eye gaze proved to be the most valuable of the temporal facial features, both in the unimodal and multimodal models. Our results can be used to determine the best combination of modalities, temporal facial features, as well as clinical interview questions for future depression screening applications. © 2022 R. Flores, M. Tlachac, E. Toto & E. Rundensteiner.",,Long short-term memory; Professional aspects; Clinical interview; Facial feature; Health disorders; Health professionals; Learning models; Machine-learning; Mental health; Multi-modal; Social and economic impacts; Virtual agent; Learning systems,Conference paper,Final,,Scopus,2-s2.0-85164540455,Movies / Media
Clough M.; Bartholomew J.; White O.; Fielding J.,"Clough, Meaghan (54943951200); Bartholomew, Jade (57744153800); White, Owen (7006065793); Fielding, Joanne (7202507959)",54943951200; 57744153800; 7006065793; 7202507959,Investigating the Utility of the BrainEye Smartphone Eye Tracking Application and Platform in Concussion Management,2025,Sports Medicine - Open,11,1,24,,,,0,10.1186/s40798-025-00819-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000036579&doi=10.1186%2fs40798-025-00819-8&partnerID=40&md5=ecbbb440c643163a9a31648bbdf9c6b0,"Background: Concussion is a common consequence of engaging in collision sports, with the often mild, transient nature of symptoms posing a considerable diagnostic and management challenge. This challenge is vastly magnified for athletes competing at grassroots/non-professional levels, who lack field side access to medical expertise in the assessment of a player’s capacity to continue playing or need for further medical attention. The aim of this pilot study was to evaluate the utility of the BrainEye application and hardware (BrainEye platform) as a concussion screening tool, specifically determining (1) its sensitivity and specificity with respect to identifying an individual with a clinically diagnosed concussion, (2) the stability of the platform through test completion/failure rates, and (3) its usability through operator feedback and uptake/integration into concussion management protocols. Results: Using the BrainEye platform, 348 male professional Australian Rules footballers from 10 Australian Football League (AFL) clubs completed 4 simple ocular protocols (pupillary light reflex, PLR; smooth pursuit eye movements, SMP; near-point convergence, NPC; horizontal gaze nystagmus, HGN) at baseline, prior to the onset of the 2022 AFL season, and following the clinical diagnosis of concussion throughout the season during a game/training/practice (n = 11 players immediately following a concussive event, and on 14 occasions 2–7 days following a concussive event). Although club participation and protocol adherence rates were suboptimal, with clubs citing COVID-19 restrictions and cumbersome hardware set-up as primary reasons for non-participation/missing data, a BrainEye score that derived from an algorithm combining smooth pursuit and pupillary light reflex measures, achieved 100% sensitivity relative to clinical judgement, in identifying all instances of clinically diagnosed concussion, and 85% specificity. Conclusions: Collectively, the results of this study suggest that by removing the requirement for add-on hardware and providing a smartphone-only option with direct feedback on performance to the user, the BrainEye application may provide a useful screening tool for sport-related concussion. © The Author(s) 2025.",Eye tracking; Post-concussion management; Smartphone-based eye tracking; Sports related concussion,adult; algorithm; area under the curve; Article; Australian football; controlled study; coronavirus disease 2019; decision making; diagnostic test accuracy study; eye movement; eye-tracking technology; follow up; football player; head movement; human; longitudinal study; male; predictive value; pupil reflex; questionnaire; risk factor; sensitivity and specificity; smooth pursuit eye movement; sport-related concussion; young adult,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-105000036579,Movies / Media
Wang Z.-M.; Rao M.-H.; Ye S.-H.; Song W.-T.; Lu F.,"Wang, Zhi-Min (57221604684); Rao, Mao-Hang (59166493500); Ye, Shang-Hua (59636103200); Song, Wei-Tao (55936562300); Lu, Feng (54956194300)",57221604684; 59166493500; 59636103200; 55936562300; 54956194300,Towards spatial computing: recent advances in multimodal natural interaction for Extended Reality headsets,2025,Frontiers of Computer Science,19,12,1912708,,,,0,10.1007/s11704-025-41123-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010087446&doi=10.1007%2fs11704-025-41123-8&partnerID=40&md5=e6c0a1a0cfae2b6114f973ae1ba1566a,"With the widespread adoption of Extended Reality (XR) headsets, spatial computing technologies are gaining increasing attention. Spatial computing enables interaction with virtual elements through natural input methods such as eye tracking, hand gestures, and voice commands, thus placing natural human-computer interaction at its core. While previous surveys have reviewed conventional XR interaction techniques, recent advancements in natural interaction, particularly driven by artificial intelligence (AI) and large language models (LLMs), have introduced new paradigms and technologies. In this paper, we review research on multimodal natural interaction for wearable XR, focusing on papers published since 2022 in six top venues: ACM CHI, UIST, IMWUT (Ubicomp), IEEE VR, ISMAR, and TVCG. We classify and analyze these studies based on application scenarios, operation types, and interaction modalities. This analysis provides a structured framework for understanding how researchers are designing advanced natural interaction techniques in XR. Based on these findings, we discuss the challenges in natural interaction techniques and suggest potential directions for future research. This review provides valuable insights for researchers aiming to design natural and efficient interaction systems for XR, ultimately contributing to the advancement of spatial computing. © The Author(s) 2025.",extended reality; eye; hand; multimodal; natural interaction; speech,Artificial intelligence; Human computer interaction; Interactive computer systems; Natural language processing systems; Wearable computers; Computing technology; Extended reality; Eye; Hand; Input methods; Interaction techniques; Multi-modal; Natural interactions; Spatial computing; Virtual elements; Eye tracking,Review,Final,,Scopus,2-s2.0-105010087446,Movies / Media
Zhao W.; Duan F.; Li X.; Li J.; Xia L.; Ren Z.; Li Y.; Song L.; Song P.; Mu L.; Wang L.; Zhang J.; Song X.; Wang Z.; Chen J.; Zhang X.; Jiao D.,"Zhao, Wei (57223808381); Duan, Fan (58261481900); Li, Xiangyu (58790627100); Li, Junda (57950555700); Xia, Lingling (57950182900); Ren, Zixuan (57223824118); Li, Yegang (59548612300); Song, Li (59548627400); Song, Peipei (57377855800); Mu, Linlin (57216849443); Wang, Lijin (57378019700); Zhang, Jing (56336401000); Song, Xun (57223826878); Wang, Ze (58260742600); Chen, Jinxuan (58671000500); Zhang, Xiaochu (8570352000); Jiao, Dongliang (56650692800)",57223808381; 58261481900; 58790627100; 57950555700; 57950182900; 57223824118; 59548612300; 59548627400; 57377855800; 57216849443; 57378019700; 56336401000; 57223826878; 58260742600; 58671000500; 8570352000; 56650692800,Cognitive control in individuals with heroin use disorder after prolonged methadone maintenance treatment,2025,BMC Psychiatry,25,1,78,,,,0,10.1186/s12888-025-06523-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217271300&doi=10.1186%2fs12888-025-06523-x&partnerID=40&md5=d4e9f2247ab5d279bd682f6873ab57f9,"Background: Although impaired cognitive control is common during the acute detoxification phase of substance use disorders (SUD) and is considered a major cause of relapse, it remains unclear after prolonged methadone maintenance treatment (MMT). The aim of the present study was to elucidate cognitive control in individuals with heroin use disorder (HUD) after prolonged MMT and its association with previous relapse. Methods: A total of 63 HUD subjects (41 subjects with previous relapse and 22 non-relapse subjects, mean MMT duration: 12.24 ± 2.92 years) and 31 healthy controls were enrolled in this study. Eye tracking tasks, prospective memory tasks, the Behavior Rating Inventory of Executive Function-Adult Version (BRIEF-A) and the Prospective and Retrospective Memory Questionnaire (PRMQ) were used to assess cognitive control. Results: HUD individuals exhibited worse saccade error rate and executive dysfunction but showed no significant impairment in prospective memory. Additionally, the relapsers performed worse in terms of antisaccade amplitude and velocity at higher difficulty gradients (11° or 16°). Antisaccade performance in terms of amplitude and velocity was negatively correlated with executive function scores. Deficits in inhibition, cognitive flexibility, and self-monitoring were found to mediate the relationship between previous relapse and impaired antisaccade performance. Conclusions: Even after prolonged MMT, HUD individuals still show partial impairments in cognitive control and antisaccade performance. Previous relapse exacerbates cognitive control deficits through executive dysfunction in inhibition, cognitive flexibility and self-monitoring, which can be screened by higher difficulty of antisaccade amplitude and velocity. More importantly, saccade error rate can reflect impaired inhibitory control in HUD individuals, whereas antisaccade amplitude and velocity appear to have potential diagnostic value for relapse. © The Author(s) 2025.",Antisaccade; Cognitive control; Executive function; Heroin use disorder; Methadone maintenance treatment; Prospective memory; Relapse,"Adult; Case-Control Studies; Cognition; Cognitive Dysfunction; Executive Function; Female; Heroin Dependence; Humans; Male; Memory, Episodic; Methadone; Middle Aged; Opiate Substitution Treatment; Recurrence; Saccades; methadone; adult; Article; cognition; controlled study; detoxification; diagnostic value; education; error; executive function; eye tracking; female; heroin dependence; human; maintenance therapy; major clinical study; male; methadone treatment; normal human; questionnaire; statistical analysis; substance use; working memory; case control study; cognition; cognitive defect; drug effect; drug therapy; episodic memory; etiology; executive function; middle aged; opiate substitution treatment; pathophysiology; physiology; procedures; psychology; recurrent disease; saccadic eye movement",Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85217271300,Movies / Media
Galli J.; Vezzoli M.; Loi E.; Micheletti S.; Molinaro A.; Tagliavento L.; Calza S.; Sokolov A.N.; Pavlova M.A.; Fazzi E.,"Galli, Jessica (23978191300); Vezzoli, Marika (55370513600); Loi, Erika (57226611952); Micheletti, Serena (41861930200); Molinaro, Anna (35068403100); Tagliavento, Lucia (57194445791); Calza, Stefano (57207776770); Sokolov, Alexander N. (7402612159); Pavlova, Marina A. (7102023223); Fazzi, Elisa (7004236903)",23978191300; 55370513600; 57226611952; 41861930200; 35068403100; 57194445791; 57207776770; 7402612159; 7102023223; 7004236903,Alterations in looking at face-pareidolia images in autism,2025,Scientific Reports,15,1,14915,,,,0,10.1038/s41598-025-98461-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003776776&doi=10.1038%2fs41598-025-98461-7&partnerID=40&md5=fd9ee3b642e9b55c5f3ecc93398e2985,"Face tuning is vital for adaptive and effective social cognition and interaction. This capability is impaired in a wide range of mental conditions including autism spectrum disorder (ASD). Yet the origins of this deficit are largely unknown. Here, an eye-tracking methodology had been implemented in adolescents with high-functioning ASD and in typically developing (TD) matched controls while administering a face-pareidolia task. The spatial distributions of eye fixation in five regions of interest [face, eyes, mouth, CFA (complementary face area, a face area beyond eyes and mouth) and non-face area (a screen area outside a face)] were recorded during spontaneous recognition of a set of Arcimboldo-like Face-n-Food images presented in a predetermined order from the least to most resembling a face. Individuals with ASD gave significantly fewer face responses and looked more often at the mouth, CFA, and non-face areas. By contrast, TD controls mostly fixated the face and eyes areas. The atypical visual scanning strategies could, at least partly, account for the lower face tuning in ASD, supporting the eye avoidance hypothesis, according to which ASD individuals concentrate less on the eyes because the eyes represent a source of emotional information that may make them feel uncomfortable. © The Author(s) 2025.",Autism spectrum disorder; Eye tracking; Face pareidolia; Social cognition; Visual scanning,"Adolescent; Autism Spectrum Disorder; Autistic Disorder; Case-Control Studies; Child; Eye-Tracking Technology; Face; Facial Recognition; Female; Fixation, Ocular; Humans; Male; adolescent; autism; case control study; child; eye fixation; eye-tracking technology; face; facial recognition; female; human; male; pathophysiology; physiology; psychology",Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-105003776776,Movies / Media
Huang H.-Y.; Xu F.; Zhang D.; Luo A.-L.; Xu Y.-M.,"Huang, Hong-yan (57193222246); Xu, Fang (57224583353); Zhang, Dan (57221543705); Luo, An-ling (57429991500); Xu, Yan-ming (57207020913)",57193222246; 57224583353; 57221543705; 57429991500; 57207020913,Prevalence of and risk factors for probable rapid eye movement sleep behavior disorder in Chinese patients with essential tremor,2025,Sleep Medicine,133,,106666,,,,0,10.1016/j.sleep.2025.106666,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009814419&doi=10.1016%2fj.sleep.2025.106666&partnerID=40&md5=fc01dc24d786662a8e83e10702d8f2c5,"Objectives: To investigate the prevalence and risk factors for probable rapid eye movement (REM) sleep behavior disorder (pRBD) in Chinese patients with essential tremor (ET). Methods: In this cross-sectional study, 391 ET patients underwent assessments of sociodemographics, lifestyles, environmental exposures, medical histories, and motor/nonmotor symptoms. pRBD status was evaluated using the RBD screening questionnaire (RBDSQ). Risk factors for pRBD in ET patients were identified via multivariable logistic regression. Results: Fifty-six patients (14.3 %) met the criteria for pRBD, with a male predominance (60.7 %). Patients with pRBD were significantly older (mean age: 61.43 vs. 51.99 years) and had late tremor onset (49.34 vs. 42.21 years) than those without pRBD (both Padjusted < 0.05). They also showed higher prevalence of jaw tremor (32.1 % vs. 9.3 %), depressive symptoms (67.9 % vs. 43.3 %), antidepressant use (10.7 % vs. 1.8 %), elevated anxiety scores (Hamilton Anxiety Rating Scale: 12.38 ± 7.47 vs. 9.05 ± 6.09), and depression scores (Hamilton Depression Rating Scale-24: 11.25 ± 7.81 vs. 7.91 ± 6.20) (all Padjusted < 0.05). Multivariate analysis identified male sex (OR = 3.038, P = 0.001), older age (OR = 1.045, P < 0.001), jaw tremor (OR = 3.734, P = 0.001), at least mild depression (OR = 2.484, P = 0.006), and antidepressant use (OR = 6.069, P = 0.009) were independent predictors. Conclusions: pRBD affects approximately 1/7 of ET patients. Identified risk factors overlap with α-synucleinopathy-associated features (male predominance, jaw tremor, depressive symptoms), suggesting ET-pRBD patients may constitute a phenoconversion-prone subgroup requiring long-term monitoring. Antidepressants known to exacerbate RBD symptoms should be prescribed judiciously in this population. © 2025 Elsevier B.V.",Clinical features; Essential tremor; Prevalence; Rapid eye movement sleep behavior disorder,antidepressant agent; adult; alcohol consumption; anxiety; Article; biochemical analysis; caffeine intake; ceruloplasmin blood level; cognition assessment; cohort analysis; constipation; controlled study; cross-sectional study; diagnostic test accuracy study; environmental exposure; essential tremor; face-to-face interview; Fahn-Tolosa-Marin Tremor Rating Scale; female; finger to nose test; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; heavy drinking; human; International Restless Legs Syndrome Study Group Rating Scale; lifestyle; major clinical study; male; middle aged; Mini Mental State Examination; nuclear magnetic resonance imaging; occupational exposure; Pittsburgh Sleep Quality Index; prevalence; REM sleep; REM Sleep Behavior Disorder Screening Questionnaire; REM sleep parasomnia; restless legs syndrome; risk factor; sensitivity analysis; sensitivity and specificity; smelling disorder; smoking; sociodemographics; synucleinopathy; thyroid function test,Article,Final,,Scopus,2-s2.0-105009814419,Movies / Media
Li Y.; Jia C.; Liu Y.; Duan W.; Qing X.; Zhang J.; Weng X.,"Li, Yongzhi (55876153600); Jia, Chunyang (59483189400); Liu, Yulin (58084989400); Duan, Wei (57211501408); Qing, Xiaolong (57214726620); Zhang, Jianguo (57216154608); Weng, Xiaolong (15133595600)",55876153600; 59483189400; 58084989400; 57211501408; 57214726620; 57216154608; 15133595600,Evaluation of electrochromic film camouflage effect based on visual perception,2025,Displays,89,,103066,,,,0,10.1016/j.displa.2025.103066,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004551014&doi=10.1016%2fj.displa.2025.103066&partnerID=40&md5=d410f97515801c8d4b3d9754cce42cf6,"Modern battlefields demand adaptive camouflage technologies for target survivability. Electrochromic films that adjust their color to blend with changing environments are applicable in active stealth camouflage. Assessing the camouflage capabilities of such devices is a critical component of their effective deployment. However, achieving consistency between subjective assessments and objective measurements represents a significant and complex challenge in camouflage evaluation. Therefore, this paper introduces a novel method for assessing the camouflage effectiveness of electrochromic films based on visual perception. This approach leverages the visual attention mechanism and target saliency detection theory to analyze target saliency through brightness, color, and texture features. The weight assigned to each feature is determined by the focus of visual attention. Subsequently, the significance value is calculated employing a Markov chain, thereby quantifying the camouflage effect. The method's scientific validity was demonstrated through observer experiments, with subjective results that were consistent with the objective evaluation. © 2025 Elsevier B.V.",Active stealth camouflage; Camouflage effect evaluation; Electrochromic film; Target saliency; Visual attention mechanism,Depth perception; Electrooculography; Eye movements; Markov processes; Active stealth; Active stealth camouflage; Camouflage effect evaluation; Camouflage technology; Changing environment; Effect evaluation; Electrochromic films; Target saliency; Visual attention mechanisms; Visual perception; Color vision,Article,Final,,Scopus,2-s2.0-105004551014,Movies / Media
Silveira I.; Varandas R.; Gamboa H.,"Silveira, Inês (57226569455); Varandas, Rui (57208422432); Gamboa, Hugo (57200265948)",57226569455; 57208422432; 57200265948,Cognitive Lab: A dataset of biosignals and HCI features for cognitive process investigation,2025,Computer Methods and Programs in Biomedicine,269,,108863,,,,0,10.1016/j.cmpb.2025.108863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007597151&doi=10.1016%2fj.cmpb.2025.108863&partnerID=40&md5=275f1b6d2ceaee1be4ee48363bfba431,"Background and Objective: Attention, cognitive workload/fatigue, and emotional states significantly influence learning outcomes, cognitive performance, and human–machine interactions. However, existing assessment methodologies fail to fully capture the multimodal nature of these cognitive processes, limiting their application in adaptive learning environments. This study presents the Cognitive Lab, a comprehensive multimodal dataset designed to investigate these cognitive processes across real-time learning scenarios. Specifically, it aims to capture and enable the classification of (1) attention and cognitive workload states using standard cognitive tasks, (2) cognitive fatigue arising from prolonged digital activities, and (3) emotional and learning states during interactive lessons. Methods: The Cognitive Lab dataset consists of three distinct subsets, each developed through specific experimental scenarios targeting different aspects of learning. Dataset 1 comprises recordings from eight participants performing N-Back and mental subtraction tasks, aimed at assessing attention and cognitive workload. Dataset 2 includes data from 10 participants engaged in a digital lesson, complemented by Corsi block-tapping and concentration tasks, to evaluate cognitive fatigue. Lastly, Dataset 3 captures data from 18 participants during an interactive Jupyter Notebook lesson, focusing on emotional states and learning processes. Each scenario combined biosignals (accelerometry, ECG, EDA, EEG, fNIRS, respiration) with Human-Computer Interaction (HCI) features (mouse-tracking, keyboard activity, screenshots). Machine learning models were applied to classify cognitive states, with cross-validation ensuring robust results. Results: The dataset enabled accurate classification of learning states, achieving up to 87% accuracy in differentiating learning states using mouse-tracking data. Furthermore, it successfully differentiated attention, cognitive workload, and cognitive fatigue states using biosignal and HCI data, with fNIRS, EEG, and ECG emerging as key contributors to classification performance. Variability across participants highlighted the potential for subject-specific calibration to enhance model accuracy. Conclusions: The Cognitive Lab dataset represents a resource for investigating cognitive phenomena in real-world learning scenarios. Its integration of biosignals and HCI features enables the classification of cognitive states and supports advancements in adaptive learning systems, cognitive neuroscience, and brain–computer interface technologies. © 2025 The Authors",Attention; Biosignals; Cognitive fatigue; Cognitive states; Cognitive workload; HCI; Learning; Learning states,Adult; Attention; Cognition; Electroencephalography; Emotions; Fatigue; Female; Humans; Learning; Machine Learning; Male; User-Computer Interface; Workload; Young Adult; Active learning; Interactive computer systems; Attention; Biosignals; Cognitive fatigue; Cognitive process; Cognitive state; Cognitive workloads; Computer interaction; Interaction features; Learning; Learning state; accelerometry; adult; Article; attention; breathing; calibration; classification; clinical article; cognition; cross validation; electrocardiography; electrodermal response; electroencephalography; emotion; fatigue; female; functional near-infrared spectroscopy; human; human computer interaction; information processing; learning; machine learning; male; n-back test; prediction; rest; self report; videorecording; workload; computer interface; young adult; Backpropagation,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-105007597151,Movies / Media
Su T.; Yang M.; Zhou W.; Tao Y.; Ni M.; Zheng W.; Hu B.,"Su, Tongxu (59559810400); Yang, Minqiang (57061181400); Zhou, Wei (58597461200); Tao, Yongfeng (58608984100); Ni, Minghui (59261536900); Zheng, Weihao (56605699800); Hu, Bin (58594670300)",59559810400; 57061181400; 58597461200; 58608984100; 59261536900; 56605699800; 58594670300,Joint probabilistic modeling analysis of head and eye behaviors in autism spectrum disorder children based on a social interaction paradigm,2025,Biomedical Signal Processing and Control,106,,107669,,,,1,10.1016/j.bspc.2025.107669,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217974954&doi=10.1016%2fj.bspc.2025.107669&partnerID=40&md5=824b5b50da90054f2db591a46187ab6c,"Autism Spectrum Disorder (ASD), as a complex neurodevelopmental disorder, is closely associated with attention deficits that manifest through eye and head movements. Previous studies on the eye gaze and head posture of children with ASD have been somewhat limited by the contexts in which the children were observed, Exploring head and eye coordination in natural environments is crucial for developing effective intervention strategies applicable to everyday life. This paper aims to examine the perceptual and behavioral responses of children with ASD in simulated real-life social environments. Using a social interaction paradigm based on real-life scenarios, we propose a joint probabilistic modeling method for head and eye behaviors. This method includes the influence of head posture on gaze direction in eye-tracking studies within social interaction contexts. For each participant, we establish a data-driven Markov chain model based on individual data, preserving the temporal nature of eye movement behavior and the highly individualized nature of visual behavior. We conducted experiments on a video dataset of children with ASD that we collected, achieving a classification accuracy of 79.66%, demonstrating the feasibility and effectiveness of our proposed method. Additionally, we found that one manifestation of attention deficits in children with ASD is an increased occurrence of head-eye counter movement. This finding provides new reference indicators for the early diagnosis and screening of ASD. © 2025 Elsevier Ltd",Autism spectrum disorder; Eye movements; Head gestures; Joint probabilistic,Diseases; Attention deficit; Autism spectrum disorders; Children with autisms; Head gestures; Head posture; Interaction paradigm; Joint probabilistic; Modeling analyzes; Probabilistic models; Social interactions; Article; attention deficit hyperactivity disorder; autism; child; early diagnosis; eye movement; eye tracking; female; gaze; gesture; head movement; head position; human; major clinical study; male; Markov chain; model; simulation; social environment; social interaction; videorecording; Eye movements,Article,Final,,Scopus,2-s2.0-85217974954,Movies / Media
Fisher G.,"Fisher, Geoffrey (55995669400)",55995669400,"Triangulating decision-making via choices, eye fixations, and reaching trajectories",2025,Organizational Behavior and Human Decision Processes,189,,104421,,,,0,10.1016/j.obhdp.2025.104421,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008351500&doi=10.1016%2fj.obhdp.2025.104421&partnerID=40&md5=67f16f6b9355fc644308183f8fd38a89,"People often face choices that involve tradeoffs over time or under uncertainty. While these decisions have been widely studied, most research focuses on the final choice rather than the process leading to it. In this paper, we combine two process-tracing tools, eye-tracking and mouse cursor tracking, to observe how decisions unfold in real time. Across two incentive-compatible experiments, we find that both visual attention and mouse movements predict choice, and together they provide complementary, non-overlapping insights. These tools also reveal how seemingly minor factors, such as where information appears on a computer screen, can influence decisions. By capturing the dynamics of the decision-making process, this approach offers valuable implications for organizations aiming to better understand, predict, or shape behavior. © 2025 Elsevier Inc.",Eye tracking; Intertemporal choice; Mouse cursor tracking; Process tracing; Risky choice,,Article,Final,,Scopus,2-s2.0-105008351500,Movies / Media
Latifzadeh K.; Gwizdka J.; Leiva L.A.,"Latifzadeh, Kayhan (57605229200); Gwizdka, Jacek (6602631792); Leiva, Luis A. (34880363200)",57605229200; 6602631792; 34880363200,A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages,2025,SIGIR 2025 - Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval,,,,3412,3421,9.0,1,10.1145/3726302.3730325,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011821992&doi=10.1145%2f3726302.3730325&partnerID=40&md5=b780c78f116f4943ddec9ae4c5a1b448,"We contribute a comprehensive dataset to study user attention and purchasing behavior on Search Engine Result Pages (SERPs). Previous work has relied on mouse movements as a low-cost large-scale behavioral proxy but also has relied on self-reported ground-truth labels, collected at post-task, which can be inaccurate and prone to biases. To address this limitation, we use an eye tracker to construct an objective ground-truth of continuous visual attention. Our dataset comprises 2,776 transactional queries on Google SERPs, collected from 47 participants, and includes: (1) HTML source files, with CSS and images; (2) rendered SERP screenshots; (3) eye movement data; (4) mouse movement data; (5) bounding boxes of direct display and organic advertisements; and (6) scripts for further preprocessing the data. In this paper we provide an overview of the dataset and baseline experiments (classification tasks) that can inspire researchers about the different possibilities for future work. © 2025 Copyright held by the owner/author(s).",eye tracking; mouse tracking; SERPs; sponsored search,Behavioral research; Classification (of information); Eye movements; Human engineering; Information systems; Mammals; Query processing; Search engines; Websites; Eye-tracking; Ground truth; Large-scales; Low-costs; Mouse movements; Mouse tracking; Purchasing behaviors; Search engine results pages; Sponsored searches; User attention; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-105011821992,Movies / Media
Lindner H.; Merabet L.B.; Lundqvist L.-O.,"Lindner, Helen (26640447200); Merabet, Lotfi B. (6603146795); Lundqvist, Lars-Olov (56186454700)",26640447200; 6603146795; 56186454700,The feasibility of using eye-tracking technology for cognitive screening in Down syndrome with dementia: A cross-sectional case series,2025,Alzheimer's and Dementia,21,6,e70385,,,,0,10.1002/alz.70385,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008354597&doi=10.1002%2falz.70385&partnerID=40&md5=b2e83ba903d24bded2ce0a43f4b55faf,"INTRODUCTION: Adults with Down syndrome (DS) are at a high risk for dementia, yet cognitive screening is complicated by premorbid intellectual disabilities. This study evaluated the feasibility of using eye-tracking technology as a screening tool. METHODS: Ten adults with DS (five with dementia, five without) completed cognitive tasks while their eye movements were recorded. Feasibility was assessed through calibration success, gaze sample quality, and task completion. RESULTS: Calibration was successful for most subjects (except one individual with dementia required five attempts and had low gaze sampling). Most subjects achieved 50%–88% gaze sample rates and completed testing with staff support. Subjects with dementia showed longer times to first fixation but similar fixation durations compared to those without dementia. Cognitive scores were lower in the dementia group but not significantly correlated with gaze quality. DISCUSSION: Eye tracking may be a feasible method for cognitive screening in DS, but further validation is needed. Highlights: Eye-tracking may be a potential non-verbal method for cognitive screening in individuals with DS. Support from staff for engaging the subjects could be essential for maintaining attention on the computer screen. © 2025 The Author(s). Alzheimer's & Dementia published by Wiley Periodicals LLC on behalf of Alzheimer's Association.",cognition; dementia; Down syndrome; eye-tracking; screening,Adult; Aged; Cognition; Cross-Sectional Studies; Dementia; Down Syndrome; Eye Movements; Eye-Tracking Technology; Feasibility Studies; Female; Humans; Male; Middle Aged; Neuropsychological Tests; adult; Article; augmentative and alternative communication; calibration; clinical article; cognition; controlled study; cross-sectional study; data quality; dementia; Down syndrome; eye tracking; eye-tracking technology; feasibility study; female; gaze; human; intellectual impairment; male; memory; mental concentration; middle aged; screening; aged; cognition; complication; diagnosis; eye movement; neuropsychological assessment; physiology,Article,Final,,Scopus,2-s2.0-105008354597,Movies / Media
Shi W.; Ono K.; Li L.,"Shi, Wenjia (59937374700); Ono, Kenta (57316521100); Li, Liang (59002699800)",59937374700; 57316521100; 59002699800,Cognitive Insights into Museum Engagement: A Mobile Eye-Tracking Study on Visual Attention Distribution and Learning Experience,2025,Electronics (Switzerland),14,11,2208,,,,0,10.3390/electronics14112208,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007788976&doi=10.3390%2felectronics14112208&partnerID=40&md5=e0e08c23731c95f558f5f17ef2a4e124,"Recent advancements in Mobile Eye-Tracking (MET) technology have enabled the detailed examination of visitors’ embodied visual behaviors as they navigate exhibition spaces. This study employs MET to investigate visual attention patterns in an archeological museum, with a particular focus on identifying “hotspots” of attention. Through a multi-phase research design, we explore the relationship between visitor gaze behavior and museum learning experiences in a real-world setting. Using three key eye movement metrics—Time to First Fixation (TFF), Average Fixation Duration (AFD), and Total Fixation Duration (TFD), we analyze the distribution of visual attention across predefined Areas of Interest (AOIs). Time to First Fixation varied substantially by element, occurring most rapidly for artifacts and most slowly for labels, while video screens showed the shortest mean latency but greatest inter-individual variability, reflecting sequential exploration and heterogeneous strategies toward dynamic versus static media. Total Fixation Duration was highest for video screens and picture panels, intermediate yet variable for artifacts and text panels, and lowest for labels, indicating that dynamic and pictorial content most effectively sustain attention. Finally, Average Fixation Duration peaked on artifacts and labels, suggesting in-depth processing of descriptive elements, and it was shortest on video screens, consistent with rapid, distributed fixations in response to dynamic media. The results provide novel insights into the spatial and contextual factors that influence visitor engagement and knowledge acquisition in museum environments. Based on these findings, we discuss strategic implications for museum research and propose practical recommendations for optimizing exhibition design to enhance visitor experience and learning outcomes. © 2025 by the authors.",cognitive engagement; contextual learning model; mobile eye tracking; museum learning; visual attention,Average fixation durations; Cognitive engagement; Contextual learning; Contextual learning model; Learning experiences; Learning models; Mobile eye-tracking; Museum learning; Video screens; Visual Attention,Article,Final,,Scopus,2-s2.0-105007788976,Movies / Media
Hauffe V.; Rauschenbach A.-L.; Fassot E.-M.; Schmitz J.; Tuschen-Caffier B.,"Hauffe, Vera (58613374200); Rauschenbach, Anna-Lina (59164829100); Fassot, Eva-Maria (57822181900); Schmitz, Julian (36053746300); Tuschen-Caffier, Brunna (6602689650)",58613374200; 59164829100; 57822181900; 36053746300; 6602689650,Early hypervigilance and sustained attention for the eye region in adolescents with social anxiety disorder,2025,Journal of Anxiety Disorders,112,,103016,,,,0,10.1016/j.janxdis.2025.103016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002211298&doi=10.1016%2fj.janxdis.2025.103016&partnerID=40&md5=ae0db2c37f880c01090226159faa3e4a,"Social anxiety disorder (SAD) is a highly prevalent and debilitating affliction that typically manifests during childhood and adolescence. While theoretical models of adult SAD emphasize the role of attentional biases, little is known about maintaining factors during childhood and adolescence. The objective of our eye-tracking study was to determine whether youth with SAD exhibit a hypervigilance-avoidance pattern of visual attention for faces. To this end, we used a free-viewing paradigm to present angry, happy, and neutral faces, and non-social object stimuli to three groups of adolescents aged 10–15 years: SAD (n = 57), specific phobia (SP; n = 41), and healthy controls (HC; n = 65). A screen-based eye tracker recorded gaze behavior and pupil dilation. Among participants, only older adolescents with SAD exhibited shorter latencies of first fixation to the eye region compared to HC. Contrary to our expectations, there were no differences in duration of first fixation to the eye region among the groups. Instead, compared to HC, older adolescents with SAD showed longer dwell times on the eye region during the first 1000 – 3000 ms of stimulus presentation. No significant differences among the groups were found regarding scanpath length or pupillary reactivity. Taken together, our findings suggest early hypervigilance followed by sustained attention to the eye region in older adolescents with SAD, which may indicate difficulties in disengaging attention. We discuss the theoretical and practical implications in detail. © 2025 The Authors",Adolescent Psychopathology; Attentional Bias; Eye Movements; Pupil Dilation; Social Anxiety Disorder,"Adolescent; Attention; Child; Eye-Tracking Technology; Facial Expression; Facial Recognition; Female; Fixation, Ocular; Humans; Male; Phobia, Social; Phobia, Specific; Phobic Disorders; adolescent; alertness; anxiety assessment; Article; attentional bias; child; controlled study; data analysis; DSM-5; exploratory research; eye; eye movement; eye tracking; facial expression; female; human; hypervigilance; latent period; major clinical study; male; pupil reflex; pupillometry; social anxiety; social phobia; visual attention; visual stimulation; attention; eye fixation; eye-tracking technology; facial recognition; pathophysiology; phobia; physiology; psychology; social phobia",Article,Final,,Scopus,2-s2.0-105002211298,Movies / Media
Robert T.; Tan Y.T.; Ganot D.; Loh Y.J.; Nityananda V.,"Robert, Théo (57193517442); Tan, Yi Ting (59952838100); Ganot, Dune (58281869900); Loh, Yi Jie (58281191100); Nityananda, Vivek (13607830000)",57193517442; 59952838100; 58281869900; 58281191100; 13607830000,Prior cueing affects the saccadic response to targets in the praying mantis Sphodromantis lineola,2025,Journal of Experimental Biology,228,11,jeb249296,,,,1,10.1242/jeb.249296,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008448600&doi=10.1242%2fjeb.249296&partnerID=40&md5=7e9d9e9aaefe0b91e57902e7c363a493,"External cues bias human attention and the perception of subsequent targets. Little is known about how cue properties, such as depth, influence insect attention. One robust cue to depth is stereoscopic disparity, which is the difference in the position of an object in the views of the two eyes. Praying mantises are known to use disparity to judge the distance to prey and are therefore ideal insect models to investigate its role in attention. We investigated how three cue properties – position, duration and stereoscopic disparity – affect mantis selective attention towards subsequent targets. We fitted mantises with 3D glasses and presented them with a cue in 2D or 3D, followed by two 3D stimuli: a high-contrast target and a ‘distractor’ at different contrasts. Our results show that cue position and distractor contrast had the most influence on responses to targets, with no strong effect of disparity. Compared with the ‘uncued’ condition, cues in two of our disparity conditions reduced target responses if presented on the opposite side of the screen, when the distractor was absent. The cues affected subsequent selective attention even when they did not themselves elicit head saccades, suggesting covert but not overt attention to the cues. Our results show that the position of prior cues can affect mantis selective attention and add further evidence for the complexity of attention-like processes in insects. © 2025 Company of Biologists Ltd. All rights reserved.",Cueing; Insect vision; Praying mantis; Selective attention; Stereoscopic vision,Animals; Attention; Cues; Male; Mantodea; Saccades; animal; association; attention; male; Mantodea; physiology; saccadic eye movement,Article,Final,,Scopus,2-s2.0-105008448600,Movies / Media
Palmović M.,"Palmović, Marijan (23568560800)",23568560800,USE OF THE EYE-TRACKING METHOD IN RESEARCH ON DYSLEXIA; [ISTRAŽIVANJA DISLEKSIJE METODOM MJERENJA POKRETA OKA],2025,Hrvatska Revija Za Rehabilitacijska Istrazivanja,61,1,,144,174,30.0,0,10.31299/hrri.61.1.9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009052199&doi=10.31299%2fhrri.61.1.9&partnerID=40&md5=b60892525d543062c9308351048d9e74,"With the development of non-invasive and easy-to-use devices, the measurement of eye movement is becoming increasingly common in research on language processing. This paper presents the use of eye-tracking devices in dyslexia research, encompassing all aspects of research on this disorder, from aetiology to diagnosis and therapy. In studies examining the causes of dyslexia, two opposing perspectives are presented: the “linguistic” and “non-linguistic” viewpoints, depending on whether the causes are attributed to phonological problems or considered a consequence of deficits in other cognitive or biological functions (e.g., oculomotor deficits). In screening and diagnosis, methods used to measure eye movement increasingly rely on machine learning algorithms that automatically classify signals from the device. The development of fonts and applications is the most common way of incorporating eye movement measurement in therapy. © 2025, University of Zagreb, Faculty of Education and Rehabilitation Sciences. All rights reserved.",aetiology; assistive technology; diagnostics; dyslexia; eye-tracking; literature review; reading,assistive technology; biological functions; cognition; diagnosis; dyslexia; etiology; eye movement; eye movement monitor; eye tracking; eye-tracking technology; human; language processing; machine learning algorithm; oculography; review,Review,Final,,Scopus,2-s2.0-105009052199,Movies / Media
Cai Y.; Strauch C.; Van der Stigchel S.; Brink A.F.T.; Cornelissen F.W.; Naber M.,"Cai, Yuqing (58755656400); Strauch, Christoph (56767914200); Van der Stigchel, Stefan (55887364000); Brink, Antonia F. Ten (57219814983); Cornelissen, Frans W. (7003574141); Naber, Marnix (24577145000)",58755656400; 56767914200; 55887364000; 57219814983; 7003574141; 24577145000,Mapping simulated visual field defects with movie-viewing pupil perimetry,2025,Graefe's Archive for Clinical and Experimental Ophthalmology,263,6,,1641,1650,9.0,1,10.1007/s00417-024-06733-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217199583&doi=10.1007%2fs00417-024-06733-1&partnerID=40&md5=7142ebc5ea868cf689bf897da5b3f145,"Purpose: Assessing the quality of the visual field is important for the diagnosis of ophthalmic and neurological diseases and, consequently, for rehabilitation. Visual field defects (VFDs) are typically assessed using standard automated perimetry (SAP). However, SAP requires participants to understand instructions, maintain fixation and sustained attention, and provide overt responses. These aspects make SAP less suitable for very young or cognitively impaired populations. Here we investigate the feasibility of a new and less demanding form of perimetry. This method assesses visual sensitivity based on pupil responses while performing the perhaps simplest task imaginable: watching movies. Method: We analyzed an existing dataset, with healthy participants (n = 70) freely watching movies with or without gaze-contingent simulated VFDs, either hemianopia (left- or right-sided) or glaucoma (large nasal arc, small nasal arc, and tunnel vision). Meanwhile, their gaze and pupil size were recorded. Using a recently published toolbox (Open-DPSM), we modeled the relative contribution of visual events to the pupil responses to indicate relative visual sensitivity across the visual field and to dissociate between conditions with and without simulated VFDs. Result: Conditions with and without simulated VFDs could be dissociated, with an AUC ranging from 0.85 to 0.97, depending on the specific simulated VFD condition. In addition, the dissociation was better when including more movies in the modeling but the model with as few movies as 10 movies was sufficient for a good classification (AUC ranging from 0.84 to 0.96). Conclusion: Movie-viewing pupil perimetry is promising in providing complementary information for the diagnosis of VFDs, especially for those who are unable to perform conventional perimetry. © The Author(s) 2025.",Glaucoma; Hemianopia; Modeling pupil size; Pupil perimetry; Simulated visual field defects,Adult; Female; Glaucoma; Healthy Volunteers; Hemianopsia; Humans; Male; Middle Aged; Motion Pictures; Pupil; Visual Field Tests; Visual Fields; Young Adult; Article; controlled study; eye movement; female; gaze; glaucoma; hemianopia; human; male; perimetry; pupil diameter; receiver operating characteristic; visual field; visual field defect; adult; diagnosis; hemianopia; middle aged; movie; normal human; pathophysiology; physiology; procedures; pupil; visual field; young adult,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85217199583,Movies / Media
Orui M.; Ishikuro M.; Obara T.; Noda A.; Shinoda G.; Murakami K.; Metoki H.; Kikuya M.; Nakaya N.; Nishimura T.; Tanaka K.; Miyake Y.; Hozawa A.; Tsuchiya K.J.; Kuriyama S.,"Orui, Masatsugu (36990527100); Ishikuro, Mami (55211552400); Obara, Taku (7103069231); Noda, Aoi (57188800236); Shinoda, Genki (58290611000); Murakami, Keiko (56939726500); Metoki, Hirohito (6701459599); Kikuya, Masahiro (7004682122); Nakaya, Naoki (7005037475); Nishimura, Tomoko (57203983652); Tanaka, Keiko (7406927266); Miyake, Yoshihiro (34571749400); Hozawa, Atsushi (7003868341); Tsuchiya, Kenji J. (8567495200); Kuriyama, Shinichi (59142892600)",36990527100; 55211552400; 7103069231; 57188800236; 58290611000; 56939726500; 6701459599; 7004682122; 7005037475; 57203983652; 7406927266; 34571749400; 7003868341; 8567495200; 59142892600,Longitudinal association between the duration of eye gaze fixation on social information and specific symptoms of neurodevelopmental disorders in children: A large-scale community-based cohort study,2025,Psychiatry and Clinical Neurosciences Reports,4,2,e70095,,,,0,10.1002/pcn5.70095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005998561&doi=10.1002%2fpcn5.70095&partnerID=40&md5=84c413ba536ca8a40cfa435372a0f240,"Aim: Autism spectrum disorder (ASD) is a neurodevelopmental condition clinically characterized by abnormalities in eye contact during social interactions. Eye-tracking systems have been used to screen individuals with ASD by capturing atypical eye gaze patterns of diagnostic significance, such as reduced duration of eye gaze fixation on social information. However, most prior studies have focused on the screening accuracy of eye-tracking systems in children already diagnosed with ASD, with few longitudinal assessments conducted on a large scale. This large-scale, longitudinal, community-based study aimed to analyze the association between specific neurodevelopmental symptoms and the duration of eye gaze fixation on social information within a community-based setting. Methods: A longitudinal study involving 2101 participants utilized a generalized linear model (GLM) to examine associations between the duration of eye gaze fixation on social information at age 4 years and subscale scores of the Strengths and Difficulties Questionnaire (SDQ) at ages 6–7. Results: GLM analysis revealed that shorter durations of eye gaze fixation on social information at age 4 years were significantly associated with emotional problems and peer problems, and with hyperactivity/inattention attention-deficit hyperactivity disorder (ADHD) at ages 6–7 years. Conclusion: These findings demonstrate the ability to detect not only peer problems characteristic of ASD but also hyperactivity/inattention characteristic of ADHD longitudinally, which it might be related to the comorbidity of ASD and ADHD. This preliminary study highlights the potential for neurodevelopmental screening; however, further research is needed to validate the accuracy of these methods. © 2025 The Author(s). Psychiatry and Clinical Neurosciences Reports published by John Wiley & Sons Australia, Ltd on behalf of Japanese Society of Psychiatry and Neurology.",ADHD; ASD; eye-tracking; Gazefinder; longitudinal,,Article,Final,,Scopus,2-s2.0-105005998561,Movies / Media
Kuric E.; Demcak P.; Majzel J.; Nguyen G.,"Kuric, Eduard (54893849100); Demcak, Peter (58110843300); Majzel, Jozef (59679377300); Nguyen, Giang (55597236900)",54893849100; 58110843300; 59679377300; 55597236900,Democratizing eye-tracking? Appearance-based gaze estimation with improved attention branch,2025,Engineering Applications of Artificial Intelligence,149,,110494,,,,1,10.1016/j.engappai.2025.110494,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000598608&doi=10.1016%2fj.engappai.2025.110494&partnerID=40&md5=c0d103d7bca15ed8caa3f282c6fa23c8,"Appearance-based gaze estimation in 2-dimensional screen coordinates–the prediction of the users’ gaze from webcam footage–cannot yet compete in accuracy with infrared (IR) eye trackers. Yet by circumventing the constraints of requiring dedicated hardware, it shows great potential in many technological industries, as evidenced by some readily available commercial solutions, bringing democratization of eye tracking closer to the people. We present Residual Appearance-based Gaze Estimation network (RAGE-net), a novel convolutional neural network for gaze estimation without need of calibration, utilizing a fraction of computational resources required by similar networks, while also achieving competitive accuracy. The angular error is measured as 4.08°in the MPIIFaceGaze dataset (Max Planck Institute for Informatics Faze Gaze) and 3.96°in the MPIIGaze dataset. The architecture's principles, covered by a comprehensive ablation study, include an attention branch, residual learning, weight sharing between eye channels, batch normalization and an eye image input normalization pipeline that removes dependence on full face input. With RAGE-net, we conduct an applicability study for gaze estimation approaches of similar accuracy for interpreting on-screen gaze in praxis. Findings demonstrate low heatmap validity, with coarse heatmaps as potential adaptation to approximate IR eye tracking. The effects of environmental factors such as camera position, illumination, distance and glasses are analyzed in-depth. © 2025 The Authors",Attention branch; Environmental factors; Eye appearance; Eye tracking; Gaze estimation; Residual learning,Face recognition; 2 - Dimensional; Appearance based; Attention branch; Environmental factors; Eye appearance; Eye-tracking; Gaze estimation; Heatmaps; Normalisation; Residual learning; Convolutional neural networks,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-86000598608,Movies / Media
Gado S.; Gamer M.,"Gado, Sabrina (57226267716); Gamer, Matthias (8979946100)",57226267716; 8979946100,Studying the influence of single social interactions on approach and avoidance behavior: A multimodal investigation in immersive virtual reality,2025,Behavior Research Methods,57,6,157,,,,0,10.3758/s13428-025-02627-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003806556&doi=10.3758%2fs13428-025-02627-0&partnerID=40&md5=1649c872ded536e5387cfecc518eedeb,"When studying spontaneous or learned emotional responses to social stimuli, research has traditionally relied on simplified stimuli repeatedly presented on a computer screen in standardized laboratory environments. While these studies have provided important insights into social perception and cognition, their restricted ecological validity may impede the extrapolation of findings to everyday social contexts. Here, we developed a novel immersive virtual reality scenario that permits the examination of social approach and avoidance behavior under naturalistic circumstances while at the same time maintaining full experimental control. Using a combination of a social conditioning procedure with a social approach–avoidance test, we conducted two experiments (both with N = 48 female participants) to investigate how individuals differing in trait social anxiety adapt their behavior after a single encounter with an either friendly or unfriendly virtual agent. In addition to overt approach and avoidance behavior, we acquired subjective ratings, eye-tracking data, and autonomic responses. Overall, we observed significant effects of the social conditioning procedure on autonomic responses and participants’ exploration behavior. After initially increased attention, participants exhibited avoidance of social threats as indicated by a higher interpersonal distance and decreased visual attention towards the negatively conditioned virtual agent in the test phase. We found no association between hypervigilance and trait social anxiety but observed higher fear ratings and enhanced avoidance of social threats in participants with elevated anxiety levels. Altogether, this study demonstrates the potential of immersive virtual environments for examining social learning processes under conditions resembling real-life social encounters. © The Author(s) 2025.",Ecological validity; Social attention; Social conditioning; Vigilance-avoidance; Virtual reality,Adolescent; Adult; Anxiety; Avoidance Learning; Fear; Female; Humans; Male; Social Behavior; Social Interaction; Social Perception; Virtual Reality; Young Adult; adolescent; adult; anxiety; avoidance behavior; fear; female; human; male; perception; physiology; psychology; social behavior; social interaction; virtual reality; young adult,Article,Final,,Scopus,2-s2.0-105003806556,Movies / Media
Kong S.D.; Schrire Z.M.; Lin P.H.; Simonetti S.; Cross N.; Mowszowski L.; Ireland C.; Rosenzweig I.; Naismith S.L.,"Kong, Shawn Dexiao (57208275758); Schrire, Zoe Menczel (57222023530); Lin, Ping Hsiu (57214145215); Simonetti, Simone (57219705946); Cross, Nathan (55927809700); Mowszowski, Loren (36437504700); Ireland, Catriona (57201251182); Rosenzweig, Ivana (6602775623); Naismith, Sharon L. (6604064942)",57208275758; 57222023530; 57214145215; 57219705946; 55927809700; 36437504700; 57201251182; 6602775623; 6604064942,Validating the CogSleep Screener in older adults at a memory and cognition clinic,2025,Journal of Sleep Research,34,3,e14355,,,,0,10.1111/jsr.14355,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205301031&doi=10.1111%2fjsr.14355&partnerID=40&md5=9fea55024767b212b5c388bb0bad1e14,"While sleep disturbances are prevalent in older people and are linked with poor health and cognitive outcomes, screening for the range of sleep disturbances is inefficient and therefore not ideal nor routine in memory and cognition clinic settings. We aimed to develop and validate a new brief self-report questionnaire for easy use within memory and cognition clinics. The design for this study was cross-sectional. Older adults (aged ≥50 in Sydney, Australia) were recruited from a memory and cognition research clinic. Participants (N = 497, mean age 67.7 years, range 50–86, 65.0% female) completed a comprehensive medical, neuropsychological, and mental health assessment, alongside self-report instruments, including existing sleep questionnaires and a new 10-item sleep questionnaire, the CogSleep Screener. We examined the factor structure, convergent validity, internal consistency, and discriminant validity of this novel questionnaire. Using exploratory factor analysis, a 3-factor solution was generated highlighting the factors of Insomnia, Rapid Eye Movement (REM) Symptoms and Daytime Sleepiness. Each factor was significantly correlated with currently used sleep questionnaires for each subdomain (all Spearman rho >0.3, all p < 0.001), suggesting good convergent validity. Internal consistency was also good (Revelle's ω =.74). Receiver operating characteristic curves showed good discriminative ability between participants with and without sleep disturbances (all area under curve >0.7, all p < 0.01). The CogSleep Screener has good psychometric properties in older to elderly adults attending a memory and cognition clinic. The instrument has the potential to be used in memory clinics and other clinical settings to provide quick and accurate screening of sleep disturbances. [Correction added on April 2025, after first publication: The number of participants has been updated and associated statistics have been updated]. © 2024 The Author(s). Journal of Sleep Research published by John Wiley & Sons Ltd on behalf of European Sleep Research Society.",memory clinic; mild cognitive impairment; older adults; psychometrics; sleep disturbances,"Aged; Aged, 80 and over; Australia; Cross-Sectional Studies; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Psychometrics; Reproducibility of Results; Self Report; Sleep Initiation and Maintenance Disorders; Sleep Wake Disorders; Surveys and Questionnaires; adult; aged; Article; clinical assessment; cognition; cognitive defect; consensus; controlled study; convergent validity; cross-sectional study; daytime somnolence; discriminant validity; exploratory factor analysis; female; human; insomnia; Insomnia Severity Index; internal consistency; major clinical study; male; memory; mental health; mild cognitive impairment; Mini Mental State Examination; neuropsychology; percentage of REM sleep; Pittsburgh Sleep Quality Index; psychometry; questionnaire; REM sleep; self report; sleep disorder; sleep quality; sleep questionnaire; Australia; diagnosis; insomnia; middle aged; neuropsychological assessment; reproducibility; self report; sleep disorder; validation study; very elderly",Article,Final,,Scopus,2-s2.0-85205301031,Movies / Media
Wang Y.; Nilsson M.,"Wang, Yiting (57344959500); Nilsson, Mattias (57192377443)",57344959500; 57192377443,Microsaccades as Indicators for Early-Stage Parkinson’s Disease: An Explainable AI Approach,2025,Eye Tracking Research and Applications Symposium (ETRA),,,17,,,,0,10.1145/3715669.3723133,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008497070&doi=10.1145%2f3715669.3723133&partnerID=40&md5=0db8bf32c464f4e8c2d494db624a5435,"Abnormal fixational eye movements are frequently observed in individuals with Parkinson’s disease (PD). While these involuntary movements have the potential to serve as objective indicators for early-stage PD screening, the specific role of microsaccades has yet to be validated using computational methods such as machine learning. In this study, we combine explainable AI (XAI) techniques with end-to-end classification to evaluate the contribution of microsaccades in differentiating early-stage PD from healthy controls using data from a simple fixation task. An attention mechanism is employed to analyze raw binocular eye position data, while integrated gradients are used to identify the most influential samples in the model’s decision-making process. Experimental results show that it is feasible to distinguish early-stage PD based on raw eye tracking data. Importantly, visualizing integrated gradients across eye position over time indicates that microsaccades play a key role in classification, underscoring their potential as discriminative features for early-stage PD screening. © 2025 Copyright held by the owner/author(s).",Early-stage Parkinson’s Disease; End-to-end Classification; Explainable AI; Fixational Eye Movement,Artificial intelligence; Classification (of information); Computer aided diagnosis; Decision making; Eye tracking; Human engineering; Learning systems; Neurodegenerative diseases; Disease screening; Early-stage parkinson’s disease; End to end; End-to-end classification; Explainable AI; Eye position; Fixational eye movements; Involuntary movements; Machine-learning; Microsaccades; Eye movements,Conference paper,Final,,Scopus,2-s2.0-105008497070,Movies / Media
Ibrahimi D.; Aviles M.; Rojas-Galván R.; Rodríguez Reséndiz J.,"Ibrahimi, Danjela (57217134424); Aviles, Marcos (57432236800); Rojas-Galván, Rafael (59387829000); Rodríguez Reséndiz, Juvenal (57204683375)",57217134424; 57432236800; 59387829000; 57204683375,"Sensory–Cognitive Profiles in Children with ADHD: Exploring Perceptual–Motor, Auditory, and Oculomotor Function",2025,Bioengineering,12,6,621,,,,0,10.3390/bioengineering12060621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009048553&doi=10.3390%2fbioengineering12060621&partnerID=40&md5=1d5793cc14ddbdcc0a27e86a98e0337f,"Objective: This observational cross-sectional study aimed to comprehensively evaluate sensory–cognitive performance in children diagnosed with Attention-Deficit/Hyperactivity Disorder (ADHD), with a focus on auditory processing, visual–perceptual abilities, visual–motor integration, and oculomotor function. The study further examined how hyperactivity, age, and gender may influence these domains. Methods: A total of 70 non-medicated children with clinically diagnosed ADHD (mean age = (Formula presented.) years; 67.1% male), all with normal visual acuity, were assessed using four standardized instruments: the Test of Auditory Processing Skills, Third Edition (TAPS-3), the Test of Visual Perceptual Skills, Fourth Edition (TVPS-4), the Beery–Buktenica Developmental Test of Visual–Motor Integration, Sixth Edition (VMI-6), and the Developmental Eye Movement (DEM) Test. Statistical analyses included one sample and independent samples t-tests, one-way ANOVA, and Pearson correlation coefficients. Results: Participants demonstrated significantly above-average performance in auditory processing (TAPS-3: (Formula presented.), (Formula presented.)), average visual–perceptual abilities (TVPS-4: (Formula presented.), (Formula presented.)), slightly below-average visual–motor integration (VMI-6: (Formula presented.), (Formula presented.)), and marked deficits in oculomotor efficiency (DEM ratio: (Formula presented.), (Formula presented.)). Statistically significant differences were observed across these domains (t-values ranging from 2.9 to 7.2, (Formula presented.)). Children with hyperactive-impulsive presentations exhibited lower horizontal DEM scores ((Formula presented.), (Formula presented.)) compared to inattentive counterparts ((Formula presented.), (Formula presented.) ; (Formula presented.)). Age and sex influenced specific subtest scores, with boys and children aged 8–9 years achieving higher outcomes in word memory ((Formula presented.)) and visual discrimination ((Formula presented.)), respectively. Moderate correlations were identified between auditory and visual–perceptual skills ((Formula presented.), (Formula presented.)), and between visual–perceptual and oculomotor performance ((Formula presented.), (Formula presented.)). Conclusions: The findings from this sample reveal a distinct sensory–cognitive profile in children with ADHD, characterized by relatively preserved auditory processing and pronounced oculomotor deficits. These results underscore the value of a multimodal assessment protocol that includes oculomotor and visual efficiency evaluations. The conclusions pertain specifically to the cohort studied and should not be generalized to all populations with ADHD without further validation. © 2025 by the authors.",ADHD; neurostimulation; ocular treatment; visual health; visual therapy,,Article,Final,,Scopus,2-s2.0-105009048553,Movies / Media
Hu X.; Mo X.; Jin X.; Hu Y.; Fan M.; Braud T.,"Hu, Xiaozhu (57223392474); Mo, Xiaoyu (57914883200); Jin, Xiaofu (57219688341); Hu, Yongquan (57952642800); Fan, Mingming (26424940800); Braud, Tristan (56427955400)",57223392474; 57914883200; 57219688341; 57952642800; 26424940800; 56427955400,Modeling the Intuitiveness of Mobile GUI Navigation by Understanding and Simulating Users' Attention Distribution,2025,WWW Companion 2025 - Companion Proceedings of the ACM Web Conference 2025,,,,2245,2252,7.0,0,10.1145/3701716.3717552,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009211616&doi=10.1145%2f3701716.3717552&partnerID=40&md5=a981e70abc601dc78c24c45f6dd32e53,"Analyzing users' attention distribution is an effective way to evaluate whether the primary UI content captures users' engagement. This has led to the development of eye trackers that gather data on users' attention, as well as computational models that simulate this distribution on individual UI screens. However, there is limited research on how users' attention distribution correlates with the intuitiveness of goal-oriented UI navigation. Additionally, simulating user attention as they reason and identify the correct UI element to navigate to the target screen remains unexplored. To address this gap, we introduce an AI-driven model, the UI Link Transformer (UILT), which predicts users' attention distribution as they navigate from the current UI screen to the target UI screen. This model helps designers to evaluate the intuitiveness of UI navigation. Our initial study aimed to understand how users typically identify the UI element that links two consecutive UI screens and how this identification relates to the intuitiveness of the UI navigation design. The insights gained from this study offer designers actionable recommendations to improve the intuitiveness of mobile GUI navigation, with a focus on users' attention distribution. Moreover, the dataset collected during this study supports the development of the UILT. Building on the insights and data from the initial study, we designed, trained, and evaluated the UILT. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Eye-tracking; Intuitive GUI navigation; User attention simulation,Behavioral research; Human engineering; Navigation; 'current; Attention model; Computational modelling; Eye trackers; Eye-tracking; Goal-oriented; Intuitive GUI navigation; User attention; User attention simulation; User engagement; Graphical user interfaces,Conference paper,Final,,Scopus,2-s2.0-105009211616,Movies / Media
Putkonen A.; Jiang Y.; Zeng J.; Tammilehto O.; Jokinen J.P.P.; Oulasvirta A.,"Putkonen, Aini (57300085900); Jiang, Yue (57209399308); Zeng, Jingchun (59674312700); Tammilehto, Olli (59674889500); Jokinen, Jussi P.P. (23035047100); Oulasvirta, Antti (13006124600)",57300085900; 57209399308; 59674312700; 59674889500; 23035047100; 13006124600,Understanding visual search in graphical user interfaces,2025,International Journal of Human Computer Studies,199,,103483,,,,0,10.1016/j.ijhcs.2025.103483,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000280590&doi=10.1016%2fj.ijhcs.2025.103483&partnerID=40&md5=56ff159666ab5404b4a06429dabffb82,"How do we find items within graphical user interfaces (GUIs)? Current understanding of this issue relies on studies using symbol matrices, natural scenes, and other non-GUI stimuli. To understand whether the effects discovered in those environments extend to mobile, desktop, and web interfaces, this paper reports on visual search performance and eye movements with 900 real-world GUIs. In an eye-tracking study, participants (N=84) were given a cue (textual or image) describing a target to find within a GUI. The study found that the type of GUI, the absence/presence of the target, and cue type affected search time more than visual complexity did. We also compared visual search to free-viewing in GUIs, concluding that these two tasks are distinctly different. Synthesis of the results points to a Guess-Scan-Confirm pattern in visual search: in the first few fixations, gaze is frequently directed toward the top-left corner of the screen, a pattern possibly related to the top-left being a statistically likely location of the target or of information that could aid in finding it; attention then gets more selectively guided, in line with the GUI's structure and the features of the target; and, finally, the user must confirm whether the target has been identified or, instead, that no target is visible. The VSGUI10K eye-tracking dataset (10,282 trials) is released for study and modeling of visual search. © 2025 The Authors",Dataset; Eye-tracking; Graphical user interfaces; Linear mixed-effects models; Visual search,Eye tracking; 'current; Dataset; Desktop interfaces; Eye-tracking; Linear mixed-effects model; matrix; Mobile interface; Natural scenes; Visual search; Web interface; Eye movements,Article,Final,All Open Access,Scopus,2-s2.0-86000280590,Movies / Media
Wusylko C.; Koh D.H.; Antonenko P.; Dawson K.; Kohnen A.,"Wusylko, Christine (57895358000); Koh, Do Hyong (59431571800); Antonenko, Pavlo (23090326200); Dawson, Kara (16238356400); Kohnen, Angela (55110748400)",57895358000; 59431571800; 23090326200; 16238356400; 55110748400,Exploring Young People’s Visual Attention while Assessing Climate Change Content on Social Media,2025,Eye Tracking Research and Applications Symposium (ETRA),,,21,,,,0,10.1145/3715669.3723130,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008492709&doi=10.1145%2f3715669.3723130&partnerID=40&md5=01874bf6ee090c83a19bb8a32a76ae4e,"In this study, we utilize a concurrent mixed methods design to explore the attention patterns and processing strategies of young people as they evaluate socioscientific information on social media. We utilized the screen-based Tobii eye tracker to capture ten 8th and twenty 9th grade student’s fixations while they evaluated if climate change information was believable or not. The students then completed a retrospective think aloud to explain their process. We find that it is possible to categorize young people’s gaze patterns into heuristic and systematic processing categories, and the think aloud data converges with these categories. Further, while most studies are done with adults in a laboratory, we demonstrate that using an eye tracker with a relatively low sampling frequency makes it possible to capture valid and reliable eye tracking in an ecologically valid setting. © 2025 Copyright held by the owner/author(s).",Adolescents; Information evaluation; Social media; Socioscientific issues,Behavioral research; Climate change; Data handling; Eye movements; Eye tracking; Human engineering; Students; Adolescent; Eye trackers; Information evaluation; Mixed method; Processing strategies; Social media; Socioscientific issues; Think aloud; Visual Attention; Young peoples; Social networking (online),Conference paper,Final,,Scopus,2-s2.0-105008492709,Movies / Media
Barnard J.; Roberts S.; Lastella M.; Callahan D.L.; Aisbett B.; Condo D.,"Barnard, Jackson (57859399300); Roberts, Spencer (57194693108); Lastella, Michele (56016883900); Callahan, Damien L. (10440617500); Aisbett, Brad (13410685700); Condo, Dominique (56541673400)",57859399300; 57194693108; 56016883900; 10440617500; 13410685700; 56541673400,Evening Alpha-Lactalbumin Supplementation Alters Sleep Architecture and Reduces Morning Reaction Time in an Athletically Trained Population With Sleep Difficulties,2025,International Journal of Sport Nutrition and Exercise Metabolism,35,3,,215,224,9.0,1,10.1123/ijsnem.2024-0094,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002745951&doi=10.1123%2fijsnem.2024-0094&partnerID=40&md5=21de174295295bc94d589d09d9501796,"Evening consumption of a whey protein rich in the amino acid tryptophan, alpha-lactalbumin (ALAC), has previously shown to benefit sleep—particularly among poor sleepers. Given trained populations often experience sleep difficulty, this study investigated whether evening supplementation of ALAC would influence sleep outcomes, mood, and next-day cognitive performance within a trained population with sleep difficulties. Nineteen trained participants (females, n = 11) with sleep difficulties (Athlete Sleep Screening Questionnaire: 8.1 ± 3.1; Pittsburgh Sleep Quality Index: 10.5 ± 4.1) completed this double-blinded, counterbalanced, randomized, crossover trial. Forty grams of ALAC or control were supplemented 2 hr presleep for three consecutive nights in a controlled environment, with sleep measured using dry electroencephalography. Blood samples were taken on the first evening of each experimental trial, with mood, sleepiness, and recovery assessed across the evening and morning. A cognitive testing battery was also completed each morning. During the ALAC condition, the primary findings were that participants had raised plasma tryptophan levels (p < .01), increased nonrapid eye movement Stage 2 sleep duration (CON: 205.9 ± 33.3; ALAC: 216.5 ± 33.1 min), reduced rapid eye movement duration (CON: 110.8 ± 27.9; ALAC: 99.7 ± 23.1 min), and improved reaction time in cognitive tests involving sensory motor speed, spatial orientation, and vigilant attention (p < .05). Data suggest evening supplementation of 40 g ALAC alters sleep architecture and improves next-morning reaction time in trained populations with sleep difficulties. Therefore, trained individuals experiencing sleep difficulty may benefit from acute ALAC supplementation to assist next-day performance. Future research should investigate this effect within habitual environments, outside of a tightly controlled setting. © 2025 Human Kinetics, Inc.",diet; protein; sleep; whey,Adult; Affect; Athletes; Cognition; Cross-Over Studies; Dietary Supplements; Double-Blind Method; Female; Humans; Lactalbumin; Male; Reaction Time; Sleep; Sleep Wake Disorders; Sports Nutritional Physiological Phenomena; Tryptophan; Young Adult; alpha lactalbumin; amino acid; tryptophan; whey protein; lactalbumin; tryptophan; adult; aged; Article; athlete; attention; blood sampling; clinical article; cognition; controlled study; crossover procedure; diet supplementation; double blind procedure; electroencephalography; eye movement; female; human; male; mental performance; mood; movement time; Pittsburgh Sleep Quality Index; questionnaire; randomized controlled trial; reaction time; REM sleep; sleep disorder; sleep time; somnolence; spatial orientation; stage 2 sleep; affect; athlete; blood; dietary supplement; drug effect; nutrition; sleep; young adult,Article,Final,,Scopus,2-s2.0-105002745951,Movies / Media
Burch M.; Kurzhals K.; Weiskopf D.,"Burch, Michael (36927991800); Kurzhals, Kuno (55390097400); Weiskopf, Daniel (6603960393)",36927991800; 55390097400; 6603960393,"Eye Tracking Studies in Visualization: Phases, Guidelines, and Checklist",2025,Eye Tracking Research and Applications Symposium (ETRA),,,85,,,,0,10.1145/3715669.3725877,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008492869&doi=10.1145%2f3715669.3725877&partnerID=40&md5=9f910f2e76af89b9b58a9c462377115b,"Qualitative and quantitative eye tracking studies are prominent in many fields to understand behavior related to visual attention, in particular, for visualization research. The design, setup, and execution of a study, as well as the analysis of the acquired eye tracking data, can be difficult. This work proposes guidelines for eye tracking studies in visualization. We differentiate three major phases, focusing on before, during, and after a study. These guidelines are based on our experiences from conducting more than 100 eye tracking studies and additional literature research for each phase. As a result, we present a structured plan and chronological order of general requirements as a checklist for conducting eye tracking studies. A living document of the checklist can be found at: https://github.com/mibu1976/etvis2025. © 2025 Copyright held by the owner/author(s).",Eye tracking; guidelines; study design; user studies,Behavioral research; Eye movements; Human computer interaction; Human engineering; Visualization; Chronological order; Eye-tracking; Eye-tracking studies; Guideline; Literature researches; Study design; Tracking data; User study; Visual Attention; Visualization research; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-105008492869,Movies / Media
Gnanaraj B.; Manivasagam S.; Sreevalsan-Nair J.,"Gnanaraj, Beryl (58304470600); Manivasagam, Swetha (59954283100); Sreevalsan-Nair, Jaya (16317584800)",58304470600; 59954283100; 16317584800,To the Point: From Dynamic Heatmap Video to Gaze Points,2025,Eye Tracking Research and Applications Symposium (ETRA),,,90,,,,0,10.1145/3715669.3725873,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008491938&doi=10.1145%2f3715669.3725873&partnerID=40&md5=b540703ded086df662632fb707109b80,"In most remote webcam-based eye-tracking solutions, dynamic heatmaps -also known as dynamic attention maps -are commonly generated as experimental outputs in video format. These videos consist of screen recordings of participants’ sessions, with hotspots marked on each frame based on estimated eye-gaze points. Despite the convenience of usage of these off-the-shelf solutions, we find that these videos are incomplete without specific gaze point coordinates, which are required for any data analytics, e.g., cognitive load estimation. In this work, we propose a novel deep learning-based method for finding the most probable gaze point from each frame of the heatmap videos. Specifically, a position coordinate (x, y) on the user’s screen is estimated as the gaze point by feeding the temporal sequence of hotspots into a deep learning model used for object detection problems in computer vision. As a proof of concept, we demonstrate that deep neural networks detect the latest changing hotspots in the frame sequence of a dynamic attention map video, thus capturing the temporal coherence. We implement hotspot detection using two Convolutional Neural Network (CNN) architectures and one transformer-based architecture, where the latter performs better in our experiments. © 2025 Copyright held by the owner/author(s).",dynamic heatmaps; Gaze point estimation; hotspot detection; supervised learning,Computer vision; Convolutional neural networks; Deep neural networks; Eye protection; Eye tracking; Human engineering; Learning systems; Object detection; Object recognition; Video recording; Dynamic heatmap; Eye-tracking; Gaze point; Gaze point estimations; Heatmaps; Hotspot detections; Hotspots; Solution dynamics; Tracking solutions; WebCams; Supervised learning,Conference paper,Final,,Scopus,2-s2.0-105008491938,Movies / Media
Chrabaszcz A.; Laurinavichyute A.; Ladinskaya N.; Baladzhaeva L.; Prior A.; Myachykov A.; Dragoy O.,"Chrabaszcz, Anna (56315589300); Laurinavichyute, Anna (56405575900); Ladinskaya, Nina (57226828847); Baladzhaeva, Liubov (57164876300); Prior, Anat (14523354200); Myachykov, Andriy (10041512100); Dragoy, Olga (36522630700)",56315589300; 56405575900; 57226828847; 57164876300; 14523354200; 10041512100; 36522630700,Writing direction influences the spatial representations of past- and future-tense forms: Evidence from eye tracking,2025,Memory and Cognition,53,4,,1079,1094,15.0,1,10.3758/s13421-024-01633-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203065357&doi=10.3758%2fs13421-024-01633-5&partnerID=40&md5=453f15b4bb618f8d42295f10595f4910,"The present study tests the hypothesis that the directionality of reading habits (left-to-right or right-to-left) impacts individuals’ representation of nonspatial events. Using the blank screen paradigm, we examine whether eye movements reflect culture-specific spatial biases in processing temporal information, specifically, grammatical tense in Russian and Hebrew. Sixty-two native speakers of Russian (a language with a left-to-right reading and writing system) and 62 native speakers of Hebrew (a language with a right-to-left reading and writing system) listened to verbs in the past or future tense while their spontaneous gaze positions were recorded. Following the verb, a visual spatial probe appeared in one of the five locations of the screen, and participants responded manually to indicate its position. While participants’ response latencies to the spatial probe revealed no significant effects, their gaze positions along the horizontal axis for past- and future-tensed verbs aligned with the reading and writing direction in their language. These results provide novel evidence that eye movements during auditory processing of grammatical tense are influenced by culturally specific reading and writing conventions, shifting leftward or rightward on the horizontal plane depending on the stimuli’s time reference (past or future) and the participants’ language (Russian or Hebrew). This spatial bias indicates a common underlying cognitive mechanism that uses spatial dimensions to represent temporal constructs. © The Psychonomic Society, Inc. 2024.",Eye movements; Grammatical tense; Ocular drift; Reading–writing habits hypothesis; Space–time congruency,Adult; Eye Movements; Eye-Tracking Technology; Female; Humans; Language; Male; Psycholinguistics; Reading; Space Perception; Writing; Young Adult; article; cognition; diagnosis; eye movement; eye tracking; eye-tracking technology; gaze; habit; human; human experiment; normal human; reaction time; writing system; adult; depth perception; eye-tracking technology; female; language; male; physiology; psycholinguistics; reading; writing; young adult,Article,Final,,Scopus,2-s2.0-85203065357,Movies / Media
Alemanno M.; Di Pompeo I.; Marcaccio M.; Canini D.; Curcio G.; Migliore S.,"Alemanno, Michela (59752214100); Di Pompeo, Ilaria (58108299900); Marcaccio, Martina (58317396600); Canini, Daniele (59752439800); Curcio, Giuseppe (6701578294); Migliore, Simone (50161958900)",59752214100; 58108299900; 58317396600; 59752439800; 6701578294; 50161958900,From Gaze to Game: A Systematic Review of Eye-Tracking Applications in Basketball,2025,Brain Sciences,15,4,421,,,,1,10.3390/brainsci15040421,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003420503&doi=10.3390%2fbrainsci15040421&partnerID=40&md5=afe0f09fcf9a77df0c628dd0d6ca8d25,"Background/Objectives: Eye-tracking technology has gained increasing attention in sports science, as it provides valuable insights into visual attention, decision-making, and motor planning. This systematic review examines the application of eye-tracking technology in basketball, highlighting its role in analyzing cognitive and perceptual strategies in players, referees, and coaches. Methods: A systematic search was conducted following PRISMA guidelines. Studies published up until December 2024 were retrieved from PubMed and Web of Science using keywords related to basketball, eye tracking, and visual search. The inclusion criteria focused on studies using eye-tracking technology to assess athletes, referees, and coaches. A total of 1706 articles were screened, of which 19 met the eligibility criteria. Results: Eye-tracking studies have shown that expert basketball players exhibit longer quiet eye (QE) durations and more efficient gaze behaviors compared to novices. In high-pressure situations, skilled players maintain more stable QE characteristics, leading to better shot accuracy. Referees rely on efficient gaze strategies to make split-second decisions, although less experienced referees tend to neglect key visual cues. In coaching, eye-tracking studies suggest that guided gaze techniques improve tactical understanding in novice players but have limited effects on experienced athletes. Conclusions: Eye tracking is a powerful tool for studying cognitive and behavioral functioning in basketball, offering valuable insights for performance enhancement and training strategies. Future research should explore real-game settings using mobile eye trackers and integrate artificial intelligence to further refine gaze-based training methods. © 2025 by the authors.",cognitive functions; eye movements; gaze behavior; sports; visual search,artificial intelligence; athlete; basketball; basketball player; coach; cognition; deception; decision making; eye-tracking technology; game; gaze; human; meta analysis; perception; Review; skiing; sports science; systematic review; training; visual attention,Review,Final,,Scopus,2-s2.0-105003420503,Movies / Media
Burns H.; Hurst A.; Garay P.; Murray N.E.; Stewart S.H.; Mejia J.; Bagnell A.; Klein R.M.; Meier S.,"Burns, Hailey (58058537500); Hurst, Austin (57212198034); Garay, Pristine (59338251400); Murray, Nicholas E. (58641556400); Stewart, Sherry H. (7401747025); Mejia, Jose (36879121000); Bagnell, Alexa (26640190900); Klein, Raymond M. (26643464000); Meier, Sandra (57216804979)",58058537500; 57212198034; 59338251400; 58641556400; 7401747025; 36879121000; 26640190900; 26643464000; 57216804979,Attentional biases for dynamic stimuli in emerging adults with anxiety: A preliminary eye-tracking study,2025,Journal of Psychiatric Research,184,,,262,271,9.0,0,10.1016/j.jpsychires.2025.02.046,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000161427&doi=10.1016%2fj.jpsychires.2025.02.046&partnerID=40&md5=86d8de3f96eb8e58c4f13a16026114b0,"While attentional biases towards negative stimuli have previously been linked to the development and maintenance of anxiety disorders, a current limitation of this research involves the use of static images for stimuli, as they cannot adequately depict the dynamic nature of real-life interactions. Since attentional biases in those with elevated anxiety remain understudied using more naturalistic stimuli, such as dynamic social videos, the purpose of this explorative study was to use novel dynamic stimuli and modern eye-tracking equipment to further investigate negative attentional biases in anxious emerging, female adults. Non-clinical participants (N = 62; mean age = 20.44 years; biologically female) completed validated questionnaires regarding their anxiety symptoms and completed a free-viewing task by watching 30-s video clips while having their eye movements tracked. The video clips were shown in side-by-side pairs (i.e., positive-neutral, negative-neutral, and positive-negative) on a split screen without audio. Overall, participants fixated more quickly on emotional videos (i.e., positive and negative) over neutral ones, with more anxious participants orienting their gaze faster to the videos, regardless of content. Moreover, individuals with greater self-reported anxiety spent more time gazing at negative videos in negative-neutral pairings, highlighting that emerging female adults with increased anxiety symptoms may show a negative attention bias when viewing social interactions. Importantly, by incorporating novel, dynamic stimuli, we expand upon prior research on attentional biases, with the potential to adapt this approach for novel interventions that may ultimately help those suffering from anxiety. © 2025 The Authors",Anxiety; Attention biases; Eye-tracking; Female emerging adults,Adolescent; Adult; Anxiety; Attentional Bias; Eye Movement Measurements; Eye Movements; Eye-Tracking Technology; Female; Humans; Male; Photic Stimulation; Young Adult; adult; anxiety; Article; attentional bias; controlled study; emotion; eye tracking; female; gaze; human; normal human; preliminary data; self-reported questionnaire; social interaction; symptom; task performance; videorecording; visual reaction time; visual stimulation; young adult; adolescent; attentional bias; eye movement; eye-tracking technology; male; oculography; pathophysiology; photostimulation; physiology,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-86000161427,Movies / Media
Saxena S.; Visram A.; Lobo N.; Mirza Z.; Khan M.; Pirabaharan B.; Nguyen A.; Fink L.K.,"Saxena, Shreshth (57754380600); Visram, Areez (59233239900); Lobo, Neil (59233914200); Mirza, Zahid (59233240000); Khan, Mehak (59907843700); Pirabaharan, Biranugan (59233914300); Nguyen, Alexander (59232716100); Fink, Lauren K (57203301548)",57754380600; 59233239900; 59233914200; 59233240000; 59907843700; 59233914300; 59232716100; 57203301548,SocialEyes: Scaling Mobile Eye-tracking to Multi-person Social Settings,2025,Conference on Human Factors in Computing Systems - Proceedings ,,,751,,,,0,10.1145/3706598.3713910,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005763950&doi=10.1145%2f3706598.3713910&partnerID=40&md5=92d1a8edd66438d83f7591e31ffb738c,"Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60). We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools. © 2025 Copyright held by the owner/author(s).",concert; eye-tracking; film; homography; joint gaze; multi-person; music; naturalistic; social settings; visualisation,Emotional intelligence; Music; Social behavior; Sociology; Concert; Eye-tracking; Homographies; Human attention; Joint gaze; Mobile eye-tracking; Multi-person; Naturalistic; Scalings; Social settings; Visualization,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-105005763950,Movies / Media
Lopukhina A.; van Heuven W.J.B.; Crowley R.; Rastle K.,"Lopukhina, Anastasiya (56292060700); van Heuven, Walter J. B. (7003726457); Crowley, Rebecca (57209216176); Rastle, Kathleen (6604064697)",56292060700; 7003726457; 57209216176; 6604064697,Where Do Children Look When Watching Videos With Same-Language Subtitles?,2025,Psychological Science,36,4,,223,236,13.0,0,10.1177/09567976251325789,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002072729&doi=10.1177%2f09567976251325789&partnerID=40&md5=3e0223ee1e0ef7be30ac032c610a4da2,"Influential campaigns in the United Kingdom and the United States have argued that same-language television subtitles may help children learn to read. In this study, we investigated the extent to which primary-school children pay attention to and read subtitles and whether this is related to their reading proficiency. We tracked the eye movements of 180 British children in Years 1 to 6 who watched videos with and without subtitles. Results showed that attention to subtitles was associated with reading proficiency: Superior readers were more likely to look at subtitles than less proficient readers and spent more time on them. When children looked at words in the subtitles, they showed evidence of reading them. We conclude that some degree of reading fluency may be necessary before children pay attention to subtitles. However, by the third or fourth year of reading instruction, most children read sufficiently quickly to follow same-language subtitles and potentially learn from them. © The Author(s) 2025.",closed captions; eye tracking; primary-school children; reading; same-language subtitles,"Attention; Child; Child, Preschool; Eye Movements; Female; Humans; Language; Male; Reading; Television; United Kingdom; attention; child; eye movement; female; human; language; male; physiology; preschool child; reading; television; United Kingdom",Article,Final,,Scopus,2-s2.0-105002072729,Movies / Media
Stickel L.; Poggesi S.; Grunert K.G.; Lähteenmäki L.; Hort J.,"Stickel, Lisa (57291034600); Poggesi, Simone (57208446236); Grunert, Klaus G. (7004726565); Lähteenmäki, Liisa (7004347122); Hort, Joanne (6701437587)",57291034600; 57208446236; 7004726565; 7004347122; 6701437587,Do you remember? Consumer reactions to health-related information on snacks in repeated exposure,2025,Food Quality and Preference,126,,105431,,,,0,10.1016/j.foodqual.2025.105431,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214870619&doi=10.1016%2fj.foodqual.2025.105431&partnerID=40&md5=8c501eee51aedf998c8838eda8ea27d3,"Health-related information on pre-packed food products can enhance purchase intention and healthy choices. However, retained positive influence of health-related information on product liking is necessary to help consumers make informed decisions about a healthy diet in the long term. According to information-reduction theory, consumers reduce the amount of information that is processed in repeated exposure. Hence, increasing familiarity with a product could lead to increased levels of ignoring health-related information and an increasing reliance on product experience-based associations. These effects were tested in a laboratory study, involving actual food tasting and repeated exposure across two sessions. Participants (N = 154) were invited to evaluate yoghurts with and without health-related information with a screen representation of the product packaging. Differences in product evaluations and attention paid to health-related information between the two sessions were recorded using both implicit and explicit methods. Findings reveal that, despite a decrease in visual attention to health-related information, the perceived healthiness of the products remained stable. However, consumers reported lower perceived tastiness when health-related information was present. The findings underscore the importance of compelling taste experiences, as taste beliefs, in contrast to health beliefs, consistently influenced product liking. Finally, the findings emphasised the need for a comprehensive understanding of consumer reactions to healthier food products that considers both implicit and explicit responses. © 2025 The Authors",EEG; Eye-tracking; Implicit reactions; Nutrition claim; Product liking; Repeated exposure,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85214870619,Movies / Media
Wang P.; Fu H.,"Wang, Pohsun (57222183017); Fu, Hao (58512633100)",57222183017; 58512633100,The Influence of Different Visual Elements of High-Density Urban Observation Decks on the Visual Behavior and Place Identity of Tourists and Residents,2025,Applied Sciences (Switzerland),15,7,3875,,,,0,10.3390/app15073875,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002279939&doi=10.3390%2fapp15073875&partnerID=40&md5=fa597d4f858ff26ee2ab1bf4bae2720d,"This study focuses on the visual attention of residents and tourists to elements of urban landscapes from above. It screens out elements that attract viewers’ attention, assesses their aesthetics, and explores how these aesthetic evaluations affect the psychology of place identity. We tracked data from 30 participants, collected responses from 237 participants, and observed differences in visual behaviors and emotional connections to place identity. The results show that while residents and tourists exhibit similar visual behaviors when viewing the same landscape, they have large differences in their perceptual behaviors for different visual elements and have very different familiarity levels in the place identity dimension. Landmark buildings attract strong visual attention despite their low proportion in the overall landscape. Aesthetic factors such as the color vividness of elements like water, mountains, and landmark buildings significantly affect place identity. This study shows that combining eye-tracking and psychometric analysis can effectively evaluate urban landscape perception and provide valuable insights for visual planning and preservation efforts in historic neighborhoods. © 2025 by the authors.",eye-tracking; Historic Centre of Macao; landscape; place identity; questionnaires; visual elements,Historic preservation; Eye-tracking; Historic center of macao; Historic centres; Landscape; Place identity; Questionnaire; Urban landscape; Visual Attention; Visual behavior; Visual elements,Article,Final,,Scopus,2-s2.0-105002279939,Movies / Media
Gherman D.E.; Krol L.R.; Klug M.; Zander T.O.,"Gherman, Diana E. (58062825700); Krol, Laurens R. (34881963200); Klug, Marius (57215601026); Zander, Thorsten O. (35104232600)",58062825700; 34881963200; 57215601026; 35104232600,An investigation of a passive BCI’s performance for different body postures and presentation modalities,2025,Biomedical Physics and Engineering Express,11,2,25052,,,,0,10.1088/2057-1976/adb58b,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001430434&doi=10.1088%2f2057-1976%2fadb58b&partnerID=40&md5=124be13204d2312a2892cc58fbdb402b,"Passive brain-computer interfaces (passive BCIs, pBCIs) enable computers to unobtrusively decipher aspects of a user’s mental state in real time from recordings of brain activity, e.g. electroencephalography (EEG). When used during human-computer interaction (HCI), this allows a computer to dynamically adapt for enhancing the subjective user experience. For transitioning from controlled laboratory environments to practical applications, understanding BCI performance in real contexts is of utmost importance. Here, Virtual Reality (VR) can play a unique role: both as a fully controllable simulation of a realistic environment and as an independent, increasingly popular real application. Given the potential of VR as a dynamic and controllable environment, and the capability of pBCIs to enable novel modes of interaction, it is tempting to envision a future where pBCI and VR are seamlessly integrated. However, the simultaneous use of these two technologies—both of which are head-mounted—presents new challenges. Due to their immediate proximity, electromagnetic artifacts can arise, contaminating the EEG. Furthermore, the active movements promoted by VR can induce mechanical and muscular artifacts in the EEG. The varying body postures and display preferences of users further complicate the practical application of pBCIs. To address these challenges, the current study investigates the influence of body posture (sitting Versus standing) and display media (computer screen Versus VR) on the performance of a pBCI in assessing cognitive load. Our results show that these conditions indeed led to some changes in the EEG data; nevertheless, the ability of pBCIs to detect cognitive load remained largely unaffected. However, when a classifier trained in one context (body posture or modality) was applied to another (e.g., cross-task application), reductions in classification accuracy were observed. As HCI moves towards increasingly adaptive and more interactive designs, these findings support the expansive potential of pBCIs in VR contexts. © 2025 The Author(s). Published by IOP Publishing Ltd.",EEG; passive BCI; passive brain-computer interfaces; pBCI; posture; virtual reality; workload,Adult; Artifacts; Brain; Brain-Computer Interfaces; Electroencephalography; Female; Humans; Male; Movement; Posture; User-Computer Interface; Virtual Reality; Young Adult; Brain computer interface; User interfaces; Virtual addresses; Virtual environments; Virtualization; Body postures; Cognitive loads; Computer interaction; Eg electroencephalography; Passive BCI; Passive brain-computer interface; Performance; Posture; Workload; adult; Article; body position; classifier; clinical article; cognitive load; controlled study; customer experience; decoding; electroencephalogram; electroencephalography; eye movement; female; human; human computer interaction; image artifact; male; measurement accuracy; mental health; muscle contraction; muscle strength; performance indicator; signal noise ratio; sitting; standing; topography; virtual reality; workload; artifact; brain; brain computer interface; computer interface; electroencephalography; movement (physiology); physiology; procedures; young adult; Virtual reality,Article,Final,All Open Access,Scopus,2-s2.0-105001430434,Movies / Media
Wang M.; Chen X.; Zhao Z.; Hu L.; Zhu M.; Cheng J.; Hu P.,"Wang, Mengqi (58930403200); Chen, Xin (57222319508); Zhao, Ziye (58916830200); Hu, Lili (58036606100); Zhu, Minhao (59520164100); Cheng, Jingjing (59480326400); Hu, Panpan (36165563300)",58930403200; 57222319508; 58916830200; 58036606100; 59520164100; 59480326400; 36165563300,Multidimensional evaluation of olfactory function in patients with Parkinson′s disease and its correlation with rapid eye movement sleep behavior disorder; [不同维度嗅觉测试在帕金森病患者中的应用价值及与快速眼动睡眠行为障碍的相关性],2025,National Medical Journal of China,105,9,,694,700,6.0,0,10.3760/cma.j.cn112137-20240823-01947,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000208369&doi=10.3760%2fcma.j.cn112137-20240823-01947&partnerID=40&md5=a184c430a46305f6e1d34239d0450e56,"Objective To analyze the application value of different dimensional olfactory tests in different dimensions of olfactory function in patients with Parkinson′s disease (PD), and to explore the clinical characteristics of different olfactory dimensions in PD patients with and without rapid eye movement sleep behavior disorder (RBD) and the correlation between different olfactory dimensions and RBD. Methods A total of 73 patients who visited the Department of Neurology, the First Affiliated Hospital of Anhui Medical University from May 2023 to June 2024 were retrospectively included. According to the Rapid Eye Movement Sleep Behavior Disorder Screening Scale (RBDSQ), PD patients were divided into 25 cases of PD with RBD (PD-RBD+) and 48 cases of PD without RBD (PD-RBD-). A total of 39 family members of patients in the same period were recruited as healthy controls. General data of all subjects were collected, and their motor symptoms, emotions, sleep status and cognitive function were evaluated. Olfactory function was evaluated by olfactory threshold, discrimination and recognition olfactory tests in three dimensions. The receiver operating characteristic (ROC) curve was used to analyze the ability of the three olfactory tests to distinguish PD patients from healthy controls.. Spearman correlation analysis was used to evaluate the correlation between different olfactory dimensions and motor and non-motor symptoms. Results There were 39 males and 34 females in PD patients, aged (63±7) years old; there were 16 males and 23 females in healthy controls, aged (64±10) years old. The olfactory threshold [(6.92±4.20) vs (9.36±4.33), P=0.005], discrimination [(7.44±3.05) vs (10.44±3.04), P<0.001] and recognition [(15.38±5.80) vs (22.72±5.09), P<0.001] scores of PD patients were lower than those of healthy controls. ROC curve analysis of different olfactory tests to distinguish PD patients from healthy controls showed that among the three olfactory tests, the area under the curve (AUC) of the olfactory threshold test was 0.671 (95%CI: 0.568-0.773, P=0.003), the AUC of the olfactory discrimination test was 0.750 (95%CI: 0.655-0.844, P<0.001), and the AUC of the olfactory identification test was 0.829 (95%CI: 0.751-0.906, P<0.001). The olfactory recognition of the PD-RBD+group [(13.36±5.77) vs (16.44±5.58), P=0.030] was significantly lower than that of the PD-RBD-group. There were no significant differences in olfactory threshold [(6.58±3.49) vs (6.69±4.04), P=0.906] and discrimination [(7.00±3.39) vs (7.00±3.39), P=0.380] between the PD-RBD+group and the PD-RBD-group. Olfactory threshold was positively correlated with Montreal Cognitive Assessment (MoCA) (r=0.236, P=0.045); olfactory discrimination was negatively correlated with Pittsburgh Sleepiness Scale (PSQI) (r=-0.347, P=0.003); olfactory identification was positively correlated with MoCA (r=0.246, P=0.036), and negatively correlated with RBDSQ (r=-0.254, P=0.030) and PSQI (r=-0.335, P=0.004). Conclusions The olfactory threshold, discrimination and identification abilities of PD patients are impaired. Olfactory identification test was more capable of distinguishing PD patients from healthy controls. PD-RBD+patients have worse olfactory identification ability than PD-RBD-patients. There is a significant correlation between olfactory identification and RBDSQ. © 2025 Chinese Medical Journals Publishing House Co.Ltd. All rights reserved.",Cross-sectional study; Olfactory disorder; Olfactory recognition; Parkinson′s disease; REM sleep behavior disorder,Female; Humans; Male; Middle Aged; Olfaction Disorders; Parkinson Disease; REM Sleep Behavior Disorder; Retrospective Studies; ROC Curve; Smell; adult; area under the curve; Article; clinical feature; cognition; controlled study; correlation analysis; cross-sectional study; diagnostic test accuracy study; disease duration; female; human; major clinical study; male; middle aged; Montreal cognitive assessment; motor performance; multidimensional scaling; neurology; olfactory discrimination; Parkinson disease; Pittsburgh Sleep Quality Index; questionnaire; rapid eye movement sleep behavior disorder screening scale; receiver operating characteristic; recognition; REM sleep; REM sleep behavior disorder; retrospective study; self report; smelling; threshold limit value; odor; pathophysiology; smelling disorder,Article,Final,,Scopus,2-s2.0-86000208369,Movies / Media
Li Y.,"Li, Yan (59751689800)",59751689800,Listen or Read? The Impact of Proficiency and Visual Complexity on Learners’ Reliance on Captions,2025,Behavioral Sciences,15,4,542,,,,0,10.3390/bs15040542,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003485172&doi=10.3390%2fbs15040542&partnerID=40&md5=c129d5863f0e2f5e086decb8a3e77044,"This study investigates how Chinese EFL (English as a foreign language) learners of low- and high-proficiency levels allocate attention between captions and audio while watching videos, and how visual complexity (single- vs. multi-speaker content) influences caption reliance. The study employed a novel paused transcription method to assess real-time processing. A total of 64 participants (31 low-proficiency [A1–A2] and 33 high-proficiency [C1–C2] learners) viewed single- and multi-speaker videos with English captions. Misleading captions were inserted to objectively measure reliance on captions versus audio. Results revealed significant proficiency effects: Low-proficiency learners prioritized captions (reading scores > listening, Z = −4.55, p < 0.001, r = 0.82), while high-proficiency learners focused on audio (listening > reading, Z = −5.12, p < 0.001, r = 0.89). Multi-speaker videos amplified caption reliance for low-proficiency learners (r = 0.75) and moderately increased reliance for high-proficiency learners (r = 0.52). These findings demonstrate that low-proficiency learners rely overwhelmingly on captions during video viewing, while high-proficiency learners integrate multimodal inputs. Notably, increased visual complexity amplifies caption reliance across proficiency levels. Implications are twofold: Pedagogically, educators could design tiered caption removal protocols as skills improve while incorporating adjustable caption opacity tools. Technologically, future research could focus on developing dynamic captioning systems leveraging eye-tracking and AI to adapt to real-time proficiency, optimizing learning experiences. Additionally, video complexity should be calibrated to learners’ proficiency levels. © 2025 by the author.",captioned videos; desirable difficulties; language processing; listening skills; proficiency levels; video complexity,,Article,Final,,Scopus,2-s2.0-105003485172,Movies / Media
Zhou Y.; Nishimura M.; Kawabata H.,"Zhou, Yizhen (57972015600); Nishimura, Mana (59505418400); Kawabata, Hideaki (36877128200)",57972015600; 59505418400; 36877128200,Gaze behavior when looking at paintings may predict autistic traits,2025,PsyCh Journal,14,2,,267,276,9.0,0,10.1002/pchj.810,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001654570&doi=10.1002%2fpchj.810&partnerID=40&md5=3bbea7ff7bd6dd55d881b623ad2a40be,"From infancy, we spend considerable time absorbing social information from the external world. Social information processing, which starts with looking at facial expressions, affects behavior and cognition. Previous research has demonstrated that looking behaviors at social cues such as faces may differ in individuals with autism spectrum disorder (ASD) by using eye-tracking studies with real photographs and movies. However, mixed results have been reported. In this study, we examined whether autistic traits in adults affected gaze behavior when participants viewed paintings. The eye-tracking results indicate that gaze patterns change over time during a 20-s free-viewing task. Although the fixations were not influenced during the first 10 s of the viewing, autistic tendencies affected gaze behavior after the overview of the painting was completed: the higher the autism-spectrum quotient scores, the shorter the fixation duration and the fewer the fixations on the facial areas of the paintings during the latter 10 s of viewing time. This result indicates that the atypical gaze behavior was more likely to be modulated by a generalized attentional process for endogenous orienting with reduced interest in social cues. Gaze patterns of viewing paintings may be used to predict autistic tendencies among people undiagnosed but suspected of having ASD. © 2025 The Author(s). PsyCh Journal published by Institute of Psychology, Chinese Academy of Sciences and John Wiley & Sons Australia, Ltd.",artwork; eye tracking; gaze behavior; social attention,"Adult; Attention; Autism Spectrum Disorder; Autistic Disorder; Cues; Eye-Tracking Technology; Facial Expression; Female; Fixation, Ocular; Humans; Male; Paintings; Young Adult; adult; association; attention; autism; eye fixation; eye-tracking technology; facial expression; female; human; male; painting; pathophysiology; physiology; young adult",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-105001654570,Movies / Media
Li X.-Y.; Tang G.; Lu J.; Zhao Y.; Lin H.; Zhang Q.; Chan K.; Liang X.; Wang J.; Shen B.; Tang Y.; Zhao J.; Sun Y.-M.; Wu J.; Yen T.-C.; Wang J.; Zuo C.; Liu F.-T.,"Li, Xin-Yi (57222963999); Tang, Gan (59350101800); Lu, Jiaying (57204000110); Zhao, Yixin (57226756529); Lin, Huamei (57542672500); Zhang, Qin (59653351800); Chan, KunWang (59653785700); Liang, Xiaoniu (56763160700); Wang, Jing (57201615880); Shen, Bo (57198796380); Tang, Yilin (56320513100); Zhao, Jue (56320709300); Sun, Yi-Min (56262499600); Wu, Jianjun (55713471600); Yen, Tzu-Chen (7202232720); Wang, Jian (55907493400); Zuo, Chuantao (16029953700); Liu, Feng-Tao (55639885900)",57222963999; 59350101800; 57204000110; 57226756529; 57542672500; 59653351800; 59653785700; 56763160700; 57201615880; 57198796380; 56320513100; 56320709300; 56262499600; 55713471600; 7202232720; 55907493400; 16029953700; 55639885900,Self-Reported REM Sleep Behavior Disorder in Patients With Progressive Supranuclear Palsy: Clinical and 18F-Florzolotau PET Imaging Findings,2025,Neurology,104,5,e213376,,,,4,10.1212/WNL.0000000000213376,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218810531&doi=10.1212%2fWNL.0000000000213376&partnerID=40&md5=857073bcad9f62ddad5b66b23c075d78,"Background and Objectives Rapid eye movement sleep behavior disorder (RBD) is increasingly recognized in patients with tauopathies, but its significance and underpinnings remain unclear. To address this gap, we investigated the prevalence of self-reported RBD in patients with progressive supranuclear palsy (PSP) and explored its clinical and imaging correlates using 18F-florzolotau PET imaging. Methods We consecutively enrolled patients meeting the 2017 Movement Disorder Society clinical criteria for PSP at a Chinese tertiary hospital between May 2019 and March 2022. Patients underwent comprehensive clinical assessments and 18F-florzolotau PET to investigate tau deposition patterns. The presence of self-reported RBD was identified using the RBD Single-Question Screen, while its frequency was retrospectively collected from medical history. Results We examined 148 patients recruited in the ongoing Progressive Supranuclear Palsy Neuroimage Initiative cohort. Self-reported RBD was identified in 18.2% of the participants (27/148). Patients with PSP-Richardson syndrome and PSP-parkinsonism reported the highest frequencies of self-reported RBD (21.7% and 18.5%, respectively), compared with PSP-progressive gait freezing (9.7%). While age and sex were similar in patients with and without self-reported RBD, the former group exhibited greater disease severity, as indicated by higher PSP Rating Scale (PSPrs) scores (38.0 vs 27.0, effect size = 0.256, p = 0.002). Furthermore, patients with RBD had significantly higher 18F-florzolotau binding in the locus coeruleus (LC) (1.50 vs 1.38, effect size = 0.231, p = 0.003), which remained significant after false discovery rate correction (p = 0.042). The frequency of RBD was found to be correlated with tau pathology in the LC (n = 8, r = 0.752, p = 0.002). Notably, the presence of self-reported RBD symptoms mediated the relationship between LC tau pathology and PSPrs total scores (proportion-mediated = 2.09%, 95% CI 0.01%-10.00%, p = 0.044). Discussion Approximately one-fifth of patients with PSP reported RBD and exhibited more severe motor and nonmotor symptoms. The elevated 18F-florzolotau binding in the LC and its association with the presence of RBD symptoms underscore the critical role of tau pathology in disrupting sleep-regulating neural circuits. Future studies with larger sample sizes should incorporate polysomnography in patients with PSP with self-reported RBD to further elucidate this relationship.  © American Academy of Neurology.",,"Aged; Female; Humans; Male; Middle Aged; Positron-Emission Tomography; REM Sleep Behavior Disorder; Retrospective Studies; Self Report; Supranuclear Palsy, Progressive; tau Proteins; antiparkinson agent; florzolotau f 18; tau protein; adult; aged; Article; assessment of humans; clinical assessment; cognition; depression; disease duration; epworth sleepiness questionnaire; false discovery rate; female; freezing of gait; Geriatric Depression Scale; human; language disability; leukoencephalopathy; locus ceruleus; major clinical study; male; Mini Mental State Examination; Non-Motor Symptoms Scale; nuclear magnetic resonance imaging; parkinson disease questionnaire 3; parkinsonism; pathology; positron emission tomography; prevalence; progressive supranuclear palsy; progressive supranuclear palsy rating scale; quality of life; rapid eye movement sleep behavior disorder screening questionnaire; REM sleep behavior disorder; somnolence; T1 weighted imaging; tauopathy; complication; diagnostic imaging; epidemiology; metabolism; middle aged; procedures; retrospective study; self report",Article,Final,,Scopus,2-s2.0-85218810531,Movies / Media
Krug A.; Huckauf A.,"Krug, Alina (58524881100); Huckauf, Anke (6701503895)",58524881100; 6701503895,Reinvestigating Endogenous Attention and Perceived Duration of Peripheral Stimuli: Differential Effects for Neutral Versus Valid and Invalid Cues,2025,Journal of Experimental Psychology: Human Perception and Performance,51,6,,732,746,14.0,0,10.1037/xhp0001307,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000271710&doi=10.1037%2fxhp0001307&partnerID=40&md5=f5da04675d08c44eeebbe33ca2008e63,"Research has shown that increasing stimulus eccentricity can shorten temporal estimations and integration. Endogenous attention has been shown to prolong subjective duration and stimulus processing, especially for more peripheral stimuli. This study investigates the impact of endogenous attention on the perceived duration of peripheral stimuli. In a temporal bisection task, participants judged the varying duration of a probe stimulus (20–220 ms) presented at 3° or 9° of eccentricity left or right from fixation as either short or long. The probe stimulus was either preceded by a valid or neutral central arrow cue (Experiment 1) or valid or invalid central arrow cue (Experiment 2) to manipulate endogenous attention. Eye movements were monitored with an eye tracker. In both experiments, subjective duration decreased with increasing stimulus eccentricity, consistent with earlier findings. Reaction times were lower for valid cues in both experiments, indicating that the cue was successful in shifting attention. While there was no significant difference in perceived duration between valid and neutral cues (Experiment 1), perceived duration was lower for invalid cues compared to valid cues (Experiment 2). In both experiments, there was no interaction between eccentricity and cue. The results are discussed in the context of the underlying processes involved in temporal processing and the notion that perceived duration does not differ between attention distributed over the screen or directed toward the peripheral stimulus, but directing attention away from the stimulus shortens perceived duration. © 2025 American Psychological Association",covert attention; eccentricity; endogenous spatial attention; time perception; visual periphery,Adult; Attention; Cues; Female; Humans; Male; Space Perception; Time Perception; Visual Perception; Young Adult; adult; association; attention; depth perception; female; human; male; physiology; time perception; vision; young adult,Article,Final,,Scopus,2-s2.0-105000271710,Movies / Media
Duffy C.M.C.; Benotsch E.G.,"Duffy, Conor M.C. (57956947000); Benotsch, Eric G. (7003389961)",57956947000; 7003389961,Nonverbal behavior in telehealth visits: A narrative review,2025,Patient Education and Counseling,132,,108600,,,,1,10.1016/j.pec.2024.108600,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211336548&doi=10.1016%2fj.pec.2024.108600&partnerID=40&md5=16672d793470e6df996c6afd2e2189db,"Objectives: To synthesize findings from research examining nonverbal behavior (NVB) in telehealth. Use of telehealth has increased substantially in recent years—thus, it is critical to identify nonverbal strategies that facilitate positive patient-provider communication in this context. Methods: Four peer-reviewed databases were searched: PubMed, PsycINFO, CINAHL, and EMBASE. Following a review of abstracts and full texts by the first author, 50 studies met inclusion criteria. Results: The role of six NVBs– gaze, facial expression, gesture, head movement, proxemics, and posture– has been examined in the context of telehealth. Most included studies assessed patients’ and providers’ perspectives of NVB in telehealth. There was a lack of research examining nonverbal behaviors, and their associations with patient-centered outcomes, in naturalistic clinical settings. Conclusions: While this review identified some promising nonverbal strategies to facilitate patient-provider rapport in telehealth, there is a need for future research that objectively measures NVBs and examines relationships between these behaviors and patient-centered outcomes. Practice implications: Potential strategies for providers to enhance quality of communication in telehealth include gazing at the camera (vs. the screen), mirroring patients’ facial expressions and head movements, leaning forward, and exaggerating gestures and facial expressions. © 2024 Elsevier B.V.",Nonverbal behavior; Nonverbal communication; Patient-provider communication; Telehealth; Telemedicine,Facial Expression; Gestures; Humans; Nonverbal Communication; Patient-Centered Care; Physician-Patient Relations; Professional-Patient Relations; Telemedicine; aphasia; body position; burnout; caregiver; clinical decision making; communication skill; decision making; emotionality; eye tracking; facial expression; fatigue; fluorescence activated cell sorting; follow up; gaze; gesture; glycemic control; head movement; health behavior; health care delivery; health care personnel; human; interpersonal communication; medical student; nonverbal communication; patient satisfaction; perception; PsycINFO; qualitative research; questionnaire; Review; schizophrenia; telehealth; telemedicine; telepsychiatry; thematic analysis; verbal communication; videoconferencing; visual field; doctor patient relationship; facial expression; person centered care; professional-patient relationship; telemedicine,Review,Final,,Scopus,2-s2.0-85211336548,Movies / Media
Castellotti S.; Castaldi E.; Blini E.; Arrighi R.,"Castellotti, Serena (57205731708); Castaldi, Elisa (55660832000); Blini, Elvio (56304623100); Arrighi, Roberto (8870558800)",57205731708; 55660832000; 56304623100; 8870558800,Pupil size as a biomarker of cognitive (dys)functions: Toward a physiologically informed screening of mental states,2025,Acta Psychologica,253,,104720,,,,0,10.1016/j.actpsy.2025.104720,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214444246&doi=10.1016%2fj.actpsy.2025.104720&partnerID=40&md5=aacef1b45ea2f3a8a61f5c7894ea1690,"The objective assessment of cognitive processes is of critical importance to understanding the mechanisms underlying various mental functions and dysfunctions. In recent years, the technological innovations related to the eye-tracking industry made the time right to organically integrate pupillometry in the assessment of cognitive profiles. Here, we review evidence showing that pupillometry offers a uniquely sensitive biomarker of the functioning of several distinct networks, cognitive functions, emotional states, and individual differences in their instantiation. We outline why and how pupillometry can be effectively exploited to enrich current research and behavioral paradigms, including those designed for clinical testing. By making the cases of anxiety disorders (both generalized and specific - e.g., generalized anxiety vs. math anxiety) and substance use disorders, we then exemplify how pupillometry can be leveraged to obtain clinically meaningful variables. We finally conclude by arguing that measuring pupil size has the potential to complement more traditional, but coarse assessment methods, to return a more graded, objective, and physiologically informed picture of cognitive functioning. © 2025",Addiction; Anxiety disorders; Biomarkers; Psychosensory pupil responses; Pupillometry,Anxiety Disorders; Biomarkers; Cognition; Cognitive Dysfunction; Eye-Tracking Technology; Humans; Pupil; Substance-Related Disorders; biological marker; anxiety disorder; cognition; cognitive defect; diagnosis; drug dependence; eye-tracking technology; human; metabolism; pathophysiology; physiology; pupil,Review,Final,,Scopus,2-s2.0-85214444246,Movies / Media
Ricchiuti G.; Tuerlinckx E.; Taillieu A.; Prinsen J.; Steyaert J.; Boets B.; Alaerts K.,"Ricchiuti, Grazia (59536404900); Tuerlinckx, Elise (59152650100); Taillieu, Aymara (57240554400); Prinsen, Jellina (57192410665); Steyaert, Jean (35312655400); Boets, Bart (10043925700); Alaerts, Kaat (16027854600)",59536404900; 59152650100; 57240554400; 57192410665; 35312655400; 10043925700; 16027854600,Toward effective oxytocin interventions in autism: Overcoming challenges and harnessing opportunities,2025,Journal of Psychopharmacology,39,3,,179,186,7.0,1,10.1177/02698811241309621,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216515085&doi=10.1177%2f02698811241309621&partnerID=40&md5=ce91c89c92a738545edbbea7aedbbc20,"Intranasal administration of oxytocin is emerging as a potential pharmacological option for mitigating social difficulties and regulating stress in autism spectrum disorder. However, initial single-dose and multiple-dose trials showed mixed results, with some demonstrating improvements in social and repetitive behavior and others showing no benefit over placebo. This perspective aims to elucidate factors contributing to this variability and to highlight pitfalls and opportunities in the field. We identified two major factors: design-related elements and individual participant characteristics. Pertaining to design-related elements, optimal dosing regimens have yet to be established, but appear to favor moderate intervention durations (i.e., 4–6 weeks) with intermittent and intermediate dosing (i.e., 24–32 IU every other day). Also, the context of the intervention seems crucial, as enhanced outcomes are mainly observed when oxytocin administration is paired with a socially stimulating and supporting environment. In addition, more adequate outcome measures have to be established to effectively assess oxytocin’s impact, including behavioral scales and objective biophysiological markers tapping into stress and neurophysiological regulation. Future research should also account for individual participant differences in biological sex, developmental stage and cognitive and adaptive functioning, and incorporate (epi)genetic screening to identify responders. Overall, refining study designs and personalizing intervention protocols are essential for optimizing oxytocin’s prosocial and anxiolytic effect in autism. © The Author(s) 2025.",autism; clinical trials; Oxytocin,"Administration, Intranasal; Animals; Autism Spectrum Disorder; Autistic Disorder; Humans; Oxytocin; Social Behavior; dopamine; oxytocin; oxytocin receptor; serotonin; serotonin uptake inhibitor; vasopressin; oxytocin; anxiety; Article; assessment of humans; autism; Autism Diagnostic Observation Schedule; Autism Treatment Evaluation Checklist; blood brain barrier; Brief Observation of Social Communication Change; Childhood Autism Rating Scale; clinical outcome; cognition; dose response; eye tracking; genetic screening; heart rate variability; human; intervention protocol; neuromodulation; neurophysiology; physiological stress; posttraumatic stress disorder; protocol; schizophrenia; self report; single nucleotide polymorphism; social anxiety; social behavior; Social Responsiveness Scale; tachycardia; tranquilizing activity; animal; drug therapy; intranasal drug administration",Article,Final,,Scopus,2-s2.0-85216515085,Movies / Media
Šola H.M.; Qureshi F.H.; Khawaja S.,"Šola, Hedda Martina (57444566400); Qureshi, Fayyaz Hussain (58096717400); Khawaja, Sarwar (58096694900)",57444566400; 58096717400; 58096694900,Human-Centred Design Meets AI-Driven Algorithms: Comparative Analysis of Political Campaign Branding in the Harris–Trump Presidential Campaigns,2025,Informatics,12,1,30,,,,0,10.3390/informatics12010030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001167561&doi=10.3390%2finformatics12010030&partnerID=40&md5=0f14f70615abd920b350ecb8290138fb,"This study compared the efficacy of AI neuroscience tools versus traditional design methods in enhancing viewer engagement with political campaign materials from the Harris–Trump presidential campaigns. Utilising a mixed-methods approach, we integrated quantitative analysis employing AI’s eye-tracking consumer behaviour metrics (Predict, trained on 180,000 screenings) with an AI-LLM neuroscience-based marketing assistant (CoPilot), with 67,429 areas of interest (AOIs). The original flyer, from an Al Jazeera article, served as the baseline. Professional graphic designers created three redesigned versions, and one was done using recommendations from CoPilot. Metrics including total attention, engagement, start attention, end attention, and percentage seen were evaluated across 13–14 areas of interest (AOIs) for each design. Results indicated that human-enhanced Design 1 with AI eye-tracking achieved superior overall performance across multiple metrics. While the AI-enhanced Design 3 demonstrated strengths in optimising specific AOIs, it did not consistently outperform human-touched designs, particularly in text-heavy areas. The study underscores the complex interplay between neuroscience AI algorithms and human-centred design in political campaign branding, offering valuable insights for future research in neuromarketing and design communication strategies. Python, Pandas, Matplotlib, Seaborn, Spearman correlation, and the Kruskal–Wallis H-test were employed for data analysis and visualisation. © 2025 by the authors.",AI eye-tracking; CoPilot; Harris vs. Trump; LLM; neurodesign; neuromarketing; political neurodesign; predict; predicting human behaviour,,Article,Final,,Scopus,2-s2.0-105001167561,Movies / Media
Gonnermann-Müller J.; Krüger J.M.,"Gonnermann-Müller, Jana (59251722500); Krüger, Jule M. (57213199474)",59251722500; 57213199474,Unlocking Augmented Reality Learning Design Based on Evidence From Empirical Cognitive Load Studies—A Systematic Literature Review,2025,Journal of Computer Assisted Learning,41,1,e13095,,,,2,10.1111/jcal.13095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211139849&doi=10.1111%2fjcal.13095&partnerID=40&md5=c270cead5bb343efa3be580403299042,"Background: Despite the numerous positive effects of augmented reality (AR) on learning, previous research has shown ambiguous results regarding the cognitive demand on the learner arising from, for example, the overlay of virtual elements or novel interaction techniques. At the same time, the number of evidence-based guidelines on designing AR is limited or focuses on global effects, primarily relying on media comparison studies, whose validity is criticised. Objective: To guide the meaningful design of learning and training settings, this paper systematically reviews empirical research on AR design and synthesises the findings to develop evidence-based recommendations for designing AR systems considering cognitive load. Methods: We conducted a systematic literature review, initially screening 810 distinct papers and ultimately analysing findings from 27 publications, which report on 29 distinct experimental studies. This selection was based on rigorously defined inclusion and exclusion criteria, adhering to the PRISMA guidelines. Results and Conclusion: The central value of this paper is the aggregation of existing evidence from empirical studies, resulting in 15 recommendations for AR design based on six design dimensions: Spatiality-related, Interaction-related, Contextuality-related, Content-related, Guidance-related and Display Selection. Additionally, with three points for future research, this systematic literature review, first, stresses the need for more empirical evidence and value-added studies. Second, learner characteristics that might influence cognitive load in AR-based learning should be examined. Third, it advocates for the inclusion of measurements beyond the NASA-TLX, and including more physiological measurements (e.g., eye-tracking, EEG) to enhance the applicability of the results for learning and training situations. © 2024 The Author(s). Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.",augmented reality; cognitive load; design guidelines; design principles; instructional design; workload,,Review,Final,,Scopus,2-s2.0-85211139849,Movies / Media
Heintz Walters B.; Huddleston W.E.; O’Connor K.M.; Wang J.; Hoeger Bement M.; Keenan K.G.,"Heintz Walters, Brittany (57389104600); Huddleston, Wendy E. (6602287410); O’Connor, Kristian M. (57194908736); Wang, Jinsung (8374142500); Hoeger Bement, Marie (8264866400); Keenan, Kevin G. (7006549493)",57389104600; 6602287410; 57194908736; 8374142500; 8264866400; 7006549493,Age-related differences in eye movements and the association with Archimedes spiral tracing performance in young and older adults,2025,Experimental Brain Research,243,2,53,,,,0,10.1007/s00221-025-07001-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217273599&doi=10.1007%2fs00221-025-07001-2&partnerID=40&md5=4569bcf341b97996cb495cb4e1789310,"Age-related hand motor impairments may critically depend on visual information though few studies have examined eye movements during tasks of hand function in older adults. The purpose of this study was to assess eye movements and their association with performance while tracing on a touchscreen in young and older adults. Eye movements of 21 young (age 20–38 years; 12 females, 9 males) and 20 older (65–85 years; 10 females, 10 males) adults were recorded while performing an Archimedes spiral tracing task, a common clinical assessment sensitive to age-associated impairments in hand function. Participants traced an Archimedes spiral template on a touchscreen as accurately as possible under three conditions, using (1) a stylus, (2) the index finger, and (3) the index finger while performing a visuospatial dual task. Older adults made fewer total fixations than young adults, and participants made fewer fixations when tracing parts of the spiral where vision of the spiral template was likely more obstructed by the hand. Inter-fixation distance and inter-fixation distance variability were greater in older compared to young adults. A relationship between increased inter-fixation distance and increased spiral tracing error demonstrates the association between age-related changes in eye movements and spiral tracing performance in older adults. Results contribute novel findings of age-associated changes in ocuomotor behavior during a common clinical assessment and offer insight into motor control in older adults. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.",Aging; Attention; Eye movements; Hand function; Older adults; Spiral tracing,"Adult; Aged; Aged, 80 and over; Aging; Eye Movements; Female; Hand; Humans; Male; Psychomotor Performance; Young Adult; adult; age; aged; archimedes spiral tracing task; Article; eye movement; female; hand disease; head movement; human; image artifact; index finger; male; mild cognitive impairment; Montreal cognitive assessment; motor control; motor dysfunction; motor dysfunction assessment; questionnaire; right handedness; senescence; spatial memory test; visual acuity; aging; hand; physiology; psychomotor performance; very elderly; young adult",Article,Final,,Scopus,2-s2.0-85217273599,Movies / Media
Vrijling A.C.L.; de Boer M.J.; Renken R.J.; Marsman J.-B.C.; Heutink J.; Cornelissen F.W.; Jansonius N.M.,"Vrijling, Anne C. L. (36195905600); de Boer, Minke J. (57202889621); Renken, Remco J. (22958013000); Marsman, Jan-Bernard C. (25957645800); Heutink, Joost (23984477100); Cornelissen, Frans W. (7003574141); Jansonius, Nomdo M. (6603178993)",36195905600; 57202889621; 22958013000; 25957645800; 23984477100; 7003574141; 6603178993,Detecting and Quantifying Glaucomatous Visual Function Loss With Continuous Visual Stimulus Tracking: A Case-Control Study,2025,Translational Vision Science and Technology,14,2,3,,,,0,10.1167/tvst.14.2.3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217853819&doi=10.1167%2ftvst.14.2.3&partnerID=40&md5=dbfa1f6cfeef976c264515c36c4f399e,"Purpose: Continuous visual stimulus tracking could be used as an easy alternative to standard automated perimetry (SAP) for visual function screening. With continuous visual stimulus tracking, we simplified the perimetric task to following a moving dot on a screen with the eyes. Here, we determined whether tracking performance (the agree-ment between gaze and stimulus position) enables the detection and quantification of glaucomatous visual function loss (in terms of SAP), and whether it shows a learning effect.Methods: We evaluated the tracking performance of 36 cases with early, moderate, or severe glaucoma (median with interquartile range [IQR] age = 70 [67–74] years) and 36 controls (median = 70, IQR = 67–72 years). All participants monocularly tracked a moving stimulus (Goldmann size III) at 3 Weber contrast levels: 40, 160, and 640%, while their eye movements were recorded.Results: Glaucoma decreased the tracking performance, with the most severe reduction in the severe glaucoma cases. A distinction between groups was possible, but depended on the contrast level: tracking performance of early glaucoma cases was significantly different from controls only at 40% contrast. Within the cases, glaucomatous visual function loss (SAP Mean Sensitivity [MS]) was best correlated with tracking performance when using 160% contrast. There was no significant learning effect.Conclusions: Overall, the data indicate that it is possible to detect and quantify glauco-matous visual function loss with continuous visual stimulus tracking. Translational Relevance: Continuous visual stimulus tracking is an easy, fast, and intuitive technique that has the potential for diagnostic applications in detection of new glaucoma cases and monitoring of previously diagnosed cases. © 2025, Association for Research in Vision and Ophthalmology Inc.. All rights reserved.",continuous visual stimulus tracking; eye movements; eye-tracking; glaucoma; perimetry; screening; visual field; visual function loss,Aged; Case-Control Studies; Eye Movements; Eye-Tracking Technology; Female; Glaucoma; Humans; Male; Photic Stimulation; Vision Disorders; Visual Acuity; Visual Field Tests; Visual Fields; accuracy; aged; Article; best corrected visual acuity; case control study; clinical article; cognition; contrast; controlled study; female; glaucoma; human; intraocular pressure; learning; male; Montreal cognitive assessment; perimetry; questionnaire; retinal nerve fiber layer thickness; spectral domain optical coherence tomography; standard automated perimetry; visual stimulation; diagnosis; eye movement; eye-tracking technology; pathophysiology; perimetry; photostimulation; physiology; procedures; visual acuity; visual disorder; visual field,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85217853819,Movies / Media
Ronconi A.; Mason L.; Manzione L.; Schüler A.,"Ronconi, Angelica (57301098500); Mason, Lucia (7102841222); Manzione, Lucia (57659798700); Schüler, Anne (36464158200)",57301098500; 7102841222; 57659798700; 36464158200,Effects of Digital Reading With On-Screen Distractions: An Eye-Tracking Study,2025,Journal of Computer Assisted Learning,41,1,e13106,,,,0,10.1111/jcal.13106,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212473543&doi=10.1111%2fjcal.13106&partnerID=40&md5=b41f26ac0facf613fc0d39f512e6fa44,"Background: During digital reading on internet-connected devices, students may be exposed to a variety of on-screen distractions. Learning by reading can therefore become a fragmented experience with potentially negative consequences for reading processes and outcomes. Objectives: This study investigated the effects of on-screen distractions, as advertisements and social media notifications, during reading on text processing, perception of cognitive load and text comprehension. Methods: University students (N = 54) participated in a within-participant design. They read two digital science expository texts, one with and the other without distractions. Participants' eye movements were recorded during reading. Process variables were the first-pass fixation time on text areas and the fixation time on distractions. Working memory was taken into account as possible moderator of outcome variables, while controlling for prior knowledge and text topic. Results: Participants spent very short time fixating the distractions. From linear mixed models the main effect of distractions did not emerge for the immediate text processing. Perception of cognitive load and text comprehension were not affected by distractions either. Among individual differences, prior knowledge contributed to text comprehension. Text topic contributed to the perception of cognitive load. Takeaways: The study suggests that simple, static and very usual on-screen distractions during reading do not seem particularly harmful for university students' processing and comprehension of expository texts. Findings indicate the importance of students' top-down attentional control over on-screen distractions not to impair their own comprehension of complex content. © 2024 The Author(s). Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.",digital reading; eye movements; multitasking; on-screen distractions; text comprehension; text processing,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85212473543,Movies / Media
Styrkowiec P.; Wierzbicki M.,"Styrkowiec, Piotr (56006845300); Wierzbicki, Michał (57215445073)",56006845300; 57215445073,Different effects of smooth pursuit eye movements on motion-based stimulus response congruency,2025,Psychological Research,89,1,17,,,,0,10.1007/s00426-024-02049-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209115677&doi=10.1007%2fs00426-024-02049-1&partnerID=40&md5=fa3e7be4cf47b5eb55e35a01d264fe8a,"In the motion-based stimulus-response compatibility (SRC) effect, responses are faster when the task-irrelevant stimulus motion is congruent with the response movement performance. In the present study, we tested whether smooth pursuit eye movements, related to tracking a moving object, influence motion-based SRC when present on their own or when combined with position-based SRC. We examined the motion-based SRC effect during both the response selection and response execution stages. When investigating motion-based SRC alone, participants responded with left or right movements of the single hand to the left or right movements of a centrally presented stimulus, either with their eyes fixated at the center or tracking the moving object. In the case of combined motion-based and position-based SRC, participants responded with left or right movements of the left or right hand to stimulus motion presented on the left or right side of the screen, again with eyes either fixated at the center or following the moving target. Results showed that during the response selection stage, smooth pursuit type eye movements had no effect on the motion-based SRC when the stimulus moved in the center, whereas the effect was enhanced when the stimulus presentation was lateralized. This aligns with the idea that attentional shifts differ between central and peripheral vision and that cognitive system computes various spatial maps for stimulus and response. In the case of response execution, smooth pursuit type eye movements had no effect on the motion-based SRC effect, regardless of stimulus location. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.",,"Adult; Attention; Female; Humans; Male; Motion Perception; Psychomotor Performance; Pursuit, Smooth; Reaction Time; Young Adult; adult; attention; female; human; male; movement perception; physiology; psychomotor performance; reaction time; smooth pursuit eye movement; young adult",Article,Final,,Scopus,2-s2.0-85209115677,Movies / Media
Katsuhisa M.; Oyama A.; Ito Y.; Sugihara N.; Teshirogi S.; Yamamoto S.; Ikegawa Y.; Nakajima T.; Nakatani Y.; Yamamoto E.; Bando H.; Tanaka S.; Hashimoto M.; Iwata K.; Takeda S.,"Katsuhisa, Mizuki (58838018600); Oyama, Akane (57210962192); Ito, Yuki (57210957952); Sugihara, Nanami (58370131200); Teshirogi, Shin (57222408094); Yamamoto, Sho (59366184200); Ikegawa, Yuya (59365938400); Nakajima, Tsuneo (57210955051); Nakatani, Yoshitaka (57222012012); Yamamoto, Eriko (59365860300); Bando, Hiromi (59366184300); Tanaka, Sayaka (59366184400); Hashimoto, Mamoru (55462859400); Iwata, Kazuhiko (56030891000); Takeda, Shuko (23475751800)",58838018600; 57210962192; 57210957952; 58370131200; 57222408094; 59366184200; 59365938400; 57210955051; 57222012012; 59365860300; 59366184300; 59366184400; 55462859400; 56030891000; 23475751800,Eye-Tracking-Based Cognitive Assessment Efficiently Detects Mild Cognitive Decline in the Predementia Stage,2025,Dementia and Geriatric Cognitive Disorders,54,1,,29,39,10.0,0,10.1159/000541235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206340572&doi=10.1159%2f000541235&partnerID=40&md5=6a6d8077f07c156b4f0a63bf145b2e89,"Introduction: The early detection of cognitive decline is key to maximizing the benefits of preventive and therapeutic interventions against dementia. Generally, dementia is first assessed by interview-based neuropsychological tests, but the lengthy interview and mental stress during the assessment process make screenings inefficient. We previously developed a rapid screening test for dementia using an eyetracking technology (eye-tracking-based cognitive assessment [ETCA]) and reported its utility for clinically detecting cognitive impairment in dementia cases. However, the ETCA's performance in detecting people with mild cognitive decline, which is the major target population for dementia prevention strategies, remains insufficiently examined. Therefore, this study aimed to evaluate the ETCA's performance in individuals aged 40 years and older (n = 94, mean age: 61.0 [SD 13.1] years) without being formally diagnosed with dementia. Methods: All participants underwent both the ETCA and neuropsychological tests, including the Mini- Mental State Examination (MMSE), Rivermead Behavioral Memory Test (RBMT), and Addenbrooke's Cognitive Examination-III (ACE-III) on the same day. We examined the correlations in scores between the ETCA and each neuropsychological test. Furthermore, we selected participants who earned normal scores in each neuropsychological test and evaluated the ETCA's performance in this subgroup. Results: Participants' ETCA scores correlated significantly with their scores on neuropsychological tests, including the MMSE, RBMT, and ACE-III. Notably, the ETCA scores correlated with the RBMT or ACE-III scores in individuals who showed normal scores in each neuropsychological test. Conclusion: The ETCA has the potential to screen mild cognitive decline efficiently at the predementia stage in nonclinical settings.  © 2024 S. Karger AG, Basel.",Cognitive assessment; Dementia; Eye-tracking; Mild cognitive impairment,Adult; Aged; Cognitive Dysfunction; Dementia; Early Diagnosis; Eye-Tracking Technology; Female; Humans; Male; Mental Status and Dementia Tests; Middle Aged; Neuropsychological Tests; Addenbrooke cognitive examination III; adult; aged; Article; cognition assessment; controlled study; correlation analysis; dementia; disease course; eye tracking; eye-tracking technology; human; major clinical study; mild cognitive impairment; Mini Mental State Examination; neuropsychological assessment; patient selection; reproducibility; Rivermead behavioral memory test; cognitive defect; dementia; dementia assessment; diagnosis; early diagnosis; eye-tracking technology; female; male; middle aged; neuropsychological assessment; psychology,Article,Final,,Scopus,2-s2.0-85206340572,Movies / Media
Wang Q.; Han Y.; Hu Y.; Li X.; Liu J.; Fang H.; Li T.; Chang Y.; Yi L.,"Wang, Qiandong (56097801000); Han, Ying (55489202900); Hu, Yixiao (57201357808); Li, Xue (56378925000); Liu, Jing (56378132800); Fang, Hui (55990714700); Li, Tianbi (57194498607); Chang, Yanmei (57211653900); Yi, Li (57200784197)",56097801000; 55489202900; 57201357808; 56378925000; 56378132800; 55990714700; 57194498607; 57211653900; 57200784197,Orienting to and away from the eyes in infants at high likelihood for autism when scanning faces,2025,Autism Research,18,1,,166,178,12.0,0,10.1002/aur.3270,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210036944&doi=10.1002%2faur.3270&partnerID=40&md5=64df5069ea26311d3b8ceae7c490fdf7,"This study employed eye-tracking technology to investigate the mechanisms underlying reduced gaze towards the eyes in infants at high likelihood (HL) for autism, specifically examining whether it results from avoidance triggered by heightened arousal when looking at the eyes or due to indifference to the eyes (i.e., unwilling to orient to the eyes). Infants at HL for autism and typically developing (TD) infants aged within 24 months were tested. In the experiment, participants' gaze was initially guided to the eye or mouth region immediately before the onset of the face. Latency to orient away from the guided regions, latency to orient to the eyes, and the location of the secondary fixation following the onset of the face were measured. The results showed that: (1) The HL infants looked less at eyes than TD infants; (2) Compared with TD infants, HL infants oriented towards eyes more slowly after being guided to the mouth; (3) After being guided to the eyes, HL infants' secondary fixation fell less in the eye region, and their latency to orient away from the eyes was also tended to be shorter. These results suggest that reduced eye-looking time was presented in HL infants, which was further explained by both eye avoidance and indifference to the eyes. Our study contributes theoretically to understanding the atypical face scanning pattern in autistic people and its related underlying mechanisms. Furthermore, our study provides important insights into the development of early screening tools and intervention protocols for autistic people. © 2024 International Society for Autism Research and Wiley Periodicals LLC.",autism; eye movement; face processing; infants; visual attention,"Attention; Autistic Disorder; Eye; Eye Movements; Eye-Tracking Technology; Face; Facial Recognition; Female; Fixation, Ocular; Humans; Infant; Male; Article; assessment of humans; autism; avoidance behavior; Communicationand Symbolic Behavior Scales; diagnostic procedure; eye movement; eye tracking; facial expression; female; happiness; human; infant; latent period; major clinical study; male; medical assessment; modified checklist for autism in toddlers; neurologic disease; risk factor; scanning faces; attention; eye; eye fixation; eye-tracking technology; face; facial recognition; pathophysiology; physiology",Article,Final,,Scopus,2-s2.0-85210036944,Movies / Media
Chen Y.; Guo Q.; Qiao C.; Wang J.,"Chen, Yuqing (58731955500); Guo, Qing (57777646200); Qiao, Cuilan (35788295500); Wang, Jingying (48662961600)",58731955500; 57777646200; 35788295500; 48662961600,A systematic review of the application of eye-tracking technology in reading in science studies,2025,Research in Science and Technological Education,43,2,,431,455,24.0,4,10.1080/02635143.2023.2285297,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178222306&doi=10.1080%2f02635143.2023.2285297&partnerID=40&md5=3ff9eed43b817d14d3c6b32ac4a074a0,"Background: Eye-tracking methods can compensate for the shortcomings of traditional reading in science in terms of understanding thereader’s cognition and the reading process, etc. There is a growing body of research on the use of eye-tracking methods in reading in science, but a systematic review is lacking. Purpose: The purpose of this study was to analyze the current state of eye-tracking in reading in science, including research trends, number of participants and grade level, brand of eye-tracker, content and subject matter of the reading material, areas of interest (AOI) delineation, eye-tracking indicators, study content and analysis methods, and conclusions drawn. Sample: Databases are Web of Science and Scopus, after screening 44 literature were included in the study. Design and methods: Systematic literature review following PRISMA process. Results: (1) The eye-tracking method has been consistently gaining attention among researchers over the past decade; (2) Participants are mainly college students and elementary school students, with the majority of participants numbering less than 100; (3) EyeLink, Tobii, and SMI are the commonly used brands of eye-tracking devices.The reading materials cover various branches of natural sciences. More than 90%of the studies used ANOVA methods. AOI can be classified according to the format of material presentation, functional attributes of the content, and the location of the material display. (4) Fifteen commonly used eye movement indicators, such as total fixation duration and number of saccades between AOI,and 8 unique eye movement indicators, such as number of blinks, as well as summarizes key general or important findings. Conclusion: This study provides significant implications for understanding the current state of research, such as research content and the use of eye movement indicators. Furthermore, recommendations are provided for future studies such as increasing the number of participants, using more diverse eye movement indicators, and analyzing methods. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",eye-tracking; Reading in science; science education; systematic review,,Review,Final,,Scopus,2-s2.0-85178222306,Movies / Media
Xie X.; Yu S.; Chen D.,"Xie, Xiaojiao (57221868555); Yu, Suihuai (13906567800); Chen, Dengkai (24773236200)",57221868555; 13906567800; 24773236200,Effects of Screen Color Mode and Color Temperature on Visual Fatigue under Different Ambient Illuminations,2025,International Journal of Human-Computer Interaction,41,2,,821,833,12.0,4,10.1080/10447318.2024.2305982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183843675&doi=10.1080%2f10447318.2024.2305982&partnerID=40&md5=46ffb5485fb9956aea7304e1e25db6c7,"Viewing electronic screens for a long time can cause visual fatigue, even induce eye problems such as refractive errors, dry eyes, etc. The relationship between screen display and visual fatigue has received much attention. This article aims to study the optimal display color temperature and color mode under two common ambient illuminations—normal office lighting (450 lux) and dark environment (3 lux). In a 2 × 2×3 experimental design, 36 participants evaluated the effects of two display color modes (light mode and dark mode) and three screen color temperatures (2800 K, 4500 K, and 6500 K) on visual fatigue under two ambient illuminations. We used eye movement tracking technology to collect blink rate and pupil diameters as objective indicators and used the Richter scale to collect subjective visual fatigue and preference score as subjective indicators. Results showed that at 450 lux, lower visual fatigue was found in the dark mode, 4500 K and 6500 K. At 3 lux, the visual fatigue was lower in the dark mode and 4500 K color temperature. Whether at daytime or night, the 2800 K color temperature resulted in the highest visual fatigue. Our findings complement the research on screen display and visual fatigue. They have practical implications for reducing visual fatigue caused by prolonged viewing of electronic screens. © 2024 Taylor & Francis Group, LLC.",ambient illumination; color mode; color temperature; Display; visual fatigue,Eye movements; Eye tracking; Ambient illumination; Color mode; Color temperatures; Dark modes; Dry eye; Eye-movement tracking; Refractive error; Screen displays; Tracking technology; Visual fatigue; Color,Article,Final,,Scopus,2-s2.0-85183843675,Movies / Media
Zahedi S.; Khoshsaligheh M.,"Zahedi, Saber (57556089700); Khoshsaligheh, Masood (56946904400)",57556089700; 56946904400,Reading of Humor-added Subtitles of Foreign Films in Persian: An Eye-tracking Study,2025,Language Related Research,16,3,,29,52,23.0,0,10.48311/LRR.16.3.2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001957098&doi=10.48311%2fLRR.16.3.2&partnerID=40&md5=5d33b54523fcfdf5cfd2874c6df955bf,"It is becoming an established strategy to add humor in Persian subtitles even often when the original dialogue does not include the created or any other humor. This study measures the impact of this strategy on viewers’ attention allocation while reading subtitles. The eye movements of 32 participants were recorded while watching a humorous and non-humorous version of the same scene extracted from Superchondriac (Boon, 2014), a French comedy. The results show that there is a significant difference between attention allocation in the two versions, and the viewers’ attention to the subtitles with added humor is significantly larger than non-humorous subtitles. The interviews showed that some viewers liked the added humor because they thought it is funny and close to their cultural and ideological views. On the other hand, some of the participants opted for the non-humorous subtitles because they thought the added humor was distracting, confusing, at times offensive, and detached from the original culture. © 2026, Tarbiat Modares University. All rights reserved.",attention allocation; audiovisual translation; eye tracking; humor; subtitling,,Article,Final,,Scopus,2-s2.0-105001957098,Movies / Media
Chan M.K.-L.; Wong C.L.; Yu K.P.; Tong R.K.-Y.,"Chan, Marko Ka-Leung (26634727100); Wong, Cho Lee (57141327900); Yu, King Pong (58419157100); Tong, Raymond Kai-Yu (35772793800)",26634727100; 57141327900; 58419157100; 35772793800,Examining Eye Tracking Metrics and Cognitive Function in Post-Stroke Individuals: A Comparison of Visual Searching Tasks between Those with and without Cognitive Impairment,2025,Cerebrovascular Diseases,53,6,,683,692,9.0,3,10.1159/000535756,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194475077&doi=10.1159%2f000535756&partnerID=40&md5=90dca1de50188b4fc2fb24b54cd3e347,"Introduction: After a stroke, individuals commonly experience visual problems and impaired cognitive function, which can significantly impact their daily lives. In addition to visual neglect and hemianopia, stroke survivors often have difficulties with visual search tasks. Researchers are increasingly interested in using eye tracking technology to study cognitive processing and determine whether eye tracking metrics can be used to screen and assess cognitive impairment in patients with neurological disorders. As such, assessing these areas and understanding their relationship is crucial for effective stroke rehabilitation. Methods: We enrolled 60 stroke patients in this study and evaluated their eye tracking performance and cognitive function through a series of tests. Subsequently, we divided the subjects into two groups based on their scores on the HK-MoCA test, with scores below 21 out of 30 indicating cognitive impairment. We then compared the eye tracking metrics between the two groups and identified any significant differences that existed. Spearman correlation analysis was conducted to explore the relationship between clinical test scores and eye tracking metrics. Moreover, we employed a Mann-Whitney U test to compare eye tracking metrics between groups with and without cognitive impairment. Results: Our results revealed significant correlations between various eye tracking metrics and cognitive tests (p ≤ 0.001–0.041). Furthermore, the group without cognitive impairment demonstrated higher saccade velocity, gaze path velocity, and shorter time to target than the group with cognitive impairment (p ≤ 0.001–0.040). Receiver operating characteristic curve analyses were performed, and the optimal cut-off values for gaze path velocity and saccade velocity were 329.665 (px/s) (sensitivity = 0.80, specificity = 0.533) and 2.150 (px/ms) (sensitivity = 0.733, specificity = 0.633), respectively. Conclusions: Our findings indicate a significant correlation between eye tracking metrics and cognitive test scores. Furthermore, the group with cognitive impairment exhibited a significant difference in these metrics, and a cut-off value was identified to predict whether a client was experiencing cognitive impairment. © 2023 The Author(s). Published by S. Karger AG, Basel.",Biomedical engineering; Cognitive impairment ·; Eye tracking ·; Stroke ·,Adult; Aged; Cognition; Cognitive Dysfunction; Eye Movements; Eye-Tracking Technology; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Predictive Value of Tests; Stroke; Visual Perception; Abbreviated Mental Test; adult; area under the curve; Article; cerebrovascular accident; cognition; cognitive defect; computer assisted tomography; controlled study; diagnostic test accuracy study; disease duration; dysphasia; educational status; experimental cognitive test; experimental test; eye tracking; female; gaze path velocity; hemiplegia; Hong Kong version of the Montreal Cognitive Assessment; human; major clinical study; male; medical parameters; middle aged; Montreal cognitive assessment; nuclear magnetic resonance; paced auditory serial addition test; receiver operating characteristic; Rivermead behavioral memory test; saccadic velocity; sensitivity and specificity; stroke patient; Stroop color and word test T-score; trail making test; Visual Searching Tasks; aged; comparative study; complication; diagnosis; etiology; eye movement; eye-tracking technology; neuropsychological assessment; pathophysiology; predictive value; psychology; vision,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85194475077,Movies / Media
Zeng Z.; Tao L.; Su R.; Tuheti A.; Huang H.; Chen C.; Chen W.,"Zeng, Zheng (57768265100); Tao, Linkai (57203776910); Su, Ruizhi (58699716100); Tuheti, Adili (58700031900); Huang, Hao (59445897000); Chen, Chen (57257578500); Chen, Wei (57087429900)",57768265100; 57203776910; 58699716100; 58700031900; 59445897000; 57257578500; 57087429900,Residual Self-Calibrated Network With Multi-Scale Channel Attention for Accurate EOG-Based Eye Movement Classification,2025,IEEE Journal of Biomedical and Health Informatics,29,1,,118,127,9.0,0,10.1109/JBHI.2024.3432930,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199353046&doi=10.1109%2fJBHI.2024.3432930&partnerID=40&md5=e6d9bb2e07e7a3ce213c701f394d6023,"Recently, Electrooculography-based Human-Computer Interaction (EOG-HCI) technology has gained widespread attention in industrial areas, including assistive robots, augmented reality in gaming, etc. However, as the fundamental step of EOG-HCI, accurate eye movement classification (EMC) still faces a significant challenge, where their constraints in extracting discriminative features limit the performance of most existing works. To address this issue, a Residual Self-Calibrated Network with Multi-Scale Channel Attention (RSCA), focusing on efficient feature extraction and enhancement is proposed. The RSCA network first employs three self-calibrated convolution blocks within a hierarchical residual framework to fully extract the discriminative multi-scale features. Then, a multi-scale channel attention module adaptively weights the learned features to screen out the discriminative representation by aggregating the multi-scale context information along the channel dimension, thus further boosting the performance. Comprehensive experiments were performed using 5 public datasets and 7 prevailing methods for comparative validation. The results confirm that the RSCA network outperforms all other methods significantly, establishing a state-of-the-art benchmark for EOG-based EMC. Furthermore, thorough ablation analyses confirm the effectiveness of the employed modules within the RSCA network, providing valuable insights for the design of EOG-based deep models. © 2013 IEEE.",Deep learning; electrooculogram (EOG); eye movement classification (EMC); residual self-calibrated network combined with multi-scale channel attention (RSCA),"Algorithms; Electrooculography; Eye Movements; Humans; Neural Networks, Computer; Signal Processing, Computer-Assisted; Augmented reality; Deep learning; Eye movements; Human robot interaction; Deep learning; Electro-oculogram; Electrooculogram; Eye movement classification; Eye movement classifications; Industrial area; Interaction technology; Multi-scales; Performance; Residual self-calibrated network combined with multi-scale channel attention (RSCA); accuracy; algorithm; Article; artifact; artificial neural network; attention; augmented reality; calibration; classification algorithm; convolutional neural network; deep learning; electroencephalography; electrooculogram; electrooculography; eye movement; feature extraction; human; human computer interaction; k nearest neighbor; learning algorithm; machine learning; measurement accuracy; multi scale channel attention; nerve cell network; nerve cell plasticity; receptive field; sensitivity and specificity; support vector machine; physiology; procedures; signal processing; Human computer interaction",Article,Final,,Scopus,2-s2.0-85199353046,Movies / Media
Wongngan M.; Hsieh T.-J.,"Wongngan, Muthita (59955255700); Hsieh, Tsuei-Ju (58553362900)",59955255700; 58553362900,Comparing Online Furniture Retail Through Strategic Multichannel Integration: A Case Study of Oh!dinary,2025,Communications in Computer and Information Science,2528 CCIS,,,406,424,18.0,0,10.1007/978-3-031-94168-9_40,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008650932&doi=10.1007%2f978-3-031-94168-9_40&partnerID=40&md5=392968082402eb1b047a0c38d6444b75,"This study investigates how virtual exhibitions impact furniture e-commerce through a case study of Oh! dinary—a new designer brand offering modern furniture and home décor. We compare user experiences across the brand’s screen-VR virtual showroom, traditional website, and Instagram presence, examining how spatial visualization affects engagement and purchase intent. Our mixed-method approach combines platform analytics with user interviews and screen-recording observations layered with eye movements data. Results show that Oh! dinary’s virtual showroom delivers more attention engagement experiences, generating higher interaction rates and purchase confidence than conventional platforms. Participants reported enhanced perception of product volume, scale and design details in the virtual showroom. This research demonstrates how virtual exhibitions help emerging designer brands overcome digital retail barriers while establishing distinctive market presence through enhanced spatial context and brand storytelling. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.",Augmented Reality; Multi-Channel Retail; Purchase Intention; Screen-VR; Spatial Visualization; User Engagement; Virtual Showroom,Electronic commerce; Eye movements; Human computer interaction; Product design; Purchasing; Sales; User experience; Virtual reality; Visualization; Case-studies; E- commerces; Multi channel; Multi-channel retail; Purchase intention; Screen-VR; Spatial visualization; User engagement; Virtual exhibitions; Virtual showroom; Augmented reality,Conference paper,Final,,Scopus,2-s2.0-105008650932,Movies / Media
Alves W.; Babouras A.; Martineau P.A.; Schutt D.; Robbins S.; Fevens T.,"Alves, William (59981710600); Babouras, Athanasios (57204007012); Martineau, Paul A. (7007044888); Schutt, Danielle (59982280300); Robbins, Shawn (19934389400); Fevens, Thomas (8548318500)",59981710600; 57204007012; 7007044888; 59982280300; 19934389400; 8548318500,Inferring concussion history in athletes using pose and ground reaction force estimation and stability analysis of plyometric exercise videos,2025,Medical and Biological Engineering and Computing,,,,,,,0,10.1007/s11517-025-03411-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009981004&doi=10.1007%2fs11517-025-03411-0&partnerID=40&md5=0158b173ec5ce2449ebc45e468431122,"Abstract: Concussions present a significant risk to athletes, with females exhibiting higher rates and prolonged recovery times than males. Current sideline concussion detection methods, such as the King-Devick test commonly used as a rapid screening tool designed to evaluate eye movement, attention, language, and cognitive processing abilities suffer from validity issues. This is especially true among young athletes highlighting the need for more accurate and objective assessment tools. This study investigates the ability of the Microsoft Kinect V2 pose estimation depth sensor to reliably measure subtle postural stability differences between athletes with a history of concussion and healthy controls. Traditional methods make use of expensive force plates which require trained personnel and controlled environments, limiting their use in resource-limited settings. Inspired by previous research utilizing force plates, our study analyzes video recordings of athletes performing specific exercises to detect dynamic balance deficits. A machine learning approach is employed to predict ground reaction forces from pose estimation video recordings, which are then analyzed to measure time to stabilization. Results reveal significant differences in movement mechanics between concussed and control groups, with the drop vertical jump (DVJ) exercise demonstrating the highest discriminatory power. Notably, concussed individuals exhibit longer time to stabilization (mean difference = 0.089 s, p = 0.046) during DVJ, indicating potential lingering balance impairments. While single-leg squat (SLS) and single-leg hop (SLH) exercises showed fewer discriminatory metrics than DVJ, they still provide valuable insights into balance capabilities. The DVJ yielded the largest statistical difference between injured and healthy male athletes, while the SLH was more effective for females and the SLS, while effective for ACL rehab progress assessment, was equally ineffective for both males and females. © International Federation for Medical and Biological Engineering 2025.",Computer vision; Concussion assessment; Machine learning; Pose estimation; Sports medicine,Biomedical engineering; Diagnosis; Discriminators; Eye movements; Screening; Sports; Sports medicine; Stabilization; Video recording; 'current; Concussion assessment; Force estimation; Force plate; Ground reaction forces; High rate; Machine-learning; Pose-estimation; Recovery time; Stability analyze; Computer vision,Article,Article in press,,Scopus,2-s2.0-105009981004,Movies / Media
Ferreira E.B.; Roselli L.R.P.; de Almeida A.T.,"Ferreira, Evanielle Barbosa (58304299400); Roselli, Lucia Reis Peixoto (57194341249); de Almeida, Adiel Teixeira (7102580955)",58304299400; 57194341249; 7102580955,Examining Interface Preferences in a Decision Support System Using Eye-Tracking,2025,Lecture Notes in Business Information Processing,546 LNBIP,,,59,75,16.0,0,10.1007/978-3-031-90863-7_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006833712&doi=10.1007%2f978-3-031-90863-7_5&partnerID=40&md5=8e0a42e530dea11d16db74b6b919bf27,"To support the decision-making process and enhance user interaction, Decision Support Systems (DSSs) are being developed and continuously improved. The aim of this study has been to investigate the interface of the FITradeoff DSS in order to investigate decision makers’ preferences in holistic evaluation and decomposition process. This study analyzed the differences between four interfaces in a DSS, as well as eye movement data from 37 participants. In the experiment (total average duration of approximately 5 min), fixation and pupil data were captured using Area of Interest (AOI) drawings, as well as heatmaps and scan paths. The results revealed that the decision-makers seemed to spend more time, attention and cognitive effort on the screen declared as preferred. In addition, it is suggested that, in one of the interfaces, the change in the arrangement of the data on the graph resulted in an increase in the demand for the task, suggesting an increase in task time, duration of fixation and pupil diameter. Hence, based on the results, the study aims to improve the FITradeoff DSS providing modulations in the FITradeoff method and it DSS. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.",Behavioral experiment; Decision Support Systems (DSSs); Decision-making tasks,Behavioral research; Behavioral experiment; Decision maker's preferences; Decision support system; Decision supports; Decision-making process; Decision-making task; Decisions makings; Eye-tracking; Support systems; User interaction; Decision making,Conference paper,Final,,Scopus,2-s2.0-105006833712,Movies / Media
Schreiner L.; Wipprecht A.; Olyanasab A.; Sieghartsleitner S.; Pretl H.; Guger C.,"Schreiner, Leonhard (57226645800); Wipprecht, Anouk (57209242923); Olyanasab, Ali (57815782600); Sieghartsleitner, Sebastian (57218249771); Pretl, Harald (7801451025); Guger, Christoph (55903211100)",57226645800; 57209242923; 57815782600; 57218249771; 7801451025; 55903211100,Brain–computer-interface-driven artistic expression: real-time cognitive visualization in the pangolin scales animatronic dress and screen dress,2025,Frontiers in Human Neuroscience,19,,1516776,,,,0,10.3389/fnhum.2025.1516776,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000548598&doi=10.3389%2ffnhum.2025.1516776&partnerID=40&md5=a8165d1ba3bed8aa78e619d65a501e88,"This paper explores the intersection of brain–computer interfaces (BCIs) and artistic expression, showcasing two innovative projects that merge neuroscience with interactive wearable technology. BCIs, traditionally applied in clinical settings, have expanded into creative domains, enabling real-time monitoring and representation of cognitive states. The first project showcases a low-channel BCI Screen Dress, utilizing a 4-channel electroencephalography (EEG) headband to extract an engagement biomarker. The engagement is visualized through animated eyes on small screens embedded in a 3D-printed dress, which dynamically responds to the wearer’s cognitive state. This system offers an accessible approach to cognitive visualization, leveraging real-time engagement estimation and demonstrating the effectiveness of low-channel BCIs in artistic applications. In contrast, the second project involves an ultra-high-density EEG (uHD EEG) system integrated into an animatronic dress inspired by pangolin scales. The uHD EEG system drives physical movements and lighting, visually and kinetically expressing different EEG frequency bands. Results show that both projects have successfully transformed brain signals into interactive, wearable art, offering a multisensory experience for both wearers and audiences. These projects highlight the vast potential of BCIs beyond traditional clinical applications, extending into fields such as entertainment, fashion, and education. These innovative wearable systems underscore the ability of BCIs to expand the boundaries of creative expression, turning the wearer’s cognitive processes into art. The combination of neuroscience and fashion tech, from simplified EEG headsets to uHD EEG systems, demonstrates the scalability of BCI applications in artistic domains. Copyright © 2025 Schreiner, Wipprecht, Olyanasab, Sieghartsleitner, Pretl and Guger.",3D-print; animatronic; art; BCI; engagement; fashion-tech; uHD EEG,adult; alertness; art; Article; artistic expression; attention; bluetooth low energy; brain function; cognition; controlled study; creativity; discriminant analysis; education; electroencephalogram; energy; engagement; experience; eye movement; eye movement control; fashion; feature extraction; female; frequency; human; human experiment; learning algorithm; light; machine learning; meditation; multisensory experience; normal human; Pholidota (animal); physiological stress; procedures; selective  laser  sintering; signal noise ratio; signal processing; society; wakefulness,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-105000548598,Movies / Media
Yuan X.; Ng K.K.H.; Yiu C.Y.; Li Q.,"Yuan, Xin (57218826228); Ng, Kam K. H. (57188646976); Yiu, Cho Yin (57352507200); Li, Qinbiao (57212447149)",57218826228; 57188646976; 57352507200; 57212447149,Optimising Pilot-Aircraft Interaction: A Low-Cost Projection-Enhanced Head-Up Display (PE-HUD) with Neuro-Ergonomic Validation,2025,Communications in Computer and Information Science,2523 CCIS,,,134,143,9.0,0,10.1007/978-3-031-94153-5_13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008649731&doi=10.1007%2f978-3-031-94153-5_13&partnerID=40&md5=5a3fe71730e62bede7ab9e11536c448f,"Modern aviation operations demand pilots to process multi-source cockpit instrumentation, creating cognitive fragmentation that degrades situational awareness (SA) and increases mental workload. While conventional head-up displays (HUDs) partially address these challenges, their static symbology and high retrofitting costs limit effectiveness. Augmented Reality (AR) solutions face adoption barriers due to visual conflicts in head-mounted displays and prohibitive waveguide HUD costs. This study proposes a low-cost Projection-Enhanced HUD (PE-HUD) using retroreflective film-screen symbiosis, achieving collimated imagery without complex optics. Neuro-ergonomic validation with functional Near-Infrared Spectroscopy (fNIRS) and eye-tracking were conducted across flight phases with ten cadet pilots under low-visibility simulations. Results demonstrated phase-specific cognitive benefits: PE-HUD significantly enhanced occipital-parietal activation during landing and improved cross-referencing between flight control units and primary displays. Take-off phases showed balanced multi-parameter monitoring, while cruise phases exhibited reduced HUD dependency. Eye-tracking revealed fewer head-down transitions compared to those without HUDs. Critically, pilots’ visual attention patterns varied dynamically across phases, necessitating adaptive interface designs. These findings establish neuro-ergonomic evidence for phase-sensitive HUD optimisation, advancing cost-effective human-machine interface (HMI) design in aviation. Future work will integrate real-time neurofeedback to enable context-aware display adaptation. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.",fNIRS; Head-Up Display; Human-Machine Interface; Neuro-Ergonomics; Situational Awareness; Visual Scanning Behaviours,Augmented reality; Cockpits (aircraft); Cost effectiveness; Ergonomics; Eye movements; Fighter aircraft; Flight control systems; Flight simulators; Head-up displays; Helmet mounted displays; Human computer interaction; Man machine systems; Cost projections; Functional near infrared spectroscopy; Head-UpDisplay; Heads-up-display; Human Machine Interface; Low-costs; Neuro-ergonomic; Situational awareness; Visual scanning; Visual scanning behavior; Near infrared spectroscopy,Conference paper,Final,,Scopus,2-s2.0-105008649731,Movies / Media
Reimer J.F.; Rosales K.P.; Sierra A.; Mobly K.; Rivera A.,"Reimer, Jason F. (7006301439); Rosales, Kevin P. (57214329253); Sierra, Anthony (36931166600); Mobly, Kyle (60007007800); Rivera, Andrew (60006741000)",7006301439; 57214329253; 36931166600; 60007007800; 60006741000,Ocular measures of controlled processing: Examining the use of proactive cognitive control in the AX-CPT,2025,Memory and Cognition,,,,,,,0,10.3758/s13421-025-01744-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011141283&doi=10.3758%2fs13421-025-01744-7&partnerID=40&md5=0e889fd8dfc48d1428f32572c83da4bf,"Assessing the use of proactive cognitive control is essential for understanding how thoughts and actions are regulated. The present study aimed to determine whether proactive control can be measured through patterns of eye movements during the cue–probe delay in a spatially modified AX-CPT. Across two experiments, we found that gaze activity at screen locations where cues and probes appeared predicted both the extent of proactive control adopted by participants and their ability to override a prepotent response tendency. However, the specific cognitive processes underlying the engagement of proactive control varied depending on task demands. Specifically, when the cue–probe delay was relatively short (Experiment 1), proactive control was characterized by rapid shifts in visual attention to support cognitive demands associated with frequent changes in the location of probe stimuli. In contrast, when the cue–probe delay was extended (Experiment 2), proactive control aligned with traditional conceptualizations, relying more on increased cue maintenance. Together, these results demonstrate that eye-movement patterns may serve as the foundation for ocular-based measures of proactive control, enabling further investigation into factors influencing its engagement and potential individual differences in its use. Implications that the results have for theories of controlled processing and inhibitory control are discussed. © The Psychonomic Society, Inc. 2025.",Cognitive control; Cue maintenance; Eye movements; Inhibitory control; Proactive control,adult; aptitude; article; cognition; cognitive processing therapy; controlled study; diagnosis; executive function; eye; eye movement; female; gaze; human; human experiment; inhibitory control; male; normal human; thinking; visual attention,Article,Article in press,,Scopus,2-s2.0-105011141283,Movies / Media
Mueller P.R.; Grimm S.; Einhäuser W.,"Mueller, Patricia R. (59755814000); Grimm, Sabine (9844230900); Einhäuser, Wolfgang (8701678900)",59755814000; 9844230900; 8701678900,"Norobust evidence for an effect of head-movement propensity on central bias in head-constrained scene viewing, despite an effect on fixation duration",2025,Journal of Vision,25,4,10,1,22,21.0,0,10.1167/jov.25.4.10,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003656214&doi=10.1167%2fjov.25.4.10&partnerID=40&md5=1ed2bbe7eaf576551323b8a56d5ce8e3,"When viewing natural scenes, participants tend to direct their gaze towards the image center, the so-called “central bias.” Unless the head is fixed, gaze shifts to peripheral targets are accomplished by a combination of eye and head movements, with substantial individual differences in the propensity to use the head. We address the relation of central bias and head-movement propensity. In one part of the experiment, participants viewed natural scenes of two different sizes without moving their head. We found that the central bias of each individual scaled with image size. In another experimental part, the same participants stood in the center of a panoramic screen and shifted their gaze to peripheral targets. Target eccentricities were either instructed by text (endogenous mode) or by a bar appearing at the target location (exogenous mode). In this “peripheral-target” task, we found a strong correlation between the exogenous and the endogenous mode, indicating that they provide a robust measure of an individual’s head-movement propensity. Despite substantial inter-individual variability in both tasks, no significant correlation was found between head-movement propensity and central bias, and a trend toward significance for a specific measure was brittle. However, individuals with a higher head-movement propensity tended to have shorter fixation durations in scene viewing. Our results suggest that central bias in free scene viewing on typical screen sizes is predominately determined by visual properties. Although head-movement propensity seems to affect some aspects of scene-viewing behavior (fixation durations), individual differences in central bias are not explained by head-movement propensity. © (2025), (Association for Research in Vision and Ophthalmology Inc.). All rights reserved.",central bias; eye-movement; head-movement propensity; inter-individual differences; natural scene viewing,"Adult; Attention; Eye Movements; Female; Fixation, Ocular; Head Movements; Humans; Male; Photic Stimulation; Visual Perception; Young Adult; adult; attention; eye fixation; eye movement; female; head movement; human; male; photostimulation; physiology; procedures; vision; young adult",Article,Final,,Scopus,2-s2.0-105003656214,Movies / Media
Sung H.-E.; Chiu T.-P.,"Sung, Hsin-En (59954682300); Chiu, Tseng-Ping (57731151600)",59954682300; 57731151600,Applying Eye-Tracking Technique to Investigate Generation Z’s Solo Dining Experience of Synesthetic Perception Between Eating and Watching Behavior,2025,Lecture Notes in Computer Science,15782 LNCS,,,221,233,12.0,0,10.1007/978-3-031-93730-9_15,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008490591&doi=10.1007%2f978-3-031-93730-9_15&partnerID=40&md5=b142a6665e9527243a93b4dc30d69e37,"This study focuses on two significant social trends: the increasing proportion of solo eaters and the widespread use of technological products. It targets Generation Z to explore the synesthetic effects between screens, visual stimuli, and taste experiences when dining alone. The research employs eye-tracking technology as the primary experimental and analytical tool, conducting two phases of experiments: a quantitative questionnaire and an eye-tracking sensory experiment. The study analyzes the differences and correlations in eye-tracking metrics, such as gaze duration, attention ratio, and effective attention ratio, under conditions where visual and taste stimuli are similar or different. In addition to exploring the synesthetic effects between the visual content delivered by screens and the taste experiences during meals in the digital age, the study also investigates the expected emotional responses during dining, the variations in visual focus depending on eating styles, and media content preferences. Ultimately, the study aims to provide insights for future innovative design approaches to enhance the development and potential of solo dining experiences. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.",emotional response; Eye-Tracking; Solo Dining; Synesthesia; visual perception,Behavioral research; Vision; Dining experience; Emotional response; Eye tracking technologies; Eye-tracking; Social trend; Solo dining; Synesthesia; Tracking techniques; Visual perception; Visual stimulus; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-105008490591,Movies / Media
Olivares Ordoñez M.A.; Smith R.C.; Yiu G.; Liu Y.A.,"Olivares Ordoñez, Marco Antonio (59501472900); Smith, Rebekah Cossette (58480653700); Yiu, Glenn (6601992788); Liu, Yin Allison (57206821840)",59501472900; 58480653700; 6601992788; 57206821840,Retinal Microstructural and Microvascular Changes in Alzheimer Disease: A Review,2025,International Ophthalmology Clinics,65,1,,59,67,8.0,1,10.1097/IIO.0000000000000549,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214186605&doi=10.1097%2fIIO.0000000000000549&partnerID=40&md5=d771743c41f3b7c00f183ee2279ec34f,"""The eyes are a window to the brain,""prompting the investigation of whether retinal biomarkers can indicate Alzheimer disease (AD) and cognitive impairment. AD is a neurodegenerative condition with a lengthy preclinical phase where pathologic changes in the central nervous system (CNS) occur before clinical symptoms. Mild cognitive impairment (MCI) often precedes AD. As part of the CNS, the retina exhibits similar pathologic changes related to AD as those seen in the brains of patients with MCI. Noninvasive imaging technologies such as optical coherence tomography (OCT) and optical coherence tomography angiography (OCTA) allow high-resolution visualization of the retina, providing an opportunity to screen and monitor AD noninvasively. In this review, we summarize the relationship between AD and retinal pathology detected by OCT and OCTA. The most common findings in patients with AD include peripapillary retinal nerve fiber layer thinning, decreased macular thickness, an enlarged foveal avascular zone, and decreased vascular densities in the superficial and deep capillary plexuses. These retinal changes correlate with magnetic resonance imaging (MRI) findings of cerebral atrophy, positron emission tomography (PET) findings of increased amyloid load, and neuropsychological testing results suggesting cognitive dysfunction. We conclude that retinal microstructural and microvascular abnormalities may serve as biomarkers for the early detection and clinical monitoring of AD and as tools for evaluating potential treatment effects. Future studies should focus on standardizing protocols for in vivo ophthalmic imaging to measure retinal pathology in AD and MCI. Copyright © 2024 Wolters Kluwer Health, Inc.",Alzheimer's disease; biomarkers; mild cognitive impairment; OCT; OCTA; retina,"Alzheimer Disease; Fluorescein Angiography; Humans; Microvessels; Retina; Retinal Diseases; Retinal Vessels; Tomography, Optical Coherence; Alzheimer disease; Article; brain atrophy; central nervous system; clinical practice; cognition; cognitive defect; eye movement; follow up; foveal avascular zone; human; mild cognitive impairment; neuroimaging; nonhuman; nuclear magnetic resonance imaging; optical coherence tomography; optical coherence tomography angiography; retina; retinopathy; risk factor; diagnosis; diagnostic imaging; etiology; fluorescence angiography; microvasculature; optical coherence tomography; pathology; procedures; retina; retina blood vessel; retina disease",Article,Final,,Scopus,2-s2.0-85214186605,Movies / Media
Xia C.; Chen H.; Han J.; Zhang D.; Li K.,"Xia, Chen (56102195500); Chen, Hexu (57219131523); Han, Junwei (24450644400); Zhang, Dingwen (56024706800); Li, Kuan (57222365001)",56102195500; 57219131523; 24450644400; 56024706800; 57222365001,Identifying Children With Autism Spectrum Disorder via Transformer-Based Representation Learning From Dynamic Facial Cues,2025,IEEE Transactions on Affective Computing,16,1,,83,97,14.0,1,10.1109/TAFFC.2024.3412032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001073052&doi=10.1109%2fTAFFC.2024.3412032&partnerID=40&md5=d0875c33044d66592f4fff652832294d,"Recognizing autism spectrum disorder (ASD) has faced great challenges due to insufficient professional clinicians and complex procedures. Automated data-driven ASD recognition models can reduce the subjectivity and physician dependency of traditional evaluation methods. Facial data, which can encode important perceptual and social behaviors, have emerged in ASD research to explore novel biomarkers for screening, diagnosing, and treating ASD. However, existing research mainly focuses on extracting low-level hand-crafted facial features for analysis and classification. Determining how to learn discriminative deep representations from dynamic facial data for computational model construction remains an unresolved challenge. In this study, we propose an ASD recognition model based on facial videos to fill the lack of temporal correlation learning of facial features. First, we utilize a vision transformer to extract frame-based global facial features. Then, we use a Longformer to establish the correlation of facial features over time. In the experiment, we recruited 146 subjects between 2 and 8 years of age to record their facial videos under a computer-based eye-tracking experiment and 76 subjects to conduct a smartphone-based experiment. Quantitative comparisons have shown the effectiveness and reliability of the proposed model. Furthermore, we have confirmed the correlation between facial and eye-tracking modalities in visual attention. © 2024 IEEE.",Autism spectrum disorder (ASD); eye-tracking; longformer; representation learning; spatiotemporal facial cues; vision transformer (ViT); visual attention,Behavioral research; Biological systems; Diseases; Face recognition; Learning systems; Smartphones; Autism spectrum disorder; Autism spectrum disorders; Biological system modeling; Brain modeling; Eye-tracking; Facial feature; Gaze-tracking; Longformer; Representation learning; Spatiotemporal facial cue; Video; Vision transformer; Visual Attention; Eye tracking,Article,Final,,Scopus,2-s2.0-105001073052,Movies / Media
Liu J.; Li K.; Li S.; Liu S.; Wang C.; Huang S.; Tu Y.; Wang B.; Zhang P.; Luo Y.; Sun G.; Chen T.,"Liu, Jiakang (58117438900); Li, Kai (57210170184); Li, Shuwu (57215545668); Liu, Shangjun (59676409300); Wang, Chen (58117605300); Huang, Shouqiang (58117772700); Tu, Yuting (59520340900); Wang, Bo (59521002100); Zhang, Pengpeng (59676225300); Luo, Yuntian (59677337900); Sun, Guanqun (57468923600); Chen, Tong (56680358800)",58117438900; 57210170184; 57215545668; 59676409300; 58117605300; 58117772700; 59520340900; 59521002100; 59676225300; 59677337900; 57468923600; 56680358800,A new method for identifying and evaluating depressive disorders in young people based on cognitive neurocomputing: an exploratory study,2025,Frontiers in Computational Neuroscience,19,,1555416,,,,0,10.3389/fncom.2025.1555416,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000542677&doi=10.3389%2ffncom.2025.1555416&partnerID=40&md5=fa50d0d475c44f19cb2d720f5c9a8527,"Background: Depressive disorders are one of the most common mental disorders among young people. However, there is still a lack of objective means to identify and evaluate young people with depressive disorders quickly. Cognitive impairment is one of the core characteristics of depressive disorders, which is of great value in the identification and evaluation of young people with depressive disorders. Methods: This study proposes a new method for identifying and evaluating depressive disorders in young people based on cognitive neurocomputing. The method evaluates cognitive impairments such as reduced attention, executive dysfunction, and slowed information processing speed that may exist in the youth depressive disorder population through an independently designed digital evaluation paradigm. It also mines digital biomarkers that can effectively identify these cognitive impairments. A total of 50 young patients with depressive disorders and 47 healthy controls were included in this study to validate the method’s identification and evaluation capability. Results: The differences analysis results showed that the digital biomarkers of cognitive function on attention, executive function, and information processing speed extracted in this study were significantly different between young depressive disorder patients and healthy controls. Through stepwise regression analysis, four digital biomarkers of cognitive function were finally screened. The area under the curve for them to jointly distinguish patients with depressive disorders from healthy controls was 0.927. Conclusion: This new method rapidly characterizes and quantifies cognitive impairment in young people with depressive disorders. It provides a new way for organizations, such as schools, to quickly identify and evaluate the population of young people with depressive disorders based on human-computer interaction. Copyright © 2025 Liu, Li, Li, Liu, Wang, Huang, Tu, Wang, Zhang, Luo, Sun and Chen.",cognitive function; cognitive impairment; depressive disorders; digital biomarkers; evaluation; identification; youth,Regression analysis; Cognitive functions; Cognitive impairment; Depressive disorder; Digital biomarker; Evaluation; Healthy controls; Identification; Neurocomputing; Young peoples; Youth; adult; algorithm; Article; cognition; cognitive computing; cognitive defect; cognitive neurocomputing; controlled study; cornea reflex; decision making; depression; executive function; exploratory research; eye movement; female; gaze; human; human computer interaction; human experiment; information processing; logistic regression analysis; male; Patient Health Questionnaire 9; processing speed; signal processing; young adult; Human computer interaction,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-86000542677,Movies / Media
Jiang Y.; Li K.; Liang Y.; Chen D.; Tan M.; Li Y.,"Jiang, Ya (59252313600); Li, Kendi (57213520244); Liang, Yuankai (59499281500); Chen, Di (57219335426); Tan, Mingkui (22837202600); Li, Yuanqing (55936283000)",59252313600; 57213520244; 59499281500; 57219335426; 22837202600; 55936283000,Daily Assistance for Amyotrophic Lateral Sclerosis Patients Based on a Wearable Multimodal Brain-Computer Interface Mouse,2025,IEEE Transactions on Neural Systems and Rehabilitation Engineering,33,,,150,161,11.0,0,10.1109/TNSRE.2024.3520984,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213940697&doi=10.1109%2fTNSRE.2024.3520984&partnerID=40&md5=cee2ac0d5aff624c7f25efe24c7d9665,"Amyotrophic lateral sclerosis (ALS) is a chronic, progressive neurodegenerative disease that mainly causes damage to upper and lower motor neurons. This leads to a progressive deterioration in the voluntary mobility of the upper and lower extremities in ALS patients, which underscores the pressing need for an assistance system to facilitate communication and body movement without relying on neuromuscular function. In this paper, we developed a daily assistance system for ALS patients based on a wearable multimodal brain-computer interface (BCI) mouse. The system comprises two subsystems: a mouse system assisting the upper extremity and a wheelchair system based on the mouse system assisting the lower extremity. By wearing a BCI headband, ALS patients can control a computer cursor on the screen with slight head rotation and eye blinking, and further operate a computer and drive a wheelchair with specially designed graphical user interfaces (GUIs). We designed operating tasks that simulate daily needs and invited ALS patients to perform the tasks. In total, 15 patients with upper extremity limitations performed the mouse system task and 9 patients with lower extremity mobility issues performed the wheelchair system task. To our satisfaction, all the participants fully accomplished the tasks and average accuracies of 83.9% and 87.0% for the two tasks were achieved. Furthermore, workload evaluation using NASA Task Load Index (NASA-TLX) revealed that the participants experienced a low workload when using the system. The experimental results demonstrate that the proposed system provides ALS patients with effective daily assistance and shows promising long-term application prospects.  © 2024 The Authors.",Amyotrophic lateral sclerosis (ALS); brain-computer interface (BCI); daily assistance; multimodal; wearable device,Electrotherapeutics; Eye controlled devices; Graphical user interfaces; Neurodegenerative diseases; Wearable computers; hydrogel; insulin pump; Amyotrophic lateral sclerose; Amyotrophic lateral sclerosis; Assistance system; Brain-computer interface; Daily assistance; Lower extremity; Multi-modal; Neurodegenerative; Upper-extremity; Wearable devices; accuracy; adult; aged; amyotrophic lateral sclerosis; anxiety; Article; blinking; body movement; case report; clinical article; degenerative disease; electroencephalography; electromyography; electrooculography; eye movement; fatigue; female; human; human experiment; Internet; male; middle aged; motoneuron; mouse; muscle strength; neuromuscular function; nonhuman; robotics; upper limb; visual stimulation; workload; Wheelchairs,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85213940697,Movies / Media
Jeong S.H.; Kim S.H.; Park C.W.; Lee H.S.; Lee P.H.; Kim Y.J.; Sohn Y.H.; Jeong Y.; Chung S.J.,"Jeong, Seong Ho (59733269500); Kim, Su Hong (57205162347); Park, Chan Wook (57202991106); Lee, Hye Sun (59658307600); Lee, Phil Hyu (35201338900); Kim, Yun Joong (57225051704); Sohn, Young H. (7201971250); Jeong, Yong (59414033900); Chung, Seok Jong (57222480778)",59733269500; 57205162347; 57202991106; 59658307600; 35201338900; 57225051704; 7201971250; 59414033900; 57222480778,Association of Striatal Dopaminergic Depletion and Cerebral Perfusion With Cognition in Brain-First and Body-First Parkinson's Disease,2025,Clinical Nuclear Medicine,,,,,,,0,10.1097/RLU.0000000000005922,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009748033&doi=10.1097%2fRLU.0000000000005922&partnerID=40&md5=d14f7e5b7322e6de95026122575fb20a,"Purpose: We aimed to investigate whether the patterns of striatal subregional dopamine loss and cerebral perfusion alterations differed between the 2 types of Parkinson's disease (PD) (ie, brain-first and body-first PD) and had an impact on cognitive prognosis in PD. Patients and Methods: This retrospective study reviewed the data of newly diagnosed patients with PD who underwent dual-phase dopamine transporter (DAT) scans in tertiary medical centers. We classified the patients into 2 groups based on the rapid eye movement sleep behavior disorder (RBD) screening questionnaire: PD with RBD (body-first PD) and PD without RBD (brain-first PD) groups. Then, we investigated intergroup differences in subregional DAT availability, regional cerebral perfusion, and the rates of dementia conversion. Results: After adjusting for confounding variables, the body-first group exhibited lower DAT availability in the anterior putamen than the brain-first group (β=-0.10, SE=0.04, P=0.044). In comparative analyses of regional cerebral perfusion, the body-first group exhibited lower regional perfusion in the bilateral parieto-occipital area and left cerebellum than the brain-first group, and vice versa in the brainstem, left hippocampus, right pallidum, bilateral thalamus, and ventral diencephalon. The dementia conversion rate was significantly higher in the body-first group (HR=1.78, P=0.027) than in the brain-first group, which was largely mediated by DAT availability in the anterior putamen and parieto-occipital cerebral perfusion in mediation analyses. Conclusions: This study demonstrated that the patterns of striatal subregional dopamine depletion and regional cerebral perfusion differed between the brain-first and body-first PD subtypes, and these differences largely mediated inter-subtype differences in cognitive outcome.  © 2025 Wolters Kluwer Health, Inc.",body-first; brain-first; cerebral perfusion; Parkinson's disease; prognosis; REM sleep behavior disorder,,Article,Article in press,,Scopus,2-s2.0-105009748033,Movies / Media
Yang L.; Lu L.,"Yang, Liwen (59402511200); Lu, Lingmei (58628494400)",59402511200; 58628494400,Anti-saccade can be used as a screening tool for early cognitive impairment: a correlation study based on anti-saccade parameters and cognitive function,2025,Psychogeriatrics,25,1,e13215,,,,0,10.1111/psyg.13215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208579200&doi=10.1111%2fpsyg.13215&partnerID=40&md5=717a6cce7a2a4397adf9658c7bd1676d,"Background: Eye movement tasks, especially anti-saccade tasks, have been used to assess cognitive function in patients with neuropsychiatric disorders. Although it has been shown that individuals with cognitive impairment perform worse on anti-saccades tasks, there is a lack of systematic evaluation of the sensitivity of parameters of anti-saccades to assess different subtypes of cognitive impairment. Methods: A total of 158 participants were enrolled in this study, consisting of 66 men and 92 women, with an average age of 50.2 ± 10 years. The comparison of pro-saccade reaction time, anti-saccade reaction time, and error rates in the saccade task between individuals with cognitive impairments and a normal group was conducted. Furthermore, we systematically analyzed the correlations between the performance in neurological function tests (Mini-Mental State Examination (MMSE), Montreal Cognitive Assessment (MoCA), Stroop) and these anti-saccade parameters. Especially, the correlation between these parameters and cognitive function in different domains of the MoCA task were also evaluated. Results: The pro-saccade reaction time, anti-saccade reaction time and error rate were negatively correlated with the MMSE and MoCA scores (P < 0.001), and positively correlated with the time used in Stroop tasks. Among them, the error rate had the strongest correlation with the performance of MMSE, MoCA and Stroop tasks (MoCA: P < 0.0001, r2 = −0.608; MMSE: P < 0.0001, r2 = −0.344; Stroop: P < 0.0001, r2 = 0.455). Among the seven cognitive domains examined by the MoCA task, error rates had relatively high correlations with visuospatial/executive (P < 0.0001, r2 = −0.4660) and delayed recall (P < 0.0001, r2 = −0.4228) compared to naming, language (P = 0.0004, r2 = −0.0788), attention (P = 0.0004, r2 = −0.0780), abstraction (P < 0.0001, r2 = −0.1515), orientation (P < 0.0001, r2 = −0.1075). Moreover, pro-saccade reaction time, anti-saccade reaction time and error rate of people with high MoCA scores were significantly higher than those of people with low MoCA scores, which can be used to identify people with mild cognitive impairment. Conclusions: Our study's results provide valuable clinical evidence supporting the effectiveness of anti-saccades in assessing cognitive impairment, which is beneficial for screening and timely clinical intervention in individuals with specific cognitive impairment. © 2024 The Author(s). Psychogeriatrics published by John Wiley & Sons Australia, Ltd on behalf of Japanese Psychogeriatric Society.",anti-saccade; cognitive impairment; error rates; reaction time,Adult; Aged; Cognition; Cognitive Dysfunction; Female; Humans; Male; Mental Status and Dementia Tests; Middle Aged; Neuropsychological Tests; Reaction Time; Saccades; adult; anti saccade task; Article; attention; cognition; cognitive defect; comparative study; controlled study; correlational study; female; human; language; major clinical study; male; Mini Mental State Examination; Montreal cognitive assessment; reaction time; saccadic eye movement; screening; Stroop test; task performance; aged; cognition; dementia assessment; diagnosis; middle aged; neuropsychological assessment; physiology; reaction time,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85208579200,Movies / Media
Watanabe M.; Hirota M.; Takigawa R.; Kato K.; Ikeda Y.,"Watanabe, Maki (58752864100); Hirota, Masakazu (56763499400); Takigawa, Ryusei (57300211100); Kato, Kanako (55773343600); Ikeda, Yuka (55774161500)",58752864100; 56763499400; 57300211100; 55773343600; 55774161500,Objective Evaluation of Relationship Between Tear Film Stability and Visual Fatigue,2025,Clinical Optometry,17,,,175,183,8.0,0,10.2147/OPTO.S522320,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010596027&doi=10.2147%2fOPTO.S522320&partnerID=40&md5=c27de7380f8ff5e5f8f7c454a2726385,"Purpose: To investigate the relationship between tear film stability and visual fatigue using two objective measurements: the non-invasive tear film break-up time (NI-BUT) and the binocular fusion maintenance (BFM) test. Methods: Eleven young adult volunteers (age [mean ± standard deviation], 20.7 ± 1.4 years) participated in this study. The NI-BUT was determined using the distortion of the mire ring. BFM was assessed by measuring the transmittance of liquid crystals placed in front of the subject’s non-dominant eye when binocular fusion was broken, and non-dominant eye was shifted to heterophoric. The volunteers were administered the NI-BUT and BFM before and after a 30-minute visual task. Results: NI-BUT (pre vs post: 9.12 ± 1.00 s vs 5.69 ± 3.11 s) was significantly shorter in the post-visual task than in the pre-visual task (P = 0.011). BFM (0.95 ± 0.09 vs 0.75 ± 0.16) was significantly lower in the post-visual task than in the pre-visual task (P = 0.012). The change in NI-BUT was significantly and positively correlated with the change in BFM (R2 = 0.385, P = 0.042). Conclusion: These objective findings support the association between tear film stability and visual fatigue. Plain Language Summary: Although subjective questionnaire studies have reported that eye dryness is associated with increased eye fatigue, objective evidence remains insufficient. In this study, we investigated the relationship between eye dryness and eye fatigue using objective measurements and found a correlation between them. These findings strengthen previous research and suggest the importance of preventing eye fatigue by maintaining proper tear film stability. © 2025 Watanabe et al. This work is published and licensed by Dove Medical Press Limited.",binocular fusion; binocular vision; eye movements; tear film; visual fatigue,,Article,Final,,Scopus,2-s2.0-105010596027,Movies / Media
Cinetto S.; Blini E.; Zangrossi A.; Corbetta M.; Zorzi M.,"Cinetto, Sebastiano (59979328600); Blini, Elvio (56304623100); Zangrossi, Andrea (56968075100); Corbetta, Maurizio (7003824365); Zorzi, Marco (7102431895)",59979328600; 56304623100; 56968075100; 7003824365; 7102431895,Spatial regularities in a closed-loop audiovisual search task bias subsequent free-viewing behavior,2025,Psychonomic Bulletin and Review,,,,,,,0,10.3758/s13423-025-02703-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009937030&doi=10.3758%2fs13423-025-02703-8&partnerID=40&md5=65c25ca734bfb96a9d517c61428e36c3,"Statistical learning of spatial regularities during visual search leads to prioritization of target-rich locations. The resulting attentional bias may subsequently affect orienting and search behavior in similar tasks but its transfer to free viewing has not been demonstrated. We exploited a novel closed-loop paradigm where human observers searched for invisible target locations on a screen only guided by real-time auditory feedback conveying gaze-target distance. Unbeknownst to participants, location probability was biased towards one hemifield. Free viewing during rest, free image viewing, and spatial judgments were assessed before and after the search task. Search performance systematically improved and peaked in the biased hemifield, showing the unfolding of statistical learning. Importantly, the spatial bias transferred to both free-viewing conditions in terms of mean horizontal fixation position, while it did not transfer to spatial judgments. Exploratory results suggest that search performance was influenced by participants’ viewing pattern, whereas transfer was modulated by pre-existing (natural) spatial biases. Our results demonstrate that task-based statistical learning transfers to ecological scenarios, paving the way for future research and clinical applications aimed at ameliorating pathological spatial biases. © The Author(s) 2025.",Eye movements and visual attention; Free viewing; Spatial attention; Statistical learning,,Article,Article in press,,Scopus,2-s2.0-105009937030,Movies / Media
Musikoyo A.; Rayment A.E.; Watson P.,"Musikoyo, Agnes (59929413300); Rayment, Andrew E. (59930303800); Watson, Poppy (55340167900)",59929413300; 59930303800; 55340167900,The role of motivation in delayed disengagement from threat in anxiety,2025,Cognition and Emotion,,,,,,,0,10.1080/02699931.2025.2514625,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007289893&doi=10.1080%2f02699931.2025.2514625&partnerID=40&md5=e1c43619ce161969d80a124860e06fb6,"The idea that highly anxious individuals have difficulty disengaging attention from threat is widely accepted, yet empirical support is limited. The term “difficulty” implies an involuntary delay in disengagement, but this has not been rigorously tested. Across three pre-registered experiments, we examined disengagement using different stimuli and protocols. Emotional and neutral images appeared at fixation, and healthy participants varying in self-reported anxiety were required to respond to a target elsewhere on the screen. Disengagement time was measured using eye-tracking (Experiment 1) and manual response times (Experiments 2 and 3). Motivation to disengage was manipulated by punishing slow responses (Exp. 1) or rewarding fast responses (Exp. 2 and 3). In Experiment 1, participants were slower to move their eyes away from a stimulus predicting punishment, regardless of anxiety level, even when delay resulted in an aversive noise. In Experiments 2 and 3, spider and snake images (but not emotional faces) slowed disengagement, but this effect was unrelated to anxiety or motivation. Disengagement bias scores showed poor reliability across all studies. These findings cast doubt on the idea that anxiety is reliably associated with impaired attentional disengagement from threat. © 2025 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",Anxiety; attentional bias; delayed disengagement; motivation; threat,adult; anxiety; article; attention; attentional bias; attentional disengagement; controlled study; diagnosis; disengagement; eye tracking; eye-tracking technology; female; human; human experiment; male; motivation; noise; normal human; punishment; reaction time; reliability; role playing; snake; spider,Article,Article in press,,Scopus,2-s2.0-105007289893,Movies / Media
Bast N.; Polzer L.; Raji N.; Schnettler L.; Kleber S.; Lemler C.; Kitzerow-Cleven J.; Kim Z.; Schaer M.; Freitag C.M.,"Bast, Nico (57200231841); Polzer, Leonie (57212460992); Raji, Naisan (58976611100); Schnettler, Luisa (59807951600); Kleber, Solvejg (58976072700); Lemler, Christian (58976742300); Kitzerow-Cleven, Janina (58976349700); Kim, Ziyon (56816522000); Schaer, Marie (57205783996); Freitag, Christine M. (7003868143)",57200231841; 57212460992; 58976611100; 59807951600; 58976072700; 58976742300; 58976349700; 56816522000; 57205783996; 7003868143,Early intervention increases reactive joint attention in autistic preschoolers with arousal regulation as mediator,2025,European Child and Adolescent Psychiatry,,,,,,,1,10.1007/s00787-025-02738-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004676769&doi=10.1007%2fs00787-025-02738-1&partnerID=40&md5=b9daeeaabf0266796123e788837e6f0a,"Reactive joint attention (RJA) describes shared attention on a cued target. This key ability is attenuated in autistic compared to non-autistic preschoolers with low cognitive ability, and thus trained during early intervention. We evaluated the development of RJA in matched autistic preschoolers within a randomized controlled trial of the naturalistic developmental behavioral intervention A-FFIP (intervention [n = 32] versus early intervention-as-usual [EIAU, n = 28]), which is further compared to non-autistic preschoolers (n = 52). A screen-based eye-tracking paradigm assessed RJA at baseline, after 12 months (end-of-intervention, 78% retention), and after 36 months (follow-up, 44% retention). Corresponding pupil size changes were utilized to investigate arousal as a mediator in RJA group differences. Generalized linear mixed models were applied to compare RJA likelihood between groups and assessment timepoints. Across timepoints, RJA likelihood was lower in autistic versus non-autistic preschoolers (ORs = 0.07–0.27). The A-FFIP - but not the EIAU group - showed an increase in RJA likelihood at end-of-intervention (OR = 1.52) and follow-up (OR = 2.38). Across both autistic groups, an increase in RJA likelihood after 12 months predicted improved social responsiveness at 36-months follow-up (β = -1.22). A higher baseline pupil size within trials was associated with a lower RJA likelihood (β = -0.32) and mediated the autistic group difference on RJA likelihood in a causal mediation analysis. The A-FFIP early intervention increased eye-tracking derived RJA in autistic preschoolers up to two years after end of intervention, which likely cascaded on improved social responsiveness. Arousal regulation is outlined as a promising mediating mechanism. © The Author(s) 2025.",Biomarker; Eye tracking; Gaze following; NDBI; Neurodiversity; Pupillometry,,Article,Article in press,,Scopus,2-s2.0-105004676769,Movies / Media
Kim N.,"Kim, Nayeon (57216898685)",57216898685,Capturing Initial Gaze Attraction in Branded Spaces Through VR Eye-Tracking Technology,2025,International Journal of Human-Computer Interaction,41,7,,4392,4405,13.0,3,10.1080/10447318.2024.2351717,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001065027&doi=10.1080%2f10447318.2024.2351717&partnerID=40&md5=609a1618ab4d4c014536d4d154576cb3,"This paper leverages recent strides in virtual reality (VR) technology to dissect user gaze patterns and initial responses in a VR-based in-store environment, with a focus on how visual elements impact attention in Human–Computer Interaction (HCI). Specifically, this exploratory study focuses on brand-centric components such as logos and colors, while also considering individual variables such as gender and design background. Employing a mixed-methods approach, the research combines qualitative and quantitative tools. A VR-integrated eye-tracking system records how participants’ gaze behaves in a virtual retail environment. The study collects data from 50 participants in four scenarios: a control store (Case 1), introduction of the brand’s logo signage (Case 2), infusion of the brand’s primary color (Case 3), and a fusion of logo and color (Case 4). Two key eye-tracking metrics—time to first fixation (TTFF) and first fixation duration (FFD)—are harnessed to scrutinize gaze behavior across elements such as wall color, logo signage, wall display fixtures, and media screens. The research unearths statistically significant effects of visual elements on gaze behavior, with particular emphasis on TTFF and FFD. Gender disparities come to light in Cases 2, 3, and 4, affecting FFD on wall color (AOI 1) and TTFF on brand logo signage (AOI 2) in Case 2. Moreover, disparities in design background surface in Cases 1 and 3. Complementing the eye-tracking data and post-experiment interviews capture users’ initial gaze attraction and preferences, offering valuable insights into their rationale. In essence, this study underscores the transformative potential of VR technology and eye-tracking techniques in HCI and furnishes actionable insights for those seeking to elevate brand recognition and consumer engagement within immersive virtual retail settings. © 2024 Taylor & Francis Group, LLC.",branded space; Eye-tracking; in-store environment; virtual reality; visual attention,Color; Consumer behavior; Human computer interaction; Virtual reality; Branded space; Eye tracking technologies; Eye-tracking; Fixation duration; Gaze behaviours; In-store environment; Store environments; Virtual reality technology; Visual Attention; Visual elements; Eye tracking,Article,Final,,Scopus,2-s2.0-105001065027,Movies / Media
Zhou L.; Xue F.; Barton M.H.,"Zhou, Lijie (57204133157); Xue, Fei (55427842300); Barton, Matthew H. (23666509500)",57204133157; 55427842300; 23666509500,"Visual attention, brand personality and mental imagery: an eye-tracking study of virtual reality (VR) advertising design",2025,Journal of Research in Interactive Marketing,,,,,,,0,10.1108/JRIM-08-2024-0406,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004350148&doi=10.1108%2fJRIM-08-2024-0406&partnerID=40&md5=9537f5a5f4d584b90698a246009958ec,"Purpose: This study used virtual reality (VR) and screen eye-tracking systems to examine the effect of visual format and background image on visual attention, sense of presence and mental imagery in VR versus two-dimensional (2D) advertising designs. Design/methodology/approach: A 2 (visual format) × 3 (visual background) between-subjects experiment was conducted to investigate participants’ visual attention, perceived product personality, mental imagery and sense of presence, using screen and VR eye-tracking systems. Findings: Two-dimensional images with empty backgrounds drew the most attention, while VR with visual backgrounds enhanced product impressions, sense of presence and mental imagery. Sincere backgrounds moderated the link between fixations and imagery quality. Originality/value: Guided by media richness theory, this is the first interactive marketing study that utilized gaze data to analyze the connection between ad design and visual reactions in both VR and 2D settings. © 2025, Emerald Publishing Limited.",Advertising; High technology marketing; Quantitative research; Viral marketing; Visual merchandising,,Article,Article in press,,Scopus,2-s2.0-105004350148,Movies / Media
Costa L.V.; Passos A.; Zagalo N.,"Costa, Liliana Vale (57221702490); Passos, Ana (58805694800); Zagalo, Nelson (8271087400)",57221702490; 58805694800; 8271087400,Behind Two Stories to Tell: An Evaluation Study of the Camera Perspective in the Game Mutation Madness,2025,Communications in Computer and Information Science,2324 CCIS,,,40,51,11.0,0,10.1007/978-3-031-81713-7_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219171956&doi=10.1007%2f978-3-031-81713-7_3&partnerID=40&md5=3f590fca724018ccabdb37e644492aa0,"A major cinematic component in game storytelling is the camera, offering the player a perspective towards the environment. Although the camera use in game storytelling has been undoubtedly important, there has been lack of understanding of its implications in narrative comprehension and relatedness to the game world. Forty-six young adults aged between 18 and 35 were selected to participate in an A/B evaluation of an in-game cinematic scene that was shown from a first- and third-person camera perspective, aimed to assess the effect of the Point of View (POV) camera on visual attention and story comprehension in the game Mutation Madness. Participants’ self-reported evaluations of the scene were collected, together with eye-tracking recordings, suggesting that whereas the third-person camera perspective in game cinematics is suitable to show the omniscient knowledge of the story and evoke the sense of time and the agents of the story, the first-person camera perspective is used to guide the player to game events. The implications of camera use in the narrative-gameplay experience based on the POV analysis, visual attention and story comprehension are discussed. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.",Camera Perspective; Game cinematics; Storytelling; Visual attention,Camera perspectives; Cinematics; Evaluation study; Eye-tracking; First person; Game cinematic; Sense of time; Storytelling; Visual Attention; Young adults,Conference paper,Final,,Scopus,2-s2.0-85219171956,Movies / Media
Zhong W.; Xia C.; Yu L.; Li K.; Li Z.; Zhang D.; Han J.,"Zhong, Wenqi (58894179700); Xia, Chen (56102195500); Yu, Linzhi (58972053200); Li, Kuan (57222365001); Li, Zhongyu (57279071300); Zhang, Dingwen (56024706800); Han, Junwei (24450644400)",58894179700; 56102195500; 58972053200; 57222365001; 57279071300; 56024706800; 24450644400,A Learning Paradigm for Selecting Few Discriminative Stimuli in Eye-Tracking Research,2025,IEEE Transactions on Pattern Analysis and Machine Intelligence,,,,,,,0,10.1109/TPAMI.2025.3573729,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006592013&doi=10.1109%2fTPAMI.2025.3573729&partnerID=40&md5=2aa35d96165a11d82f09b0f707ef210e,"Eye-tracking is a reliable method for quantifying visual information processing and holds significant potential for group recognition, such as identifying autism spectrum disorder (ASD). However, eye-tracking research typically faces the heterogeneity of stimuli and is time-consuming due to the large number of observed stimuli. To address these issues, we first mathematically define the stimulus selection problem and introduce the concept of stimulus discrimination ability to reduce the computational complexity of the solution. Then, we construct a scanpath-based recognition model to mine the stimulus discrimination ability. Specifically, we propose cross-subject entropy and cross-subject divergence scores for quantitatively evaluating stimulus discrimination ability, effectively capturing differences in intra-group collective trends and inter-subject consistency within a group. Furthermore, we propose an iterative learning mechanism that employs stimulus-wise attention to focus on discriminative stimuli for discrimination purification. In the experiment, we construct an ASD eye-tracking dataset with diverse stimulus types and conduct extensive tests on three representative models to validate our approach. Remarkably, our method demonstrates superior performance using only 10 selected stimuli compared to models utilizing 220 stimuli. Additionally, we perform experiments on another eye-tracking task, gender prediction, to further validate our method. We believe that our approach is both simple and flexible for integration into existing models, promoting large-scale ASD screening and extending to other eye-tracking research domains. © 1979-2012 IEEE.",autism spectrum disorder (ASD); classification; discrimination; Eye-tracking; neural networks; scanpath; stimulus selection; visual attention,Autism spectrum disorder; Autism spectrum disorders; Discrimination; Discrimination ability; Eye-tracking; Learning paradigms; Neural-networks; Scan path; Stimulus selection; Visual Attention; Learning algorithms,Article,Article in press,,Scopus,2-s2.0-105006592013,Movies / Media
Seitz F.I.; Albrecht R.; von Helversen B.; Rieskamp J.; Rosner A.,"Seitz, Florian I. (57224583715); Albrecht, Rebecca (56358758200); von Helversen, Bettina (57203177455); Rieskamp, Jörg (6507866774); Rosner, Agnes (57208692837)",57224583715; 56358758200; 57203177455; 6507866774; 57208692837,Identifying similarity- and rule-based processes in quantitative judgments: A multi-method approach combining cognitive modeling and eye tracking,2025,Psychonomic Bulletin and Review,,,,,,,0,10.3758/s13423-024-02624-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218878239&doi=10.3758%2fs13423-024-02624-y&partnerID=40&md5=3ac7ac2e9307edc983016fa420c5ff78,"Quantitative judgments have been suggested to result from a mixture of similarity- and rule-based processing. People can judge an object’s criterion value based on the object’s similarity to previously experienced exemplars and based on a rule that integrates the object’s cues like a linear regression. In order to better understand these processes, the present work combines cognitive modeling and eye tracking and tests whether people who rely more on the similarity to exemplars also look more at the exemplar locations on the screen. In two eye-tracking studies, participants learned to assign each of four exemplars to a different screen corner and criterion value and then judged the criterion value of briefly presented test stimuli. Eye tracking measured participants’ gazes to the now empty exemplar locations (a phenomenon called looking-at-nothing); cognitive modeling of the test phase judgments quantified participants’ reliance on a similarity- over a rule-based process. Participants showed more similarity use and more looking-at-nothing in the study in which the cues were linked to the criterion by a multiplicative function than in the study with an additive cue-criterion link. Focusing on the study with a multiplicative environment, participants relying more on the similarity to exemplars also showed more looking-at-nothing (τ = 0.25, p =.01). Within trials, looking-at-nothing was usually directed at the one exemplar that was most similar to the test stimulus. These results show that a multi-method approach combining process tracing and cognitive modeling can provide mutually supportive insights into the processes underlying higher-order cognition. © The Author(s) 2025.",Computational modeling; Decision-making; Exemplar; Eye tracking; Judgment; Looking-at-nothing,,Article,Article in press,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85218878239,Movies / Media
Wang M.; Zhang S.; Zhou X.,"Wang, Mengrui (57195241390); Zhang, Shuting (59542933500); Zhou, Xiang (59543541300)",57195241390; 59542933500; 59543541300,Campus environments and mental restoration: eye-tracking evidence from dynamic stimuli,2025,"Engineering, Construction and Architectural Management",,,,,,,2,10.1108/ECAM-10-2024-1420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216989741&doi=10.1108%2fECAM-10-2024-1420&partnerID=40&md5=d04a80b08d297e860c7f0e1ef1aef679,"Purpose: Understanding the restorative potential of built environments is essential for promoting mental well-being. However, existing studies often rely on static image-based methods, which are inherently limited in capturing the temporal and spatial dynamics of environmental perception. These methods frequently introduce biases, such as selective framing and abrupt transitions, failing to reflect natural viewing behavior. Addressing these limitations, this study investigates the restorative qualities of campus environments using dynamic VR stimuli and eye-tracking technology. By providing continuous temporal and spatial information, dynamic VR stimuli offer a more immersive and ecologically valid approach to understanding how specific environmental features contribute to psychological restoration. Design/methodology/approach: This study investigates the restorative qualities of campus environments using VR eye-tracking technology and dynamic stimuli. Campus environments were filmed through walking sequences and paired with PRS audio prompts. About 40 university students participated in the experiment, with eye-tracking data processed using computer vision-based semantic segmentation and the concept of relative areas of interest, followed by correlation analysis with restorative quality scores. Findings: The results revealed that natural elements such as “sky,” “tree,” “waterscape” and “landscape corridor” were significantly positively correlated with the being-away and fascination dimensions, indicating their role in capturing attention and supporting psychological recovery. Conversely, architectural elements like “architectural corridor” and “building facade” were negatively correlated with the extent dimension, while “architectural open space” positively correlated, enhancing spatial perception and exploration. Originality/value: These findings underscore the importance of natural elements and open spaces in built environments while also revealing the complex influence of architectural features. The study provides valuable insights for optimizing campus design to support students’ mental health and well-being. © 2025, Emerald Publishing Limited.",Architectural environment; Campus design; Dynamic stimuli; Restorative environment; VR eye-tracking,Architectural design; Architectural environment; Built environment; Campus design; Dynamic stimuli; Eye tracking technologies; Eye-tracking; Natural elements; Restorative environment; VR eye-tracking; Well being; Semantic Segmentation,Article,Article in press,,Scopus,2-s2.0-85216989741,Movies / Media
Ishikawa M.; Smith T.J.,"Ishikawa, Mitsuhiko (57193431831); Smith, Tim J. (55568512084)",57193431831; 55568512084,Value-Driven Anticipatory Looking to Emotional Faces in 8-Month-Old Infants,2025,Emotion,,,,,,,0,10.1037/emo0001521,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001813316&doi=10.1037%2femo0001521&partnerID=40&md5=a5e8df1cbfaf004aa264ea439806d65a,"Developmental studies have adopted preferential-looking paradigms to investigate infant interest in emotional face stimuli. However, because of the attention-grabbing nature of threatening stimuli, research has reported inconsistent results regarding infants’ fixation on happy and angry faces. A recent value-based framework of social looking behavior suggested that infants’ looking behavior depends on the value of looking (i.e., the expected reward value of a specific looking behavior). Using anticipatory-looking tests alongside preferential-looking tests, we aimed to investigate whether or not infants’ looking behavior to faces is value driven. A total of thirty-two 8-month-old infants completed an eye-tracking study. In each block, two faces displaying a combination of happy, neutral, or angry expressions were repeatedly presented side-by-side on the screen. A block consisted of a preferential-looking test and four trials of an anticipatory-looking test. The results of the preferential-looking test showed longer durations of total fixation at the happy and angry faces than the neutral face. In the anticipatory-looking test, infants predictively looked at the position of the happy face compared with the positions of the neutral and angry faces. Furthermore, infants predictively looked at the position of the neutral face more than that of the angry face. A control study using inverted faces indicated that these emotion effects were not due to low-level stimulus differences. Our findings suggest that infants focus on facial stimuli that are affectively arousing regardless of their valence, while anticipatory-looking behavior depends on the value of looking. © 2025 American Psychological Association",emotional faces; eye tracking; infants; looking behavior; value,article; attention; duration; emotion; eye tracking; eye-tracking technology; female; human; infant; reward,Article,Article in press,,Scopus,2-s2.0-105001813316,Movies / Media
Ali M.; Huang P.-J.; Cardona-Rivera R.E.,"Ali, Monthir (57219362760); Huang, Po-Jui (59698689100); Cardona-Rivera, Rogelio E. (55143980500)",57219362760; 59698689100; 55143980500,World-Space Cueing: A Geometrically-Compact Modulation Technique for Subtle Gaze Direction in Head-Mounted Virtual Reality Displays,2025,"Proceedings - 2025 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality, AIxVR 2025",,,,10,18,8.0,0,10.1109/AIxVR63409.2025.00011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000283871&doi=10.1109%2fAIxVR63409.2025.00011&partnerID=40&md5=b20fae9434627749fe2693aab4b46709,"This paper presents World-space Cueing - a virtual reality (VR) gaze guidance technique for head-mounted displays (HMDs) that combines World-space modulation and eye tracking to subtly direct users' gaze to regions of interest (ROIs) within the rendered virtual environment. World-space Cueing extends two dimensional Subtle Gaze Direction (SGD) in a novel way: unlike existing SGD-based techniques, it restricts modulation to the exact dimensions of the ROI, thereby avoiding potential distortion issues introduced via screen-space modulation. We gauged the efficacy of World-space Cueing in guiding a user's gaze via an ablated VR pilot study. Our analysis centered on the average time it takes users to find an object when it is World-space Cued, versus when it is not. Based on our results, using World-space Cueing can meaningfully impact users' gaze in an HMD-based VR system with binocular eye tracking without them actively perceiving the modulation. When World-space Cueing was used, participants were able to find a cued object faster relative to a no-cue control condition. We discuss the implications of our findings and how World-space cueing can impact the design of VR experiences.  © 2025 IEEE.",Attention; Experimentation; Perception; Texturing; Virtual Reality,Binoculars; Eye tracking; Head-up displays; Virtual environments; Virtual reality; Attention; Experimentation; Eye-tracking; Gaze direction; Head mounted virtual reality; Head-mounted-displays; Modulation techniques; Region-of-interest; Regions of interest; Virtual-reality display; Helmet mounted displays,Conference paper,Final,,Scopus,2-s2.0-105000283871,Movies / Media
Ren Y.,"Ren, Yuan (59794423300)",59794423300,The Impact of Mild Depression on Evaluative Language Cognition and Social Interactive Behavior Based on Eye-Tracking Experiment,2025,International Journal of Healthcare Information Systems and Informatics,20,1,,1,15,14.0,0,10.4018/IJHISI.372899,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004546400&doi=10.4018%2fIJHISI.372899&partnerID=40&md5=e7a7db3273f549cf5567842dff7a5553,"Verbal communication with evaluative characters of different emotional valence occurs often in our daily social interaction. Generally, positive evaluative language involving praise and appreciation triggers social approach whereas negative evaluative language involving criticism and censure triggers social avoidance. Differently, individuals with depression may display distorted social behavior due to their excessive sensitivity to negative evaluative language but blunt to positive information. Based on the eye-tracking experiment, this study employs an evaluative movie watching task to investigate the influence of depression-induced negatively-biased processing for evaluative language on gaze to evaluation-givers’ eyes. The results suggest that negative self-schema in depressed individuals contributes to their excessive sensitivity to negative evaluative language, which leads to their avoidance behavior in response to social criticism. The findings have great implications for understanding social dysfunctions in individuals with depressive symptoms. © 2025 IGI Global. All rights reserved.",Attention Control; Evaluative Language; Eye Contact; Eye-Tracking; Mild Depression,Consumer behavior; Economic and social effects; Emotional intelligence; Social psychology; Attention control; Behavior-based; Emotional valences; Evaluative language; Eye-contact; Eye-tracking; Interactive behavior; Mild depression; Social interactions; Verbal communications; Social behavior,Article,Final,,Scopus,2-s2.0-105004546400,Movies / Media
Greenaway A.-M.; Hwang F.; Nasuto S.; Ho A.K.,"Greenaway, Anne-Marie (57344002200); Hwang, Faustina (55795533000); Nasuto, Slawomir (9275024700); Ho, Aileen K (7402675285)",57344002200; 55795533000; 9275024700; 7402675285,Home-Based Attentional Bias Modification with Webcam-Based Eye Tracking with Persons with Cognitive Impairment: A Feasibility Study,2025,Clinical Gerontologist,,,,,,,0,10.1080/07317115.2025.2523049,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009471754&doi=10.1080%2f07317115.2025.2523049&partnerID=40&md5=ffd5c9faf5ba5555de0222a7d620c526,"Objectives: Remotely delivered attentional bias modification (ABM) studies involving persons with cognitive impairment are lacking. Thus, the feasibility of an adapted ABM paradigm with webcam-based eye tracking was explored. Methods: Four of the eight participants recruited (males, Mage = 69 years, Alzheimer’s disease = 3, mild cognitive impairment = 1) completed up to four daily ABM sessions. Tasks comprised pre- and post-intervention depression (PHQ-9), anxiety (GAD-7), and rumination (RRS) measures, a cognitive screen (TICS) (A), affect (PANAS) (B) and dot-probe AB measures (C), and dot-probe ABM (D) (Session 1–A, B, C, D, C, and B; Sessions 2 to 4–B, D, C, and B). Results: The intervention was feasible (as defined by completion rates) and appeared beneficial in this small sample (as defined by post-intervention improvements in mood). Sessions were long, and task completion/adherence was impacted by task access/participants’ ability to complete tasks independently. Mind wandering, stimuli familiarity, and eye/fatigue were reported. Conclusions: The intervention requires further adaptation (e.g. fewer eye-tracking tasks per session). Limitations include participant self-selection/loss, a lack of control group, and that the determinants of mood change are unclear. Clinical Implications: ABM, a novel intervention, may be an effective mood-disorder treatment for individuals with cognitive impairment. © 2025 The Author(s). Published with license by Taylor & Francis Group, LLC.",Alzheimer’s disease; anxiety; attentional bias modification; depression; rumination; webcam eye-tracking,,Article,Article in press,,Scopus,2-s2.0-105009471754,Movies / Media
Kodama N.; Takahashi S.; Tsuji M.; Kawase Y.; Naruse S.; Urakami K.,"Kodama, Naoki (16175277300); Takahashi, Sou (60001970300); Tsuji, Masazumi (60000604100); Kawase, Yuji (60001970400); Naruse, Satoshi (57224308838); Urakami, Katsuya (55250770200)",16175277300; 60001970300; 60000604100; 60001970400; 57224308838; 55250770200,Possibility of screening for mild cognitive impairment via an eye tracking-based cognitive scale,2025,Frontiers in Aging,6,,1532550,,,,0,10.3389/fragi.2025.1532550,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010936132&doi=10.3389%2ffragi.2025.1532550&partnerID=40&md5=379362c5f9a17cb8f937a8963f48733a,"Introduction: The Montreal Cognitive Assessment (MoCA) is widely used as a screening test for mild cognitive impairment (MCI). However, the MoCA takes approximately 15 min to administer and evaluate by skilled examiners, such as medical professionals. This study assessed whether an eye tracking-based cognitive scale using virtual reality (VR) was accurate and efficient to screen for MCI. Methods: This study included 143 patients. The Virtual Reality-Based Cognitive Function Examination (VR-E) was used with all participants to evaluate their memory, judgment, spatial cognition, calculation, and language function. Results: Significant differences were observed in all cognitive domains of memory, judgment, spatial cognition, calculation, and language function between the Alzheimer’s disease (AD), MCI, and older healthy control (HC) groups. The area under the curve value of the VR-E score for the HC and MCI groups was 0.857, and that for the AD and MCI groups was 0.870. The correlation coefficient between the MMSE and VR-E scores was 0.566 (p < 0.001), and that between the Japanese version of the MoCA (MoCA-J) and VR-E scores was 0.648 (p < 0.001), which indicated a moderate correlation in both comparisons. Conclusion: The VR-E had the same diagnostic performance results as the MoCA-J, thus the VR-E has potential for use in screening patients for MCI. Copyright © 2025 Kodama, Takahashi, Tsuji, Kawase, Naruse and Urakami.",Alzheimer’s disease; eye tracking-based cognitive scale; mild cognitive impairment; screening; virtual reality,,Article,Final,,Scopus,2-s2.0-105010936132,Movies / Media
Chan A.; Harkinish-Murray Z.I.; Colmone S.; Orens J.E.; Thomas S.; Albanese N.; McCabe K.; Freitas R.; Bailey S.P.; Ramdhari R.L.; Verrengia M.T.; Siddiqui K.F.; Lopez O.E.; DeFelice S.; Mukherji B.R.; Neuwirth L.S.,"Chan, Anders (59729676400); Harkinish-Murray, Zachary I. (59729987500); Colmone, Sabrina (59729987600); Orens, Jessica E. (57886803800); Thomas, Sharon (59730294200); Albanese, Nicole (59730142700); McCabe, Katherine (57203872340); Freitas, Rui (59729357500); Bailey, Stephanie P. (59729517500); Ramdhari, Ravi L. (57219878171); Verrengia, Michael T. (57885417600); Siddiqui, Kainaat F. (59729517600); Lopez, Oscar E. (57217235792); DeFelice, Stacey (59730142800); Mukherji, Basabi Runi (7005882610); Neuwirth, Lorenz S. (26423874200)",59729676400; 59729987500; 59729987600; 57886803800; 59730294200; 59730142700; 57203872340; 59729357500; 59729517500; 57219878171; 57885417600; 59729517600; 57217235792; 59730142800; 7005882610; 26423874200,Visual attentional differences in psychology students with and without disabilities: a pilot study assessing the flanker task for prescriptive visual accommodative technologies,2025,Frontiers in Psychology,16,,1484536,,,,0,10.3389/fpsyg.2025.1484536,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002229152&doi=10.3389%2ffpsyg.2025.1484536&partnerID=40&md5=56ba61362852366a20bacafd3294f0dc,"Introduction: The percentage of college students with disabilities has been growing and has doubled in the last two decades; thus, students with disabilities are pursuing college degrees in increasing numbers. Unfortunately, this population growth has not been matched with growth in available accommodative technologies in institutions of higher learning. Colleges and universities often do not have resources to fund and provide specific accommodative technology and support for this steadily increasing population. What is worse is that there is also a lag in emergent assessment and screening tools which are required to match student disabilities with appropriate accommodative technologies, resulting in a mismatch between student needs with appropriate accommodative technologies. The present pilot study was conducted with students with a range of disabilities, such as learning disabilities, emotional or psychiatric conditions, orthopedic or mobility impairments, attention-deficit disorder/attention-deficit hyperactivity disorder, health impairments (HI), and multiple disabilities, which were assessed using a Flanker Task, specifically to determine how sensitive it was in detecting differences in their visual attention performance. This information could be used to predict whether the student would benefit from specific accommodative technologies. Materials and methods: Undergraduate psychology students with and without disabilities volunteered to participate in a triple-blind study that sought to investigate whether their visual attention performance on a 10-min Flanker Task could be used to predict which students might benefit from visual accommodative technologies. The first experiment was used as a negative control to assess whether environmental distractions could interfere with participant visual attention. The second experiment compared the Flanker Task performance of students with and without disabilities in a controlled Neuropsychology Laboratory sound-attenuated environment. The third experiment evaluated the cumulative records for percent (%) accuracy and reaction times (RTs) for students with and without disabilities to examine patterns in visual attentional performance. The fourth experiment disaggregated the students with disabilities and examined their patterns in visual attentional performance. Results: The results showed the Flanker Task was sensitive in detecting differences in students’ visual attention performance between noisy and controlled environments differentiated students with and without disabilities. Furthermore, when students with disabilities were aggregated, their Flanker Task cumulative records were sensitive in detecting shifts in their visual attention behavior patterns. Lastly, the Flanker Task cumulative records were also sensitive in detecting disaggregated students with disability differences in their visual attention performance. Conclusion: The pilot study proved promising that a 10-min Flanker Task can be used as an effective screening tool to match students with disabilities with appropriate accommodative technologies based on their visual attentional abilities. This type of screening tool is easy to create, has minimal cost, and can be implemented quickly. This provides colleges and universities with an easy approach to assessing the needs of students with disabilities and tailoring appropriate assistive technologies. Copyright © 2025 Chan, Harkinish-Murray, Colmone, Orens, Thomas, Albanese, McCabe, Freitas, Bailey, Ramdhari, Verrengia, Siddiqui, Lopez, DeFelice, Mukherji and Neuwirth.",Gazepoint eye tracking; pilot study; students with a disability; undergraduate psychology students; visual accommodative technologies; visual attention; visual distractions; visual eye tracking,,Article,Final,,Scopus,2-s2.0-105002229152,Movies / Media
Jaisle E.M.; Musser E.D.; Yon M.; Garcia S.; Piergies A.M.H.; Miller M.,"Jaisle, Emma M. (57329623100); Musser, Erica D. (6507032453); Yon, Maylinn (59976204900); Garcia, Susana (59975855600); Piergies, Antonia M. H. (57204159656); Miller, Meghan (57192265289)",57329623100; 6507032453; 59976204900; 59975855600; 57204159656; 57192265289,Do Infant Heart Rate Variability and Visual Attention Predict Autism and Concerns for ADHD?,2025,Journal of Attention Disorders,,,1.08705E+16,,,,0,10.1177/10870547251345539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009767328&doi=10.1177%2f10870547251345539&partnerID=40&md5=2c8e259a02a5f329e396faa9e5ece4af,"Objective: Investigate whether patterns of heart rate variability (indexed via respiratory sinus arrhythmia) and visual attention at 12 to 18 months of age predict elevated ADHD symptoms, autism, or neither during the preschool period. Method: Ninety infants 12 to 18 months of age (M = 17.27, SD = 1.93; 36 females; 82.2% non-Hispanic) participated in a split-screen eye-tracking task of dynamic social and non-social moving objects. Respiratory sinus arrhythmia was derived from heart rate data collected at baseline and during the task condition. Between 24 and 65 months of age (M = 38.22, SD = 11.14), participants were evaluated and classified into one of three outcome groups: ADHD Concerns (n = 21), Autism (n = 12), or Comparison (i.e., non-Autism/non-ADHD Concerns; n = 57). Results: The ADHD Concerns group exhibited significantly less whole-screen looking time (t(76) = −2.98, p = .004, d = 0.82) and spent a significantly lower proportion of time attending to the social portion of the stimulus (t(76) = −2.53, p = .01, d = 0.67) than the Comparison group. Respiratory sinus arrhythmia reactivity moderated the association between proportion of time spent looking at the social portion of the stimulus in infancy and ADHD symptoms during the preschool period (b = 0.004, 95% CI [0.0001, 0.01], t(89) = 2.11, p = .04), such that greater quantity/intensity of ADHD symptoms was associated with a smaller proportion of look time to the social portion of the stimulus for infants engaging in HRV withdrawal, but not HRV augmentation. Hypotheses focused on autism were not supported. Conclusions: Infants demonstrate distinct patterns of visual attention predictive of elevated ADHD symptoms in the preschool period. Heart rate variability may also demonstrate predictive utility in the context of early ADHD when examined in relation to social attention, but not independently. © The Author(s) 2025",ADHD; autism; self-regulation; visual attention,,Article,Article in press,,Scopus,2-s2.0-105009767328,Movies / Media
Zheng Y.; Zhao X.; Yang Y.; Wang J.; Pi Z.; Li X.,"Zheng, Yan (57495489000); Zhao, Xin (57195590517); Yang, Yuan (59196686100); Wang, Jiayu (59694510500); Pi, Zhongling (56704731200); Li, Xiying (8567859100)",57495489000; 57195590517; 59196686100; 59694510500; 56704731200; 8567859100,Investigating behavioral patterns of high- and low-performers in learning by teaching with educational videos,2025,Active Learning in Higher Education,,,1.46979E+16,,,,0,10.1177/14697874241305944,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004474860&doi=10.1177%2f14697874241305944&partnerID=40&md5=0bf25a2e4043f726af04bf9cbf103153,"Learning by teaching is an increasingly popular strategy in educational videos, designed to foster active learning. However, the relationship between instructional behaviors and learners’ performance in this context remains underexplored. This study employed a combination of eye-tracking and screen recording techniques to examine how learners’ behaviors while preparing for teaching through video viewing and engaging in subsequent teaching are associated with their own learning performance. The participants were 100 undergraduate students (86 females and 14 males) randomly recruited from a Chinese university, organized into 50 dyads. They engaged in face-to-face interaction, including viewing educational videos to prepare for teaching and subsequent teaching. Correlational analyses indicated that viewing behaviors, such as self-monitoring and rewinding during video viewing, were positively associated with the effectiveness of the learning by teaching strategy. Additionally, instructional behaviors involving elaboration, focused attention on instructional content, and interaction with students were positively correlated with enhanced learning performance. Lag sequential analysis and independent samples t-tests revealed that, compared to low-performers, high-performers were more likely to engage in behavioral sequences such as rewinding and clarifying during video viewing, as well as actively querying, providing feedback, adjusting teaching activities, and elaborating during instruction. Our findings on learners’ behaviors while preparing for teaching through video viewing and engaging in subsequent teaching provided practical insight for the learning by teaching strategy in video lectures to promote active learning. Educational practitioners are encouraged to create opportunities that foster effective learning and teaching interactions identified in this study, and to implement targeted support interventions to enhance the effectiveness of the learning by teaching strategy in educational videos. © The Author(s) 2025.",behavioral patterns; educational videos; learning by teaching; learning performance; learning strategies,,Article,Article in press,,Scopus,2-s2.0-105004474860,Movies / Media
Mateu-Salat M.; Stanton-Yonge N.; Santaló F.S.; Vela J.I.; Cascajosa J.D.; Pérez E.S.; Rego-Lorca D.; Chico A.,"Mateu-Salat, Manel (57218166790); Stanton-Yonge, Nicole (59481790400); Santaló, Frederic Sampedro (56079540900); Vela, José Ignacio (23476171100); Cascajosa, Jesús Díaz (59380166900); Pérez, Eva Safont (59482305700); Rego-Lorca, Daniela (57217289999); Chico, Ana (6701361445)",57218166790; 59481790400; 56079540900; 23476171100; 59380166900; 59482305700; 57217289999; 6701361445,Retinal Microperimetry as a Novel Tool for Early Detection of Subclinical Cognitive Dysfunction and Brain Damage in Type 1 Diabetes: A Pilot Study,2025,"Endocrinology, Diabetes and Metabolism",8,1,e70018,,,,0,10.1002/edm2.70018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212707197&doi=10.1002%2fedm2.70018&partnerID=40&md5=f5525b63e7dbdff0766e3623eea866d7,"Context: Retinal microperimetry (MPR) is a non-invasive method that measures retinal light sensitivity (RS) and gaze fixation stability (GFS). MPR has been described as a marker of cognitive impairment in people with Type 2 diabetes, but it has never been assessed in people with Type 1 diabetes (T1D). Our group described subclinical cognitive alterations, structural brain differences, and increased levels of light chain neurofilament (NfL) in people with T1D and impaired awareness of hypoglycaemia. Objective: To measure RS and GFS using MPR in individuals with T1D and evaluate its correlation with neuropsychological assessment, plasma NfL levels and CGM-derived glucometric parameters. Secondary objectives: to evaluate the possible differences of RS and GFS in people with T1D depending on hypoglycaemia awareness. Design, Setting and Participants: Pilot observational study, people with T1D without clinical cognitive impairment, moderate–severe retinopathy or glaucoma. MPR was performed with MAIA3. Results: A total of 30 subjects were studied: 40% women, age 58 ± 11 years; T1D duration 31 ± 9 years, mild retinopathy 33%. RS was 27.5 dB (26.1–28.3) and GFS(%) 97.6% (93.5%–99.5%). We found a correlation between RS and memory alteration tests (p = 0.016) and between GFS(%) and a composite of attention and executive neuropsychological tests (p = 0.025). An inverse correlation between GFS and time below range was found. No correlation was found with NfL. Conclusion: This first exploratory study in people with T1D supports the potential utility of MPR as a screening tool for subclinical neurocognitive alterations in this population. © 2024 The Author(s). Endocrinology, Diabetes & Metabolism published by John Wiley & Sons Ltd.",brain damage; cognitive dysfunction; hypoglycaemia; microperimetry; type 1 diabetes,insulin pump; adult; Article; brain damage; case control study; clinical article; cognitive defect; controlled study; cross-sectional study; disease duration; disease severity; early diagnosis; eye tracking; female; human; hypoglycemia; insulin dependent diabetes mellitus; male; mental performance; middle aged; Mini Mental State Examination; neuropsychological assessment; non insulin dependent diabetes mellitus; non invasive procedure; observational study; perimetry; pilot study; retinal microperimetry; retinopathy,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85212707197,Movies / Media
Bleimeister I.H.; Avni I.; Granovetter M.C.; Meiri G.; Ilan M.; Michaelovski A.; Menashe I.; Behrmann M.; Dinstein I.,"Bleimeister, Isabel H. (57204772135); Avni, Inbar (57211622769); Granovetter, Michael C. (55837810100); Meiri, Gal (7801433301); Ilan, Michal (57194595484); Michaelovski, Analya (57201374867); Menashe, Idan (57220360596); Behrmann, Marlene (7005717481); Dinstein, Ilan (21742041100)",57204772135; 57211622769; 55837810100; 7801433301; 57194595484; 57201374867; 57220360596; 7005717481; 21742041100,Idiosyncratic pupil regulation in autistic children,2024,Autism Research,17,12,,2503,2513,10.0,0,10.1002/aur.3234,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205854508&doi=10.1002%2faur.3234&partnerID=40&md5=eba575cc15eaec80221b0d80fcc44002,"Recent neuroimaging and eye-tracking studies have suggested that children with autism exhibit more variable and idiosyncratic brain responses and eye movements than typically developing (TD) children. Here, we extended this research to pupillometry recordings. We successfully acquired pupillometry recordings from 111 children (74 with autism), 4.5-years-old on average, who viewed three 90 s movies, twice. We extracted their pupillary time-course for each movie, capturing their stimulus evoked pupillary responses. We then computed the correlation between the time-course of each child and those of all others in their group as well as between each autistic child and all children in the TD group. This yielded an average inter-subject correlation value per child, representing how similar their pupillary responses were to all others in their group or the comparison group. Children with autism exhibited significantly weaker inter-subject correlations than TD children in all comparisons. These differences were independent of previously reported differences in gaze inter-subject correlations and were largest in responses to a naturalistic movie containing footage of a social interaction between two TD children. The results demonstrate the utility of measuring the idiosyncrasy of pupil regulation, which can be performed with passive viewing of movies even by young children with co-occurring intellectual disability. These findings reveal that a considerable number of children with autism have significantly less stable, idiosyncratic pupil regulation than TD children, indicative of more variable, weakly regulated, underlying neural activity. © 2024 The Author(s). Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.",Autism; idiosyncrasy; inter-subject; naturalistic; pupil; pupillometry,"Autistic Disorder; Child; Child, Preschool; Eye Movements; Female; Humans; Male; Motion Pictures; Photic Stimulation; Pupil; area under the curve; Article; autism; Autism Diagnostic Observation Schedule; child; cognition; correlation analysis; diagnostic test accuracy study; DSM-5; eye movement; eye tracking; female; gaze; human; idiosyncratic drug reaction; major clinical study; male; naturalistic inquiry; preschool child; pupil; pupil diameter; pupillometry; receiver operating characteristic; school child; sensitivity and specificity; Social Responsiveness Scale; stimulus; test retest reliability; autism; movie; pathophysiology; photostimulation; physiology; procedures",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85205854508,Movies / Media
Chen H.; Du H.; Yi F.; Wang T.; Yang S.; Pan Y.; Yan H.; Liu D.; Zhou M.; Chen Y.; Zhao M.; Pi J.; Yang Y.; Fan X.; Cai X.; Qiu Z.; Zhang J.; Liu Y.; Gu W.; Wang Y.,"Chen, Huimin (55743102400); Du, Hao (58156454200); Yi, Fang (35207261200); Wang, Tingting (58910922300); Yang, Shuo (59366955200); Pan, Yuesong (57221836037); Yan, Hongyi (57189391285); Liu, Dandan (57777499900); Zhou, Mengyuan (57201937983); Chen, Yiyi (57204572435); Zhao, Mengxi (57216285130); Pi, Jingtao (57222958377); Yang, Yingying (57203133607); Fan, Xiangmin (57202047305); Cai, Xueli (57209564486); Qiu, Ziyu (59366421300); Zhang, Jipeng (57608498300); Liu, Yawei (58599016400); Gu, Wenping (7202449169); Wang, Yilong (58909618400)",55743102400; 58156454200; 35207261200; 58910922300; 59366955200; 57221836037; 57189391285; 57777499900; 57201937983; 57204572435; 57216285130; 57222958377; 57203133607; 57202047305; 57209564486; 59366421300; 57608498300; 58599016400; 7202449169; 58909618400,Artificial intelligence–assisted oculo-gait measurements for cognitive impairment in cerebral small vessel disease,2024,Alzheimer's and Dementia,20,12,,8516,8526,10.0,2,10.1002/alz.14288,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206367035&doi=10.1002%2falz.14288&partnerID=40&md5=7dec12c89f018ca5538c1d72e62d013a,"INTRODUCTION: Oculomotor and gait dysfunctions are closely associated with cognition. However, oculo-gait patterns and their correlation with cognition in cerebral small vessel disease (CSVD) remain unclear. METHODS: Patients with CSVD from a hospital-based cohort (n = 194) and individuals with presumed early CSVD from a community-based cohort (n = 319) were included. Oculo-gait patterns were measured using the artificial intelligence (AI) –assisted ‘EyeKnow’ eye-tracking and ‘ReadyGo’ motor evaluation systems. Multivariable linear and logistic regression models were employed to investigate the association between the oculo-gait parameters and cognition. RESULTS: Anti-saccade accuracy, stride velocity, and swing velocity were significantly associated with cognition in both patients and community dwellers with CSVD, and could identify cognitive impairment in CSVD with moderate accuracy (area under the curve [AUC]: hospital cohort, 0.787; community cohort, 0.810) after adjusting for age and education. DISCUSSION: The evaluation of oculo-gait features (anti-saccade accuracy, stride velocity, and swing velocity) may help screen cognitive impairment in CSVD. Highlights: Oculo-gait features (lower anti-saccade accuracy, stride velocity, and swing velocity) were associated with cognitive impairment in cerebral small vessel disease (CSVD). Logistic model integrating the oculo-gait features, age, and education level moderately distinguished cognitive status in CSVD. Artificial intelligence–assisted oculomotor and gait measurements provide quick and accurate evaluation in hospital and community settings. © 2024 The Author(s). Alzheimer's & Dementia published by Wiley Periodicals LLC on behalf of Alzheimer's Association.",artificial intelligence; cerebral small vessel disease; cognition; eye tracking; gait,Aged; Artificial Intelligence; Cerebral Small Vessel Diseases; Cognitive Dysfunction; Cohort Studies; Female; Gait; Humans; Male; Middle Aged; Neuropsychological Tests; adult; Alzheimer disease; Article; artificial intelligence; cerebrovascular disease; cognition; cognition assessment; cognitive defect; cohort analysis; controlled study; evaluation study; eye movement; eye movement disorder; eye tracking; female; fluid-attenuated inversion recovery imaging; gait; human; major clinical study; male; middle aged; mood; saccadic eye movement; susceptibility weighted imaging; T1 weighted imaging; T2 weighted imaging; walking speed; aged; complication; diagnosis; gait; neuropsychological assessment; physiology,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85206367035,Movies / Media
Coelho F.; Goncalves D.; Abreu A.M.,"Coelho, Franz (57462452200); Goncalves, Daniel (35588555000); Abreu, Ana Maria (37036768300)",57462452200; 35588555000; 37036768300,Game On: A Pilot Study of a Gamified Digital Learning Platform and Protocol,2024,ACM International Conference Proceeding Series,,,,70,77,7.0,1,10.1145/3696230.3696235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216570978&doi=10.1145%2f3696230.3696235&partnerID=40&md5=0646b01d27520de8c1154ea60380bd8a,"Gamification use in educational contexts impacts learning performance, engagement, motivation, cognition, and emotions. However, limited theoretical support, heterogeneous results, and lack of objective measures or validated questionnaires hinder gamification research. Via descriptive statistics and qualitative analysis, this pilot study aimed to assess the usability and functionality of the gamified digital learning platform, validate the study protocol through platform usage, gauge the presence of promising evidence regarding its effectiveness, and gain insights into hypotheses. A digital course was nested within different versions of a gamified digital learning platform with embedded game elements alongside a version without game elements. Eight students completed the course (6 participated in the embedded versions and 2 participated in the version without game elements), watching video lectures and doing exercises, while we measured affective states, motivation, user experience, and feedback through questionnaires. Furthermore, we assessed learning performance by analyzing the exercises and gathered webcam-based eye-tracking and facial emotion recognition data to gauge student attention and emotional states. Participants adeptly executed the established protocol, and the gamified digital learning platform (coupled with both webcam applications for eye-tracking and facial emotion recognition) functioned properly, capturing all requisite data. Due to the small sample size and limited statistical power in this pilot study, the other results across all measurements were further discussed to derive insights, formulate hypotheses, and identify potential enhancements for the forthcoming randomized control trial, which will involve a larger sample size. Our results will allow us to refine the experimental design to further evaluate the influence of gamification in a digital learning setting and thoroughly investigate, via scientific inquiry, how it can significantly enrich the field of education. Moreover, the platform’s potential for controlled experimental research augments its usefulness for diverse other studies, delving into the impact of game elements on educational outcomes. © 2024 Copyright held by the owner/author(s).",Cognition; Emotion; Gamification; Learning,Adversarial machine learning; Curricula; Emotion Recognition; Face recognition; Federated learning; Gamification; Students; Cognition; Digital-learning; Emotion; Game elements; Gamification; Learning; Learning performance; Learning platform; Pilot studies; WebCams; Contrastive Learning,Conference paper,Final,,Scopus,2-s2.0-85216570978,Movies / Media
Vingron N.; Müller Karoza L.A.; Azevedo N.; Johnson A.; Konstantinidis E.; Bamidis P.; Võ M.; Kehayia E.,"Vingron, Naomi (57210313269); Müller Karoza, Lea Alexandra (59523605100); Azevedo, Nancy (8856578500); Johnson, Aaron (7410015428); Konstantinidis, Evdokimos (24587110400); Bamidis, Panagiotis (6603398831); Võ, Melissa (9634349400); Kehayia, Eva (6701586207)",57210313269; 59523605100; 8856578500; 7410015428; 24587110400; 6603398831; 9634349400; 6701586207,How words can guide our eyes: Increasing engagement with art through audio-guided visual search in young and older adults,2024,Mental Lexicon,19,1,,78,89,11.0,0,10.1075/ml.24024.vin,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003453288&doi=10.1075%2fml.24024.vin&partnerID=40&md5=a5bcfe34dfc75264149cb8da2866a2ed,"Pursuing cognitively stimulating activities, such as engaging with art, is crucial to a healthy lifestyle. The current work simulates visits to an art museum in a laboratory setting. Using eye tracking, we explored how linguistically guided visual search may increase attention, enjoyment and retention of information when viewing art. Two groups of adults, young (under 35 years) and older (over 65 years) viewed ten paintings on a computer screen presented either with or without an accompanying audio-guide, while having their eye movements recorded. Audio-guides referred to specific areas of the painting, marked as Interest Areas (IA). Across age groups, as attested by gaze fixations, the audio-guides increased attention to these areas compared to free-viewing. Audio-guided viewing did not lead to a significantly increase over free-viewing in information recall accuracy or feelings of enjoyment and engagement. Overall, older adults did report feeling more positively about both audio-guided and free viewing than young adults. Thus, the use of audio-guides, specifically the gamification through linguistically guided visual search, may be a useful tool to promote meaningful attentional interactions with art. © John Benjamins Publishing Company.",audio-guide; eye movements; museum; visual search,,Article,Final,,Scopus,2-s2.0-105003453288,Movies / Media
Schneider B.; Sung G.,"Schneider, Bertrand (55051404100); Sung, Gahyun (57365373400)",55051404100; 57365373400,Is Seeing the Instructor’s Face or Gaze in Online Videos Helpful for Learning?,2024,Journal of Learning Analytics,11,3,,210,223,13.0,1,10.18608/jla.2024.8235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213528675&doi=10.18608%2fjla.2024.8235&partnerID=40&md5=fcd3e79838879d5c2cd803212c3d4d26,"Over the last decade, the prevalence of online learning has dramatically increased. As part of their curriculum, students are expected to spend more and more time watching videos. These videos tend to follow a widespread format: a screen recording of slides with a picture-in-picture (PiP) image of the instructor’s face. While this format is ubiquitous, there is mixed evidence that it supports student learning. In this paper, we explore alternative formats for designing educational videos. Based on prior work showing the significance of joint attention for social learning, we create instructional videos augmented with the instructor’s gaze and/or face. Testing these formats in a semester-long online course using a 2x2 experimental design, we found that showing the instructor’s face had no significant effect on learning, while adding the instructor’s eye-tracking data to the video promoted conceptual understanding of the material. Mediation analysis showed that joint visual attention played a significant mediatory role for learning. We conclude by discussing the implications of these findings and formulate recommendations for designing learning videos. © 2024, Society for Learning Analytics Research (SOLAR). All rights reserved.",instructor presence; multimodal learning analytics; Online learning; shared gaze visualizations,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85213528675,Movies / Media
Bovo R.; Abreu S.; Ahuja K.; Gonzalez E.J.; Cheng L.-T.; Gonzalez-Franco M.,"Bovo, Riccardo (57204780702); Abreu, Steven (58161118700); Ahuja, Karan (57192554466); Gonzalez, Eric J (25642446000); Cheng, Li-Te (59781918900); Gonzalez-Franco, Mar (36080251200)",57204780702; 58161118700; 57192554466; 25642446000; 59781918900; 36080251200,EmBARDiment: an Embodied AI Agent for Productivity in XR,2025,"Proceedings - 2025 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2025",,,,708,717,9.0,0,10.1109/VR59515.2025.00093,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002726792&doi=10.1109%2fVR59515.2025.00093&partnerID=40&md5=f8408ebeef115f4731496a0352980270,"XR devices running chat-bots powered by Large Language Models (LLMs) have the to become always-on agents that enable much better productivity scenarios. Current screen based chat-bots do not take advantage of the the full-suite of natural inputs available in XR, including inward facing sensor data, instead they over-rely on explicit voice or text prompts, sometimes paired with multi-modal data dropped as part of the query. We propose a solution that leverages an attention framework that derives context implicitly from user actions, eye-gaze, and contextual memory within the XR environment. Our work minimizes the need for engineered explicit prompts, fostering grounded and intuitive interactions that glean user insights for the chat-bot.  © 2025 IEEE.",AI Agents; AI input; Chatbots; Multi-window; XR productivity,Bot (Internet); 'current; AI agent; AI input; Chat bots; Chatbots; Language model; Multi-modal data; Multi-Windows; Sensors data; XR productivity; Chatbots,Conference paper,Final,,Scopus,2-s2.0-105002726792,Movies / Media
Rajimehr R.; Xu H.; Farahani A.; Kornblith S.; Duncan J.; Desimone R.,"Rajimehr, Reza (6603416388); Xu, Haoran (59788758500); Farahani, Asa (57666131700); Kornblith, Simon (57214131049); Duncan, John (57211727566); Desimone, Robert (56238587200)",6603416388; 59788758500; 57666131700; 57214131049; 57211727566; 56238587200,Functional architecture of cerebral cortex during naturalistic movie watching,2024,Neuron,112,24,,4130,4.15E+06,,8,10.1016/j.neuron.2024.10.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210093546&doi=10.1016%2fj.neuron.2024.10.005&partnerID=40&md5=abb205c4eb033dc4d774d084f7a8eb22,"Characterizing the functional organization of cerebral cortex is a fundamental step in understanding how different kinds of information are processed in the brain. However, it is still unclear how these areas are organized during naturalistic visual and auditory stimulation. Here, we used high-resolution functional MRI data from 176 human subjects to map the macro-architecture of the entire cerebral cortex based on responses to a 60-min audiovisual movie stimulus. A data-driven clustering approach revealed a map of 24 functional areas/networks, each explicitly linked to a specific aspect of sensory or cognitive processing. Novel features of this map included an extended scene-selective network in the lateral prefrontal cortex, separate clusters responsive to human-object and human-human interaction, and a push-pull interaction between three executive control (domain-general) networks and domain-specific regions of the visual, auditory, and language cortex. Our cortical parcellation provides a comprehensive and unified map of functionally defined areas in the human cerebral cortex. © 2024 The Author(s)",cerebral cortex; clustering; cortical map; fMRI; Human Connectome Project; parcellation,Acoustic Stimulation; Adult; Auditory Perception; Brain Mapping; Cerebral Cortex; Female; Humans; Magnetic Resonance Imaging; Male; Motion Pictures; Photic Stimulation; Visual Perception; Young Adult; action observation network; adult; Article; auditory cortex; auditory stimulation; brain cortex; brain function; cognition; controlled study; default mode network; eye position; eye tracking; female; functional connectivity; functional magnetic resonance imaging; human; human experiment; image analysis; information processing; language processing; lateral prefrontal cortex; major clinical study; male; memory test; mirror neuron system; naturalistic movie watching; nerve cell network; normal human; phylogenetic tree; recreation; social cognition; stimulus; superior temporal sulcus; T1 weighted imaging; T2 weighted imaging; videorecording; visual cortex; visual stimulation; young adult; brain mapping; diagnostic imaging; hearing; movie; nuclear magnetic resonance imaging; photostimulation; physiology; procedures; vision,Article,Final,,Scopus,2-s2.0-85210093546,Movies / Media
Xu Y.; Zhang C.; Pan B.; Yuan Q.; Zhang X.,"Xu, Ying (58286264600); Zhang, Chi (58313979700); Pan, Baobao (58287352900); Yuan, Qing (58286979800); Zhang, Xu (55139219300)",58286264600; 58313979700; 58287352900; 58286979800; 55139219300,A portable and efficient dementia screening tool using eye tracking machine learning and virtual reality,2024,npj Digital Medicine,7,1,219,,,,4,10.1038/s41746-024-01206-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201805706&doi=10.1038%2fs41746-024-01206-5&partnerID=40&md5=745ba4dcdc32757decf36cd7f6a1008b,"Dementia represents a significant global health challenge, with early screening during the preclinical stage being crucial for effective management. Traditional diagnostic biomarkers for Alzheimer’s Disease, the most common form of dementia, are limited by cost and invasiveness. Mild cognitive impairment (MCI), a precursor to dementia, is currently identified through neuropsychological tests like the Montreal Cognitive Assessment (MoCA), which are not suitable for large-scale screening. Eye-tracking technology, capturing and quantifying eye movements related to cognitive behavior, has emerged as a promising tool for cognitive assessment. Subtle changes in eye movements could serve as early indicators of MCI. However, the interpretation of eye-tracking data is challenging. This study introduced a dementia screening tool, VR Eye-tracking Cognitive Assessment (VECA), using eye-tracking technology, machine learning, and virtual reality (VR) to offer a non-invasive, efficient alternative capable of large-scale deployment. VECA was conducted with 201 participants from Shenzhen Baoan Chronic Hospital, utilizing eye-tracking data captured via VR headsets to predict MoCA scores and classify cognitive impairment across different educational backgrounds. The support vector regression model employed demonstrated a high correlation (0.9) with MoCA scores, significantly outperforming baseline models. Furthermore, it established optimal cut-off scores for identifying cognitive impairment with notable sensitivity (88.5%) and specificity (83%). This study underscores VECA’s potential as a portable, efficient tool for early dementia screening, highlighting the benefits of integrating eye-tracking technology, machine learning, and VR in cognitive health assessments. © The Author(s) 2024.",,Diagnosis; Electronic health record; Neurodegenerative diseases; Virtualization; Cognitive assessments; Cognitive impairment; Dementia screenings; Eye tracking technologies; Eye-tracking; Global health; Machine-learning; Screening tool; Tracking data; Tracking machines; adult; aged; area under the curve; Article; cognition; controlled study; dementia; diagnostic test accuracy study; education; eye tracking; eye-tracking technology; female; human; machine learning; major clinical study; male; mean absolute error; memory; recall; root mean squared error; Shapley additive explanation; support vector machine; virtual reality; Support vector regression,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85201805706,Movies / Media
El Hmimdi A.E.; Palpanas T.; Kapoula Z.,"El Hmimdi, Alae Eddine (57302842800); Palpanas, Themis (55888054500); Kapoula, Zoi (7003732501)",57302842800; 55888054500; 7003732501,Efficient diagnostic classification of diverse pathologies through contextual eye movement data analysis with a novel hybrid architecture,2024,Scientific Reports,14,1,21461,,,,0,10.1038/s41598-024-68056-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204167441&doi=10.1038%2fs41598-024-68056-9&partnerID=40&md5=969096788a3c1449231dd3e48d69f925,"The analysis of eye movements has proven valuable for understanding brain function and the neuropathology of various disorders. This research aims to utilize eye movement data analysis as a screening tool for differentiation between eight different groups of pathologies, including scholar, neurologic, and postural disorders. Leveraging a dataset from 20 clinical centers, all employing AIDEAL and REMOBI eye movement technologies this study extends prior research by considering a multi-annotation setting, incorporating information from recordings from saccade and vergence eye movement tests, and using contextual information (e.g. target signals and latency of the eye movement relative to the target and confidence level of the quality of eye movement recording) to improve accuracy while reducing noise interference. Additionally, we introduce a novel hybrid architecture that combines the weight-sharing feature of convolution layers with the long-range capabilities of the transformer architecture to improve model efficiency and reduce the computation cost by a factor of 3.36, while still being competitive in terms of macro F1 score. Evaluated on two diverse datasets, our method demonstrates promising results, the most powerful discrimination being Attention & Neurologic; with a macro F1 score of up to 78.8%; disorder. The results indicate the effectiveness of our approach in classifying eye movement data from different pathologies and different clinical centers accurately, thus enabling the creation of an assistant tool in the future. © The Author(s) 2024.",Classification; Deep learning; Eye movement; Hybrid; Saccade; Time serie; Vergence,Data Analysis; Eye Movements; Humans; Male; Nervous System Diseases; Saccades; adult; article; brain function; classification; controlled study; deep learning; eye movement; eye-tracking technology; female; human; hybrid; latent period; male; neuropathology; noise; oculography; saccadic eye movement; data analysis; diagnosis; neurologic disease; physiology; saccadic eye movement,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85204167441,Movies / Media
Paromov D.; Moïn-Darbari K.; Cedras A.M.; Maheu M.; Bacon B.-A.; Champoux F.,"Paromov, Daniel (58647458100); Moïn-Darbari, Karina (55850005700); Cedras, Assan Mary (57226861774); Maheu, Maxime (56913211400); Bacon, Benoit-Antoine (7101743729); Champoux, François (14630156600)",58647458100; 55850005700; 57226861774; 56913211400; 7101743729; 14630156600,Protocol for exploring the relationship between sound localization and the representation of the body in space,2024,STAR Protocols,5,4,103412,,,,1,10.1016/j.xpro.2024.103412,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207782412&doi=10.1016%2fj.xpro.2024.103412&partnerID=40&md5=fb2d3094dd9892deb1cf5e6d9c006dd2,"The influence of multisensory integration on spatial hearing has received more attention in recent years. Notably, incongruent sensory inputs can bias auditory spatial processing. Here, we present a protocol for producing an illusory shift in the localization of a sound source by inducing an unconscious shift in the representation of the body in space. We describe steps for screening participants and evaluating vestibular and hearing abilities. We then detail procedures for performing auditory localization tasks both with and without disorientation. For complete details on the use and execution of this protocol, please refer to Paromov et al.1 © 2024 The Author(s)",cognitive neuroscience; health sciences; neuroscience,Acoustic Stimulation; Adult; Female; Humans; Male; Sound Localization; Space Perception; anatomical concepts; Article; auditory processing disorder; auditory stimulation; evoked brain stem auditory response; eye tracking; female; handedness; head movement; hearing; hearing impairment; human; male; otoscopy; range of motion; sensory stimulation; sound detection; spatial analysis; spatial behavior; traumatic brain injury; tympanometry; unconsciousness; vestibular function; adult; depth perception; physiology; procedures,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85207782412,Movies / Media
Göktaş O.; Ergin E.; Tuğcu K.C.,"Göktaş, Osman (6603078281); Ergin, Engin (59134152200); Tuğcu, Kadir Cem (59667549400)",6603078281; 59134152200; 59667549400,Determining the relationship between visual interest measured with eye tracking technology and furniture purchasing preferences and examining its usability as a demand forecasting method; [Göz izleme teknolojisi ile ölçülen görsel ilginin mobilya satın alma tercihleri ile ilişkisinin belirlenerek talep tahmini yöntemi olarak kullanılabilirliğinin incelenmesi],2024,Furniture and Wooden Material Research Journal,7,2,,204,219,15.0,1,10.33725/mamad.1556670,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219740470&doi=10.33725%2fmamad.1556670&partnerID=40&md5=c9b538aac0f2faff778a74649f4abfa1,"The functionality and aesthetics of the furniture used to furnish spaces also have an impact on user interest. Products that attract more attention from users are expected to achieve sales success in parallel. Concordantly, evaluating furniture products in terms of visual interest is important in terms of affordability. Therefore, it is a necessity to conduct consumer research using contemporary technologies such as eye tracking in the furniture sector. Eye tracking technology, a tool of neuromarketing, provides insights into users' visual interests. This study aimed to assess the usability of eye tracking as a demand forecasting method in the furniture industry during the production decision-making phase. Participants wore eye-tracking devices while viewing furniture images on a computer screen, allowing researchers to determine their visual interest levels. The determined visual interest levels were compared with the sales data of the furniture. Additionally, a survey was conducted to obtain information about some demographic characteristics of the participant group. The findings revealed that eye tracking technology was partially favorable in predicting demand for the furniture industry. © 2024, DergiPark. All rights reserved.",Demand Forecasting; Eye Tracking Technology; Furniture; Neuromarketing,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85219740470,Movies / Media
Cui M.; Jin Z.; Wang Y.; Jiang J.; Peng S.; Wei Q.; Zhang S.; Tuo Q.; Xie J.; Leng H.; Wang H.; Zhao Y.; Lei P.; Xu J.; Wang K.; Zhang J.; Jiang Y.; Ding D.; Xie F.; Yu J.; Dong Q.,"Cui, Mei (36777059000); Jin, Zishuo (59408397700); Wang, Yingzhe (57204734163); Jiang, Jiwei (57203416534); Peng, Sisi (57192203338); Wei, Qiang (55845721400); Zhang, Shuting (54969473300); Tuo, Qingzhang (55839195900); Xie, Junchao (56452025200); Leng, Haixia (57210416325); Wang, Hongxing (55236344200); Zhao, Yanxin (55361357100); Lei, Peng (37026284800); Xu, Jun (57196733433); Wang, Kai (56959592900); Zhang, Junjian (57206849062); Jiang, Yanfeng (57204719011); Ding, Ding (35331652300); Xie, Fang (57193095745); Yu, Jintai (24068133900); Dong, Qiang (7201748905)",36777059000; 59408397700; 57204734163; 57203416534; 57192203338; 55845721400; 54969473300; 55839195900; 56452025200; 57210416325; 55236344200; 55361357100; 37026284800; 57196733433; 56959592900; 57206849062; 57204719011; 35331652300; 57193095745; 24068133900; 7201748905,"Imaging, biomarkers, and vascular cognitive impairment in China: Rationale and design for the VICA study",2024,Alzheimer's and Dementia,20,12,,8898,8909,11.0,0,10.1002/alz.14352,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208934177&doi=10.1002%2falz.14352&partnerID=40&md5=06db3b6ca7309b3b9394bb91fc918346,"INTRODUCTION: Vascular cognitive impairment (VCI) is highly heterogeneous, with unclear pathogenesis. Individuals with vascular risk factors (VRF), cerebral small vessel disease (CSVD), and stroke are all at risk of developing VCI. To address the growing challenges posed by VCI, the “Vascular, Imaging and Cognition Association of China” (VICA) was established. METHODS: VICA aims to recruit 10,000 participants, including 2000 with VRF, 3000 with CSVD, and 5000 stroke patients, to form a nationwide multicenter cohort. The study integrates clinical, neuroimaging, and multi-omics data to better understand VCI heterogeneity, improve disease prediction, and ensure timely diagnosis. RESULTS: VICA has screened 2045 eligible VRF participants from six communities in Wuhan, Shanghai, and Taizhou, along with 602 CSVD and 1269 stroke patients from 135 hospitals nationwide. Baseline enrollment and follow-up work are still ongoing. DISCUSSION: Establishing a high-quality longitudinal cohort is crucial for understanding VCI pathogenesis and developing novel markers for early screening and diagnosis. Highlights: Establish a large-scale prospective longitudinal cohort comprising 10,000 participants, focusing on the high-risk population of vascular cognitive impairment (VCI) in China. Establish a nationwide three-tier medical network, make full use of resources, and achieve extensive enrollment of patients with cerebral small vessel disease and stroke patients. Utilize multimodal imaging and biomarkers to lay the foundation for constructing more-precise risk models. Introduce eye movement and gait analysis as new methods for assessing cognitive function. Use positron emission tomography to further investigate the interaction between vascular factors and neurodegeneration. © 2024 The Author(s). Alzheimer's & Dementia published by Wiley Periodicals LLC on behalf of Alzheimer's Association.",China; cohort; community; CSVD; hospital; imaging; omics research; stroke; vascular cognitive impairment,"Aged; Biomarkers; Cerebral Small Vessel Diseases; China; Cognitive Dysfunction; Cohort Studies; Dementia, Vascular; Female; Humans; Longitudinal Studies; Male; Middle Aged; Neuroimaging; Prospective Studies; Risk Factors; Stroke; biological marker; adult; aged; arterial spin labeling; Article; cerebrovascular disease; China; cognitive defect; cohort analysis; diagnostic accuracy; diffusion tensor imaging; diffusion weighted imaging; female; fluid-attenuated inversion recovery imaging; follow up; functional magnetic resonance imaging; genomics; human; longitudinal study; magnetic resonance angiography; major clinical study; male; metabonomics; multiomics; neuroimaging; neuropsychological assessment; nuclear magnetic resonance imaging; observational study; positron emission tomography; prediction; stroke patient; susceptibility weighted imaging; T1 weighted imaging; T2 weighted imaging; cerebrovascular accident; clinical trial; complication; diagnosis; diagnostic imaging; middle aged; multicenter study; multiinfarct dementia; prospective study; risk factor",Article,Final,,Scopus,2-s2.0-85208934177,Movies / Media
Perkovich E.; Laakman A.; Mire S.; Yoshida H.,"Perkovich, E. (58001687100); Laakman, A. (55989887300); Mire, S. (55239921300); Yoshida, H. (7408720088)",58001687100; 55989887300; 55239921300; 7408720088,Conducting head-mounted eye-tracking research with young children with autism and children with increased likelihood of later autism diagnosis,2024,Journal of Neurodevelopmental Disorders,16,1,7,,,,4,10.1186/s11689-024-09524-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186841190&doi=10.1186%2fs11689-024-09524-1&partnerID=40&md5=e1bf1ae31fa1096e001d0a5a5aaf18ab,"Background: Over the past years, researchers have been using head-mounted eye-tracking systems to study young children’s gaze behaviors in everyday activities through which children learn about the world. This method has great potential to further our understanding of how millisecond-level gaze behaviors create multisensory experiences and fluctuate around social environments. While this line of work can yield insight into early perceptual experiences and potential learning mechanisms, the majority of the work is exclusively conducted with typically-developing children. Sensory sensitivities, social-communication difficulties, and challenging behaviors (e.g., disruption, elopement) are common among children with developmental disorders, and they may represent potential methodological challenges for collecting high-quality data. Results: In this paper, we describe our research practices of using head-mounted eye trackers with 41 autistic children and 17 children with increased likelihood of later autism diagnosis without auditory or visual impairments, including those who are minimally or nonspeaking and/or have intellectual disabilities. The success rate in gathering data among children with autism was 92.68%. 3 of 41 children failed to complete the play-session, resulting in an 86.36% success rate among 1–4-year-olds and a 100.00% success rate among 5–8-year-olds. 1 of 17 children with increased likelihood of later autism diagnosis failed to complete the play-session, resulting in a success rate of 94.11%. There were numerous “challenging” behaviors relevant to the method. The most common challenging behaviors included taking the eye-tracking device off, elopement, and becoming distressed. Overall, among children with autism, 88.8% of 1–4-year-olds and 29.4% of 5–8-year-olds exhibited at least one challenging behavior. Conclusions: Research capitalizing on this methodology has the potential to reveal early, socially-mediated gaze behaviors that are relevant for autism screening, diagnosis, and intervention purposes. We hope that our efforts in documenting our study methodology will help researchers and clinicians effectively study early naturally-occuring gaze behaviors of children during non-experimental contexts across the spectrum and other developmental disabilities using head-mounted eye-tracking. Ultimately, such applications may increase the generalizability of results, better reflect the diversity of individual characteristics, and offer new ways in which this method can contribute to the field. © The Author(s) 2024.",Attention; Autism spectrum disorder; Eye-tracking; Social behavior; Social cognition,"Autistic Disorder; Child; Child, Preschool; Communication; Compulsive Behavior; Eye-Tracking Technology; Humans; Intellectual Disability; aggression; Article; attention; autism; automutilation; behavior disorder; child; child behavior; clinical article; clinician; eye tracking; feeding behavior; female; human; intellectual impairment; language; male; Mullen scales of early learning; Peabody picture vocabulary test; play therapy; practice guideline; preschool child; school child; social behavior; social cognition; vocabulary; complication; compulsion; eye-tracking technology; intellectual impairment; interpersonal communication",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85186841190,Movies / Media
Wong S.W.; Kopecny L.; Crowe P.,"Wong, Shing Wai (55344576600); Kopecny, Lloyd (57947770900); Crowe, Philip (35511035700)",55344576600; 57947770900; 35511035700,Interventions to prevent visual fatigue during robotic surgery,2024,Journal of Robotic Surgery,18,1,396,,,,2,10.1007/s11701-024-02154-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208741668&doi=10.1007%2fs11701-024-02154-8&partnerID=40&md5=efe7d9cc59e47bb2893ee41ce3b8149d,"The robotic surgeon is at risk of visual fatigue from prolonged viewing of the video display resulting in digital eye strain and use of the three-dimensional binoculars resulting in accommodative stress. Symptoms of digital eye strain include blurred vision, dry eyes, eyestrain, neck and back ache, diplopia, light sensitivity, and headaches. Vergence or accommodation-related symptoms include blurred near or distance vision, difficulty refocusing, and diplopia. Beneficial ergonomic interventions to manage digital eye strain during robotic surgery include appropriate lighting, improved neck positioning, optimal screen positioning, improved image parameters, screen breaks, optimising environmental factors, and eye exercises. Correction of refractive error, use of lubricating eye drops, and blink efficiency training to induce motor memory have been shown to be effective in reducing visual fatigue. Vergence–accommodation mismatch can be reduced with slower movement of the camera, screen breaks, and correction of refractive error. Robotic surgeons should adopt these simple and non-invasive interventions to minimise visual fatigue. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.",fatigue; robotic surgery; vision,"Accommodation, Ocular; Asthenopia; Ergonomics; Humans; Robotic Surgical Procedures; Binoculars; Ergonomics; Eye movements; Noninvasive medical procedures; Robot vision; Transplantation (surgical); artificial tear; eye drops; Dry eye; Ergonomic intervention; Eye strain; Image parameters; Refractive error; Robotics surgery; Vergences; Video display; Vision difficulties; Visual fatigue; accommodation; backache; binocular convergence; blink rate; blurred vision; diplopia; dry eye; environmental factor; ergonomics; eyelid reflex; fatigue; headache; high fidelity simulation training; human; illumination; laparoscopy; multidimensional scaling; physiological stress; refraction error; Review; robot assisted surgery; surgeon; trapezius muscle; visual fatigue; adverse event; asthenopia; etiology; physiology; prevention and control; procedures; Robotic surgery",Review,Final,,Scopus,2-s2.0-85208741668,Movies / Media
Chaston A.; Thomas N.; Niechwiej-Szwedo E.,"Chaston, Andrew (59314196500); Thomas, Naomi (59315579200); Niechwiej-Szwedo, Ewa (8592081600)",59314196500; 59315579200; 8592081600,Evaluation of motor capacity and neuromotor control for tapping and sliding movements reveals differences in visuomotor control,2024,Human Movement Science,98,,103279,,,,0,10.1016/j.humov.2024.103279,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203131241&doi=10.1016%2fj.humov.2024.103279&partnerID=40&md5=34ac9b6263a2a93277dd1b8894b0af56,"The Fitts' task is a simple and effective method for evaluating motor capacity that can be used to reveal detailed aspects of visuomotor control when hand and eye kinematics are recorded simultaneously. With advances in technology, the classical Fitts' reciprocal tapping task was modified for use with digitizer tablets and computer screens that require sliding rather than tapping hand movements, which may rely on different visuomotor control strategies. Given the ubiquity of digital devices and touchscreens that often require execution of sliding movements, it is important to compare the underlying visuomotor control and eye-hand coordination involved in reciprocal sliding and tapping movements, which was the aim of the current study. Twelve young adults performed both tasks while their hand and eye movements were recorded. Results revealed motor capacity was significantly higher (p < 0.0001, d = 2.67) in the tapping task (19.62 ± 5.89 bits/s) compared to the sliding task (7.87 ± 2.02 bits/s). Examining hand kinematics showed the deceleration interval was significantly longer in the sliding compared to the tapping task at the lowest task difficulty (ID 2.28: 0.160 s ± 0.026 vs 0.129 s ± 0.017; p < 0.01), which was exacerbated as task difficulty increased (ID 6.97: 0.355 s ± 0.059 vs 0.226 s ± 0.020, p < 0.0001), indicating greater reliance on visual feedback during the sliding task. Examining temporal eye-hand coordination pattern showed that hand movement initiation tended to precede eye movement in both tasks. Overall, the results of this study provide a comprehensive examination of eye and hand kinematics demonstrating salient differences in visuomotor control between tapping and sliding movements. The findings also reveal a novel insight into the temporal pattern of eye-hand coordination for reciprocal tapping and sliding movements, which is in contrast to previous studies that examined discrete (rather than reciprocal) target-directed pointing movements where the eyes typically precede the hand by approximately 100 ms. In conclusion, the current study revealed substantial differences between the two tasks, one major finding being the sliding movements were performed slower compared to parabolic tapping hand movements, which may have implications for designing interactive digital devices and assessment of eye-hand coordination. © 2024 The Authors",Eye movements; Eye-hand coordination; Fitts' task; Kinematics; Visuomotor control,Adult; Biomechanical Phenomena; Eye Movements; Female; Hand; Humans; Male; Movement; Psychomotor Performance; Reaction Time; Young Adult; adult; arm; Article; deceleration; eye hand coordination; eye movement; fatigue; female; hand movement; human; human experiment; kinematics; male; motoneuron; motor performance; movement time; normal human; pupil diameter; shoulder; visual acuity; visual feedback; visuomotor coordination; young adult; biomechanics; hand; movement (physiology); physiology; psychomotor performance; reaction time,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85203131241,Movies / Media
Suslow T.; Hoepfel D.; Kersting A.; Bodenschatz C.M.,"Suslow, Thomas (7006752467); Hoepfel, Dennis (57485404100); Kersting, Anette (7004545968); Bodenschatz, Charlott Maria (57201664569)",7006752467; 57485404100; 7004545968; 57201664569,Depressive symptoms and visual attention to others’ eyes in healthy individuals,2024,BMC Psychiatry,24,1,184,,,,2,10.1186/s12888-024-05633-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186901642&doi=10.1186%2fs12888-024-05633-2&partnerID=40&md5=3d2f9240ee030dc67f3a498ac7ceaa2a,"Background: Eye contact is a fundamental part of social interaction. In clinical studies, it has been observed that patients suffering from depression make less eye contact during interviews than healthy individuals, which could be a factor contributing to their social functioning impairments. Similarly, results from mood induction studies with healthy persons indicate that attention to the eyes diminishes as a function of sad mood. The present screen-based eye-tracking study examined whether depressive symptoms in healthy individuals are associated with reduced visual attention to other persons’ direct gaze during free viewing. Methods: Gaze behavior of 44 individuals with depressive symptoms and 49 individuals with no depressive symptoms was analyzed in a free viewing task. Grouping was based on the Beck Depression Inventory using the cut-off proposed by Hautzinger et al. (2006). Participants saw pairs of faces with direct gaze showing emotional or neutral expressions. One-half of the face pairs was shown without face masks, whereas the other half was presented with face masks. Participants’ dwell times and first fixation durations were analyzed. Results: In case of unmasked facial expressions, participants with depressive symptoms looked shorter at the eyes compared to individuals without symptoms across all expression conditions. No group difference in first fixation duration on the eyes of masked and unmasked faces was observed. Individuals with depressive symptoms dwelled longer on the mouth region of unmasked faces. For masked faces, no significant group differences in dwell time on the eyes were found. Moreover, when specifically examining dwell time on the eyes of faces with an emotional expression there were also no significant differences between groups. Overall, participants gazed significantly longer at the eyes in masked compared to unmasked faces. Conclusions: For faces without mask, our results suggest that depressiveness in healthy individuals goes along with less visual attention to other persons’ eyes but not with less visual attention to others’ faces. When factors come into play that generally amplify the attention directed to the eyes such as face masks or emotions then no relationship between depressiveness and visual attention to the eyes can be established. © The Author(s) 2024.",Depressive symptoms; Eye-tracking; Eyes; Face mask; Facial expression; Gaze behavior; Visual attention,Affect; Depression; Emotions; Health Status; Humans; Psychiatric Status Rating Scales; adult; Article; Beck Depression Inventory; clinical article; controlled study; depression; differential emotions scale; emotion; eye movement; eye tracking; facial expression; female; gaze; human; human experiment; male; normal human; scoring system; social interaction; task performance; visual attention; young adult; affect; health status; psychological rating scale,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85186901642,Movies / Media
Monéger J.; Noiret N.,"Monéger, Jean (57808738700); Noiret, Nicolas (56222724100)",57808738700; 56222724100,Looking through a glass onion: Exploring the validity of eye-tracking technology in capturing self-directed attention,2024,Journal of Research in Personality,113,,104538,,,,1,10.1016/j.jrp.2024.104538,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203276069&doi=10.1016%2fj.jrp.2024.104538&partnerID=40&md5=3953430e8428040a80e94f1e815faba3,"Self-directed attention is a central aspect in most psychological models in the clinical, social and personality literature. However, precise measures of self-directed attention are lacking. Building on recent methodological developments, the present study (N=104) provides an exploratory assessment of the Incidental Mirror Exposure (I-ME) paradigm combining reflective screens with eye-tracking devices to measure self-directed attention. Personality traits associated with self-directed attention were assessed to evaluate the theoretical validity of basic oculometric measures. We additionally suggest a novel measure of self-focus integrating time spent looking at the self-reflecting area of the screen and depth of the gaze looking through the screen. Results underline the relevance of eye-tracking paradigms to capture maladaptive self-directed attention such as social anxiety, vulnerable narcissism, and self-absorption. © 2024 The Author(s)",Eye-tracker; Personality; Psychometrics; Self-consciousness; Self-directed attention,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85203276069,Movies / Media
Freitag C.W.; Behrens M.; Bielitzki R.; Al-Nosairy K.O.; Stolle F.H.; Prabhakaran G.T.; Beyer R.; Thieme H.; Hoffmann M.B.; Schega L.,"Freitag, Constantin W. (58740492000); Behrens, Martin (36695862000); Bielitzki, Robert (57222222720); Al-Nosairy, Khaldoon O. (57204701582); Stolle, Francie H. (58740148400); Prabhakaran, Gokulraj T. (57196018246); Beyer, Rosalie (58740838100); Thieme, Hagen (7005637197); Hoffmann, Michael B. (7402353459); Schega, Lutz (8525221300)",58740492000; 36695862000; 57222222720; 57204701582; 58740148400; 57196018246; 58740838100; 7005637197; 7402353459; 8525221300,Gaze behavior in open-angle glaucoma patients during visuo-cognitive-motor tasks: a cross-sectional study,2024,Scientific Reports,14,1,20978,,,,0,10.1038/s41598-024-70987-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203319619&doi=10.1038%2fs41598-024-70987-2&partnerID=40&md5=283bb5df7cfeef5be10c408c75a2e2f2,"This study investigated gaze behavior during visuo-cognitive-motor tasks with a change of movement direction in glaucoma patients and healthy controls. Nineteen glaucoma patients (10 females, 9 males) and 30 healthy sighted controls (17 females, 13 males) participated in this cross-sectional study. Participants performed two visuo-cognitive-motor tasks with a change of movement direction: (i) the “Speed-Court-Test” that involved stepping on different sensors in response to a visual sign displayed on either a large or small screen (165″ and 55″, respectively); (ii) the “Trail-Walking-Test” that required walking to 15 cones labeled with numbers (1–8) or letters (A-G) in an alternately ascending order. During these tasks, the time needed for completing each task was determined and the gaze behavior (e.g., saccade duration, fixation duration) was recorded via eye tracking. Data were analyzed with repeated measures analyses of covariance (ANCOVA; GROUP × SCREEN) and one-way ANCOVA. No differences between groups were found for the time needed to complete the tasks. However, during the “Trail-Walking-Test”, the fixation duration was longer for glaucoma patients than for controls (p = 0.016, ηp2 = 0.131). Furthermore, during the “Speed-Court-Test”, there was a screen size effect. Irrespective of group, saccade amplitudes were lower (p < 0.001, ηp2 = 0.242) and fixation durations were higher (p = 0.021, ηp2 = 0.125) for the small screen. Fixation durations were longer in glaucoma patients during the cognitively demanding “Trail-Walking-Test”, which might indicate a strategy to compensate for their visual impairment. © The Author(s) 2024.",,"Adult; Aged; Case-Control Studies; Cognition; Cross-Sectional Studies; Eye Movements; Female; Fixation, Ocular; Glaucoma, Open-Angle; Humans; Male; Middle Aged; Psychomotor Performance; adult; aged; case control study; cognition; cross-sectional study; eye fixation; eye movement; female; human; male; middle aged; open angle glaucoma; pathophysiology; physiology; psychomotor performance",Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85203319619,Movies / Media
Tan X.; Jia H.; Song J.,"Tan, Xueqing (57637962200); Jia, Huimin (59438386800); Song, Jun (57199024858)",57637962200; 59438386800; 57199024858,The focus effect of sentence comprehension in natural reading of Chinese and English: a meta-analysis based on eye movement studies,2024,Current Psychology,43,46,,35438,35452,14.0,0,10.1007/s12144-024-06957-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210385240&doi=10.1007%2fs12144-024-06957-8&partnerID=40&md5=e0a1bf245bcf1680d137fc6e4717545b,"This meta-analysis examined how focus guided the allocation of readers’ attention in natural reading of Chinese and English. After the literature search and screening, 15 eye movement experimental studies were obtained, and Cohen’s d effect values (consisting of 480 subjects and 552 groups of experimental materials) were extracted to explore the focus effect values of various eye movement indicators and to explore whether they are regulated by focus marking and language type. The indices of first fixation time (FFD), gaze time (GD), total fixation time (TFD), and regression path reading time were selected for analysis. The findings were as follows: (1) In the focus condition, the first fixation time, the gaze duration, and the total fixation time of focus in the target region were shorter. They had medium effects. (2) Subgroup analysis revealed no difference in the effect size between Chinese and English media or in the types of focus marking (focus particles vs. syntactic markers). Additionally, the focus effect was not adjusted. This indicates that focus, as a special grammatical marker, has the characteristics of stably attracting attention resources and promoting information processing faster, regardless of language type and marking method. Nonetheless, it is easily influenced by other language rules. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",Eye movement; Focus particles; Focus-marked words; Meta-analysis; Natural reading,,Article,Final,,Scopus,2-s2.0-85210385240,Movies / Media
Vaníček O.; Krejčová L.; Hůla M.; Potyszová K.; Klapilová K.; Bártová K.,"Vaníček, Ondřej (57203978393); Krejčová, Lucie (55785827400); Hůla, Martin (57190061600); Potyszová, Kateřina (57223183095); Klapilová, Kateřina (53871473700); Bártová, Klára (57112478800)",57203978393; 55785827400; 57190061600; 57223183095; 53871473700; 57112478800,Eye-tracking does not reveal early attention processing of sexual copulatory movement in heterosexual men and women,2024,Scientific Reports,14,1,5306,,,,0,10.1038/s41598-024-53243-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186562007&doi=10.1038%2fs41598-024-53243-5&partnerID=40&md5=f625e21e8e55a61c7fa2313a591008a2,"Men and women respond differently when presented with sexual stimuli. Men's reaction is gender-specific, and women's reaction is gender-nonspecific. This might be a result of differential cognitive processing of sexual cues, namely copulatory movement (CM), which is present in almost every dynamic erotic stimulus. A novelty eye-tracking procedure was developed to assess the saliency of short film clips containing CM or non-CM sexual activities. Results from 29 gynephilic men and 31 androphilic women showed only small and insignificant effects in attention bias and no effects in attentional capture. Our results suggest that CM is not processed differently in men and women and, therefore, is not the reason behind gender-nonspecific sexual responses in women. © The Author(s) 2024.",,Animals; Attentional Bias; Copulation; Eye-Tracking Technology; Female; Heterosexuality; Humans; Male; Sexual Behavior; animal; attentional bias; copulation; eye-tracking technology; female; heterosexuality; human; male; sexual behavior,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85186562007,Movies / Media
Li S.; Zhang D.; Li X.; Ou C.; An L.; Xu Y.; Yang W.; Zhang Y.; Cheng K.-T.,"Li, Shuhan (56123380800); Zhang, Dong (58738547400); Li, Xiaomeng (57192493244); Ou, Chubin (57188923649); An, Lin (59304631100); Xu, Yanwu (55516961100); Yang, Weihua (56070103200); Zhang, Yanchun (57208761436); Cheng, Kwang-Ting (7402997957)",56123380800; 58738547400; 57192493244; 57188923649; 59304631100; 55516961100; 56070103200; 57208761436; 7402997957,Vessel-promoted OCT to OCTA image translation by heuristic contextual constraints,2024,Medical Image Analysis,98,,103311,,,,1,10.1016/j.media.2024.103311,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202561511&doi=10.1016%2fj.media.2024.103311&partnerID=40&md5=904464e3842857682de56a5e65f2bc3b,"Optical Coherence Tomography Angiography (OCTA) is a crucial tool in the clinical screening of retinal diseases, allowing for accurate 3D imaging of blood vessels through non-invasive scanning. However, the hardware-based approach for acquiring OCTA images presents challenges due to the need for specialized sensors and expensive devices. In this paper, we introduce a novel method called TransPro, which can translate the readily available 3D Optical Coherence Tomography (OCT) images into 3D OCTA images without requiring any additional hardware modifications. Our TransPro method is primarily driven by two novel ideas that have been overlooked by prior work. The first idea is derived from a critical observation that the OCTA projection map is generated by averaging pixel values from its corresponding B-scans along the Z-axis. Hence, we introduce a hybrid architecture incorporating a 3D adversarial generative network and a novel Heuristic Contextual Guidance (HCG) module, which effectively maintains the consistency of the generated OCTA images between 3D volumes and projection maps. The second idea is to improve the vessel quality in the translated OCTA projection maps. As a result, we propose a novel Vessel Promoted Guidance (VPG) module to enhance the attention of network on retinal vessels. Experimental results on two datasets demonstrate that our TransPro outperforms state-of-the-art approaches, with relative improvements around 11.4% in MAE, 2.7% in PSNR, 2% in SSIM, 40% in VDE, and 9.1% in VDC compared to the baseline method. The code is available at: https://github.com/ustlsh/TransPro. © 2024 Elsevier B.V.",Image translation; OCT and OCTA images; OCT to OCTA translation,"Algorithms; Angiography; Heuristics; Humans; Imaging, Three-Dimensional; Retinal Diseases; Retinal Vessels; Tomography, Optical Coherence; Image enhancement; chorionic gonadotropin; Angiography images; Coherence tomography; Image translation; Optical coherence tomography and optical coherence tomography angiography image; Optical coherence tomography to optical coherence tomography angiography translation; Optical-; algorithm; Article; B scan; blood vessel; blood vessel density; capillary; controlled study; data visualization; diagnostic value; eye movement; heuristics; human; image reconstruction; morphology; optical coherence tomography; optical coherence tomography angiography; performance indicator; prediction; quantization; retina blood vessel; retina disease; signal noise ratio; three-dimensional imaging; angiography; diagnostic imaging; heuristics; procedures; retina blood vessel; Optical coherence tomography",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85202561511,Movies / Media
Yu M.; Bi C.,"Yu, Mengmeng (58261179800); Bi, Chongke (36801122300)",58261179800; 36801122300,Adaptive 360° video timeline exploration in VR environment,2024,Computers and Graphics (Pergamon),125,,104108,,,,2,10.1016/j.cag.2024.104108,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208553995&doi=10.1016%2fj.cag.2024.104108&partnerID=40&md5=14b3fccac02552d39e2cb3a95f9fd973,"Timeline control is a crucial interaction during video viewing, aiding users in quickly locating or jumping to specific points in the video playback, especially when dealing with lengthy content. 360°videos, with their ability to offer an all-encompassing view, have gradually gained popularity, providing a more immersive experience compared to videos with a single perspective. While most 360°videos are currently displayed on two-dimensional screens, the timeline design has largely remained similar to that of conventional videos. However, virtual reality (VR) headsets provide a more immersive viewing experience for 360°videos and offer additional dimensions for timeline design. In this paper, we initially explored 6 timeline design styles by varying the shape and interaction distance of the timeline, aiming to discover designs more suitable for the VR environment of 360°videos. Subsequently, we introduced an adaptive timeline display mechanism based on eye gaze sequences to optimize the timeline, addressing issues like obstructing the view and causing distractions when the timeline is consistently visible. Through two studies, we first demonstrated that in the 360°space, the three-dimensional timeline performs better in terms of usability than the two-dimensional one, and the reachable timeline has advantages in performance and experience over the distant one. Secondly, we verified that, without compromising interaction efficiency and system usability, the adaptive display timeline gained more user preference due to its accurate prediction of user timeline needs. © 2024 Elsevier Ltd",360°video; Adaptive interface; Spatial interaction; Timeline; Virtual reality,360°video; Adaptive interface; Design styles; Immersive; Spatial interaction; Timeline; Two-dimensional; Video Playback; Virtual-reality environment; Virtual-reality headsets; Virtual environments,Article,Final,,Scopus,2-s2.0-85208553995,Movies / Media
Öztürk D.; Aydoğan S.; Kök İ.; Akın Bülbül I.; Özdemir S.; Özdemir S.; Akay D.,"Öztürk, Demet (58577856200); Aydoğan, Sena (57201616522); Kök, İbrahim (57200283688); Akın Bülbül, Işık (57421376900); Özdemir, Selda (23985940600); Özdemir, Suat (23467461900); Akay, Diyar (6507100086)",58577856200; 57201616522; 57200283688; 57421376900; 23985940600; 23467461900; 6507100086,Linguistic summarization of visual attention and developmental functioning of young children with autism spectrum disorder,2024,Health Information Science and Systems,12,1,39,,,,2,10.1007/s13755-024-00297-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198735119&doi=10.1007%2fs13755-024-00297-4&partnerID=40&md5=1e87205cd1bf671e429378b56099da9f,"Diagnosing autism spectrum disorder (ASD) in children poses significant challenges due to its complex nature and impact on social communication development. While numerous data analytics techniques have been proposed for ASD evaluation, the process remains time-consuming and lacks clarity. Eye tracking (ET) data has emerged as a valuable resource for ASD risk assessment, yet existing literature predominantly focuses on predictive methods rather than descriptive techniques that offer human-friendly insights. Interpretation of ET data and Bayley scales, a widely used assessment tool, is challenging for ASD assessment of children. It should be understood clearly to perform better analytic tasks on ASD screening. Therefore, this study addresses this gap by employing linguistic summarization techniques to generate easily understandable summaries from raw ET data and Bayley scales. By integrating ET data and Bayley scores, the study aims to improve the identification of children with ASD from typically developing children (TD). Notably, this research represents one of the pioneering efforts to linguistically summarize ET data alongside Bayley scales, presenting comparative results between children with ASD and TD. Through linguistic summarization, this study facilitates the creation of simple, natural language statements, offering a first and unique approach to enhance ASD screening and contribute to our understanding of neurodevelopmental disorders. © The Author(s) 2024.",Autism spectrum disorder; Bayley; Eye-tracking; Fuzzy logic; Linguistic summarization,Article; artificial intelligence; artificial neural network; autism; Bayley Scales of Infant Development; child; cognitive aging; data mining; decision making; deep learning; developmental disorder; developmental psychology; dwell time; electroencephalogram; eye tracking; eye-tracking technology; functional connectivity; fuzzy logic; gene mutation; global quality score; human; interpersonal communication; language ability; linguistic summarization; machine learning; mathematical analysis; mental disease; metaheuristics; natural language processing; neuroimaging; risk assessment; schizophrenia; scoring system; summarization; support vector machine; visual attention,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85198735119,Movies / Media
Vasant Bidwe R.; Mishra S.; Kamini Bajaj S.; Kotecha K.,"Vasant Bidwe, Ranjeet (57657096900); Mishra, Sashikala (57195369705); Kamini Bajaj, Simi (57215349322); Kotecha, Ketan (6506676097)",57657096900; 57195369705; 57215349322; 6506676097,Attention-Focused Eye Gaze Analysis to Predict Autistic Traits Using Transfer Learning,2024,International Journal of Computational Intelligence Systems,17,1,120,,,,9,10.1007/s44196-024-00491-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193500076&doi=10.1007%2fs44196-024-00491-y&partnerID=40&md5=88b7744847215e0e9d5960b72299958c,"Autism spectrum disorder (ASD) is a complex developmental issue that affects the behavior and communication abilities of children. It is extremely needed to perceive it at an early age. The research article focuses on attentiveness by considering eye positioning as a key feature and its implementation is completed in two phases. In the first phase, various transfer learning algorithms are implemented and evaluated to predict ASD traits on available open-source image datasets Kaggle and Zenodo. To reinforce the result, fivefold cross-validation is used on the dataset. Progressive pre-trained algorithms named VGG 16, VGG 19, InceptionV3, ResNet152V2, DenseNet201, ConNextBase, EfficientNetB1, NasNetMobile, and InceptionResNEtV2 implemented to establish the correctness of the result. The result is being compiled and analyzed that ConvNextBase model has the best diagnosing ability on both datasets. This model achieved a prediction accuracy of 80.4% on Kaggle with a batch size of 16, a learning rate of 0.00002, 10 epochs and 6 units, and a prediction accuracy of 80.71% on the Zenodo dataset with a batch size of 4, a learning rate of 0.00002, 10 epochs and 4 units. The accuracy of the model ConvNextBase is found challenging in nature as compared to an existing model. Attentiveness is a parameter that will accurately diagnose the visual behavior of the participant which helps in the automatic prediction of autistic traits. In the second phase of the proposed model, attentiveness is engrossed in identifying autistic traits. The model uses a dlib library that uses HOG and Linear SVM-based face detectors to identify a particular facial parameter called EAR and it is used to measure participants' attentiveness based on the eye gaze analysis. If the EAR value is less than 0.20 for more than 100 consecutive frames, the model concludes the participant is un-attentive. The model generated a special graph for a time period by continuously plotting the value of EAR based on the attention level. The average EAR value will depict the attentiveness of the participant. © The Author(s) 2024.",Autism spectrum disorder; Convolutional neural networks (CNN); Deep neural networks (DNN); Facial features; Machine learning (ML); Transfer learning (TL),Convolutional neural networks; Diseases; Forecasting; Learning algorithms; Support vector machines; Transfer learning; Autism spectrum disorders; Convolutional neural network; Deep neural network; Eye-gaze; Facial feature; Machine learning; Machine-learning; Transfer learning; Deep neural networks,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85193500076,Movies / Media
Wong S.W.; Crowe P.,"Wong, Shing Wai (55344576600); Crowe, Philip (35511035700)",55344576600; 35511035700,Cognitive ergonomics and robotic surgery,2024,Journal of Robotic Surgery,18,1,110,,,,12,10.1007/s11701-024-01852-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186541716&doi=10.1007%2fs11701-024-01852-7&partnerID=40&md5=a90482b5960889bcd166fa9f3d76616a,"Cognitive ergonomics refer to mental resources and is associated with memory, sensory motor response, and perception. Cognitive workload (CWL) involves use of working memory (mental strain and effort) to complete a task. The three types of cognitive loads have been divided into intrinsic (dependent on complexity and expertise), extraneous (the presentation of tasks) and germane (the learning process) components. The effect of robotic surgery on CWL is complex because the postural, visualisation, and manipulation ergonomic benefits for the surgeon may be offset by the disadvantages associated with team separation and reduced situation awareness. Physical fatigue and workflow disruptions have a negative impact on CWL. Intraoperative CWL can be measured subjectively post hoc with the use of self-reported instruments or objectively with real-time physiological response metrics. Cognitive training can play a crucial role in the process of skill acquisition during the three stages of motor learning: from cognitive to integrative and then to autonomous. Mentorship, technical practice and watching videos are the most common traditional cognitive training methods in surgery. Cognitive training can also occur with computer-based cognitive simulation, mental rehearsal, and cognitive task analysis. Assessment of cognitive skills may offer a more effective way to differentiate robotic expertise level than automated performance (tool-based) metrics. © The Author(s) 2024.",Cognition; Cognitive workload; Ergonomics; Robotic surgery,Benchmarking; Ergonomics; Humans; Learning; Robotic Surgical Procedures; Robotics; Computer aided analysis; Ergonomics; Job analysis; Physiological models; Sensory perception; Surgical equipment; Cognition; Cognitive ergonomics; Cognitive loads; Cognitive robotics; Cognitive training; Cognitive workloads; Motor response; Robotics surgery; Sensory motors; Working memory; awareness; behavior; burnout; cognition; cognitive load; depth perception; electromyography; emotion; ergonomics; fatigue; human; job satisfaction; learning; learning curve; memory; mental stress; mentor; motor learning; perception; rating scale; Review; robot assisted surgery; self report; sensorimotor function; sequence alignment; simulation; skill; surgeon; task performance; training; videorecording; workflow; working memory; benchmarking; ergonomics; procedures; robotics; Robotic surgery,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85186541716,Movies / Media
Fong L.H.N.; Nong S.Z.; Wu A.M.S.; Fong D.K.C.,"Fong, Lawrence Hoc Nang (55752318000); Nong, Sunny Zhenzhen (57210124017); Wu, Anise M. S. (57211720826); Fong, Davis Ka Chio (56443530800)",55752318000; 57210124017; 57211720826; 56443530800,Scent-driven Selective Attention on Gambling Outcome: Implications for Responsible Gambling,2024,Journal of Gambling Studies,40,4,,1823,1838,15.0,1,10.1007/s10899-024-10346-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200940062&doi=10.1007%2fs10899-024-10346-y&partnerID=40&md5=2307eff445f6b848aff3dc6d0400260a,"Many casinos diffuse a pleasant ambient scent into their facilities as a customer experience management practice, but the ethics of this scenting process is questionable. Although the effect of a pleasant scent on cognitive, emotional, and behavioral responses has been well-documented, its effect on attention during gambling has yet to be explored. Grounded in the tenets of the top-down control of attention and cross-modal correspondence between vision and olfaction, we conduct two eye-tracking experiments that involve different electronic casino games including video slots and live Cussec. The findings consistently show that pleasant ambient scent prolongs attention and induces more frequent attention to the win/loss areas on the video screen. The findings add to the implications related to responsible gambling by inspiring the stakeholders to consider the use of ambient scent in the gambling environment. Theoretically, the findings offer insights into scent as the catalyst that directs attention to goal-related information, while scent and goal do not need to be congruent in traits. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",Ambient scent; Responsible gambling; Selective attention; Sensory marketing; Top-down control,"Adult; Attention; Behavior, Addictive; Female; Gambling; Humans; Male; Odorants; Smell; Young Adult; fragrance; article; catalyst; cognition; commercial phenomena; consumer; eye tracking; eye-tracking technology; gambling; game; human; marketing; odor; selective attention; smelling; videorecording; vision; addiction; adult; attention; female; male; odor; psychology; young adult",Article,Final,,Scopus,2-s2.0-85200940062,Movies / Media
Lonardo L.; Völter C.J.; Hepach R.; Lamm C.; Huber L.,"Lonardo, Lucrezia (57226570287); Völter, Christoph J. (55953494400); Hepach, Robert (55220099400); Lamm, Claus (56566285000); Huber, Ludwig (7102868913)",57226570287; 55953494400; 55220099400; 56566285000; 7102868913,Do dogs preferentially encode the identity of the target object or the location of others’ actions?,2024,Animal Cognition,27,1,28,,,,2,10.1007/s10071-024-01870-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188931789&doi=10.1007%2fs10071-024-01870-w&partnerID=40&md5=7068490ccb7e021d2b2277bd46565e3d,"The ability to make sense of and predict others’ actions is foundational for many socio-cognitive abilities. Dogs (Canis familiaris) constitute interesting comparative models for the study of action perception due to their marked sensitivity to human actions. We tested companion dogs (N = 21) in two screen-based eye-tracking experiments, adopting a task previously used with human infants and apes, to assess which aspects of an agent’s action dogs consider relevant to the agent’s underlying intentions. An agent was shown repeatedly acting upon the same one of two objects, positioned in the same location. We then presented the objects in swapped locations and the agent approached the objects centrally (Experiment 1) or the old object in the new location or the new object in the old location (Experiment 2). Dogs’ anticipatory fixations and looking times did not reflect an expectation that agents should have continued approaching the same object nor the same location as witnessed during the brief familiarization phase; this contrasts with some findings with infants and apes, but aligns with findings in younger infants before they have sufficient motor experience with the observed action. However, dogs’ pupil dilation and latency to make an anticipatory fixation suggested that, if anything, dogs expected the agents to keep approaching the same location rather than the same object, and their looking times showed sensitivity to the animacy of the agents. We conclude that dogs, lacking motor experience with the observed actions of grasping or kicking performed by a human or inanimate agent, might interpret such actions as directed toward a specific location rather than a specific object. Future research will need to further probe the suitability of anticipatory looking as measure of dogs’ socio-cognitive abilities given differences between the visual systems of dogs and primates. © The Author(s) 2024.",Action perception; Dog cognition; Eye-tracking; Goal-directed actions; Social cognition,Animals; Cognition; Dogs; Hominidae; Humans; animal; cognition; dog; hominid; human,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85188931789,Movies / Media
Patterson K.; Street J.A.; Myachykov A.,"Patterson, Kinga (58947004000); Street, James A. (14523613000); Myachykov, Andriy (10041512100)",58947004000; 14523613000; 10041512100,Phrasal frequency and literacy as predictors of individual differences in on-line processing and comprehension of english complex NP subject-verb agreement,2024,Journal of Cultural Cognitive Science,8,3,,247,274,27.0,0,10.1007/s41809-024-00149-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208920384&doi=10.1007%2fs41809-024-00149-3&partnerID=40&md5=4cca9f94bc5fbeb6b3710640eab02a69,"We present experimental evidence suggesting that frequency and literacy predict online processing and comprehension of subject-verb agreement constructions by adult native speakers of English. We measured participants’ eye fixations, reaction times, and response accuracy in a forced-choice task using audio-visual eye-tracking paradigm. Participants completed a battery of tasks, inc. the Literacy Rating Scale (Tarone et al., Literacy and Second Language Oracy-Oxford Applied Linguistics, Oxford University Press, 2013), Agreement Judgement Task (e.g., Veenstra et al., Frontiers in Psychology 5:783, 2014). The AJT involved matching an auditorily presented subject phrase to one of two images of easily distinguishable colours presented on a computer screen (e.g., stars, circles). Participants heard 42 test sentences, counterbalanced across the three types: Type 1 (e.g., ‘The stars with the circles are blue’), Type 2 (e.g., ‘The star with the circles is blue’) and Type 3 (e.g., ‘The star with the circles are blue’*. Type 1 and Type 2 constructions are considerably more frequent in writing than in speech (Miller et al., Spontaneous spoken language: Syntax and discourse, Oxford University Press on Demand, 1998) with Type 2 producing more attraction errors (Bock et al., Cognitive Psychology 43:83–128, 2001; Becker, L., & Dąbrowska, E. (2020). Does experience with written language influence grammaticality intuitions? UK Cognitive Linguistics Conference: University of Birmingham [conference presentation].). Data were analysed with linear mixed effects models and generalised additive models. Results show lower literacy participants took longer to process sentential cues and made more attraction errors. These findings support usage-based research showing frequency and experience effects on online comprehension of canonical and non-canonical constructions (Farmer, T. A., Misyak, J. B., & Christiansen, M. H. (2012). Individual differences in sentence processing. In Cambridge handbook of psycholinguistics (pp. 353-364)., Street, Language Sciences 59:192–203, 2017), detection and production of agreement attraction errors (Becker, L., & Dąbrowska, E. (2020). Does experience with written language influence grammaticality intuitions? UK Cognitive Linguistics Conference: University of Birmingham [conference presentation].) and demonstrate how linguistic and attentional processes interact (Tomlin and Myachykov, Attention and salience, Handbook of Cognitive Linguistics, 2015). They also complement corpus-based studies by providing evidence that native speakers are sensitive to observed distributions (Miller et al., Spontaneous spoken language: Syntax and discourse, Oxford University Press on Demand, 1998). © The Author(s) 2024.",Eye-tracking; Frequency; Literacy; Subject-verb agreement; Usage-based,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85208920384,Movies / Media
Hermens F.; Krucien N.; Ryan M.,"Hermens, Frouke (6603194458); Krucien, Nicolas (39962034400); Ryan, Mandy (7403185259)",6603194458; 39962034400; 7403185259,The use of machine learning to understand the role of visual attention in multi-attribute choice,2024,Acta Psychologica,251,,104581,,,,0,10.1016/j.actpsy.2024.104581,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209684353&doi=10.1016%2fj.actpsy.2024.104581&partnerID=40&md5=1dba53197ff606268c1e8efdb0644bd1,"Whether eye movements (as a measure of visual attention) contribute to the understanding of how multi-attribute decisions are made, is still a matter of debate. In this study, we show how machine learning methods can be used to separate the effects of the information presented, eye movement patterns, and attention to specific information. We also show how to deal with data from a relatively small sample of participants, often found in eye tracking studies that require in-lab testing. We make use of a dataset of 30 females who decided whether or not to accept screening for Chlamydia in 21 different scenarios. For this dataset, we find that eye movements did not add to the prediction of choice beyond the information presented to participants. Future studies should determine whether the same conclusion holds for other eye tracking datasets. © 2024 The Authors",Eye movements; Health decisions; Machine learning; Multi-attribute choice; Visual attention,Adolescent; Adult; Attention; Choice Behavior; Eye Movements; Eye-Tracking Technology; Female; Humans; Machine Learning; Visual Perception; Young Adult; adolescent; adult; attention; decision making; eye movement; eye-tracking technology; female; human; machine learning; physiology; vision; young adult,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85209684353,Movies / Media
Saalwirth C.; Stefani M.; Sauter M.; Mack W.,"Saalwirth, Christina (57221946463); Stefani, Maximilian (57214142408); Sauter, Marian (56763649100); Mack, Wolfgang (56248614100)",57221946463; 57214142408; 56763649100; 56248614100,Eye-tracking analysis of attentional disengagement in phobic and non-phobic individuals,2024,"Attention, Perception, and Psychophysics",86,8,,2643,2658,15.0,1,10.3758/s13414-024-02968-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206386065&doi=10.3758%2fs13414-024-02968-6&partnerID=40&md5=8ebd9e791970bb809965dfd16e73a16b,"This study investigated threat-related attention biases using a new visual search paradigm with eye tracking, which allows for measuring attentional disengagement in isolation. This is crucial as previous studies have been unable to distinguish between engagement, disengagement, and behavioral freezing. Thirty-three participants (Mage = 28.75 years, SD = 8.98; 21 women) with self-reported specific phobia (spiders, snakes, and pointed objects) and their matched controls (Mage = 28.38 years, SD = 8.66; 21 women) took part in the experiment. The participants were instructed to initially focus on a picture in the center of the screen, then search for a target picture in an outer circle consisting of six images, and respond via a button press whether the object in the target picture was oriented to the left or right. We found that phobic individuals show delayed disengagement and slower decision times compared with non-phobic individuals, regardless of whether the stimulus was threat-related or neutral. These results indicate that phobic individuals tend to exhibit poorer attentional control mechanisms and problems inhibiting irrelevant information. We also confirmed a threat-unrelated shared feature effect with complex stimuli (delayed disengagement when an attended stimulus and an unattended target share common stimulus features). This process might play a role in various experimental setups investigating attentional disengagement that has not yet been considered. These findings are important, as good attentional control may serve as a protective mechanism against anxiety disorders. © The Author(s) 2024.",Attentional disengagement; Behavioral freezing; Fear; Phobia; Visual search,"Adult; Attention; Attentional Bias; Eye-Tracking Technology; Female; Humans; Male; Pattern Recognition, Visual; Phobia, Specific; Phobic Disorders; Reaction Time; Young Adult; adult; attention; attentional bias; eye-tracking technology; female; human; male; phobia; physiology; psychology; reaction time; visual pattern recognition; young adult",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85206386065,Movies / Media
Song J.; Huang H.; Liu J.; Wu J.; Chen Y.; Wang L.; Zhong F.; Wang X.; Lin Z.; Yan M.; Zhang W.; Liu X.; Tang X.; Lü Y.; Yu W.,"Song, Jiaqi (57468431600); Huang, Haodong (57286689300); Liu, Jiarui (58888165300); Wu, Jiani (58041582500); Chen, Yingxi (57221679671); Wang, Lisong (59281423800); Zhong, Fuxin (57224929454); Wang, Xiaoqin (57468591600); Lin, Zihan (59281945300); Yan, Mengyu (58076529300); Zhang, Wenbo (57207696292); Liu, Xintong (57207691654); Tang, Xinyi (59278322800); Lü, Yang (59157685200); Yu, Weihua (54407546800)",57468431600; 57286689300; 58888165300; 58041582500; 57221679671; 59281423800; 57224929454; 57468591600; 59281945300; 58076529300; 57207696292; 57207691654; 59278322800; 59157685200; 54407546800,Diagnostic Potential of Eye Movements in Alzheimer’s Disease via a Multiclass Machine Learning Model,2024,Cognitive Computation,16,6,,3364,3378,14.0,2,10.1007/s12559-024-10346-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201607495&doi=10.1007%2fs12559-024-10346-5&partnerID=40&md5=e1d159aa5feda0e64b867977a8137e8f,"Early diagnosis plays a crucial role in controlling Alzheimer’s disease (AD) progression and delaying cognitive decline. Traditional diagnostic tools present great challenges to clinical practice due to their invasiveness, high cost, and time-consuming administration. This study was designed to construct a non-invasive and cost-effective classification model based on eye movement parameters to distinguish dementia due to AD (ADD), mild cognitive impairment (MCI), and normal cognition. Eye movement data were collected from 258 subjects, comprising 111 patients with ADD, 81 patients with MCI, and 66 individuals with normal cognition. The fixation, smooth pursuit, prosaccade, and anti-saccade tasks were performed. Machine learning methods were used to screen eye movement parameters and build diagnostic models. Pearson’s correlation analysis was used to assess the correlations between the five most important eye movement indicators in the optimal model and neuropsychological scales. The gradient boosting classifier model demonstrated the best classification performance, achieving 68.2% of accuracy and 66.32% of F1-score in multiclass classification of AD. Moreover, the correlation analysis indicated that the eye movement parameters were associated with various cognitive functions, including general cognitive status, attention, visuospatial ability, episodic memory, short-term memory, and language and instrumental activities of daily life. Eye movement parameters in conjunction with machine learning methods achieve satisfactory overall accuracy, making it an effective and less time-consuming method to assist clinical diagnosis of AD. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",Alzheimer’s disease; Eye movement; Machine learning model; Mild cognitive impairment; Multiclass diagnosis,Adaptive boosting; Diagnosis; Neurodegenerative diseases; Noninvasive medical procedures; Alzheimer; Alzheimer’s disease; Cognitive impairment; Correlation analysis; Diagnostic potential; Early diagnosis; Machine learning methods; Machine learning models; Mild cognitive impairment; Multiclass diagnose; Disease control,Article,Final,,Scopus,2-s2.0-85201607495,Movies / Media
Liu Z.; Li J.; Zhang Y.; Wu D.; Huo Y.; Yang J.; Zhang M.; Dong C.; Jiang L.; Sun R.; Zhou R.; Li F.; Yu X.; Zhu D.; Guo Y.; Chen J.,"Liu, Zhongling (58722894700); Li, Jinkai (58544379700); Zhang, Yuanyuan (56157881900); Wu, Dan (57211180475); Huo, Yanyan (57223200676); Yang, Jianxin (57275319100); Zhang, Musen (59466107200); Dong, Chuanfei (58808897700); Jiang, Luhui (59357909800); Sun, Ruohan (59466038000); Zhou, Ruoyin (59466038100); Li, Fei (59466023000); Yu, Xiaodan (55673878300); Zhu, Daqian (57210554839); Guo, Yao (57188987287); Chen, Jinjin (37046653000)",58722894700; 58544379700; 56157881900; 57211180475; 57223200676; 57275319100; 59466107200; 58808897700; 59357909800; 59466038000; 59466038100; 59466023000; 55673878300; 57210554839; 57188987287; 37046653000,Auxiliary Diagnosis of Children With Attention-Deficit/Hyperactivity Disorder Using Eye-Tracking and Digital Biomarkers: Case-Control Study,2024,JMIR mHealth and uHealth,12,,,e58927,,,3,10.2196/58927,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211521803&doi=10.2196%2f58927&partnerID=40&md5=1098aa4165c14daf93950b2cfb826301,"BACKGROUND: Attention-deficit/hyperactivity disorder (ADHD) is a common neurodevelopmental disorder in school-aged children. The lack of objective biomarkers for ADHD often results in missed diagnoses or misdiagnoses, which lead to inappropriate or delayed interventions. Eye-tracking technology provides an objective method to assess children's neuropsychological behavior. OBJECTIVE: The aim of this study was to develop an objective and reliable auxiliary diagnostic system for ADHD using eye-tracking technology. This system would be valuable for screening for ADHD in schools and communities and may help identify objective biomarkers for the clinical diagnosis of ADHD. METHODS: We conducted a case-control study of children with ADHD and typically developing (TD) children. We designed an eye-tracking assessment paradigm based on the core cognitive deficits of ADHD and extracted various digital biomarkers that represented participant behaviors. These biomarkers and developmental patterns were compared between the ADHD and TD groups. Machine learning (ML) was implemented to validate the ability of the extracted eye-tracking biomarkers to predict ADHD. The performance of the ML models was evaluated using 5-fold cross-validation. RESULTS: We recruited 216 participants, of whom 94 (43.5%) were children with ADHD and 122 (56.5%) were TD children. The ADHD group showed significantly poorer performance (for accuracy and completion time) than the TD group in the prosaccade, antisaccade, and delayed saccade tasks. In addition, there were substantial group differences in digital biomarkers, such as pupil diameter fluctuation, regularity of gaze trajectory, and fixations on unrelated areas. Although the accuracy and task completion speed of the ADHD group increased over time, their eye-movement patterns remained irregular. The TD group with children aged 5 to 6 years outperformed the ADHD group with children aged 9 to 10 years, and this difference remained relatively stable over time, which indicated that the ADHD group followed a unique developmental pattern. The ML model was effective in discriminating the groups, achieving an area under the curve of 0.965 and an accuracy of 0.908. CONCLUSIONS: The eye-tracking biomarkers proposed in this study effectively identified differences in various aspects of eye-movement patterns between the ADHD and TD groups. In addition, the ML model constructed using these digital biomarkers achieved high accuracy and reliability in identifying ADHD. Our system can facilitate early screening for ADHD in schools and communities and provide clinicians with objective biomarkers as a reference. ©Zhongling Liu, Jinkai Li, Yuanyuan Zhang, Dan Wu, Yanyan Huo, Jianxin Yang, Musen Zhang, Chuanfei Dong, Luhui Jiang, Ruohan Sun, Ruoyin Zhou, Fei Li, Xiaodan Yu, Daqian Zhu, Yao Guo, Jinjin Chen. Originally published in JMIR mHealth and uHealth (https://mhealth.jmir.org), 29.11.2024.",antisaccade; attention deficit disorder with hyperactivity; auxiliary diagnosis; digital biomarker; eye-tracking; machine learning,Attention Deficit Disorder with Hyperactivity; Biomarkers; Case-Control Studies; Child; Eye-Tracking Technology; Female; Humans; Male; biological marker; attention deficit hyperactivity disorder; case control study; child; diagnosis; eye-tracking technology; female; human; male,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85211521803,Movies / Media
Wang Y.; Panchadsaram S.; Sherkati R.; Clark J.J.,"Wang, Yinan (58560175200); Panchadsaram, Sansitha (59308387100); Sherkati, Rezvan (57003693400); Clark, James J. (7407828577)",58560175200; 59308387100; 57003693400; 7407828577,An egocentric video and eye-tracking dataset for visual search in convenience stores,2024,Computer Vision and Image Understanding,248,,104129,,,,0,10.1016/j.cviu.2024.104129,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202778192&doi=10.1016%2fj.cviu.2024.104129&partnerID=40&md5=ca4df07f48c15a0e6170122b2fe5347b,"We introduce an egocentric video and eye-tracking dataset, comprised of 108 first-person videos of 36 shoppers searching for three different products (orange juice, KitKat chocolate bars, and canned tuna) in a convenience store, along with the frame-centered eye fixation locations for each video frame. The dataset also includes demographic information about each participant in the form of an 11-question survey. The paper describes two applications using the dataset — an analysis of eye fixations during search in the store, and a training of a clustered saliency model for predicting saliency of viewers engaged in product search in the store. The fixation analysis shows that fixation duration statistics are very similar to those found in image and video viewing, suggesting that similar visual processing is employed during search in 3D environments and during viewing of imagery on computer screens. A clustering technique was applied to the questionnaire data, which resulted in two clusters being detected. Based on these clusters, personalized saliency prediction models were trained on the store fixation data, which provided improved performance in prediction saliency on the store video data compared to state-of-the art universal saliency prediction methods. © 2024 The Author(s)",Attention; Egocentric; Eye-tracking; Saliency,Video analysis; Attention; Convenience stores; Egocentric; Eye fixations; Eye-tracking; First person; Orange juice; Saliency; Video-tracking; Visual search; Fruit juices,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85202778192,Movies / Media
Nawaz O.; Khatibi S.; Sheikh M.N.; Fiedler M.,"Nawaz, Omer (25646229200); Khatibi, Siamak (57191281051); Sheikh, Muhammad Nauman (59425928600); Fiedler, Markus (7006649020)",25646229200; 57191281051; 59425928600; 7006649020,Eye Tracking and Human Influence Factors’ Impact on Quality of Experience of Mobile Gaming,2024,Future Internet,16,11,420,,,,0,10.3390/fi16110420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210229630&doi=10.3390%2ffi16110420&partnerID=40&md5=119269e07a60983cfbe911df300e81c7,"Mobile gaming accounts for more than 50% of global online gaming revenue, surpassing console and browser-based gaming. The success of mobile gaming titles depends on optimizing applications for the specific hardware constraints of mobile devices, such as smaller displays and lower computational power, to maximize battery life. Additionally, these applications must dynamically adapt to the variations in network speed inherent in mobile environments. Ultimately, user engagement and satisfaction are critical, necessitating a favorable comparison to browser and console-based gaming experiences. While Quality of Experience (QoE) subjective evaluations through user surveys are the most reliable method for assessing user perception, various factors, termed influence factors (IFs), can affect user ratings of stimulus quality. This study examines human influence factors in mobile gaming, specifically analyzing the impact of user delight towards displayed content and the effect of gaze tracking. Using Pupil Core eye-tracking hardware, we captured user interactions with mobile devices and measured visual attention. Video stimuli from eight popular games were selected, with resolutions of 720p and 1080p and frame rates of 30 and 60 fps. Our results indicate a statistically significant impact of user delight on the MOS for most video stimuli across all games. Additionally, a trend favoring higher frame rates over screen resolution emerged in user ratings. These findings underscore the significance of optimizing mobile gaming experiences by incorporating models that estimate human influence factors to enhance user satisfaction and engagement. © 2024 by the authors.",eye tracking in mobile gaming; gaze tracking; human IFs and multimedia; mobile gaming; QoE,Geological surveys; Eye tracking in mobile gaming; Eye-tracking; Gaze-tracking; Human influence factor and multimedium; Human influences; Mobile gaming; Quality of experience; User engagement; Users' satisfactions; Display devices,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85210229630,Movies / Media
Børsting C.K.; Batuev A.; Shalvi S.; Orquin J.L.,"Børsting, Caroline Kjær (57354121900); Batuev, Aleksandr (58946508800); Shalvi, Shaul (26030072600); Orquin, Jacob Lund (55199940500)",57354121900; 58946508800; 26030072600; 55199940500,Choosing not to see: Visual inattention as a method of information avoidance,2024,Journal of Experimental Social Psychology,115,,104661,,,,3,10.1016/j.jesp.2024.104661,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198560356&doi=10.1016%2fj.jesp.2024.104661&partnerID=40&md5=0c3259b09fcad06c661240f41fa6ce62,"People rely on a number of methods to avoid information that would compel them to change their beliefs or behaviors. However, it remains unclear whether people use visual inattention as a method of information avoidance. In three eye-tracking experiments, we test the hypothesis that people avoid visual information by strategically suppressing and facilitating visual attention depending on where desired and avoided information is likely to appear. Introducing a novel search task, we independently manipulate the probability of where desired and avoided information appear on the screen. Study 1 show that participants learn statistical regularities in information location and utilize this to gradually suppress attention to undesired information. Study 2 and 3 show that participants can simultaneously reduce and increase visual attention to areas where avoided and desired information are most likely to appear. The findings point to suppression of attention as a mechanism behind information avoidance through visual inattention and that reducing the predictability of where information appears could be a fruitful avenue for reducing it. © 2024",Eye-tracking; Facilitation; Information avoidance; Suppression; Visual attention,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85198560356,Movies / Media
Lacoste-Badie S.; Yu J.J.; Droulers O.,"Lacoste-Badie, S. (56568328000); Yu, J.J. (59185147100); Droulers, O. (55611613500)",56568328000; 59185147100; 55611613500,Do health warning labels on alcohol packaging attract visual attention? A systematic review,2024,Public Health,236,,,184,192,8.0,2,10.1016/j.puhe.2024.07.030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204066423&doi=10.1016%2fj.puhe.2024.07.030&partnerID=40&md5=43a6400d85d4d90658c3bc70a3610220,"Objectives: To synthesize eye-tracking-based evidence on consumers' visual attention devoted to alcohol warning labels (AWLs) on alcohol packaging. Study design: A systematic review was conducted and reported in accordance with the PRISMA guidelines. Methods: Two rounds of a literature search were conducted to identify relevant peer-reviewed articles and unpublished grey literature. While the first round (July 3 to August 21, 2023) was based on three electronic databases (PubMed, Web of Science, and PsycINFO), the second round (May 20 to 28, 2024) followed a multiple-step protocol that systematically searched the grey literature. Five criteria were applied to screen eligible articles. Using established quality control tools, the identified articles were assessed for overall quality and then for quality specific to the eye-tracking method. Results: Six published peer-reviewed articles were thus included in the current review along with one unpublished research paper from a doctoral thesis. This review paper summarizes earlier findings in terms of bottom-up (i.e., AWL design-related) factors such as size, color, surrounding border, and pictorial elements, and top-down (i.e., goal-driven) factors such as motivation to change drinking behavior and self-affirmation. The review found that people tend to pay very little attention to AWLs displayed on alcohol packaging, although there is mixed evidence as to the effectiveness of specific factors. Conclusions: Further investigations using eye-tracking are needed to collect additional evidence on attention devoted to AWLs. Meanwhile, we put forward implications for policymakers and future avenues for research based on our review of the existing literature. © 2024 The Authors",Alcohol warning label (AWL); Bottom-up factors; Eye-tracking; Top-down factors; Visual attention,Alcoholic Beverages; Attention; Eye-Tracking Technology; Humans; Product Labeling; Product Packaging; advertising; alcohol consumption; alcoholic beverage; consumption behavior; future prospect; health care; health policy; literature review; policy making; research work; visualization; warning system; alcohol packaging; health warning label; human; methodological quality; methodology; packaging; quality control; Review; systematic review; visual attention; alcoholic beverage; attention; eye-tracking technology; packaging; product labeling,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85204066423,Movies / Media
Gibbs M.C.; Huxley J.; Readman M.R.; Polden M.; Bredemeyer O.; Crawford T.J.; Antoniades C.A.,"Gibbs, Melissa C. (57350858300); Huxley, Jenna (59373021800); Readman, Megan Rose (57222650875); Polden, Megan (57212676994); Bredemeyer, Oliver (57851997600); Crawford, Trevor J. (57209863519); Antoniades, Chrystalina A. (16644609800)",57350858300; 59373021800; 57222650875; 57212676994; 57851997600; 57209863519; 16644609800,Naturalistic Eye Movement Tasks in Parkinson's Disease: A Systematic Review,2024,Journal of Parkinson's Disease,14,7,,1369,1386,17.0,2,10.3233/JPD-240092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206843364&doi=10.3233%2fJPD-240092&partnerID=40&md5=7cb1023a4cbae0842f741ad9273d6052,"Background: Eye tracking assessments in the laboratory have previously highlighted clear differences in eye movements between Parkinson's disease (PD) and healthy aging. However, laboratory-based eye movement tasks are artificial and limit the ecological validity of observed results. Eye movement tasks utilizing more naturalistic scenarios may provide more accurate insight into cognitive function but research in this area is limited. Objective: This systematic review aims to ascertain what naturalistic tasks have revealed about oculomotor deficits in PD and what this information may help us understand about the underlying sensorimotor and cognitive processes. Methods: Adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement, a literature search of PsycInfo, Medline, Scopus, and Web of Science was conducted using predetermined search terms. Articles including both individuals with PD and healthy older adults completing eye tracking tasks involving naturalistic eye movements (e.g., reading, video-watching, unrestricted visual search) or naturalistic stimuli were included. Results: After screening, 30 studies were identified as matching the inclusion criteria. Results revealed consistent findings across tasks, including longer fixation durations and smaller saccadic amplitudes in PD compared to healthy aging. However, inconsistencies in the literature and a lack of standardization in tasks limit interpretation of these results. Conclusions: Naturalistic eye movement tasks highlight some consistent differences in eye movements between people with PD and healthy aging. However, future research should expand the current literature in this area and strive towards standardization of naturalistic tasks that can preferably be conducted remotely.  © 2024 - The authors. Published by IOS Press.",Eye movements; Parkinson's disease; saccades; systematic review,Eye Movement Measurements; Eye Movements; Eye-Tracking Technology; Humans; Parkinson Disease; cognition; eye movement disorder; eye tracking; healthy aging; human; Parkinson disease; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; Review; saccadic eye movement; sensorimotor function; systematic review; visual stimulation; complication; eye movement; eye-tracking technology; oculography; pathophysiology; physiology,Review,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85206843364,Movies / Media
Kontos A.P.; Zynda A.J.; Minerbi A.,"Kontos, Anthony P (7004528698); Zynda, Aaron J (57205679373); Minerbi, Amir (6503847285)",7004528698; 57205679373; 6503847285,Comparison of Vestibular/Ocular Motor Screening (VOMS) and Computerized Eye-tracking to Identify Exposure to Repetitive Head Impacts,2024,Military Medicine,189,12-Nov,,2291,2297,6.0,0,10.1093/milmed/usae065,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208582137&doi=10.1093%2fmilmed%2fusae065&partnerID=40&md5=43b5bca40f802730eff61013ecf3ba66,"Introduction: Military service members (SMs) are exposed to repetitive head impacts (RHIs) in combat and training that are purported to adversely affect brain health, including cognition, behavior, and function. Researchers have reported that RHI from blast-related exposure may affect both vestibular and ocular function, which in turn may be related to symptomology. As such, an examination of the effects of RHI on exposed military SMs should incorporate these domains. To date, researchers have not compared groups of exposed special operations forces (SOF) operators on combined clinical vestibular/ocular and eye-tracker-based outcomes. Therefore, the primary purpose of this study was to compare participant-reported symptoms and performance on the Vestibular/Ocular Motor Screening (VOMS) tool with performance on the computerized RightEye tracking system between SOF operators exposed to blast-related RHI and healthy controls without blast-related exposure. In addition, the study aimed to compare subgroups of snipers and breachers exposed to RHI to controls on the preceding metrics, as well as identify a subset of individual (demographic) factors, participant-reported symptoms, and performance metrics on VOMS and RightEye that best identify SOF operators exposed to RHI from unexposed controls. Materials and Methods: The study involved a cross-sectional design including 25 Canadian SOF SMs comprised of breachers (n = 9), snipers (n = 9), and healthy, unexposed controls (n = 7). The former 2 groups were combined into an RHI group (n = 18) and compared to controls (n = 7). Participants provided demographics and completed a self-reported concussion-related symptom report via the Military Acute Concussion Evaluation 2, the VOMS, and RightEye computerized eye-tracking assessments. Independent samples t-tests and ANOVAs were used to compare the groups on the outcomes, with receiver operating characteristic curve and area under the curve (AUC) analyses to identify predictors of blast exposure. This study was approved by the Defence Research Development Canada Human Research Ethics Committee and the Canadian Forces Surgeon General/Special Forces Command. Results: The results from t-tests supported group differences for age (P =. 012), participant-reported symptoms (P =. 006), and all VOMS items (P range = <.001-.02), with the RHI group being higher than healthy controls on all variables. ANOVA results supported group differences among snipers, breachers, and controls for age (P =. 01), RightEye saccades (P =. 04), participant-reported total symptom severity (P =. 03), and VOMS total scores (P =. 003). The results of the receiver operating characteristic curve analyses supported age (AUC = 0.81), Military Acute Concussion Evaluation 2 participant-reported total symptom severity (AUC = 0.87), and VOMS total scores (AUC = 0.92) as significant predictors of prior blast exposure. Conclusions: Participant-reported concussion symptoms, VOMS scores, and age were useful in identifying SOF operators exposed to RHI from controls. RightEye metrics were not useful in differentiating RHI groups from controls. Differences between snipers and breachers warrant further research. Overall, the findings suggest that VOMS may be a useful tool for screening for the effects of exposure to RHI in SOF operators. Future investigations should be conducted on a larger sample of military SMs, consider additional factors (e.g., RHI exposure levels, medical history, and sex), and include additional assessment domains (e.g., balance, cognitive, and psychological).  © 2024 The Association of Military Surgeons of the United States. All rights reserved. For commercial re-use, please contact reprints@oup.com for reprints and translation rights for reprints. All other permissions can be obtained through our RightsLink service via the Permissions link on the article page on our site-for further information please contact journals.permissions@oup.com.",,Adult; Blast Injuries; Eye-Tracking Technology; Female; Humans; Male; Mass Screening; Military Personnel; adult; blast injury; comparative study; complication; diagnosis; eye-tracking technology; female; human; male; mass screening; military personnel; pathophysiology; procedures,Article,Final,,Scopus,2-s2.0-85208582137,Movies / Media
Pelica S.; Aguiar T.R.; Frade S.; Guerra R.; Prada M.,"Pelica, Sofia (58399069400); Aguiar, Tiago Rôxo (59178945600); Frade, Sofia (59404475200); Guerra, Rita (36606116700); Prada, Marília (56781193400)",58399069400; 59178945600; 59404475200; 36606116700; 56781193400,Are you what you emoji? How skin tone emojis and profile pictures shape attention and social inference processing,2024,Telematics and Informatics,95,,102207,,,,0,10.1016/j.tele.2024.102207,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208665617&doi=10.1016%2fj.tele.2024.102207&partnerID=40&md5=8045a76f9a05ecf475e014cfa0bd8d62,"Emojis can express emotions and some aspects of the sender's identity; however, only limited research has explored how the choice of skin tone in emojis influences the perceptions of the users. We examined the interaction between emoji skin tones and profile pictures in instant messaging, using self-reported and eye tracking measures. White participants viewed 14 screenshots of conversations (9 target and 5 fillers) where the sender used an emoji in a Darker or Lighter skin tone, or the default Yellow; alongside profile pictures displaying a Black or White individual, or a landscape as a neutral condition. Results showed that Black senders using Darker emojis were seen as warmer and closer to the receiver, but less competent, suggesting a dimensional compensation effect. Conversely, Black senders using Lighter emojis appeared more competent, but less warm. In the Neutral condition, Lighter emojis improved warmth and relationship quality, but reduced competence inferences, unlike Yellow and Darker emojis, suggesting a black sheep effect (in-group strictness). Yellow emojis were assumed to be sent by White individuals. Eye-tracking measures revealed an implicit bias towards White senders using Darker emojis, although such an impact was not observed for Black senders using Lighter emojis. Overall, findings indicate that skin tone emojis and profile pictures influence sender perception and challenge the neutrality of Yellow emojis. © 2024 The Author(s)",Computer-mediated communication; Eye tracking; Instant messaging; Person perception; Racialized bias; Skin tone emojis,Computer-mediated communication; Express emotions; Eye-tracking; Instant messaging; Neutral conditions; Person perception; Racialized bias; Screenshots; Skin tone; Skin tone emoji; Instant messaging applications,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85208665617,Movies / Media
Lau A.R.; Baxter A.; He S.; Loyant L.; Ortiz-Jimenez C.A.; Bauman M.D.; Bales K.L.; Freeman S.M.,"Lau, Allison R. (57203900900); Baxter, Alexander (57204176800); He, Shuyu (59328372000); Loyant, Louise (57214121482); Ortiz-Jimenez, Chelsea A. (57218249404); Bauman, Melissa D. (7007019458); Bales, Karen L. (7005760126); Freeman, Sara M. (15727807300)",57203900900; 57204176800; 59328372000; 57214121482; 57218249404; 7007019458; 7005760126; 15727807300,"Age, pair tenure and parenting, but not face identity, predict looking behaviour in a pair-bonded South American primate",2024,Animal Behaviour,217,,,53,63,10.0,0,10.1016/j.anbehav.2024.08.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203990979&doi=10.1016%2fj.anbehav.2024.08.015&partnerID=40&md5=1979ac3963daa544bda2c37686d439d9,"Social bonds are crucial to many animal species. To maintain these bonds, individuals must be able to differentiate the identity of conspecifics. Pair-bonding primates, in general, maintain close bonds with their selected mate. Little is known about visual preferences of pair-bonded primates. To characterize visual preference for images of familiar and unfamiliar faces, we assessed visual attention in coppery titi monkeys, Plecturocebus cupreus. Coppery titi monkeys, like many other pair-bonding species, show a behavioural partner preference when placed in a partner preference paradigm and maintain greater durations of physical proximity to their pair mate compared to an unfamiliar stranger. Using a previously validated noninvasive eye-tracking method, we investigated whether titi monkeys display visual partner preference. We presented adult titi monkeys with 10 static slides showing two conspecific faces side by side: either (1) their partner's face and a stranger's face, or (2) two strangers' faces. Face side was counterbalanced, and slide presentation order was randomized, across all subjects. We present five looking-behaviour outcome measures for a study of 40 titi monkeys. We found no evidence of a visual preference for still photographs of one's pair mate, but we did find that age, pair tenure and parenting experience predicted looking behaviour. Animals with longer pair tenures spent more time looking at facial images. Younger animals looked at the screen for the first time faster, spent less time looking and looked fewer times at the stimuli compared to older animals. Parenting status positively predicted fixation count, total visit duration and visit count, such that parents with more experience looked at the stimuli longer and more times than animals without parenting experience. This study is the first to characterize social looking in a pair-bonded monkey. © 2024 The Authors",eye tracking; monogamy; pair bond; social looking; visual preference,conspecific; monogamy; pair bond; parental care; primate; tracking,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85203990979,Movies / Media
Xiong W.; Li X.; Huang X.; Xu J.; Qu Z.; Su Y.; Li Y.; Han Y.; Cui T.; Zhang X.,"Xiong, Wenjuan (57223007638); Li, Xinyu (59295881600); Huang, Xiaoqing (58789772100); Xu, Jinghan (59052877300); Qu, Zhiyi (57443848000); Su, Yuanyuan (56723164500); Li, Yin (58038647600); Han, Yu (56272148700); Cui, Tingkai (57201096519); Zhang, Xin (58500805500)",57223007638; 59295881600; 58789772100; 59052877300; 57443848000; 56723164500; 58038647600; 56272148700; 57201096519; 58500805500,Impaired motor and social skill development in infancy predict high autistic traits in toddlerhood,2024,Neuroscience,558,,,114,121,7.0,0,10.1016/j.neuroscience.2024.08.024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201876874&doi=10.1016%2fj.neuroscience.2024.08.024&partnerID=40&md5=316c3b0af6056f2016ae37cc5def1cb6,"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder. Early diagnosis in the critical period is important for ASD children. Recent studies of neurodevelopmental behavioral features and joint attention in high-risk infants showed there are some special cues which can distinguish ASD from typical development infant. But the findings of high-risk population may not be applicable to the general population. It is necessary to “analogically” study the potential warning traits of ASD in infancy in the general population. We did a nested case-control study from June 2019 to November 2022 in Tianjin, China, including 76 general infants whom completed the neurodevelopmental evaluation, the Checklist for Autism in Toddlers-23 (CHAT-23) screening, and eye tracking task. Social behavior quotient in infancy was negatively correlated to CHAT-23 total scores in toddlerhood. Social behavior quotient in infancy was positively correlated to initiating joint attention in toddlerhood. Regression model showed that high fine motor scale and social behaviour scale quotient in infancy were associated with an decreased risk of the total score of CHAT-23 ≥ 2 in toddlerhood. The Receiver operating characteristic curve showed the social behaviour in infancy alone and the combination of fine motor and social behaviour in infancy contributed to auxiliary diagnosis of higher level of autistic traits in toddlerhood. These findings suggest that Impaired development of fine motor and social behavior in infancy are potential warning features of high autistic traits in general population. © 2024",Autistic trait; Fine motor; Joint attention; Neurodevelopment; Social behavior,"Autism Spectrum Disorder; Case-Control Studies; Child Development; Child, Preschool; Female; Humans; Infant; Male; Motor Skills; Social Behavior; Social Skills; Apgar score; Article; autism; child; child development; controlled study; cross-sectional study; diagnostic test accuracy study; early diagnosis; eye tracking; female; high risk population; human; infancy; major clinical study; male; motor dysfunction; nerve cell differentiation; prediction; questionnaire; risk factor; school child; self report; sensitivity and specificity; social behavior; social competence; toddler; case control study; diagnosis; infant; motor performance; pathophysiology; physiology; preschool child",Article,Final,,Scopus,2-s2.0-85201876874,Movies / Media
Pham T.; Hwang W.-Y.; Pham X.-L.,"Pham, Thao (57213330065); Hwang, Wu-Yuin (55703771100); Pham, Xuan-Lam (57188740550)",57213330065; 55703771100; 57188740550,Investigation of the influences of instructors and different media on learning attention with a wearable eye-tracking system in the physical classrooms,2024,Journal of Computer Assisted Learning,40,5,,2208,2225,17.0,0,10.1111/jcal.13023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194878992&doi=10.1111%2fjcal.13023&partnerID=40&md5=392c914d4ddef03d98d1e6eaf9397680,"Background: Examining student attention in physical classrooms is crucial, but it faces challenges due to the lack of accurate monitoring. Constraints posed by device limitations and the design of educational materials impede the integration of eye-tracking technology in these settings. Objectives: This study aims to (1) develop a wearable eye-tracking system specifically designed to monitor students' eye movements and gaze points on the projector screen within a physical classroom setting; (2) explore the impact of instructor gestures (by compare live instruction by an instructor and video-recorded instruction) on student attention and examine the effectiveness of directing students' attention from text to image through instructor intervention. Methods: An innovative wearable eye-tracking system was developed to monitor learners' eye movements within the physical classroom. Twenty-five students participated in the experiment, which included two approaches: classroom lectured by the instructor and by a video presentation. Results and Conclusions: The results indicate that participants exhibit a stronger inclination to allocate additional time to text content than image content when receiving instruction through video presentations with a laser pointer in the physical classroom. This tendency can be attributed to the participants' requirement for longer reading and comprehension time in the absence of an instructor. Additionally, the instructor's gestures and body movements significantly impacted participants' fixation on text slides compared to the image slides. The heatmap analyses support these findings and further indicate that participants focus on the instructor's face rather than other body parts. Takeaways: The wearable eye-tracking technology developed in this study holds promise for future educational research, offering further exploration and analysis opportunities. © 2024 John Wiley & Sons Ltd.",improving classroom teaching; instructor; learning attention; multimedia learning; physical classroom; wearable eye-tracking,,Article,Final,,Scopus,2-s2.0-85194878992,Movies / Media
Tawa J.; Lang Y.; Jernigan M.M.,"Tawa, John (36783595900); Lang, Yuanguo (57558347400); Jernigan, Maryam M. (21834407300)",36783595900; 57558347400; 21834407300,Cognitive and Affective Precursors to Decisions to use Lethal Force Against Black Suspects: A Virtual Reality Application,2024,Race and Justice,14,4,,490,517,27.0,2,10.1177/21533687221127448,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142719164&doi=10.1177%2f21533687221127448&partnerID=40&md5=32486ae6a00817a7e2d137a3858e02d5,"Here we investigated the role of physiological stress on participants' lethal force decisions with Black suspects using a novel virtual reality (VR) paradigm. We examined the conditional and mediational roles of implicit racism and visual attention to Black suspects. For this study, we filmed a series of high-risk suspect-police interactions with a 360° video camera which, when viewed through the VR headset, embeds the participants in these scenarios from the perspective of a police officer. Embedded eye tracking in the VR enabled assessment of both physiological stress (through pupil dilation) and attention (through gaze location). Analysis of these behavioral data with criminal justice majors (N = 39) revealed a facilitative function of physiological stress for improving accuracy in lethal force decisions, specifically among those with low levels of implicit racism. Findings also indicated that dysregulated attention—characterized by either disorganized or fixated attentional patterns—compromised lethal force decision making. Results are discussed in relation to future applications of VR to inform our understanding of cognitive and affective precursors of poor decision making. Implications include the promise of cognitive-behavioral interventions for mitigating dysregulated attention patterns, ultimately towards the end of reducing unwarranted uses of lethal force against Black men and women. © The Author(s) 2022.",Black/African American; cognitive-behavioral therapy; decision-making; lethal force; physiological stress; visual attention,,Article,Final,,Scopus,2-s2.0-85142719164,Movies / Media
Chikha H.B.; Mguidich H.; Zoudji B.; Khacharem A.,"Chikha, Houssem Ben (58108865200); Mguidich, Hajer (58740365700); Zoudji, Bachir (6504620730); Khacharem, Aïmen (55628220800)",58108865200; 58740365700; 6504620730; 55628220800,Uncovering the roles of complexity and expertise in memorizing tactical movements from videos with coach's pointing gestures and guided gaze,2024,International Journal of Sports Science and Coaching,19,5,,1883,1896,13.0,1,10.1177/17479541241258708,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195368022&doi=10.1177%2f17479541241258708&partnerID=40&md5=21b6ea3e6d34dfea584f699c4028809e,"Background: Improving the acquisition of complex tactical knowledge through video presentations has attracted considerable attention. Previous research has aimed to facilitate learning by structuring videos including pointing gestures and guided gaze. However, it is debatable whether these cues actually contribute to improved performance in the context of tactical learning for players with varying levels of expertise. Objectives: The present study examined the moderating roles of content complexity and expertise level on recall scores, mental effort, and visual attention while watching videos involving coach's pointing gestures and guided gaze, as well as videos with no cues. Methods: One hundred sixty novice and expert basketball learners were randomly divided into four groups: (i) simple content + no-cues, (ii) simple content + gesture/gaze, (iii) more complex content + no-cues, and (iv) more complex content + gesture/cues. They were instructed to learn the evolution of a tactical scene described by the coach, rate their mental effort invested during the learning phase, and reproduce the learned tactical scene. Results and conclusions: The results showed that regardless of the complexity of the content, novices achieved better recall performance and higher visual attention in the gesture/gaze condition than in the no-cues condition. However, the results showed that experts benefited equally from both conditions when the content was simple, whereas they benefited more from the gesture/gaze condition when the content was more complex. The results showed that the effectiveness of videos involving pointing gestures and guided gaze depends on the content complexity and the expertise level. © The Author(s) 2024.",Cognitive load; eye tracking; instruction; mental effort; multimedia; visual attention,,Article,Final,,Scopus,2-s2.0-85195368022,Movies / Media
Cheng S.; Shang P.; Zhang Y.; Guan J.; Chen Y.; Lv Z.; Huang S.; Liu Y.; Xie H.,"Cheng, Shiyu (58931155700); Shang, Pan (57221309692); Zhang, Yingwei (57196086140); Guan, Jianhe (24801961000); Chen, Yiqiang (35408792800); Lv, Zeping (23989263900); Huang, Shuyun (56140362600); Liu, Yajing (57205702469); Xie, Haiqun (35182279000)",58931155700; 57221309692; 57196086140; 24801961000; 35408792800; 23989263900; 56140362600; 57205702469; 35182279000,An fNIRS representation and fNIRS-scales multimodal fusion method for auxiliary diagnosis of amnestic mild cognitive impairment,2024,Biomedical Signal Processing and Control,96,,106646,,,,6,10.1016/j.bspc.2024.106646,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198914032&doi=10.1016%2fj.bspc.2024.106646&partnerID=40&md5=ecc620464a425624bc0b4c70ae858fd5,"Amnestic mild cognitive impairment (aMCI) is the prodromal period of more serious neurodegenerative diseases (e.g., Alzheimer's disease), characterized by declines in memory and thinking abilities. Auxiliary assessment and early diagnosis of aMCI are crucial in preventing the continued deterioration of cognitive abilities; nevertheless, this task poses a formidable challenge due to the inconspicuous nature of early symptoms. Functional near-infrared spectroscopy (fNIRS) is a non-invasive, low-cost, and user-friendly neuroimaging technique, which is capable of detecting subtle changes in brain activity among different subjects. Moreover, multimodal fusion can assess cognition status from different perspectives and enhance auxiliary diagnosis accuracy significantly. This paper proposes an fNIRS representation and fNIRS-scales multimodal fusion method for auxiliary diagnosis of aMCI. Specifically, we convert one-dimensional time-series fNIRS signals into two-dimensional images with Gramian Angular Field and achieve end-to-end fNIRS representation with convolutional neural network. Then, we integrate the extracted features with cognitive scales at the decision-making level to improve the diagnosis accuracy of aMCI, employing the data balance strategy to prevent biased prediction. What is more, based on the fNIRS features, we also propose a data-driven cognitive scales-screening method to help the physician to assess aMCI with higher efficiency. We conducted experiments on 86 subjects (including 53 aMCI patients and 33 normal controls) recruited from Foshan First People's Hospital. The diagnosis accuracy reaches 88.02% and 93.90% with fNIRS representation and further fNIRS-scales fusion, respectively. With the cognitive scales-screening, we delete 50% scales, reducing test time but only losing 2.54% accuracy. © 2024 The Author(s)",Auxiliary diagnosis; fNIRS; Mild cognitive impairment; Multimodal fusion; Scales; Scales screening,Behavioral research; Brain; Convolutional neural networks; Decision making; Deterioration; Infrared devices; Near infrared spectroscopy; Neurodegenerative diseases; tau protein; Alzheimers disease; Auxiliary diagnose; Cognitive impairment; Early diagnosis; Functional near infrared spectroscopy; Fusion methods; Mild cognitive impairment; Multi-modal fusion; Scale; Scale screening; aged; Article; Bayesian learning; clinical assessment; controlled study; diagnostic accuracy; diagnostic test accuracy study; diffuse Lewy body disease; early diagnosis; electroencephalogram; eye movement; female; functional magnetic resonance imaging; functional near-infrared spectroscopy; health auxiliary; human; light intensity; machine learning; major clinical study; male; medical decision making; mild cognitive impairment; Mini Mental State Examination; Montreal cognitive assessment; multimodal imaging; senile dementia; Diagnosis,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85198914032,Movies / Media
Munari D.; von Wartburg A.; Garcia-Marti V.G.; Zadravec M.; Matjačić Z.; Veneman J.F.,"Munari, Daniele (36895060100); von Wartburg, Angela (58947032500); Garcia-Marti, Veronica G. (59388190100); Zadravec, Matjaž (48862321900); Matjačić, Zlatko (6701664801); Veneman, Jan F. (14034948200)",36895060100; 58947032500; 59388190100; 48862321900; 6701664801; 14034948200,Clinical Feasibility of Applying Immersive Virtual Reality during Robot-Assisted Gait Training for Individuals with Neurological Diseases: A Pilot Study,2024,Brain Sciences,14,10,1002,,,,0,10.3390/brainsci14101002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207680049&doi=10.3390%2fbrainsci14101002&partnerID=40&md5=923a8fbf1c9c670b69e5e525059ef8a1,"Background: Immersive virtual reality has the potential to motivate and challenge patients who need and want to relearn movements in the process of neurorehabilitation. Objective: The aim of this study was to evaluate the feasibility and user acceptance of an innovative immersive virtual reality system (head-mounted display) used in combination with robot-assisted gait training in subjects suffering from neurological diseases. Methods: Fifteen participants suffering from cerebrovascular accident or spinal cord injury completed a single session of immersive virtual reality using a head-mounted display during a Lokomat® gait session. Training parameters and safety indicators were collected, and acceptance was investigated among participants and therapists. Results: The results suggest that an immersive virtual reality system is feasible in terms of safety and tolerance. Furthermore, the very positive overall acceptance of the system suggests that it has the potential to be included in a robot-assisted gait training session using Lokomat®. Conclusion: Overall, this study demonstrates that a fully immersive virtual reality system based on a head-mounted display is both feasible and well received by cerebrovascular accident and spinal cord injury patients and their therapists during robot-assisted gait training. This study suggests that such a virtual reality system could be a viable alternative to the screen-based training games currently used in neurorehabilitation. It may be especially suitable for enhancing patient motivation and adherence to training, particularly if the application is enjoyable and not mentally taxing. © 2024 by the authors.",medical robotics; medical treatment; neurology; neurorehabilitation; virtual reality,adult; Article; body mass; body weight; cardiovascular disease; cerebrovascular accident; clinical article; dizziness; eye tracking; fatigue; feasibility study; female; headache; human; Likert scale; male; middle aged; Mini Mental State Examination; motion sickness; neurologic disease; neurorehabilitation; pain; pilot study; questionnaire; rigidity; robot assisted gait training; spinal cord injury; training; virtual reality; walking speed,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85207680049,Movies / Media
Szarkowska A.; Ragni V.; Szkriba S.; Black S.; Orrego-Carmona D.; Kruger J.-L.,"Szarkowska, Agnieszka (54416458200); Ragni, Valentina (57214091563); Szkriba, Sonia (58683003400); Black, Sharon (57220177354); Orrego-Carmona, David (57201389752); Kruger, Jan-Louis (9277428700)",54416458200; 57214091563; 58683003400; 57220177354; 57201389752; 9277428700,"Watching subtitled videos with the sound off affects viewers' comprehension, cognitive load, immersion, enjoyment, and gaze patterns: A mixed-methods eye-tracking study",2024,PLoS ONE,19,10-Oct,e0306251,,,,4,10.1371/journal.pone.0306251,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205790105&doi=10.1371%2fjournal.pone.0306251&partnerID=40&md5=75471ddff30e2d582864cdca841b63f2,"Every day, millions of viewers worldwide engage with subtitled content, and an increasing number choose to watch without sound. In this mixed-methods study, we examine the impact of sound presence or absence on the viewing experience of both first-language (L1) and second-language (L2) viewers when they watch subtitled videos. We explore this novel phenomenon through comprehension and recall post-tests, self-reported cognitive load, immersion, and enjoyment measures, as well as gaze pattern analysis using eye tracking. We also investigate viewers’ motivations for opting for audiovisual content without sound and explore how the absence of sound impacts their viewing experience, using in-depth, semi-structured interviews. Our goal is to ascertain whether these effects are consistent among L2 and L1 speakers from different language varieties. To achieve this, we tested L1-British English, L1-Australian English and L2-English (L1-Polish) language speakers (n = 168) while they watched English-language audiovisual material with English subtitles with and without sound. The findings show that when watching videos without sound, viewers experienced increased cognitive load, along with reduced comprehension, immersion and overall enjoyment. Examination of participants’ gaze revealed that the absence of sound significantly affected the viewing experience, increasing the need for subtitles and thus increasing the viewers’ propensity to process them more thoroughly. The absence of sound emerged as a global constraint that made reading more effortful. Triangulating data from multiple sources made it possible to tap into some of the metacognitive strategies employed by viewers to maintain comprehension in the absence of sound. We discuss the implications within the context of the growing trend of watching subtitled videos without sound, emphasising its potential impact on cognitive processes and the viewing experience. Copyright: © 2024 Szarkowska et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Adolescent; Adult; Cognition; Comprehension; Eye-Tracking Technology; Female; Fixation, Ocular; Humans; Language; Male; Middle Aged; Pleasure; Sound; Video Recording; Young Adult; adult; Article; cognition; cognitive load; cohort analysis; comprehension; English (language); eye movement; eye tracking; fatigue; female; fitness center; gaze; head movement; human; human experiment; immersion; information; interview; language; male; middle aged; motivation; nightmare; Polish citizen; questionnaire; recall; semi structured interview; torture; videorecording; visual attention; adolescent; cognition; eye fixation; eye-tracking technology; physiology; pleasure; sound; videorecording; young adult",Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85205790105,Movies / Media
Stellpflug S.J.; Dalrymple K.A.; Dummer M.F.; Schindler B.R.; Ashton S.V.; Bachman D.S.; Lefevere R.C.,"Stellpflug, Samuel J. (28568155800); Dalrymple, Kirsten A. (15724194500); Dummer, Matthew F. (57217359438); Schindler, Broc R. (59088654300); Ashton, Sarah V. (59235831000); Bachman, David S. (59176368400); Lefevere, Robert C. (57194631141)",28568155800; 15724194500; 57217359438; 59088654300; 59235831000; 59176368400; 57194631141,Cognitive Assessment in Grappling Athletes Following Choke versus Nonchoke Submissions,2024,Medicine and Science in Sports and Exercise,56,10,,1861,1866,5.0,1,10.1249/MSS.0000000000003494,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199693463&doi=10.1249%2fMSS.0000000000003494&partnerID=40&md5=5300affd1c690e127168bf1216467144,"STELLPFLUG, S. J., K. A. DALRYMPLE, M. F. DUMMER, B. R. SCHINDLER, S. V. ASHTON, D. S. BACHMAN, and R. C. LEFEVERE. Cognitive Assessment in Grappling Athletes Following Choke versus Nonchoke Submissions. Med. Sci. Sports Exerc., Vol. 56, No. 10, pp. 1861- 1866, 2024. Purpose: Participation in Brazilian jiu-jitsu and mixed martial arts has increased over the last three decades. These sports feature submission attacks, including strangles. These strangles, termed “chokes” in this context, primarily limit blood flow to the brain via compression of neck vasculature. There has been discussion in literature of the possibility of measurable cognitive effects following transient choking episodes. The present study used the King-Devick test (KDT) platform, a tablet-based reaction time and accuracy task designed to measure participants’ number recognition, cognition, and verbal expression. This task requires functional vision, saccadic eye movements, comprehension, and expression. Methods: Volunteer participants were screened for exclusion (prior brain injury) criteria and survey information before testing. Athletes were tested with the KDT immediately before a Brazilian jiu-jitsu training session, again immediately after succumbing to either a choke (“Choke” arm) or nonchoke (“Non-Choke” arm) submission while sparring, and again after a 10-min rest period following the postsubmission test. Analysis was done on test failures, total test times, and individual difference scores between baseline and subsequent testing. Results: Sixty-two (32 Choke, 30 Non-Choke) participants were analyzed. There was no significant difference between Choke and Non-Choke in test failures (χ2(1,62) = 1.25, P = 0.263), total times (t(60) = 0.62, P = 0.540; 95% CI, −3.44 to 6.51), and individual difference scores (t(60) = 0.29, P = 0.776; 95% CI, −2.41 to 3.21). Conclusions: There were no significant differences between study arms in any of the three analyzed measures. This suggests that cognitive functioning, as measured by the KDT, is not affected by transient choking episodes. © 2024 by the American College of Sports Medicine.",CAROTID; CONCUSSION; JIU-JITSU; JUDO; KING-DEVICK; MIXED MARTIAL ARTS; NECK; STRANGLE,Adult; Cognition; Female; Humans; Male; Martial Arts; Neuropsychological Tests; Reaction Time; Young Adult; adult; cognition; female; human; male; martial art; neuropsychological assessment; physiology; reaction time; young adult,Article,Final,,Scopus,2-s2.0-85199693463,Movies / Media
Tian P.; Xu G.; Han C.; Zheng X.; Zhang K.; Du C.; Zhang X.; Wei F.; Ma Y.; Zhang S.; Wu Q.,"Tian, Peiyuan (57218932029); Xu, Guanghua (55632209100); Han, Chengcheng (56166400100); Zheng, Xiaowei (57201071086); Zhang, Kai (56611003500); Du, Chenghang (57209471685); Zhang, Xun (57195516898); Wei, Fan (57219011183); Ma, Yunhao (59323207600); Zhang, Sicong (15754711700); Wu, Qingqiang (57196278245)",57218932029; 55632209100; 56166400100; 57201071086; 56611003500; 57209471685; 57195516898; 57219011183; 59323207600; 15754711700; 57196278245,Research on an Indoor Light Environment Comfort Evaluation Index Based on Electroencephalogram and Pupil Signals,2024,Electronics (Switzerland),13,17,3411,,,,0,10.3390/electronics13173411,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203662582&doi=10.3390%2felectronics13173411&partnerID=40&md5=1401359dd19bd0545df49aafb5ff939a,"With the development of modern technology, many people work for a long time around various artificial light sources and electronic equipment, causing them to feel discomfort in their eyes and even eye diseases. The industry currently lacks an objective quantitative environmental–visual comfort index that combines subjective and objective indicators. For this experiment, objective eye movement and electroencephalogram (EEG) signals were collected in combination with a subjective questionnaire survey and a preference inquiry for comprehensive data mining. Finally, the results on a Likert scale show that high screen brightness can reduce the visual fatigue of subjects under high illuminance and high correlated color temperature (CCT). Pupil data show that, under medium and high ambient illuminance, visual perception sensitivity is more likely to be stimulated, and visual fatigue is more likely to deepen. EEG data show that visual fatigue is related to illuminance and screen brightness. On this basis, this study proposes a new evaluation index, the visual comfort level (0.6404 average at a low screen brightness, 0.4218 average at a medium screen brightness, and 0.5139 average at a high screen brightness), where a higher score for the visual comfort level represents a better visual experience. The visual comfort level provides a useful reference for enhancing the processing of multi-dimensional and biomedical signals and protecting the eyes. © 2024 by the authors.",EEG; light sources; pupil; screen brightness; visual comfort level,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85203662582,Movies / Media
,,,MuC 2024 - Proceedings of the 2024 Mensch und Computer,2024,ACM International Conference Proceeding Series,,,,,,707.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203702708&partnerID=40&md5=00331a41605f9582a5100b1aa30d941c,The proceedings contain 81 papers. The topics discussed include: UnitEye: introducing a user-friendly plugin to democratize eye tracking technology in unity environments; statistical analysis of eye movement data for beginners; multimodal detection of external and internal attention in virtual reality using EEG and eye tracking features; physiological and perceptual effects of avatars’ muscularity while rowing in virtual reality; do you dare to ask? influence of question recipient and information medium on prompting preparatory questions for MR imaging; from skepticism to acceptance: a qualitative study on the dynamics of elderly engagement with mixed reality; beyond screen time: exploring smartwatch interventions for digital well-being; and leaf your chair behind—calm persuasion for frequent sitting breaks among office-workers.,,,Conference review,Final,,Scopus,2-s2.0-85203702708,Movies / Media
Uchikoshi M.; Yu L.; Hattori Y.,"Uchikoshi, Makiko (6603534332); Yu, Lira (56640182000); Hattori, Yuko (35229160600)",6603534332; 56640182000; 35229160600,Applying an eye tracking technique to gibbons: First study using scanpath measurements for visual stimuli,2024,Behavioural Processes,221,,105080,,,,0,10.1016/j.beproc.2024.105080,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199952590&doi=10.1016%2fj.beproc.2024.105080&partnerID=40&md5=78d481f7e5397d20f0d853b0d73316fe,"Compared to the abundance of research on cognition in various nonhuman primate species, studies of gibbons – often called “the small apes” – remain limited, despite the importance of gibbons for understanding evolutionary processes in humans and other apes. Over the past decade, eye tracking techniques have been established in chimpanzees and other nonhuman primates using the free-participation method, which requires no physical restraint of the subjects. We investigated the feasibility of using the same method to record visual scanpaths in gibbons. We attempted to measure the eye movements of three adult gibbons while they spontaneously viewed images, with no prior fixation training. Calibration was successful in all three individuals, with errors of less than one degree. In total, 24 stimuli were used, with landscape and nonhuman primate face photographs presented on one-quarter of the screen, to test the prediction that gibbons would change their viewing time depending on image category. All three gibbons viewed the images for longer than the background, and primate face images for longer than landscapes. These results are consistent with previous findings in other primate species that faces attract more attention than non-face stimuli, suggesting that this effect is common across primates. This study demonstrates the feasibility of using eye tracking with gibbons. Further studies on gibbon visual exploration and cognition may enhance our understanding of the phylogenetic origins of hominid intelligence as well as the unique evolution of gibbons. © 2024 Elsevier B.V.",Comparative cognition; Eye-tracking; Gibbons; Methodology; Visual attention,Animals; Attention; Eye Movements; Eye-Tracking Technology; Female; Hylobates; Male; Photic Stimulation; Visual Perception; cognition; fixation; hominid; local participation; prediction; primate; tracking; visualization; adult; animal tissue; article; calibration; chimpanzee; cognition; controlled study; eye movement; eye tracking; eye-tracking technology; hominid; human; Hylobatidae; intelligence; male; nonhuman; participation; photography; physical restraint; prediction; visual attention; animal; attention; eye movement; female; Hylobates; photostimulation; physiology; procedures; vision,Article,Final,,Scopus,2-s2.0-85199952590,Movies / Media
Pei Y.; Wang L.; Xue C.,"Pei, Yuying (58745947200); Wang, Linlin (57203459083); Xue, Chengqi (14053333400)",58745947200; 57203459083; 14053333400,Human–AI Co-Drawing: Studying Creative Efficacy and Eye Tracking in Observation and Cooperation,2024,Applied Sciences (Switzerland),14,18,8203,,,,1,10.3390/app14188203,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205310585&doi=10.3390%2fapp14188203&partnerID=40&md5=965e43c3053e10ecb6aa0655006aec12,"Artificial intelligence (AI) tools are rapidly transforming the field of traditional artistic creation, influencing painting processes and human creativity. This study explores human–AI cooperation in real-time artistic drawing by using the AIGC tool KREA.AI. Participants wear eye trackers and perform drawing tasks by adjusting the AI parameters. The research aims to investigate the impact of cross-screen and non-cross-screen conditions, as well as different viewing strategies, on cognitive load and the degree of creative stimulation during user–AI collaborative drawing. Adopting a mixed design, it examines the influence of different cooperation modes and visual search methods on creative efficacy and visual perception through eye-tracking data and creativity performance scales. The cross-screen type and task type have a significant impact on total interval duration, number of fixation points, average fixation duration, and average pupil diameter in occlusion decision-making and occlusion hand drawing. There are significant differences in the variables of average gaze duration and average pupil diameter among different task types and cross-screen types. In non-cross-screen situations, occlusion and non-occlusion have a significant impact on average gaze duration and pupil diameter. Tasks in non-cross-screen environments are more sensitive to visual processing. The involvement of AI in hand drawing in non-cross-screen collaborative drawing by designers has a significant impact on their visual perception. These results help us to gain a deeper understanding of user behaviour and cognitive load under different visual tasks and cross-screen conditions. The analysis of the creative efficiency scale data reveals significant differences in designers’ ability to supplement and improve AI ideas across different modes. This indicates that the extent of AI participation in the designer’s hand-drawn creative process significantly impacts the designer’s behaviour when negotiating design ideas with the AI. © 2024 by the authors.",creative efficacy; eye tracking; human–AI cooperation; human–computer co-drawing,Behavioral research; Drawing (graphics); Vision; Cognitive loads; Collaborative drawing; Condition; Creative efficacy; Creatives; Eye-tracking; Human–artificial intelligence cooperation; Human–computer co-drawing; Intelligence cooperation; Pupil diameter; Decision making,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85205310585,Movies / Media
McKee C.S.; Bleakley C.; Rankin A.; Matthews M.,"McKee, Connor Shane (59041589500); Bleakley, Chris (8256319500); Rankin, Alan (17346637900); Matthews, Mark (57190181954)",59041589500; 8256319500; 17346637900; 57190181954,Outcome measures used in adolescent sport-related concussion research: a scoping review,2024,BMJ Open,14,9,e075590,,,,0,10.1136/bmjopen-2023-075590,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204060403&doi=10.1136%2fbmjopen-2023-075590&partnerID=40&md5=d40a7f6f55ffbee35105ec0ad76d6540,"Objectives To provide an overview of the outcome measures currently used after sports-related concussion (SRC) in adolescents, categorising by the constructs they assess, follow-up duration and their feasibility of use. Design Scoping review. Data sources We searched three electronic databases (MEDLINE, EMBASE and CINAHL). We also undertook citation tracking of the included articles and searched for ongoing or unpublished trials using ClinicalTrials.gov and Theses Global. Eligibility criteria Studies tracking concussion recovery in adolescent athletes. Results 15 782 records were identified. After initial title and abstract screening, we retrieved 87 studies for full-text screening, with 75 studies fulfilling the eligibility criteria and included in the review, comprising 13 107 participants (9480 male, 3615 female and 12 unreported), ranging in age from 5 to 19 years. 46 different outcome measures were used, with Post-Concussion Symptom Scale (n=42) and Immediate Post-Concussion Assessment and Cognitive Testing (n=21) the most common. Most outcome measures quantified aspects of sensorimotor function including balance, oculomotor function and cognition. Follow-up duration ranged from 7 days to 1 year. 60% of studies ceased follow-up assessments within 6 weeks post-SRC. Conclusions Adolescent SRC literature uses a wide range of outcome measures. Most research quantifies cognitive/fatigue domains in the acute/subacute stages post-SRC, using male participants. Other key domains such as anxiety/mood, migraine and key modifiers (cervical and sleep disturbance) are less well represented in the literature. Many of the outcome measures used in current research are associated with high cost and require highly qualified examiners, creating barriers to their implementation in some adolescent sporting environments. © Author(s) (or their employer(s)) 2024.",,"Adolescent; Athletic Injuries; Brain Concussion; Child; Female; Humans; Male; Outcome Assessment, Health Care; biological marker; glial fibrillary acidic protein; ubiquitin thiolesterase; adolescent; adult; anxiety; Anxiety Sensitivity Index; Article; athlete; child; clinician; cognition; electrocardiogram; electroencephalogram; eye movement control; feasibility study; female; follow up; Generalized Anxiety Disorder-7; global rating of change scale; hand grip; human; male; mood; neurologic examination; nuclear magnetic resonance imaging; outcome assessment; Patient Health Questionnaire 9; patient-reported outcome; post-concussion symptom scale; quality of life; questionnaire; Satisfaction with Life Scale; sensorimotor function; sleep; sport-related concussion; systematic review; treatment duration; working memory; youth sport; brain concussion; diagnosis; sport injury",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85204060403,Movies / Media
Keane B.P.; Silverstein S.M.; Papathomas T.V.; Krekelberg B.,"Keane, Brian P. (35279561600); Silverstein, Steven M. (7101686199); Papathomas, Thomas V. (7005253954); Krekelberg, Bart (6701355516)",35279561600; 7101686199; 7005253954; 6701355516,Correcting visual acuity beyond 20/20 improves contour element detection and integration: A cautionary tale for studies of special populations,2024,PLoS ONE,19,9,e0310678,,,,1,10.1371/journal.pone.0310678,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205140031&doi=10.1371%2fjournal.pone.0310678&partnerID=40&md5=9a40f14c4aeeaa2ef22e376524fbc3f7,"Contrary to popular lore, optimal visual acuity is typically better than 20/20. Could correcting acuity beyond 20/20 offer any benefit? An affirmative answer could present new confounds in studies of aging, development, psychiatric illness, neurodegenerative disorders, or any other population where refractive error might be more likely. An affirmative answer would also offer a novel explanation of inter-observer variability in visual performance. To address the question, we had individuals perform two well-studied visual tasks, once with 20/20 vision and once with optical correction, so that observers could see one line better on an eye chart. In the contour integration task, observers sought to identify the screen quadrant location of a sparsely defined (integrated) shape embedded in varying quantities of randomly oriented “noise” elements. In the collinear facilitation task, observers sought to detect a low-contrast element flanked by collinear or orthogonal high-contrast elements. In each case, displays were scaled in size to modulate element visibility and spatial frequency (4–12 cycles/deg). We found that improving acuity beyond 20/20 improved contour integration for the high spatial frequency displays. Although improving visual acuity did not affect collinear facilitation, it did improve detection of the central low-contrast target, especially at high spatial frequencies. These results, which were large in magnitude, suggest that optically correcting beyond 20/20 improves the detection and integration of contour elements, especially those that are smaller and of higher spatial frequency. Refractive blur within the normal range may confound special population studies, explain inter-observer differences, and meaningfully impact performance in low-visibility environments. © 2024 Keane et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,Adult; Female; Form Perception; Humans; Male; Visual Acuity; Young Adult; accuracy; adult; Article; degenerative disease; error; eye movement; facilitation; fatigue; female; human; hypermetropia; integration; mental disease; noise; observer variation; optical density; orientation; photoreceptor; psychophysics; retina fovea; visibility; visual acuity; visual field; visual stimulation; male; pattern recognition; physiology; visual acuity; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85205140031,Movies / Media
Li W.; Kuang Z.; Leng X.; Mayer R.E.; Wang F.,"Li, Wenjing (57195377465); Kuang, Ziyi (57256354300); Leng, Xiaoxue (58773248800); Mayer, Richard E. (7403065717); Wang, Fuxing (57191895027)",57195377465; 57256354300; 58773248800; 7403065717; 57191895027,Role of Gesturing Onscreen Instructors in Video Lectures: A Set of Three-level Meta-analyses on the Embodiment Effect,2024,Educational Psychology Review,36,3,67,,,,3,10.1007/s10648-024-09910-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197589167&doi=10.1007%2fs10648-024-09910-0&partnerID=40&md5=f6713a5be1fa37e8b52d68a29c0d06e2,"Although gesturing onscreen instructors are widely included in video lectures, it is still unclear whether, when, and how they are conducive to learning. To clarify this issue, we conducted a set of three-level meta-analyses of 662 effect sizes from 83 articles, spanning Web of Science, PsycINFO, ERIC, Education Research Complete, ProQuest Dissertations & Theses, and Google Scholar up to March 2024. We included randomized controlled trials of gesturing instructors in multimedia learning, measuring retention test score, transfer test score, fixation time, fixation count, cognitive load, and/or social perception across all languages of publication. Funnel plot and Egger sandwich test were used to assess risk of bias. Results showed that adding gesturing instructors improved retention (g = 0.28, 95% CI:[0.19,0.37]) and transfer test scores (g = 0.31, 95% CI:[0.21,0.41]), yielding an embodiment effect. This effect was stronger when the instructor displayed deictic, metaphorical, or a mixture of multiple gestures; when the instructor in the control condition was not visible; when the lecture was learner-paced and longer. Moreover, it increased learners’ social connection ratings and eye fixation time and count on core learning material (but only when deictic gestures were used). Thus, gesturing onscreen instructors may promote learning by social and cognitive paths, deepening our understanding of the role of gesturing onscreen instructors in multimedia learning and providing guidance for designing effective video lectures. More studies with clear experimental descriptions and eye-tracking studies are needed. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.",Embodiment; Gesturing instructor; Meta-analysis; Multimedia learning; Video lecture,,Article,Final,,Scopus,2-s2.0-85197589167,Movies / Media
Walcher S.; Korda Ž.; Körner C.; Benedek M.,"Walcher, Sonja (57203527419); Korda, Živa (58140250600); Körner, Christof (56225106900); Benedek, Mathias (13006425600)",57203527419; 58140250600; 56225106900; 13006425600,How workload and availability of spatial reference shape eye movement coupling in visuospatial working memory,2024,Cognition,249,,105815,,,,3,10.1016/j.cognition.2024.105815,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193239181&doi=10.1016%2fj.cognition.2024.105815&partnerID=40&md5=3742818ef5fc732f0347a6ec9a524a53,"Eyes are active in memory recall and visual imagination, yet our grasp of the underlying qualities and factors of these internally coupled eye movements is limited. To explore this, we studied 50 participants, examining how workload, spatial reference availability, and imagined movement direction influence internal coupling of eye movements. We designed a visuospatial working memory task in which participants mentally moved a black patch along a path within a matrix and each trial involved one step along this path (presented via speakers: up, down, left, or right). We varied workload by adjusting matrix size (3 × 3 vs. 5 × 5), manipulated availability of a spatial frame of reference by presenting either a blank screen (requiring participants to rely solely on their mental representation of the matrix) or spatial reference in the form of an empty matrix, and contrasted active task performance to two control conditions involving only active or passive listening. Our findings show that eye movements consistently matched the imagined movement of the patch in the matrix, not driven solely by auditory or semantic cues. While workload influenced pupil diameter, perceived demand, and performance, it had no observable impact on internal coupling. The availability of spatial reference enhanced coupling of eye movements, leading more frequent, precise, and resilient saccades against noise and bias. The absence of workload effects on coupled saccades in our study, in combination with the relatively high degree of coupling observed even in the invisible matrix condition, indicates that eye movements align with shifts in attention across both visually and internally represented information. This suggests that coupled eye movements are not merely strategic efforts to reduce workload, but rather a natural response to where attention is directed. © 2023",Embodiment; Eye behavior; Internal attentional focus; Internal coupling; Internally directed cognition; Overt and covert attention; Saccades; Visuospatial working memory,"Adult; Eye Movements; Female; Humans; Imagination; Male; Memory, Short-Term; Psychomotor Performance; Space Perception; Visual Perception; Young Adult; adult; article; attention; cognition; eye movement; female; human; human experiment; imagination; male; memory; mental representation; noise; normal human; pupil diameter; recall; saccadic eye movement; task performance; working memory; workload; depth perception; physiology; psychomotor performance; short term memory; vision; young adult",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85193239181,Movies / Media
Wei Q.; Dong W.; Yu D.; Wang K.; Yang T.; Xiao Y.; Long D.; Xiong H.; Chen J.; Xu X.; Li T.,"Wei, Qiuhong (57222967324); Dong, Wenxin (58037415600); Yu, Dongchuan (8252029100); Wang, Ke (57737415900); Yang, Ting (55866092700); Xiao, Yuanjie (58923533300); Long, Dan (58035699700); Xiong, Haiyi (57816132100); Chen, Jie (55441741600); Xu, Ximing (57209825371); Li, Tingyu (15832244100)",57222967324; 58037415600; 8252029100; 57737415900; 55866092700; 58923533300; 58035699700; 57816132100; 55441741600; 57209825371; 15832244100,Early identification of autism spectrum disorder based on machine learning with eye-tracking data,2024,Journal of Affective Disorders,358,,,326,334,8.0,8,10.1016/j.jad.2024.04.049,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192561968&doi=10.1016%2fj.jad.2024.04.049&partnerID=40&md5=106f8526f7f95297ff55c0e41315c6ce,"Background: Early identification of autism spectrum disorder (ASD) improves long-term outcomes, yet significant diagnostic delays persist. Methods: A retrospective cohort of 449 children (ASD: 246, typically developing [TD]: 203) was used for model development. Eye-movement data were collected from the participants watching videos that featured eye-tracking paradigms for assessing social and non-social cognition. Five machine learning algorithms, namely random forest, support vector machine, logistic regression, artificial neural network, and extreme gradient boosting, were trained to classify children with ASD and TD. The best-performing algorithm was selected to build the final model which was further evaluated in a prospective cohort of 80 children. The Shapley values interpreted important eye-tracking features. Results: Random forest outperformed other algorithms during model development and achieved an area under the curve of 0.849 (< 3 years: 0.832, ≥ 3 years: 0.868) on the external validation set. Of the ten most important eye-tracking features, three measured social cognition, and the rest were related to non-social cognition. A deterioration in model performance was observed using only the social or non-social cognition-related eye-tracking features. Limitations: The sample size of this study, although larger than that of existing studies of ASD based on eye-tracking data, was still relatively small compared to the number of features. Conclusions: Machine learning models based on eye-tracking data have the potential to be cost- and time-efficient digital tools for the early identification of ASD. Eye-tracking phenotypes related to social and non-social cognition play an important role in distinguishing children with ASD from TD children. © 2024 Elsevier B.V.",Autism spectrum disorder; Eye-tracking; Machine learning,"Algorithms; Autism Spectrum Disorder; Child; Child, Preschool; Early Diagnosis; Eye Movements; Eye-Tracking Technology; Female; Humans; Machine Learning; Male; Prospective Studies; Retrospective Studies; Social Cognition; Support Vector Machine; accuracy; algorithm; Article; artificial neural network; autism; child; classifier; cognition; cohort analysis; cross-sectional study; demographics; disease severity; eye tracking; female; human; machine learning; major clinical study; male; preschool child; random forest; retrospective study; saccadic velocity; sensitivity and specificity; social cognition; support vector machine; diagnosis; early diagnosis; eye movement; eye-tracking technology; pathophysiology; physiology; prospective study",Article,Final,,Scopus,2-s2.0-85192561968,Movies / Media
Leharanger M.; Liu P.; Vandromme L.; Balédent O.,"Leharanger, Maxime (58508974000); Liu, Pan (57190688101); Vandromme, Luc (57019167100); Balédent, Olivier (6602747852)",58508974000; 57190688101; 57019167100; 6602747852,Eye Tracking Post Processing to Detect Visual Artifacts and Quantify Visual Attention under Cognitive Task Activity during fMRI,2024,Sensors,24,15,4916,,,,0,10.3390/s24154916,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200913540&doi=10.3390%2fs24154916&partnerID=40&md5=decef53059b92259551cc61f8fbc2e75,"Determining visual attention during cognitive tasks using activation MRI remains challenging. This study aimed to develop a new eye-tracking (ET) post-processing platform to enhance data accuracy, validate the feasibility of subsequent ET-fMRI applications, and provide tool support. Sixteen volunteers aged 18 to 20 were exposed to a visual temporal paradigm with changing images of objects and faces in various locations while their eye movements were recorded using an MRI-compatible ET system. The results indicate that the accuracy of the data significantly improved after post-processing. Participants generally maintained their visual attention on the screen, with mean gaze positions ranging from 89.1% to 99.9%. In cognitive tasks, the gaze positions showed adherence to instructions, with means ranging from 46.2% to 50%. Temporal consistency assessments indicated prolonged visual tasks can lead to decreased attention during certain tasks. The proposed methodology effectively identified and quantified visual artifacts and losses, providing a precise measure of visual attention. This study offers a robust framework for future work integrating filtered eye-tracking data with fMRI analyses, supporting cognitive neuroscience research. © 2024 by the authors.",behavioral feedback; cognitive tasks; eye-tracking; signal processing; visual stimuli,Adolescent; Adult; Artifacts; Attention; Cognition; Eye Movements; Eye-Tracking Technology; Female; Humans; Magnetic Resonance Imaging; Male; Young Adult; Behavioral research; Eye movements; Magnetic resonance imaging; Behavioral feedback; Cognitive task; Data accuracy; Eye-tracking; Post-processing; Processing platform; Signal-processing; Visual artifacts; Visual Attention; Visual stimulus; adolescent; adult; artifact; attention; cognition; eye movement; eye-tracking technology; female; human; male; nuclear magnetic resonance imaging; physiology; procedures; young adult; Eye tracking,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85200913540,Movies / Media
Radons D.L.; Löbler M.L.; Visentini M.S.,"Radons, Daiane Lindner (56514037200); Löbler, Mauri Leodir (35789994700); Visentini, Monize Sâmara (56736472600)",56514037200; 35789994700; 56736472600,Validation of Decision-Making Experimental Tasks in a Social Commerce Environment; [Validação de Tarefas Experimentais de Decisão em Ambiente de Social Commerce],2024,Brazilian Business Review,21,5,e20221337,,,,0,10.15728/bbr.2022.1337.en,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204286451&doi=10.15728%2fbbr.2022.1337.en&partnerID=40&md5=f4eee3682aaa1e5cfd5e528e91ab53d6,"This study aimed to validate two purchase decision experimental tasks in a social commerce environment. This refers to online interactions and their contributions to users on websites in order to assist in their acquisition of goods and services. For that purpose, a quasi-experiment was developed to simulate the decision invoved in making a hotel reservation and purchasing a TV, using the eye tracking technique to analyze the processing of information. Task validation comprised the operationalization of the eye tracker, validation with specialists, and a pilot test. The fixation metrics and heat maps identified the areas of interest that received the most visual attention from the participants. It should be noted that the products’ recommendations were the most considered criterion. This study contributes to understanding the search for information and purchase decisions in social commerce. © 2024 FUCAPE Business School. All rights reserved.",Decision-Making Process; Experiment; Eye Tracker; Social Commerce,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85204286451,Movies / Media
Schmidt A.; Grey N.; Strauss C.; Gaysina D.,"Schmidt, Alexandra (57257179500); Grey, Nick (16137352700); Strauss, Clara (37038599500); Gaysina, Darya (24778218700)",57257179500; 16137352700; 37038599500; 24778218700,Predictors of treatment outcome of psychological therapies for common mental health problems (CMHP) in older adults: A systematic literature review,2024,Clinical Psychology Review,112,,102463,,,,0,10.1016/j.cpr.2024.102463,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197144312&doi=10.1016%2fj.cpr.2024.102463&partnerID=40&md5=1b57791ca2c4e81afadc9f57ca01d139,"Identifying factors that impact psychological treatment outcomes in older people with common mental health problems (CMHP) has important implications for supporting healthier and longer lives. The aim of the present study was to synthesise the evidence on predictors of psychological treatment outcomes in older people (aged 65+). PubMed, Scopus, Web of Science and PsycINFO were searched and 3929 articles were identified and screened, with 42 studies (N = 7978, M age = 68.9, SD age = 2.85) included: depression: k = 21, anxiety: k = 11, panic disorder: k = 3, mixed anxiety & depression: k = 3, PTSD: k = 2, various CMHP: k = 2, with CBT being the most common treatment (71%). The review identified 28 factors reported as significant predictors of treatment outcome in at least one study, across different domains: psychosocial (n = 9), clinical (n = 6), treatment-related (n = 6), socio-demographic (n = 4), neurobiological (n = 3). Homework completion was the most consistent predictor of positive treatment outcome. Baseline symptom severity was the most frequently studied significant predictor and across all conditions, with higher baseline symptom severity largely linked to worse treatment outcomes. No significant effects on treatment outcome were reported for gender, income and physical comorbidities. For a large majority of factors evidence was mixed or inconclusive. Further studies are required to identify factors affecting psychological treatment outcomes, which will be important for the development of personalised treatment approaches. © 2023",Anxiety; CBT; Depression; Late life; Moderator; Older adults,"Aged; Humans; Mental Disorders; Outcome Assessment, Health Care; Psychotherapy; Treatment Outcome; hydrocortisone; psychotropic agent; aged; agoraphobia; agoraphobic cognitions questionnaire; anxiety disorder; anxiety disorders interview schedule; assertiveness; Beck Anxiety Inventory; Beck Depression Inventory; Beck Hopelessness Scale; behavior therapy; behavioural couple therapy; blame (psychology); brain function; brain size; Brief Symptom Inventory; Center for Epidemiological Studies Depression Scale; Clinician Administered PTSD Scale; cluster B personality disorder; cognition; cognitive behavioral therapy; Cognitive Failures Questionnaire; cognitive flexibility; cognitive therapy; cohort analysis; comorbidity; confounding variable; coping; couple therapy; data extraction; demographics; denial; depression; Diagnostic and Statistical Manual of Mental Disorders; disease duration; disease severity; effective public health practice project; emotional support; ethnicity; executive function; expectation; exposure and response prevention; eye movement desensitization and reprocessing; female; follow up; gender; generalised anxiety disorder severity scale; generalized anxiety disorder; Generalized Anxiety Disorder Scale; Generalized Anxiety Disorder-7; Geriatric Depression Scale; Hamilton Anxiety Scale; Hamilton Depression Rating Scale; health care utilization; hippocampus; Hopkins Symptom Checklist-20; human; hydrocortisone blood level; hypochondriasis; income; information retrieval; International Classification of Diseases; interpersonal psychotherapy; interrater reliability; life stress; locus of control; male; marriage; medical service; Medline; mental disease; mild cognitive impairment; mindfulness-based cognitive therapy; mini international neuropsychiatric interview; Mini Mental State Examination; mixed anxiety and depression; mobility inventory avoidance scale; Montgomery Asberg Depression Rating Scale; neurobiology; neurosis; observational study; obsessive compulsive disorder; occupation; openness to experience; panic; Patient Health Questionnaire 9; patient reported outcomes measurement information system; Penn State Worry Questionnaire; personality; phobia; population research; post-traumatic diagnostic scale; posttraumatic growth (psychology); posttraumatic stress disorder; prefrontal cortex; problem solving; psychological counseling; psychological well-being; psychotherapy; PsycINFO; quick inventory of depressive symptomatology; race; randomized controlled trial (topic); religious behavior; Review; Schedule for Affective Disorders and Schizophrenia; Scopus; secondary analysis; selection bias; self concept; social anxiety; social support; sociodemographics; State Trait Anxiety Inventory; Stroop test; Structured Clinical Interview for DSM Disorders; Structured Interview Guide for the Hamilton Anxiety Scale; symptom scale self report; systematic review; tertiary education; therapeutic alliance; treatment outcome; verbal fluency; verbal paired associates retention; Web of Science; web-based intervention; Wisconsin Card Sorting Test; mental disease; outcome assessment; procedures; therapy; treatment outcome",Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85197144312,Movies / Media
Pirwani N.; Szabo A.,"Pirwani, Neha (59001369400); Szabo, Attila (8719927800)",59001369400; 8719927800,Sports and exercise-related smartphone use is antagonistic to hedonic use in regular exercisers: A cross-sectional study examining the roles of exercise frequency and duration,2024,Health Science Reports,7,8,e2271,,,,1,10.1002/hsr2.2271,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199995796&doi=10.1002%2fhsr2.2271&partnerID=40&md5=226af45cec6f1c48633fca64bc3ecca9,"Background: Hedonic smartphone use has been associated with dependence and addiction studied under the umbrella term Problematic Smartphone Use (PSU). Research usually explores total screen time as an index of PSU. A few studies suggest that exercise is inversely related to smartphone use time. However, it is unknown which primary characteristics of exercise behavior are related to more moderate smarthone use. Furthermore, the purpose of smartphone use, such as hedonic use associated with PSU versus utilitarian use, was not tested in the sports and exercise contexts. Hedonic use generally means playing with the smartphone for joy, distraction, and satisfaction. Utilitarian use implies practical and valuable use. There is a conjecture that sports involvement may foster utilitarian use through increased involvement in sports-related information-seeking, goal-setting, and self-monitoring. Methods: Therefore, we examined whether weekly exercise frequency, workout duration, and perceived exercise intensity relate to total daily smarthone and hedonic use and whether this relationship is mediated by sports-related utilitarian device use. We tested regularly exercising adults (n = 360, 132 males, Mage = 39.0 ± 9.8, Mweekly exercise = 5.8 ± 1.9) who volunteered for this study and provided demographic information about their exercise habits and smartphone use. Results: The results revealed that all exercise parameters mediated the total daily smartphone use, with perceived exercise intensity being a negative predictor. Further, exercise frequency and duration (but not intensity) positively predicted sports-related smartphone use, which inversely predicted hedonic use. Conclusion: These results suggest that exercise parameters directly relate to daily smartphone use, which completely mediates hedonic use. These findings may partially account for the frequently reported inverse relationship between regular exercise and PSU by suggesting that the connection is mediated via sports-related smartphone use. © 2024 The Author(s). Health Science Reports published by Wiley Periodicals LLC.",dependence; entertainment; internet; leisure; mobile phone,adult; aerobic exercise; Article; athlete; body mass; cross-sectional study; duration; exercise; exercise intensity; eye tracking; female; human; human experiment; information seeking; Internet; internet addiction; leisure; male; mobile phone addiction; physical activity; physiological stress; questionnaire; screen time; self care; self monitoring; self report; sport; training; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85199995796,Movies / Media
Hou W.; Jiang Y.; Yang Y.; Zhu L.; Li J.,"Hou, Wenwen (57217853959); Jiang, Yingying (57873309100); Yang, Yunmei (57576496300); Zhu, Liqi (14520635900); Li, Jing (54386939600)",57217853959; 57873309100; 57576496300; 14520635900; 54386939600,Evaluating the validity of eye-tracking tasks and stimuli in detecting high-risk infants later diagnosed with autism: A meta-analysis,2024,Clinical Psychology Review,112,,102466,,,,2,10.1016/j.cpr.2024.102466,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199105478&doi=10.1016%2fj.cpr.2024.102466&partnerID=40&md5=1c9fa934a67dd50cd47b89b9375ad95f,"Gaze abnormalities are well documented in infants at elevated risk for autism spectrum disorder (ASD). However, variations in experimental design and stimuli across studies have led to mixed results. The current meta-analysis aimed to identify which type of eye tracking task and stimulus are most effective at differentiating high-risk infants (siblings of children with ASD) who later meet diagnosis criteria from low-risk infants without familial autism. We synthesized 35 studies that used eye tracking to investigate gaze behavior in infants at high genetic risk for autism before 2 years of age. We found that stimulus features, regions of interest (ROIs) and study quality moderated effect sizes across studies. Overall, dynamic stimuli and socially-relevant regions in the social stimuli (i.e. the target and activity of characters' shared focus) reliably detected high-risk infants who later develop ASD. Attention disengagement task and stimuli depicting interactions between human and nonhuman characters could identify high-risk infants who later develop ASD and those who have autism-related symptoms but do not meet the diagnostic criteria as well. These findings provide sensitive and reliable early markers of ASD, which is helpful to develop objective and quantitative early autism screening and intervention tools. © 2024 Elsevier Ltd",Autism spectrum disorder (ASD); Early detection; Eye tracking; Gaze behavior; Infants,"Autism Spectrum Disorder; Eye-Tracking Technology; Fixation, Ocular; Humans; Infant; attentional bias; autism; comparative study; eye tracking; female; gaze; genetic risk; high risk infant; human; infant; low risk population; male; meta analysis; Review; social interaction; diagnosis; eye fixation; eye-tracking technology; pathophysiology; physiology",Review,Final,,Scopus,2-s2.0-85199105478,Movies / Media
Li S.; Zhang Y.; Li H.; Hao B.; He W.; Luo W.,"Li, Shuaixia (57196039902); Zhang, Yihan (58614518300); Li, Hui (59151999800); Hao, Bin (58305809700); He, Weiqi (23485431900); Luo, Wenbo (35574179600)",57196039902; 58614518300; 59151999800; 58305809700; 23485431900; 35574179600,"Is processing superiority a universal trait for all threats? Divergent impacts of fearful, angry, and disgusted faces on attentional capture",2024,Cortex,177,,,37,52,15.0,5,10.1016/j.cortex.2024.05.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194881273&doi=10.1016%2fj.cortex.2024.05.005&partnerID=40&md5=ee4edc86514069eef57c4efe14b80f06,"Fearful, angry, and disgusted facial expressions are evolutionarily salient and convey different types of threat signals. However, it remains unclear whether these three expressions impact sensory perception and attention in the same way. The present ERP study investigated the temporal dynamics underlying the processing of different types of threatening faces and the impact of attentional resources employed during a perceptual load task. Participants were asked to judge the length of bars superimposed over faces presented in the center of the screen. A mass univariate statistical approach was used to analyze the EEG data. Behaviorally, task accuracy was significantly reduced following exposure to fearful faces relative to neutral distractors, independent of perceptual load. The ERP results revealed that the P1 amplitude over the right hemisphere was found to be enhanced for fearful relative to disgusted faces, reflecting the rapid and coarse detection of fearful cues. The N170 responses elicited by fearful, angry, and disgusted faces were larger than those elicited by neutral faces, suggesting the largely automatic and preferential processing of threats. Furthermore, the early posterior negativity (EPN) component yielded increased responses to fearful and angry faces, indicating prioritized attention to stimuli representing acute threats. Additionally, perceptual load exerted a pronounced influence on the EPN and late positive potential (LPP), with larger responses observed in the low perceptual load condition, indicating goal-directed cognitive processing. Overall, the early sensory processing of fearful, angry, and disgusted faces is characterized by differential sensitivity in capturing attention automatically, despite the importance of these facial signals for survival. Fearful faces produce a strong interference effect and are processed with higher priority than angry and disgusted ones. © 2024 Elsevier Ltd",ERPs; Mass univariate statistics; Perceptual load; Threatening faces,Adult; Anger; Attention; Brain; Disgust; Electroencephalography; Emotions; Evoked Potentials; Facial Expression; Fear; Female; Humans; Male; Photic Stimulation; Reaction Time; Young Adult; adult; arousal; Article; attention; behavior; comparative study; controlled study; disgust; electroencephalogram; electrooculogram; emotion; eye movement; eyelid reflex; facial expression; female; human; human experiment; male; normal human; sensation; signal processing; threat; univariate analysis; vision; visual information; young adult; anger; attention; brain; electroencephalography; emotion; evoked response; fear; photostimulation; physiology; procedures; psychology; reaction time,Article,Final,,Scopus,2-s2.0-85194881273,Movies / Media
Witt J.; Schorer J.; Loffing F.; Roden I.,"Witt, Jelto (58663776900); Schorer, Jörg (55911448800); Loffing, Florian (36138894000); Roden, Ingo (55613294800)",58663776900; 55911448800; 36138894000; 55613294800,Eye-tracking research on teachers’ professional vision: A scoping review,2024,Teaching and Teacher Education,144,,104568,,,,4,10.1016/j.tate.2024.104568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189496093&doi=10.1016%2fj.tate.2024.104568&partnerID=40&md5=5ce54f3611b03b3382c9199afdc6960e,"This scoping review examines N = 16 peer-reviewed quantitative and mixed-method eye-tracking studies on pre- and in-service teachers' noticing and reasoning in classroom contexts published 2014 to 2022. Eye-tracking results suggest in-service teachers’ noticing is characterised by more frequent, shorter fixations on relevant areas-of-interest in watching video-stimuli or during teaching, whereas pre-service teachers show less frequent, more dispersed, irrelevant fixations potentially leading to a lack of reasoning. Results, however, are inconclusive between all reviewed studies. The findings indicate the benefits of quantitative attention measures for future professional vision research especially in mixed-method designs, which are still only rarely applied. © 2024 The Authors",Classroom management; Education; Eye movement; Gaze behaviour; Teaching; Visual attention,,Review,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85189496093,Movies / Media
Xu Y.-D.; Zhou X.-Y.; Wei S.-D.; Liu F.-T.; Zhao J.; Tang Y.-L.; Shen B.; Ding Z.-T.; Wu J.-J.; Sun Y.-M.; Wang J.,"Xu, Yi-Dan (57218941754); Zhou, Xin-Yue (57210204864); Wei, Si-Di (57219198181); Liu, Feng-Tao (55639885900); Zhao, Jue (56320709300); Tang, Yi-Lin (56320513100); Shen, Bo (57198796380); Ding, Zheng-Tong (7401550572); Wu, Jian-Jun (55713471600); Sun, Yi-Min (56262499600); Wang, Jian (55907493400)",57218941754; 57210204864; 57219198181; 55639885900; 56320709300; 56320513100; 57198796380; 7401550572; 55713471600; 56262499600; 55907493400,"Clinical features, disease progression, and nuclear imaging in ATXN2-related parkinsonism in a longitudinal cohort",2024,Neurological Sciences,45,7,,3191,3200,9.0,1,10.1007/s10072-024-07383-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184476754&doi=10.1007%2fs10072-024-07383-1&partnerID=40&md5=a6232ffeff5088fc23ee40af019d906d,"Background: Spinocerebellar ataxia 2 (SCA2) with a low range of CAG repeat expansion of ATXN2 gene can present with predominant or isolated parkinsonism that closely resembles Parkinson’s disease (PD). This study is aimed at comparing clinical features, disease progression, and nuclear imaging between ATXN2-related parkinsonism (ATXN2-P) and PD. Methods: Three hundred and seventy-seven clinically diagnosed PD with family history were screened by multiplex ligation-dependent probe amplification, whole-exome sequencing or target sequencing, and dynamic mutation testing of 10 SCA subtypes. The baseline and longitudinal clinical features as well as the dual-tracer positron emission tomography (PET) imaging were compared between ATXN2-P and genetically undefined familial PD (GU-fPD). Results: Fifteen ATXN2-P patients from 7 families and 50 randomly selected GU-fPD patients were evaluated. Significantly less resting tremor and more symmetric signs were observed in ATXN2-P than GU-fPD. No significant difference was found in motor progression and duration from onset to occurrence of fluctuation, dyskinesia, and recurrent falls between the two groups. Cognitive impairment and rapid-eye-movement sleep behavior disorder were more common in ATXN2-P. During follow-up, olfaction was relatively spared, and no obvious progression of cognition dysfunction evaluated by Mini-Mental State Examination scores was found in ATXN2-P. PET results of ATXN2-P demonstrated a symmetric, diffuse, and homogenous dopamine transporter loss of bilateral striatum and a glucose metabolism pattern inconsistent with that in PD. Conclusions: Symmetric motor signs and unique nuclear imaging might be the clues to distinguish ATXN2-P from GU-fPD. © Fondazione Società Italiana di Neurologia 2024.",ATXN2; Parkinsonism; Parkinson’s disease; Trinucleotide repeat diseases,"Adult; Aged; Ataxin-2; Cohort Studies; Disease Progression; Female; Humans; Longitudinal Studies; Male; Middle Aged; Parkinsonian Disorders; Positron-Emission Tomography; Spinocerebellar Ataxias; ataxin 2; cft c 11; dopamine transporter; fluorodeoxyglucose f 18; glucose; tracer; unclassified drug; ataxin 2; ATXN2 protein, human; adult; Article; clinical feature; cognitive defect; cohort analysis; controlled study; corpus striatum; disease duration; disease exacerbation; duration; dyskinesia; falling; family history; female; follow up; glucose metabolism; human; longitudinal study; major clinical study; male; Mini Mental State Examination; motor dysfunction; multiplex ligation dependent probe amplification; Parkinson disease; parkinsonism; pedigree; physical disease by body function; positron emission tomography; REM sleep behavior disorder; smelling; spinocerebellar degeneration; tremor; whole exome sequencing; aged; diagnostic imaging; disease exacerbation; genetics; middle aged; positron emission tomography",Article,Final,,Scopus,2-s2.0-85184476754,Movies / Media
Zukowski L.A.; Brinkerhoff S.A.; Levin I.; Herter T.M.; Hetrick L.; Lockhart S.N.; Miller M.E.; Laurienti P.J.; Kritchevsky S.B.; Hugenschmidt C.E.,"Zukowski, Lisa A. (53985764200); Brinkerhoff, Sarah A. (57210262688); Levin, Ilana (57193885728); Herter, Troy M. (8504686900); Hetrick, Lena (59199889400); Lockhart, Samuel N. (55147825800); Miller, Michael E. (57203774837); Laurienti, Paul J. (6603066653); Kritchevsky, Stephen B. (7005494101); Hugenschmidt, Christina E. (16480605500)",53985764200; 57210262688; 57193885728; 8504686900; 59199889400; 55147825800; 57203774837; 6603066653; 7005494101; 16480605500,Amyloid-β Deposition Predicts Grocery Shopping Performance in Older Adults Without Cognitive Impairment,2024,Journal of Alzheimer's Disease,100,1,,53,75,22.0,1,10.3233/JAD-231108,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197343648&doi=10.3233%2fJAD-231108&partnerID=40&md5=9e8681534739acb984dd64cd04aa6e0f,"Background: A screening tool sensitive to Alzheimer's disease (AD) risk factors, such as amyloid-β (Aβ) deposition, and subtle cognitive changes, best elicited by complex everyday tasks, is needed. Objective: To determine if grocery shopping performance could differentiate older adults at elevated risk of developing AD (OAer), older adults at low risk of developing AD (OAlr), and young adults (YA), and if amount of Aβ deposition could predict grocery shopping performance in older adults (OA). Methods: Twenty-one OAer (78±5 years), 33 OAlr (78±5 years), and 28 YA (31±3 years) performed four grocery shopping trials, with the best and worst performances analyzed. Measures included trial time, number of correct items, number of grocery note fixations, and number of fixations and percentage of time fixating on the correct shelving unit, correct brand, and correct shelf. Linear mixed effects models compared measures by performance rank (best, worst) and group (OAer, OAlr, YA), and estimated the effect of Aβ deposition on measures in OA. Results: Relative to their best performance, OAer and OAlr exhibited more correct shelving unit fixations and correct brand fixations during their worst performance, while YA did not. Within OA's worst performance, greater Aβ deposition was associated with a smaller percentage of time fixating on the correct shelving unit, correct shelf, and correct brand. Within OA, greater Aβ deposition was associated with more grocery note fixations. Conclusions: OA with elevated Aβ deposition may exhibit subtle working memory impairments and less efficient visual search strategies while performing a cognitively demanding everyday task.  © 2024-IOS Press. All rights reserved.",Alzheimer's disease; cognition; eye-Tracking; visual processing,"Activities of Daily Living; Adult; Aged; Aged, 80 and over; Aging; Alzheimer Disease; Amyloid beta-Peptides; Brain; Female; Humans; Male; Neuropsychological Tests; Positron-Emission Tomography; Young Adult; amyloid beta protein; Pittsburgh compound B; amyloid beta protein; aged; Alzheimer disease; Article; clinical article; controlled study; female; high risk patient; human; low risk patient; male; prediction; shopping; task performance; adult; aging; Alzheimer disease; brain; daily life activity; metabolism; neuropsychological assessment; physiology; positron emission tomography; psychology; very elderly; young adult",Article,Final,,Scopus,2-s2.0-85197343648,Movies / Media
Saleem M.R.; Mayne R.; Napolitano R.,"Saleem, Muhammad Rakeh (57645214200); Mayne, Robert (58108751700); Napolitano, Rebecca (57194621055)",57645214200; 58108751700; 57194621055,Evaluating Human Expert Knowledge in Damage Assessment Using Eye Tracking: A Disaster Case Study,2024,Buildings,14,7,2114,,,,1,10.3390/buildings14072114,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199639034&doi=10.3390%2fbuildings14072114&partnerID=40&md5=3a86f2ee0f74af62e2509054fbe17242,"The rising frequency of natural disasters demands efficient and accurate structural damage assessments to ensure public safety and expedite recovery. Human error, inconsistent standards, and safety risks limit traditional visual inspections by engineers. Although UAVs and AI have advanced post-disaster assessments, they still lack the expert knowledge and decision-making judgment of human inspectors. This study explores how expertise shapes human–building interaction during disaster inspections by using eye tracking technology to capture the gaze patterns of expert and novice inspectors. A controlled, screen-based inspection method was employed to safely gather data, which was then used to train a machine learning model for saliency map prediction. The results highlight significant differences in visual attention between experts and novices, providing valuable insights for future inspection strategies and training novice inspectors. By integrating human expertise with automated systems, this research aims to improve the accuracy and reliability of post-disaster structural assessments, fostering more effective human–machine collaboration in disaster response efforts. © 2024 by the authors.",damage assessment; disaster reconnaissance; eye tracking; fixation maps; saliency maps; visual features,Automation; Behavioral research; Damage detection; Decision making; Eye tracking; Image segmentation; Structural analysis; Case-studies; Damage assessments; Disaster reconnaissance; Expert and novices; Eye-tracking; Fixation map; Human expert knowledge; Post disasters; Saliency map; Visual feature; Disasters,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85199639034,Movies / Media
Carrillo González C.M.; Parra-Meroño M.C.; Juárez Varón D.; Gandía Sabater M.,"Carrillo González, Carmen María (58779130600); Parra-Meroño, María Concepción (53164426500); Juárez Varón, David (55790655400); Gandía Sabater, Marta (59359909800)",58779130600; 53164426500; 55790655400; 59359909800,Rational versus emotional products in the Eco food category. A packaging study using neuromarketing; [Productos racionales versus emocionales en categoría alimentación Eco. Un estudio de envases mediante neuromarketing],2024,European Public and Social Innovation Review,9,,,,,,0,10.31637/epsir-2024-786,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205918731&doi=10.31637%2fepsir-2024-786&partnerID=40&md5=23c7b54fc00813fc1edab129dfccf1b0,"Introduction: Society is changing in values and consumption, with a greater emphasis on health. Consumers are looking for healthy and sustainable foods, such as organic products, that respect the environment and their well-being. This paper investigates how consumers interact with packaging.in my opinion, the paper should be accepted. Methodology: Experiment with a group of 30 young people, through neuromarketing tools (Eye Tracking and EEG), to test if there are differences in the areas of interest of packaging in Eco foods, functional (milk) versus emotional (chocolate). Results: Eye Tracking indicates that individuals focus their attention primarily on the Eco features of both products. They stay longer and view the Eco content of the emotional product more often and consider the brand dispensable in both products. EEG shows greater brain performance when handling the products and greater emotional connection than when viewing the products on screen. Discussion and conclusions: For the recordings done with EEG biometry, the values are higher for the emotional product, so there is a better perception of the Eco chocolate packaging compared to the Eco milk packaging (on an emotional level) when handling the product, than with Eye Tracking. © 2024, HISIN (History of Information Systems). All rights reserved.",Consumer behavior; EEG; emotional; Eye Tracking; Neuromarketing; organic products; packaging; rational,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85205918731,Movies / Media
Thorup E.; Bölte S.; Falck-Ytter T.,"Thorup, Emilia (56392839400); Bölte, Sven (7003433798); Falck-Ytter, Terje (14026541100)",56392839400; 7003433798; 14026541100,Less frequent face looking in infancy is related to autism likelihood status but not diagnosis: A study of parent-infant interaction,2024,Research in Autism Spectrum Disorders,115,,102422,,,,2,10.1016/j.rasd.2024.102422,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194330864&doi=10.1016%2fj.rasd.2024.102422&partnerID=40&md5=7001e95b9caca23443bd8d48654f4238,"Background: Previous research suggest that autistic children look less at faces than neurotypically developing children, but this finding is based predominantly on screen-based eye tracking studies, with unfamiliar faces used as stimuli. The aim of the current study was to assess 10-month-olds’ gaze to faces in a more naturalistic context - during free play with a parent - in relation to later autism diagnosis. Method: Parents were asked to play with their infant ‘as they usually would’ with a set of toys on the floor. During the first 5 min of play, infant gaze to parent's face was video coded. Results: Infants at elevated likelihood of autism (N = 18 with later diagnosis; 46 without later diagnosis), regardless of later diagnostic status, produced fewer gaze shifts towards their parents’ faces than infants at low likelihood of autism (N = 18). Infants in all groups spent only ∼3 % of their time looking at parents’ faces, and there was no group difference in terms of the proportion of time spent looking at faces. There was neither a correlation between infant face looking and scores on the Autism Diagnostic Observation Schedule-2, nor between infant face looking and autistic traits in the parent. Conclusions: During toy play, all infants – irrespective of later diagnosis – spent very little time looking at parents’ faces. Infants at elevated likelihood of autism made fewer gazes to their parents’ faces than neurotypically developing infants, which could potentially affect opportunities for social learning. The effect was not specifically linked to later autism diagnosis. © 2024 The Authors",Autism; Face preference; Parent-infant interaction; Social attention; Socio-cognitive development,Article; autism; Autism Diagnostic Observation Schedule; autism-spectrum quotient; child parent relation; clinical article; female; gaze; human; infant; male; Mullen scales of early learning; videorecording,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85194330864,Movies / Media
Özdel S.; Rong Y.; Albaba B.M.; Kuo Y.-L.; Wang X.; Kasneci E.,"Özdel, Süleyman (58317529800); Rong, Yao (57215968958); Albaba, Berat Mert (57211575098); Kuo, Yen-Ling (57207831987); Wang, Xi (59070755800); Kasneci, Enkelejda (56059892600)",58317529800; 57215968958; 57211575098; 57207831987; 59070755800; 56059892600,A Transformer-Based Model for the Prediction of Human Gaze Behavior on Videos,2024,Eye Tracking Research and Applications Symposium (ETRA),,,1,,,,4,10.1145/3649902.3653439,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196524314&doi=10.1145%2f3649902.3653439&partnerID=40&md5=7fc8492fb9f36420641eba4734f265f2,"Eye-tracking applications that utilize the human gaze in video understanding tasks have become increasingly important. To effectively automate the process of video analysis based on eye-tracking data, it is important to accurately replicate human gaze behavior. However, this task presents significant challenges due to the inherent complexity and ambiguity of human gaze patterns. In this work, we introduce a novel method for simulating human gaze behavior. Our approach uses a transformer-based reinforcement learning algorithm to train an agent that acts as a human observer, with the primary role of watching videos and simulating human gaze behavior. We employed an eye-tracking dataset gathered from videos generated by the VirtualHome simulator, with a primary focus on activity recognition. Our experimental results demonstrate the effectiveness of our gaze prediction method by highlighting its capability to replicate human gaze behavior and its applicability for downstream tasks where real human-gaze is used as input.  © 2024 ACM.",Action recognition; Eye-tracking; Human attention; Human gaze prediction,Behavioral research; Forecasting; Learning algorithms; Reinforcement learning; Action recognition; Eye-tracking; Gaze behaviours; Human attention; Human gaze prediction; Inherent complexity; Tracking application; Tracking data; Video analysis; Video understanding; Eye tracking,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85196524314,Movies / Media
Mayer-Suess L.; Ibrahim A.; Moelgg K.; Cesari M.; Knoflach M.; Högl B.; Stefani A.; Kiechl S.; Heidbreder A.,"Mayer-Suess, Lukas (57199394766); Ibrahim, Abubaker (57221936675); Moelgg, Kurt (57222361404); Cesari, Matteo (59061836200); Knoflach, Michael (6506563484); Högl, Birgit (57024774200); Stefani, Ambra (56383497100); Kiechl, Stefan (57207788534); Heidbreder, Anna (16042294500)",57199394766; 57221936675; 57222361404; 59061836200; 6506563484; 57024774200; 56383497100; 57207788534; 16042294500,"Sleep disorders as both risk factors for, and a consequence of, stroke: A narrative review",2024,International Journal of Stroke,19,5,,490,498,8.0,16,10.1177/17474930231212349,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177033876&doi=10.1177%2f17474930231212349&partnerID=40&md5=9f8b79aad014f0d857cef35a5701f715,"Background and purpose: Sleep disorders are increasingly implicated as risk factors for stroke, as well as a determinant of stroke outcome. They can also occur secondary to the stroke itself. In this review, we describe the variety of different sleep disorders associated with stroke and analyze their effect on stroke risk and outcome. Methods: A search term-based literature review (“sleep,” “insomnia,” “narcolepsy,” “restless legs syndrome,” “periodic limb movements during sleep,” “excessive daytime sleepiness” AND “stroke” OR “cerebrovascular” in PubMed; “stroke” and “sleep” in ClinicalTrials.gov) was performed. English articles from 1990 to March 2023 were considered. Results: Increasing evidence suggests that sleep disorders are risk factors for stroke. In addition, sleep disturbance has been reported in half of all stroke sufferers; specifically, an increase is not only sleep-related breathing disorders but also periodic limb movements during sleep, narcolepsy, rapid eye movement (REM) sleep behavior disorder, insomnia, sleep duration, and circadian rhythm sleep–wake disorders. Poststroke sleep disturbance has been associated with worse outcome. Conclusion: Sleep disorders are risk factors for stroke and associated with worse stroke outcome. They are also a common consequence of stroke. Recent guidelines suggest screening for sleep disorders after stroke. It is possible that treatment of sleep disorders could both reduce stroke risk and improve stroke outcome, although further data from clinical trials are required. © 2023 World Stroke Organization.",insomnia; narcolepsy; PLMS; prevention; RBD; RLS; sleep; Stroke,Humans; Risk Factors; Sleep Wake Disorders; Stroke; melatonin; anxiety; atrial fibrillation; behavior disorder; blood pressure; cerebrovascular accident; circadian rhythm; clinical trial (topic); cognitive behavioral therapy; continuous positive airway pressure; daytime somnolence; degenerative disease; dementia; depression; diabetes mellitus; dysphagia; eye movement; fatigue; hematocrit; hemodynamics; human; hypersomnia; hypertension; hypoxemia; insomnia; narcolepsy; nonhuman; nonREM sleep; obesity; obstructive sleep apnea; periodic limb movement disorder; polysomnography; prevalence; randomized controlled trial (topic); Rankin scale; REM sleep; restless legs syndrome; Review; risk factor; sleep apnea syndromes; sleep deprivation; sleep disorder; sleep quality; sleep time; sleep waking cycle; somnolence; complication; epidemiology; risk factor,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85177033876,Movies / Media
Li X.; Shen M.; Shen Z.; Han Z.; Jiao J.; Tong X.,"Li, Xudong (13908143400); Shen, Miaoxin (57211949843); Shen, Zhihong (58798684600); Han, Ziling (57222512703); Jiao, Jinsong (7102382957); Tong, Xiaopeng (57222513318)",13908143400; 57211949843; 58798684600; 57222512703; 7102382957; 57222513318,Reading the mind in the eyes in patients with idiopathic REM sleep behavior disorder,2024,Neurological Sciences,45,6,,2697,2703,6.0,0,10.1007/s10072-024-07303-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181716343&doi=10.1007%2fs10072-024-07303-3&partnerID=40&md5=403842b9a7196d2dce350091a72e5318,"Objectives: Idiopathic rapid eye movement (REM) sleep behavior disorder (iRBD) is characterized by vocalizations, jerks, and motor behaviors during REM sleep, often associated with REM-related dream content, which is considered a prodromal stage of α-synucleinopathy. The results of the Reading the Mind in the Eyes (RME) reflecting affective Theory of Mind (ToM) are inconsistent in α-synucleinopathy. The present study tried to investigate the RME in patients with iRBD. Methods: A total of 35 patients with iRBD and 26 healthy controls were included in the study. All participants were administered the RME and the cognitive assessments according to a standard procedure. The patients with iRBD were further divided into two groups (high or low RME) according to the scores of the RME (> 21, or ≤ 20). Results: The patients with iRBD had worse scores on cognitive tests compared with healthy controls involving global cognitive screening, memory, and visuospatial abilities (p < 0.05), but the scores of the RME were similar between the two groups (20.83 ± 3.38, 20.58 ± 3.43) (p ˃ 0.05). Patients with low RME had more obvious cognitive impairments than healthy controls. After applying Bonferroni correction for multiple tests, the low REM group only performed worse on the Sum of trials 1 to 5 and delayed recall of the RAVLT compared with the healthy control group (p < 0.001, = 0.002). The RME correlated with the scores of cognitive tests involving executive function, attention, memory, and visuospatial function. Conclusions: The changes in RME had a relationship with cognitive impairments, especially memory, in patients with iRBD. © Fondazione Società Italiana di Neurologia 2024.",Cognition; Idiopathic rapid eye movement sleep behavior disorder; Reading the mind in the eyes; Synucleinopathy; Theory of Mind,Aged; Cognitive Dysfunction; Female; Humans; Male; Middle Aged; Neuropsychological Tests; REM Sleep Behavior Disorder; Theory of Mind; adult; aged; Article; attention; clinical article; clinical evaluation; cognition; cohort analysis; controlled study; correlation coefficient; executive function; female; human; Kolmogorov Smirnov test; locomotion; male; memory; middle aged; Mini Mental State Examination; parasomnia; percentage of REM sleep; recall; REM sleep; REM sleep behavior disorder; sex determination; statistical significance; synucleinopathy; theory of mind; vocalization; cognitive defect; neuropsychological assessment; pathophysiology; physiology; psychology,Article,Final,,Scopus,2-s2.0-85181716343,Movies / Media
Chen-Sankey J.; Weiger C.; La Capria K.,"Chen-Sankey, Julia (57205214429); Weiger, Caitlin (57191092881); La Capria, Kathryn (58541610600)",57205214429; 57191092881; 58541610600,Using Eye tracking to Examine Young Adults' Visual Attention to E-cigarette Advertising Features and Associated Positive E-cigarette Perceptions,2024,Annals of Behavioral Medicine,58,6,,445,456,11.0,4,10.1093/abm/kaae018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194095549&doi=10.1093%2fabm%2fkaae018&partnerID=40&md5=6dfd24c9c55546db8ea056f6084af800,"Background: Little is known about the influence of e-cigarette marketing features on the antecedents of e-cigarette use. Purpose: Using an eye-Tracking experiment, we examined visual attention to common features in e-cigarette ads and its associations with positive e-cigarette perceptions among young adults. Methods: Young adults (ages 18-29) who smoke cigarettes (n = 40) or do not use tobacco (n = 71) viewed 30 e-cigarette ads on a computer screen. Eye-Tracking technology measured dwell time (fixation duration) and entry time (time to first fixation) for 14 pre-defined ad features. Participants then completed a survey about perceptions of e-cigarettes shown in the ads. We used regression models to examine the associations between ad features and standardized attention metrics among all participants and by tobacco-use status and person-Aggregated standardized attention for each ad feature and positive e-cigarette perceptions. Results: Dwell time was the longest for smoker-Targeted claims, positive experience claims, and price promotions. Entry time was the shortest for multiple flavor descriptions, nicotine warnings, and people. Those who do not use tobacco had a longer dwell time for minor sales restrictions and longer entry time for purchasing information than those who smoke. Longer dwell time for multiple flavor descriptions was associated with e-cigarette appeal. A shorter entry time for fruit flavor description was associated with positive e-cigarette-use expectancies. Conclusions: Young adults allocated attention differently to various e-cigarette ad features, and such viewing patterns were largely similar by tobacco-use statuses. Multiple or fruit flavors may be the features that contribute to the positive influence of e-cigarette marketing among young adults.  © 2024 The Author(s). Published by Oxford University Press on behalf of the Society of Behavioral Medicine.",Advertisement features; E-cigarettes; Eye-Tracking; Marketing influence; Young adults,Adolescent; Adult; Advertising; Attention; Electronic Nicotine Delivery Systems; Eye-Tracking Technology; Female; Humans; Male; Vaping; Young Adult; adolescent; adult; advertising; attention; electronic cigarette; eye-tracking technology; female; human; male; psychology; vaping; young adult,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85194095549,Movies / Media
Fantozzi P.M.; Anil A.; McHugh S.; Srsich A.R.; Zope M.; Parish-Morris J.; Schultz R.T.; Herrington J.; Hocking M.C.,"Fantozzi, Peter M. (57207197568); Anil, Ashley (58582487600); McHugh, Sean (58089855300); Srsich, Alannah R. (58635314100); Zope, Manali (58932197200); Parish-Morris, Julia (17346649600); Schultz, Robert T. (57818870200); Herrington, John (35884707600); Hocking, Matthew C. (12761299200)",57207197568; 58582487600; 58089855300; 58635314100; 58932197200; 17346649600; 57818870200; 35884707600; 12761299200,Social impairment in survivors of pediatric brain tumors via reduced social attention and emotion-specific facial expression recognition,2024,Pediatric Blood and Cancer,71,6,e30943,,,,3,10.1002/pbc.30943,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187432321&doi=10.1002%2fpbc.30943&partnerID=40&md5=45dd04e04e7b34a29131dda55d52300f,"Background/objectives: Survivors of pediatric brain tumors (SPBT) experience significant social challenges, including fewer friends and greater isolation than peers. Difficulties in face processing and visual social attention have been implicated in these outcomes. This study evaluated facial expression recognition (FER), social attention, and their associations with social impairments in SPBT. Methods: SPBT (N = 54; ages 7–16) at least 2 years post treatment completed a measure of FER, while parents completed measures of social impairment. A subset (N = 30) completed a social attention assessment that recorded eye gaze patterns while watching videos depicting pairs of children engaged in joint play. Social Prioritization scores were calculated, with higher scores indicating more face looking. Correlations and regression analyses evaluated associations between variables, while a path analysis modeling tool (PROCESS) evaluated the indirect effects of Social Prioritization on social impairments through emotion-specific FER. Results: Poorer recognition of angry and sad facial expressions was significantly correlated with greater social impairment. Social Prioritization was positively correlated with angry FER but no other emotions. Social Prioritization had significant indirect effects on social impairments through angry FER. Conclusion: Findings suggest interventions aimed at improving recognition of specific emotions may mitigate social impairments in SPBT. Further, reduced social attention (i.e., diminished face looking) could be a factor in reduced face processing ability, which may result in social impairments. Longitudinal research is needed to elucidate temporal associations between social attention, face processing, and social impairments. © 2024 The Authors. Pediatric Blood & Cancer published by Wiley Periodicals LLC.",brain tumor; face processing; social attention,Adolescent; Attention; Brain Neoplasms; Cancer Survivors; Child; Emotions; Facial Expression; Facial Recognition; Female; Follow-Up Studies; Humans; Male; adolescent; Article; attention; brain tumor; child; confidence interval; controlled study; descriptive research; emotion; facial expression; facial recognition; female; gaze; human; intelligence quotient; major clinical study; male; path analysis; peer acceptance; play; social behavior; cancer survivor; follow up; psychology,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85187432321,Movies / Media
Sujaini H.; Safriadi N.; Khairiyah D.,"Sujaini, Herry (53265170700); Safriadi, Novi (57208839386); Khairiyah, Dian (59180843000)",53265170700; 57208839386; 59180843000,System interactive reader using eye-tracker technology in ebook reader,2024,Bulletin of Electrical Engineering and Informatics,13,3,,1676,1684,8.0,1,10.11591/eei.v13i3.5877,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196491903&doi=10.11591%2feei.v13i3.5877&partnerID=40&md5=023bdb08ceb37275eee7508100656532,"Interest in using ebooks by the academic community is very high. Still, there is a problem when readers are reading through screens, tend to read fast, only scan the necessary parts, and don't focus on paying attention to the content they read, so this reduces the quality of reading because readers don't study the overall meaning of the sentence. Hence, this research aims to build an interactive reader system by integrating eye tracker technology with a webcam which is expected to solve the problem of decreasing the quality of reading through the screen by helping readers stay focused on their reading and providing an interactive system that makes it easier for readers to control the computer while reading. This research adopts the waterfall method and is divided into six stages. The system is designed using class diagrams, use case diagrams, and activity diagrams. Also, the system is built using the Python language with the Django framework. Then, the interactive reader system was tested using black box testing and usability testing methods. Based on the test results, it is shown that the interactive reader system that was built can help improve the quality and concentration when reading activities take place. © 2024, Institute of Advanced Engineering and Science. All rights reserved.",Django framework; Ebook reader; Eye tracker; Interactive system; Reading activity,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85196491903,Movies / Media
Urbanus E.; Swaab H.; Tartaglia N.; Van Rijn S.,"Urbanus, Evelien (57205197267); Swaab, Hanna (8296112400); Tartaglia, Nicole (6602924707); Van Rijn, Sophie (8296112100)",57205197267; 8296112400; 6602924707; 8296112100,"Social Communication in Young Children with Sex Chromosome Trisomy (XXY, XXX, XYY): A Study with Eye Tracking and Heart Rate Measures",2024,Archives of Clinical Neuropsychology,39,4,,482,497,15.0,1,10.1093/arclin/acad088,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194084429&doi=10.1093%2farclin%2facad088&partnerID=40&md5=1847d7fe8ccdf38d3e6b1b7f63cabeab,"Objective: Children with sex chromosome trisomy (SCT) have an increased risk for suboptimal development. Difficulties with language are frequently reported, start from a very young age, and encompass various domains. This cross-sectional study examined social orientation with eye tracking and physiological arousal responses to gain more knowledge on how children perceive and respond to communicative bids and evaluated the associations between social orientation and language outcomes, concurrently and 1 year later. Method: In total, 107 children with SCT (33 XXX, 50 XXY, and 24 XYY) and 102 controls (58 girls and 44 boys) aged between 1 and 7 years were included. Assessments took place in the USA and Western Europe. A communicative bids eye tracking paradigm, physiological arousal measures, and receptive and expressive language outcomes were used. Results: Compared to controls, children with SCT showed reduced attention to the face and eyes of the on-screen interaction partner and reduced physiological arousal sensitivity in response to direct versus averted gaze. In addition, social orientation to the mouth was related to concurrent receptive and expressive language abilities in 1-year-old children with SCT. Conclusions: Children with SCT may experience difficulties with social communication that extend past the well-recognized risk for early language delays. These difficulties may underlie social-behavioral problems that have been described in the SCT population and are an important target for early monitoring and support.  © 2023 The Author(s). Published by Oxford University Press. All rights reserved.",Early development; Eye tracking; Language and communication; Physiological arousal; Sex chromosome trisomy; Social orientation,"Child; Child, Preschool; Communication; Cross-Sectional Studies; Eye-Tracking Technology; Female; Heart Rate; Humans; Infant; Male; Sex Chromosome Aberrations; Trisomy; child; cross-sectional study; eye-tracking technology; female; heart rate; human; infant; interpersonal communication; male; pathophysiology; physiology; preschool child; sex chromosome aberration; trisomy",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85194084429,Movies / Media
Signes-Soler I.; Ragot A.; Nangena S.; Wekesa A.; Llamusí R.M.,"Signes-Soler, Isabel (39262515300); Ragot, Alfred (59005869600); Nangena, Sheilah (59006139000); Wekesa, Andrew (59455420200); Llamusí, Raúl Montalbán (57802021000)",39262515300; 59005869600; 59006139000; 59455420200; 57802021000,"Prevalence of visual impairment and estimation of refractive errors among school children in Kakamega, Kenya",2024,International Journal of Ophthalmology,17,5,,932,939,7.0,1,10.18240/ijo.2024.05.19,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191571373&doi=10.18240%2fijo.2024.05.19&partnerID=40&md5=11cee8d6828fc8b8cede247b524d2d5e,"• AIM: To investigate the prevalence of visual impairment (VI) and provide an estimation of uncorrected refractive errors in school-aged children, conducted by optometry students as a community service. • METHODS: The study was cross-sectional. Totally 3343 participants were included in the study. The initial examination involved assessing the uncorrected distance visual acuity (UDVA) and visual acuity (VA) while using a +2.00 D lens. The inclusion criteria for a subsequent comprehensive cycloplegic eye examination, performed by an optometrist, were as follows: a UDVA<0.6 decimal (0.20 logMAR) and/or a VA with +2.00 D ≥0.8 decimal (0.96 logMAR). • RESULTS: The sample had a mean age of 10.92±2.13y (range 4 to 17y), and 51.3% of the children were female (n=1715). The majority of the children (89.7%) fell within the age range of 8 to 14y. Among the ethnic groups, the highest representation was from the Luhya group (60.6%) followed by Luo (20.4%). Mean logMAR UDVA choosing the best eye for each student was 0.29±0.17 (range 1.70 to 0.22). Out of the total, 246 participants (7.4%) had a full eye examination. The estimated prevalence of myopia (defined as spherical equivalent ≤-0.5 D) was found to be 1.45% of the total sample. While around 0.18% of the total sample had hyperopia value exceeding +1.75 D. Refractive astigmatism (cil<-0.75 D) was found in 0.21% (7/3343) of the children. The VI prevalence was 1.26% of the total sample. Among our cases of VI, 76.2% could be attributed to uncorrected refractive error. Amblyopia was detected in 0.66% (22/3343) of the screened children. There was no statistically significant correlation observed between age or gender and refractive values. • CONCLUSION: The primary cause of VI is determined to be uncorrected refractive errors, with myopia being the most prevalent refractive error observed. These findings underscore the significance of early identification and correction of refractive errors in school-aged children as a means to alleviate the impact of VI. © 2024 International Journal of Ophthalmology (c/o Editorial Office). All rights reserved.",amblyopia; myopia; refractive errors; sustainable development goals; visual impairment,cyclopentolate; adolescent; adult; amblyopia; Article; astigmatism; awareness; biomicroscopy; cataract; cataract extraction; child; congenital cataract; convergent strabismus; cross-sectional study; diabetic macular edema; diabetic retinopathy; error; ethnicity; eye axis length; eye examination; eye movement; fatigue; female; glaucoma; health care access; human; hypermetropia; intraocular pressure; Kenya; Kolmogorov Smirnov test; major clinical study; male; myopia; optical coherence tomography; optical coherence tomography angiography; prevalence; psychometry; quality of life; questionnaire; refraction error; school child; social phobia; social welfare; subcapsular cataract; visual acuity; visual impairment; visual system parameters; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85191571373,Movies / Media
Li X.; Zhang R.; Wang T.; Dong Y.; Chen Y.,"Li, Xueshun (58904750100); Zhang, Ruinan (57217824976); Wang, Taiyang (58085553800); Dong, Yu (41761203400); Chen, Yang (56809854900)",58904750100; 57217824976; 58085553800; 41761203400; 56809854900,Using Machine Learning to Optimize the Visual Perceptual Environment of Inter-house Leisure Spaces in Cold Winter Environments,2024,ACM International Conference Proceeding Series,,,,370,378,8.0,0,10.1145/3677892.3677950,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203330969&doi=10.1145%2f3677892.3677950&partnerID=40&md5=fe2dfb8c3f4c45cdb732a44a12fcf3fd,"In the winter environment of cold regions, the visual perception of inter-house leisure space in settlements has an important impact on the physical and mental health of residents. The study used an eye-tracking device combined with a semantic differential (SD) questionnaire to screen the visual attention elements and attributes of winter residents in cold regions, including the spatial aspect ratio (D/H), residential elevation saturation (RES), and the percentage of lawn in the field of view (POL). Orthogonal experiments were established in an immersive virtual environment to reveal the influence mechanism of visual perceptual environmental factors of cold regions settlements on residents' leisure space evaluation in winter environment. The study trained and compared four visual perception machine learning agent models, combining genetic algorithms (GA) with k-nearest neighbor algorithms (KNN), resulting in optimized threshold ranges of D/H: 2.22-2.54, RES: 68.47-82.34, and POL: 10%-14% in winter environments.  © 2024 Copyright held by the owner/author(s).",Cold regions; Inter-house leisure space; Machine learning; Virtual reality; Visual perception,Adversarial machine learning; Contrastive Learning; Leisure; Nearest neighbor search; Vision; Cold regions; Cold winter; Eye tracking devices; Inter-house leisure space; Machine-learning; Mental health; Physical health; Semantic differential; Visual Attention; Visual perception; Houses,Conference paper,Final,,Scopus,2-s2.0-85203330969,Movies / Media
Kulke L.; Ertugrul S.; Reyentanz E.; Thomas V.,"Kulke, Louisa (57087027500); Ertugrul, Sahura (58773178200); Reyentanz, Emely (58772402800); Thomas, Vanessa (58771829600)",57087027500; 58773178200; 58772402800; 58771829600,Uncomfortable staring? Gaze to other people in social situations is inhibited in both infants and adults,2024,Developmental Science,27,3,e13468,,,,3,10.1111/desc.13468,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180196782&doi=10.1111%2fdesc.13468&partnerID=40&md5=1bb0c14c770df0d85c6a0a66f94676e5,"People attract infants’ and adults’ gaze when presented on a computer screen. However, in live social situations, adults inhibit their gaze at strangers to avoid sending inappropriate social signals. Such inhibition of gaze has never been directly investigated in infants. The current preregistered study measured gaze and neural responses (EEG alpha power) to a confederate in a live social situation compared to a video of this confederate. Adults looked less at the live confederate than at the video of the confederate, although their neural responses suggest that they were overall equally attentive in both situations. Infants also looked less at the live confederate than at the video of the confederate, with similar neural response patterns. The gaze difference between live social and video situations increased with age. The study shows that young infants are already sensitive to social context and show decreased gaze to strangers in social situations. Research Highlights: This study shows that infants and adults look more at a video of a stranger than at a stranger that is present live in a social situation. Neural responses suggest that adults are equally attentive in both live and video situations but inhibit their gaze at the stranger in live social situations. Infants show a similar pattern of shorter gaze at a stranger who is present in person than at a video of this stranger. The study shows that gaze in infants and adults may diverge from cognitive processes measured through EEG, highlighting the importance of combining behavioural and neural measures in natural interactions. © 2023 The Authors. Developmental Science published by John Wiley & Sons Ltd.",attention; EEG; eye-movements; live social situations; social interaction,"Adult; Attention; Fixation, Ocular; Humans; Infant; Social Behavior; Social Environment; adult; attention; eye fixation; human; infant; physiology; social behavior; social environment",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85180196782,Movies / Media
Li H.; Peng A.; Lai W.; Wu J.; Ji S.; Hu D.; Chen S.; Zhu C.; Hong Q.; Zhang M.; Chen L.,"Li, Hua (57188820652); Peng, Anjiao (57194614725); Lai, Wanlin (57196344507); Wu, Junru (57797732000); Ji, Shuming (57229888000); Hu, Dan (57226133668); Chen, Shujuan (58235519800); Zhu, Chenxing (58017607500); Hong, Qiulei (58106433400); Zhang, Mingsha (7601557626); Chen, Lei (57032035500)",57188820652; 57194614725; 57196344507; 57797732000; 57229888000; 57226133668; 58235519800; 58017607500; 58106433400; 7601557626; 57032035500,Impacts of education level on Montreal Cognitive Assessment and saccades in community residents from Western China,2024,Clinical Neurophysiology,161,,,27,39,12.0,2,10.1016/j.clinph.2024.02.017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186508890&doi=10.1016%2fj.clinph.2024.02.017&partnerID=40&md5=ef5725b5b66a84ba470b3c44a4fea733,"Objectives: This cross-sectional study sought to evaluate the effectiveness of the Montreal Cognitive Assessment (MoCA) and saccade in discerning the cognitive function levels among community populations characterized by diverse educational backgrounds. Methods: Data from 665 Western China individuals encompassed MoCA scores and saccade performance. The study examined how education level and age influenced these assessments and highlighted the contrasting abilities of these measures in detecting cognitive abnormalities. Results: The saccade model revealed a consistent cognitive impairment prevalence (15.5%) compared to previous clinical data (9.7% to 23.3%), while MoCA exhibited variable rates (25.1% to 52.8%). Notably, saccades and MoCA significantly diverged in detecting cognitive dysfunction. Additionally, education level had a greater impact on MoCA (effect size: 0.272) compared to saccades (0.024) affecting all MoCA sub-items, with age exerting a smaller influence on MoCA (0.037) compared to saccades (0.056). Conclusion: Saccades are less susceptible to the influence of education level when compared to MoCA, making saccade a potentially more suitable cognitive screening tool for rural community populations. Significance: This study represents a pioneering approach by employing saccade detection within community populations to distinguish cognitive function status. © 2024 International Federation of Clinical Neurophysiology",Education level; Eye movement; MoCA; Montreal Cognitive Assessment; Saccade,"Adult; Aged; Aged, 80 and over; China; Cognitive Dysfunction; Cross-Sectional Studies; Educational Status; Female; Humans; Male; Mental Status and Dementia Tests; Middle Aged; Saccades; Young Adult; adult; age; aged; Article; China; Chinese; clinical effectiveness; clinical evaluation; clock drawing test; cognition; cognitive defect; cohort analysis; college; comparative study; controlled study; cross-sectional study; dementia; diagnostic test accuracy study; differential diagnosis; educational status; female; high school; human; major clinical study; male; middle school; mild cognitive impairment; Montreal cognitive assessment; population differentiation; predictive value; prevalence; primary school; randomized controlled trial; rural area; rural population; saccadic eye movement; sensitivity and specificity; social background; susceptible population; trail making test; visual memory; cognitive defect; dementia assessment; middle aged; pathophysiology; physiology; very elderly; young adult",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85186508890,Movies / Media
Renberg S.E.; Stuebe C.M.; Quinsey C.,"Renberg, Sarah E. (58962178400); Stuebe, Caren M. (57192431237); Quinsey, Carolyn (36922904400)",58962178400; 57192431237; 36922904400,Autonomic dysfunction in patients with tectal plate compression: A systematic review,2024,Clinical Neurology and Neurosurgery,240,,108247,,,,0,10.1016/j.clineuro.2024.108247,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188995338&doi=10.1016%2fj.clineuro.2024.108247&partnerID=40&md5=331ba206a836e008b26fca7bf426f8ef,"Introduction: Pineal region lesions can result in tectal plate compression, hydrocephalus, and associated symptoms including headache, Parinaud's Syndrome, and epileptic phenomena. No studies have looked at the relationship between these lesions and the autonomic nervous system. Methods: To evaluate the clinical presentation of pineal lesions secondary to tectal plate compression with a focus on autonomic dysfunction, a systematic review was completed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Case reports and prospective and retrospective studies on patients with pineal or tectal region lesions were included. Results: Of 73 identified studies, 43 underwent full text screening. 26 studies (n=363 patients; age range 0–69 years) were included. 47.1% of patients were male (n=171). Obstructive hydrocephalus was identified in 119 patients (32.8%). The most common symptom was headache (n=228, 62.8%), followed by epileptic phenomena (n=76, 20.9%). Vision related symptoms were identified in 88 patients (24.2%). 251 patients (69.1%) had symptoms associated with autonomic dysfunction including dizziness, nausea, pupillary dysfunction, photophobia and fatigue. Of the 200 (55%) patients who underwent surgery, 135 patients (67.5%) had improved or resolved symptoms post-operatively, including 120 patients with improved autonomic dysfunction symptoms. Conclusions: Though these lesions are most characterized by Parinaud's syndrome and hydrocephalus, this review suggests dysfunction of the autonomic nervous system may be at play and require consideration at initial presentation and treatment. © 2024 Elsevier B.V.",Autonomic dysfunction; Compression; Pineal lesion; Systematic review; Tectal plate,"Adolescent; Adult; Aged; Autonomic Nervous System Diseases; Child; Child, Preschool; Female; Headache; Humans; Hydrocephalus; Male; Middle Aged; Pineal Gland; Tectum Mesencephali; Young Adult; adolescent; adult; aged; anxiety; arachnoid cyst; astrocytoma; ataxia; autonomic dysfunction; balance impairment; blurred vision; brain stem injury; cerebrospinal fluid shunting; child; cognitive defect; composite autonomic symptom score; cyst; depression; diplopia; dizziness; dysconjugate gaze; epilepsy; eye movement disorder; facial nerve paralysis; faintness; fatigue; female; fenestration; follow up; gait disorder; germ cell tumor; headache; hemiparesis; human; hyperacusis; infant; male; muscle weakness; nausea; newborn; obstructive hydrocephalus; papilledema; parinaud syndrome; photophobia; pineal body; pineal body tumor; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; pupil disease; Review; sleep disorder; symptom assessment; systematic review; tectal plate compression; third ventriculostomy; tremor; trochlear nerve palsy; visual disorder; visual impairment; vomiting; autonomic neuropathy; headache; hydrocephalus; middle aged; pathophysiology; preschool child; tectum; young adult",Review,Final,,Scopus,2-s2.0-85188995338,Movies / Media
Zihl J.; Unterberger L.; Lippenberger M.,"Zihl, Josef (7005978856); Unterberger, Lydia (58093166400); Lippenberger, Myriam (58092948800)",7005978856; 58093166400; 58092948800,Visual and cognitive profiles in children with and without cerebral visual impairment,2024,British Journal of Visual Impairment,42,2,,557,576,19.0,3,10.1177/02646196221149564,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147515976&doi=10.1177%2f02646196221149564&partnerID=40&md5=ff3ca516c384a9939dd44e01ecadc828,"Reliable differentiation of visual-perceptual difficulties in children with and without cerebral visual impairment (CVI) can often pose a diagnostic challenge. We, therefore, assessed the visual-perceptual profile in 94 children with and 77 children without suspected CVI between the ages of 8 and 17 years in a non-clinical setting, using a screening questionnaire and standardized visual-perceptual tests. Children with suspected CVI reported more frequently greater visual difficulties, had lower visual acuity, and were significantly impaired in visual search tests, in visual form and object perception, in visual space perception, and in visual text processing. There were no significant differences between groups in stereopsis, fixation stability, motility, horizontal saccadic eye movements, and convergence and accommodation. Cognitive performance in auditory attention and verbal short-term and working memory was similar in both groups. Our results indicate that the use of an appropriate questionnaire and specific visual-perceptual tests enables valid diagnostic detection of CVI. The additional use of cognitive tests also allows differentiation between primary and secondary impairments in visual perception. © The Author(s) 2023.",Assessment; cerebral visual impairment; cognition; reading; visual perception,,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85147515976,Movies / Media
Leng X.; Wang F.; Mayer R.E.; Zhao T.,"Leng, Xiaoxue (58773248800); Wang, Fuxing (57191895027); Mayer, Richard E. (7403065717); Zhao, Tingting (57217203602)",58773248800; 57191895027; 7403065717; 57217203602,How to train students to engage in text-picture integration for multimedia lessons,2024,British Journal of Educational Technology,55,3,,1167,1188,21.0,4,10.1111/bjet.13419,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180197753&doi=10.1111%2fbjet.13419&partnerID=40&md5=debb72ba0cd610944a74803d82f249e5,"This study investigated the effectiveness of visual training or verbal training on how to use a text-picture processing strategy for learning from computer-based multimedia instructional material. Sixty-nine university students were randomly assigned to the verbal training group (students received text-based instruction for a text-picture processing strategy), the visual training group (students observed a video depicting an expert's eye fixations while using a text-picture processing strategy for an initial portion of a multimedia lesson) or the control group (students did not receive any instruction). During reading a multimedia lesson on biology, students' eye movements were tracked; and after the lesson, students took a posttest. Concerning learning outcomes, both visual and verbal training helped students perform better than the control group on a recall test and the verbal training group perform better on a transfer test. Concerning learning processes, both visual and verbal training caused students to attend less to on-screen text and more to on-screen pictures as compared to the control group. Mediation analysis showed that increased attention to pictures was a mediator for better learning outcomes. Practical and theoretical implications are discussed. Practitioner notes What is already known about this topic Pre-training on key concepts or terms improves learning, but little is known whether and how pre-training on strategy acquisition supports learning. Mayer's multimedia principle suggests people learn better from illustrated text than from text alone; however, learners sometimes fail to integrate text and picture. What this paper adds Pre-training on text-picture processing strategy is effective. Verbal and visual training foster text-picture processing strategy acquisition. Verbal training improves both recall and transfer test performance, and visual training improves only recall test performance. Verbal training is better in improving outcomes. Fixation time on pictures mediates the effects of training on learning outcomes. Implications for practice and/or policy Pre-training should be used to support learners' strategy acquisition. This study also provides suggestions on how to design pre-training on strategy acquisition. © 2023 British Educational Research Association.",eye movement modelling examples; multimedia learning; pre-training principle; strategy acquisition; text-picture integration,E-learning; Eye movements; Image processing; Mergers and acquisitions; Control groups; Eye movement model; Eye movement modeling example; Multi-media learning; Pre-training; Pre-training principle; Processing strategies; Strategy acquisitions; Text-picture integration; Visual trainings; Students,Article,Final,,Scopus,2-s2.0-85180197753,Movies / Media
Wang G.; Ma L.; Wang L.; Pang W.,"Wang, Guan (57204819528); Ma, Lian (58734259000); Wang, Lili (57172374800); Pang, Weiguo (55292857200)",57204819528; 58734259000; 57172374800; 55292857200,Independence Threat or Interdependence Threat? The Focusing Effect on Social or Physical Threat Modulates Brain Activity,2024,Brain Sciences,14,4,368,,,,0,10.3390/brainsci14040368,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191702007&doi=10.3390%2fbrainsci14040368&partnerID=40&md5=1eec1d631dff9a560dd2639a2fa64fd1,"Objective: The neural basis of threat perception has mostly been examined separately for social or physical threats. However, most of the threats encountered in everyday life are complex. The features of interactions between social and physiological threats under different attentional conditions are unclear. Method: The present study explores this issue using an attention-guided paradigm based on ERP techniques. The screen displays social threats (face threats) and physical threats (action threats), instructing participants to concentrate on only one type of threat, thereby exploring brain activation characteristics. Results: It was found that action threats did not affect the processing of face threats in the face-attention condition, and electrophysiological evidence from the brain suggests a comparable situation to that when processing face threats alone, with higher amplitudes of the N170 and EPN (Early Posterior Negativity) components of anger than neutral emotions. However, when focusing on the action-attention condition, the brain was affected by face threats, as evidenced by a greater N190 elicited by stimuli containing threatening emotions, regardless of whether the action was threatening or not. This trend was also reflected in EPN. Conclusions: The current study reveals important similarities and differences between physical and social threats, suggesting that the brain has a greater processing advantage for social threats. © 2024 by the authors.",action threat; emotion threat; ERP; physical threat; social threat,Article; body movement; data analysis; data extraction; electroencephalogram; electrooculogram; emotion; event related potential; eye movement; gymnastics; human; independent component analysis; life threat; Likert scale; physical activity; psychology; questionnaire; rating scale; reliability; social behavior; validity,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85191702007,Movies / Media
Ayala N.; Mardanbegi D.; Zafar A.; Niechwiej-Szwedo E.; Cao S.; Kearns S.; Irving E.; Duchowski A.T.,"Ayala, Naila (57202583510); Mardanbegi, Diako (42761947400); Zafar, Abdullah (57996046700); Niechwiej-Szwedo, Ewa (8592081600); Cao, Shi (54580778600); Kearns, Suzanne (36025314800); Irving, Elizabeth (7004439553); Duchowski, Andrew T. (6701824388)",57202583510; 42761947400; 57996046700; 8592081600; 54580778600; 36025314800; 7004439553; 6701824388,Does fiducial marker visibility impact task performance and information processing in novice and low-time pilots?,2024,Computers and Graphics (Pergamon),119,,103889,,,,8,10.1016/j.cag.2024.103889,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185286631&doi=10.1016%2fj.cag.2024.103889&partnerID=40&md5=dbc1c4df00d92d99833e846a29edb37f,"Invisible fiducial markers are introduced for localization of Areas Of Interest (AOIs) in mobile eye tracking applications. Fiducial markers are made invisible through the use of film passing Infra-Red (IR) light while blocking the visible spectrum. An IR light source is used to illuminate the markers which are then detected by an IR-sensitive camera, but which are imperceptible by the human eye. We provide the first empirical study that demonstrates such invisible markers are not distracting to a given task, as demonstrated in a flight simulator where distraction of visible and invisible markers are compared between experienced and novice pilots. Fixation frequency and subjective distraction scores showed that visible markers disrupted natural gaze behavior, particularly in novice pilots. Our findings show that invisible markers should be used when there is a need for them to remain inconspicuous. © 2024 The Authors",Augmented reality; Aviation; Eye tracking,Augmented reality; Flight simulators; Light sources; Area of interest; Eye-tracking; Fiducial marker; Infra red; Invisible markers; Localisation; Mobile eye-tracking; Red light; Task information; Task performance; Eye tracking,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85185286631,Movies / Media
Kruger-Marais E.,"Kruger-Marais, Elmarie (58566130600)",58566130600,Subtitling for language acquisition: Eye tracking as predictor of attention allocation in education,2024,International Journal of Language Studies,18,2,,129,150,21.0,13,10.5281/zenodo.10475319,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180865220&doi=10.5281%2fzenodo.10475319&partnerID=40&md5=908162bda5c3f576e74bcb54f78f4d8f,"This paper focuses on the cognitive effectiveness of watching subtitled discipline-specific videos to determine how subtitling, as an emerging technology, encourages language equity, social justice, and the rise of technomultilinguialism. Cognitive effectiveness is investigated using gaze duration in eye-tracking as a proxy for attention allocation and gist comprehension together with scene and word recognition. It also considers whether academic English subtitles permit students enough time to look at both on-screen images and text. This study uses eye-tracking data from seven student participants in the Faculty of Natural and Agricultural Sciences at the University of Pretoria. The students were offered subtitles in English, Afrikaans, isiZulu, and Sepedi. However, the participants who volunteered for the study selected largely English and Afrikaans subtitles, and the isiZulu and Sepedi subtitles were unfortunately not utilised during this particular study. This paper concludes that the participants preferred English subtitles and remembered certain concepts from the videos better when their focus was on the subtitles themselves rather than exclusively on the on-screen image. © 2024 IJLS; Printed in The USA by Lulu Press Inc.",Cognitive Effectiveness; Eye-Tracking; Gaze Duration; Language Equity; Multilingualism; Social Justice; Subtitles; Technomultilinguialism,,Article,Final,,Scopus,2-s2.0-85180865220,Movies / Media
Amazu C.W.; Mietkiewicz J.; Abbas A.N.; Briwa H.; Alonso Perez A.; Baldissone G.; Demichela M.; Fissore D.; Madsen A.L.; Leva M.C.,"Amazu, Chidera Winifred (58414875400); Mietkiewicz, Joseph (58722067000); Abbas, Ammar N. (57214515882); Briwa, Houda (58913653400); Alonso Perez, Andres (58917517600); Baldissone, Gabriele (56131809800); Demichela, Micaela (6602178643); Fissore, Davide (6602383239); Madsen, Anders L. (7005614704); Leva, Maria Chiara (25647897300)",58414875400; 58722067000; 57214515882; 58913653400; 58917517600; 56131809800; 6602178643; 6602383239; 7005614704; 25647897300,Experiment data: Human-in-the-loop decision support in process control rooms,2024,Data in Brief,53,,110170,,,,2,10.1016/j.dib.2024.110170,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186376835&doi=10.1016%2fj.dib.2024.110170&partnerID=40&md5=fb0be06771d0113fcd052b4b863f4df4,"These datasets contain measures from multi-modal data sources. They include objective and subjective measures commonly used to determine cognitive states of workload, situational awareness, stress, and fatigue using data collection tools such as NASA-TLX, SART, eye tracking, EEG, Health Monitoring Watch, a survey to assess training, and a think-aloud situational awareness assessment following the SPAM methodology. Also, data from a simulation formaldehyde production plant based on the interaction of the participants in a controlled control room experimental setting is included. The interaction with the plant is based on a human-in-the-loop alarm handling and process control task flow, which includes Monitoring, Alarm Handling, Recovery planning, and intervention (Troubleshooting, Control and Evaluation). Data was collected from 92 participants, split into four groups while they underwent the described task flow. Each participant tested three scenarios lasting 15–18 min with a –10-min survey completion and break period in between using different combinations of decision support tools. The decision support tools tested and varied for each group include alarm prioritisation vs. none, paper-based vs. Digitised screen-based procedures, and an AI recommendation system. This is relevant to compare current practices in the industry and the impact on operators’ performance and safety. It is also applicable to validate proposed solutions for the industry. A statistical analysis was performed on the dataset to compare the outcomes of the different groups. Decision-makers can use these datasets for control room design and optimisation, process safety engineers, system engineers, human factors engineers, all in process industries, and researchers in similar or close domains. © 2024 The Author(s)",Biometrics; Decision support; Design of experiment; Human–machine interaction; Process industry; Safety; Simulated study; Surveys,Decision making; Decision support systems; Design of experiments; Eye tracking; Modal analysis; NASA; Process control; Alarm-handling; Decision supports; Experiment data; Human machine interaction; Human-in-the-loop; Process industries; Simulated study; Situational awareness; Support tool; Task flows; Accident prevention,Data paper,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85186376835,Movies / Media
Wang R.; Lian T.; He M.; Guo P.; Yu S.; Zuo L.; Hu Y.; Zhang W.,"Wang, Ruidan (57188803012); Lian, Tenghong (56538015400); He, Mingyue (57219401485); Guo, Peng (57202236178); Yu, Shuyang (55933540500); Zuo, Lijun (57225929445); Hu, Yang (55934196600); Zhang, Wei (56192715500)",57188803012; 56538015400; 57219401485; 57202236178; 55933540500; 57225929445; 55934196600; 56192715500,Clinical features and neurobiochemical mechanisms of olfactory dysfunction in patients with Parkinson disease,2024,Journal of Neurology,271,4,,1959,1972,13.0,3,10.1007/s00415-023-12122-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180639398&doi=10.1007%2fs00415-023-12122-1&partnerID=40&md5=f255d2ea29b439fd9c2ac6f7d8a8a322,"This study aimed to investigate clinical features, influencing factors and neurobiochemical mechanisms of olfactory dysfunction (OD) in Parkinson disease (PD). Total 39 patients were divided into the PD with OD (PD–OD) and PD with no OD (PD–nOD) groups according to overall olfactory function, including threshold, discrimination and identification, assessed by Sniffin’ Sticks test. Motor function and non-motor symptoms were rated by multiple scales. Dopamine, acetylcholine, norepinephrine and 5-hydroxytryptamine levels in cerebrospinal fluid (CSF) were measured. We found that the PD–OD group showed significantly lower score of Montreal Cognitive Assessment Scale, higher scores of rapid eye movement sleep behavior disorder (RBD) Screening Questionnaire and Epworth Sleepiness Scale than the PD–nOD group (p < 0.05). RBD Screening Questionnaire score was independently associated with the scores of overall olfactory function and discrimination (p < 0.05). Dopamine and acetylcholine levels in CSF from the PD–OD group was significantly lower than that from the PD–nOD group (p < 0.05). Dopamine and acetylcholine levels in CSF were significantly and positively correlated with the scores of overall olfactory function, threshold, discrimination and identification in PD patients (p < 0.05). RBD Screening Questionnaire score was significantly and negatively correlated with acetylcholine level in CSF in PD patients with poor olfactory detection (p < 0.05). This investigation reveals that PD–OD is associated with cognitive impairment, probable RBD and excessive daytime sleepiness. PD–OD is correlated with the decreased levels of dopamine and acetylcholine in CSF. RBD is an independent influencing factor of overall olfactory function and discrimination, and the decreased acetylcholine level in CSF may be the common neurobiochemical basis of RBD and OD in PD patients. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany 2023.",Clinical features; Neurobiochemical mechanisms; Olfactory dysfunction; Parkinson disease; Rapid eye movement sleep behavior disorder,Acetylcholine; Dopamine; Humans; Olfaction Disorders; Parkinson Disease; REM Sleep Behavior Disorder; Smell; acetylcholine; dopamine; noradrenalin; serotonin; acetylcholine; dopamine; adult; Article; cerebrospinal fluid; clinical article; clinical feature; cognition; controlled study; dopamine blood level; Epworth sleepiness scale; excessive daytime sleepiness; female; human; male; middle aged; Montreal cognitive assessment; motor performance; noradrenalin blood level; Parkinson disease; REM Sleep Behavior Disorder Screening Questionnaire; serotonin level; smelling; smelling disorder; complication; odor; REM sleep behavior disorder,Article,Final,,Scopus,2-s2.0-85180639398,Movies / Media
Bigne E.; Ruiz C.; Curras-Perez R.,"Bigne, Enrique (55132662600); Ruiz, Carla (55952545600); Curras-Perez, Rafael (24921496800)",55132662600; 55952545600; 24921496800,Furnishing your home? The impact of voice assistant avatars in virtual reality shopping: A neurophysiological study,2024,Computers in Human Behavior,153,,108104,,,,9,10.1016/j.chb.2023.108104,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180370399&doi=10.1016%2fj.chb.2023.108104&partnerID=40&md5=5ab99d3669a84167f03682043abdebc6,"This study provides insights into the informational cues consumers use in virtual reality (VR)-based retail shopping experiences. The aim of the study is to identify the number and type (extrinsic versus intrinsic) of informational cues that most attract consumers' visual attention, and that are most important in their purchase decision-making in a VR store, with special emphasis on the role of voice assistant (VA) avatars. A sample of 152 Spanish consumers participated in a laboratory-based 2 × 2 between-subjects experiment. The study's main stimulus was a recreation, in both 2D and VR, of a living room in a home. The participants were asked to view the recreation using either a computer screen (2D) or a head-mounted display (HMD). Clickstream data, neurophysiological measures (eye-tracking and GSR) and self-reported measures were used to test the hypotheses. We found that consumers used more informational cues in the product choice process in the 2D online store than in the VR store, but that the VR store generated higher flow state; that the type of cue used depended on the type of platform and that the presence of VA avatars did not influence the number of informational cues consumers used but made them pay more visual attention to the products, and evoked higher arousal. © 2023 Elsevier Ltd",Arousal; Clickstream data; Eye-tracking; Virtual reality; Voice assisted avatars,Behavioral research; Decision making; Helmet mounted displays; Neurophysiology; Speech recognition; Virtual reality; Arousal; Clickstream data; Computer screens; Decisions makings; Eye-tracking; Living room; Purchase decision; Subject experiment; Visual Attention; Voice assisted avatar; Eye tracking,Article,Final,,Scopus,2-s2.0-85180370399,Movies / Media
Jiang Z.; Seyedi S.; Vickers K.L.; Manzanares C.M.; Lah J.J.; Levey A.I.; Clifford G.D.,"Jiang, Zifan (57208290393); Seyedi, Salman (57215548524); Vickers, Kayci L. (57201336304); Manzanares, Cecelia M. (36950308700); Lah, James J. (56834296100); Levey, Allan I. (7101644033); Clifford, Gari D. (7004468844)",57208290393; 57215548524; 57201336304; 36950308700; 56834296100; 7101644033; 7004468844,Disentangling Visual Exploration Differences in Cognitive Impairment,2024,IEEE Transactions on Biomedical Engineering,71,4,,1197,1208,11.0,2,10.1109/TBME.2023.3330976,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177091979&doi=10.1109%2fTBME.2023.3330976&partnerID=40&md5=6146e51c8449de287a3e980d0dfe5cc6,"Objective: Individuals with cognitive impairment (CI) exhibit different oculomotor functions and viewing behaviors. In this work we aimed to quantify the differences in these functions with CI severity, and assess general CI and specific cognitive functions related to visual exploration behaviors. Methods: A validated passive viewing memory test with eyetracking was administered to 348 healthy controls and CI individuals. Spatiotemporal properties of the scanpath, the semantic category of the viewed regions, and other composite features were extracted from the estimated eyegaze locations on the corresponding pictures displayed during the test. These features were then used to characterize viewing patterns, classify cognitive impairment, and estimate scores in various neuropsychological tests using machine learning. Results: Statistically significant differences in spatial, spatiotemporal, and semantic features were found between healthy controls and individuals with CI. The CI group spent more time gazing at the center of the image, looked at more regions of interest (ROI), transitioned less often between ROI yet in a more unpredictable manner, and exhibited different semantic preferences. A combination of these features achieved an area under the receiver-operator curve of 0.78 in differentiating CI individuals from controls. Statistically significant correlations were identified between actual and estimated CI scores and other neuropsychological tests. Conclusion: Evaluating visual exploration behaviors provided quantitative and systematic evidence of differences in CI individuals, leading to an improved approach for passive cognitive impairment screening. Significance: The proposed passive, accessible, and scalable approach could help with earlier detection and a better understanding of cognitive impairment. © 1964-2012 IEEE.",Alzheimer's diseases; machine learning; mild cognitive impairment; visual exploration,Cognition; Cognitive Dysfunction; Humans; Machine Learning; Neuropsychological Tests; Diagnosis; Feature extraction; Job analysis; Neurodegenerative diseases; Visualization; Alzheimers disease; Atmospheric measurement; Cognitive impairment; Features extraction; Machine-learning; Mild cognitive impairment; Particle measurement; Task analysis; Visual exploration; aged; Alzheimer disease; Article; cognition; cognitive defect; cohort analysis; comparative study; controlled study; disease severity; eye tracking; female; gaze; human; machine learning; major clinical study; male; memory test; mild cognitive impairment; neuropsychological assessment; quantitative analysis; receiver operating characteristic; semantic memory; spatiotemporal analysis; vision; cognitive defect; Semantics,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85177091979,Movies / Media
Suzuki Y.; Wild F.; Scanlon E.,"Suzuki, Yuko (58642871300); Wild, Fridolin (55876635700); Scanlon, Eileen (7005219969)",58642871300; 55876635700; 7005219969,Measuring cognitive load in augmented reality with physiological methods: A systematic review,2024,Journal of Computer Assisted Learning,40,2,,375,393,18.0,21,10.1111/jcal.12882,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173916705&doi=10.1111%2fjcal.12882&partnerID=40&md5=11609ae4eb737164f6ebe23135e6e194,"Background: Cognitive load during AR use has been measured conventionally by performance tests and subjective rating. With the growing interest in physiological measurement using non-invasive biometric sensors, unbiased real-time detection of cognitive load in AR is expected. However, a range of sensors and parameters are used in various subject fields, and reported results are fragmented. Objectives: The aim of this review is to analyse systematically how physiological methods have been used to measure cognitive load and what the implications are for the future research on AR-based tools. Methods: This paper took the systematic review approach. Through screening with 10 exclusion criteria, 23 studies, that contain 3 key elements: AR-based intervention, cognitive state examination and physiological methods, were identified, analysed and synthesised. Results: Physiological methods in their current form require reference to provide meaningful interpretations and suggestions. Therefore, they are often combined with conventional methods. Many studies investigate the effect of wearable devices in comparison with non-AR stimuli, which has been controversial, but detection of different causes of cognitive load are on the horizon. Eye-tracking is the method most used and most consistent in the use of its parameters. Conclusions: A multi-method approach combining two or more evaluation instruments is essential for the validation of users' cognitive state. In addition to the AR stimuli in question, having another independent variable such as task difficulty in experiment design is useful. Statistical approaches with more data input could help establish a reliable scale. The future research should attempt to dissociate cognitive load caused by different effects such as device, instruction, and other AR techniques as well as intrinsic and extraneous aspects, in a better experimental setup with multiple parameters. © 2023 The Authors. Journal of Computer Assisted Learning published by John Wiley & Sons Ltd.",augmented reality; cognitive load; human-computer interaction; physiological method; systematic review; technology enhanced learning,,Review,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85173916705,Movies / Media
Kuang Z.; Wang F.; Andrasik F.; Hu X.,"Kuang, Ziyi (57256354300); Wang, Fuxing (57191895027); Andrasik, Frank (57204668145); Hu, Xiangen (7404710283)",57256354300; 57191895027; 57204668145; 7404710283,Instructor's direct gaze not body orientation affects learning,2024,Journal of Computer Assisted Learning,40,2,,731,741,10.0,3,10.1111/jcal.12917,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178176888&doi=10.1111%2fjcal.12917&partnerID=40&md5=37c1a613349750bdf1ea1dd2ba0aa83f,"Background: Little is known about the effectiveness of instructors when presenting content in videos alone. In recent years, researchers have increasingly begun to explore the effects of instructors' social cues (e.g., eye gaze, body orientation, etc.) on learning. However, previous studies exploring the effects of eye gaze have confounded the role of body orientation, while studies exploring body orientation have confounded the role of eye gaze. Objectives: To explore the role of direct gaze and body orientation in learning with instructional videos, absent an instructional screen, in a less confounded manner. Methods: A total of 63 subjects were presented select concepts regarding schizophrenia. Eye-tracking technology combined with current theories of parasocial interaction and social agency was used to explore different social cues that affect learning performance. Students were randomly assigned to one of three experimental conditions: frontal body + direct gaze group (FD group), frontal body + no direct gaze group (FND group), and lateral body + no direct gaze group (LND group). Result and Conclusions: Direct gaze facilitated students' immediate retention and transfer scores, reduced learners' extraneous cognitive load, and guided students' attention to the instructor. However, counter to our expectations, parasocial interaction did not affect social cues. Implications: In both online and offline classes, instruction is expected to be enhanced by focusing on the camera to the extent possible, particularly when instructional screens are absent. © 2023 John Wiley & Sons Ltd.",body orientation; eye gaze; multimedia learning; parasocial interaction; video learning,,Article,Final,,Scopus,2-s2.0-85178176888,Movies / Media
Chen Z.; Zhang K.; Cai H.; Ding X.; Jiang C.; Chen Z.,"Chen, Zhao (56419098400); Zhang, Kao (56723128300); Cai, Hao (55601452300); Ding, Xiaoying (56571839900); Jiang, Chenxi (58921395300); Chen, Zhenzhong (55737671700)",56419098400; 56723128300; 55601452300; 56571839900; 58921395300; 55737671700,Audio-visual saliency prediction for movie viewing in immersive environments: Dataset and benchmarks,2024,Journal of Visual Communication and Image Representation,100,,104095,,,,1,10.1016/j.jvcir.2024.104095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186763411&doi=10.1016%2fj.jvcir.2024.104095&partnerID=40&md5=6c6b45186c9b03a4eed4e07dc82cf79e,"In this paper, an eye-tracking dataset of movie viewing in the immersive environment is developed, which contains 256 movie clips with 2K QHD resolution and corresponding movie genre labels from IMDb (Internet Movie Database). The dataset provides the audio-visual clues for studying the human visual attention when watching movie using a VR headset, by recording the eye movements using integrated eye tracker. To provide benchmarks for a saliency prediction for movie viewing in the immersive environment, fifteen computational models are evaluated on the dataset, including a newly developed multi-stream audio-visual saliency prediction model based on deep neural networks, named as MSAV. Detailed quantitative and qualitative comparisons and analyses are also provided. The developed dataset and benchmarks could help to facilitate the studies of visual saliency prediction for movie viewing in the immersive environments. © 2024 Elsevier Inc.",Movie viewing; Saliency prediction; Virtual reality; Visual attention,Behavioral research; Deep neural networks; Eye movements; Eye tracking; Motion pictures; Virtual reality; Visualization; Audio-visual; Eye-tracking; Immersive environment; Internet movie database; Movie clips; Movie genres; Movie viewing; Saliency prediction; Visual Attention; Visual saliency; Forecasting,Article,Final,,Scopus,2-s2.0-85186763411,Movies / Media
Pitigoi I.C.; Coe B.C.; Calancie O.G.; Brien D.C.; Yep R.; Riek H.C.; Kirkpatrick R.H.; Noyes B.K.; White B.J.; Blohm G.; Munoz D.P.,"Pitigoi, Isabell C. (58482963300); Coe, Brian C. (7006220583); Calancie, Olivia G. (57193678315); Brien, Donald C. (8896316400); Yep, Rachel (57201885862); Riek, Heidi C. (57659595400); Kirkpatrick, Ryan H. (57201740287); Noyes, Blake K. (57222215610); White, Brian J. (7401650125); Blohm, Gunnar (6603426101); Munoz, Douglas P. (7103163217)",58482963300; 7006220583; 57193678315; 8896316400; 57201885862; 57659595400; 57201740287; 57222215610; 7401650125; 6603426101; 7103163217,"Attentional Modulation of Eye Blinking Is Altered by Sex, Age, and Task Structure",2024,eNeuro,11,3,ENEURO.0296-23.2024,,,,8,10.1523/ENEURO.0296-23.2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186619076&doi=10.1523%2fENEURO.0296-23.2024&partnerID=40&md5=f4dd461a1f6ae0acbcd2ea12a051e8ae,"Spontaneous eye blinking is gaining popularity as a proxy for higher cognitive functions, as it is readily modulated by both environmental demands and internal processes. Prior studies were impoverished in sample size, sex representation, and age distribution, making it difficult to establish a complete picture of the behavior. Here we present eye-tracking data from a large cohort of normative participants (n = 604; 393 F; aged 5–93 years) performing two tasks: one with structured, discrete trials (interleaved pro-/anti-saccade task, IPAST) and one with a less structured, continuous organization in which participants watch movies (free-viewing; FV). Sex-and age-based analyses revealed that females had higher blink rates between the ages of 22 and 58 years in the IPAST and 22 and 34 years in FV. We derived a continuous measure of blink probability to reveal behavioral changes driven by stimulus appearance in both paradigms. In the IPAST, blinks were suppressed near stimulus appearance, particularly on correct anti-saccade trials, which we attribute to the stronger inhibitory control required for anti-saccades compared with pro-saccades. In FV, blink suppression occurred immediately after scene changes, and the effect was sustained on scenes where gaze clustered among participants (indicating engagement of attention). Females were more likely than males to blink during appearance of novel stimuli in both tasks, but only within the age bin of 18–44 years. The consistency of blink patterns in each paradigm endorses blinking as a sensitive index for changes in visual processing and attention, while sex and age differences drive interindividual variability. © 2024 Pitigoi et al.",anti-saccade; blink timing; free-viewing; inhibitory control; visual processing,adult; age; aged; Article; Attentional modulation; blinking; child; cohort analysis; eye; eye movement; eye position; eye tracking; female; gaze; human; human experiment; male; middle aged; normal human; preschool child; sex; sex difference; stimulus; visual attention; young adult,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85186619076,Movies / Media
Hudspeth K.M.; Lewis C.,"Hudspeth, Kimberley M. (57224513408); Lewis, Charlie (57208121772)",57224513408; 57208121772,Touchscreens can promote infant object-interlocutor reference switching,2024,Infant Behavior and Development,74,,101914,,,,0,10.1016/j.infbeh.2023.101914,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179129897&doi=10.1016%2fj.infbeh.2023.101914&partnerID=40&md5=58b8f1a06d1a30989e0a651656242b39,"We re-examine whether the type of object played with influences parent-infant joint attention. A within-participants comparison of 24 parent-9-month-old dyads, used head-mounted eye-tracking to measure parental naming and infant attention during play with touchscreen apps on a touchscreen tablet or matched interactive toys. Infants engaged in sustained attention more to the toy than the tablet. Parents named objects less in toy play. Infants exhibited more gaze shifts between the object and their parent during tablet play. Contrasting previous studies, these findings suggest that joint tablet play can be more interactive than with toys, and raise questions about the recommendation that infants should not be exposed at all to such technology. © 2023 Elsevier Inc.",Eye-tracking; Infant development; Joint attention; Screen time; Sustained attention; Triadic interaction,"Attention; Child, Preschool; Humans; Infant; Parents; Play and Playthings; article; attention; child development; controlled study; eye tracking; eye-tracking technology; female; gaze; human; infant; male; screen time; child parent relation; preschool child; recreation",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85179129897,Movies / Media
Mössing W.A.; Schroeder S.C.Y.; Biel A.L.; Busch N.A.,"Mössing, Wanja A. (57218352710); Schroeder, Svea C.Y. (57200679140); Biel, Anna Lena (57031665900); Busch, Niko A. (7006235162)",57218352710; 57200679140; 57031665900; 7006235162,Contralateral delay activity and alpha lateralization reflect retinotopic and screen-centered reference frames in visual memory,2024,Progress in Neurobiology,234,,102576,,,,1,10.1016/j.pneurobio.2024.102576,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186595890&doi=10.1016%2fj.pneurobio.2024.102576&partnerID=40&md5=3d993715e1fe509b2298a2fc665ada33,"The visual system represents objects in a lateralized manner, with contralateral cortical hemispheres responsible for left and right visual hemifields. This organization extends to visual short-term memory (VSTM), as evidenced by electrophysiological indices of VSTM maintenance: contralateral delay activity (CDA) and alpha-band lateralization. However, it remains unclear if VSTM represents object locations in gaze-centered (retinotopic) or screen-centered (spatiotopic) coordinates, especially after eye movements. In two experiments, participants encoded the colors of target objects and made a lateral saccade during the maintenance interval, thereby shifting the object's location on the retina. A non-lateralized probe stimulus was then presented at the new fixation for a change detection task. The CDA maintained lateralization towards the target's original retinotopic location, unaffected by subsequent saccades, and did not invert polarity even when a saccade brought that location into the opposite hemifield. We also found conventional alpha lateralization towards the target's location before a saccade. After a saccade, however, alpha was lateralized towards the screen center regardless of the target's original location, even in a control condition without any memory requirements. This suggests that post-saccadic alpha-band lateralization reflects attentional processes unrelated to memory, while pre- and post-saccade CDA reflect VSTM maintenance in a retinotopic reference frame. © 2024 The Authors",Capacity; EEG; Eye movements; Remapping; Visual short-term memory,"Attention; Eye Movements; Humans; Memory, Short-Term; Retina; Saccades; article; controlled study; electroencephalogram; electroencephalography; electrophysiology; eye movement; female; gaze; hemisphere; human; human experiment; male; memory; normal human; saccadic eye movement; short term memory; visual memory; visual system; attention; physiology; retina; saccadic eye movement; short term memory",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85186595890,Movies / Media
Gu C.; Peng Y.; Nastase S.A.; Mayer R.E.; Li P.,"Gu, Chanyuan (57217152438); Peng, Yingying (57559856900); Nastase, Samuel A. (55586258200); Mayer, Richard E. (7403065717); Li, Ping (56222449000)",57217152438; 57559856900; 55586258200; 7403065717; 56222449000,Onscreen presence of instructors in video lectures affects learners' neural synchrony and visual attention during multimedia learning,2024,Proceedings of the National Academy of Sciences of the United States of America,121,12,e2309054121,,,,11,10.1073/pnas.2309054121,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187803214&doi=10.1073%2fpnas.2309054121&partnerID=40&md5=80a548f1299345609b1d997f04a760e6,"COVID-19 forced students to rely on online learning using multimedia tools, and multimedia learning continues to impact education beyond the pandemic. In this study, we combined behavioral, eye-tracking, and neuroimaging paradigms to identify multimedia learning processes and outcomes. College students viewed four video lectures including slides with either an onscreen human instructor, an animated instructor, or no onscreen instructor. Brain activity was recorded via fMRI, visual attention was recorded via eye-tracking, and learning outcome was assessed via post-tests. Onscreen presence of instructor, compared with no instructor presence, resulted in superior post-test performance, less visual attention on the slide, more synchronized eye movements during learning, and higher neural synchronization in cortical networks associated with socio-emotional processing and working memory. Individual variation in cognitive and socio-emotional abilities and intersubject neural synchronization revealed different levels of cognitive and socio-emotional processing in different learning conditions. The instructor-present condition evoked increased synchronization, likely reflecting extra processing demands in attentional control, working memory engagement, and socio-emotional processing. Although human instructors and animated instructors led to comparable learning outcomes, the effects were due to the dynamic interplay of information processing vs. attentional distraction. These findings reflect a benefit-cost trade-off where multimedia learning outcome is enhanced only when the cognitive benefits motivated by the social presence of onscreen instructor outweigh the cognitive costs brought about by concurrent attentional distraction unrelated to learning. Copyright © 2024 the Author(s). Published by PNAS.",individual difference; multimedia learning; neural synchrony; socio-emotional processing; visual attention,"Cognition; Humans; Learning; Memory, Short-Term; Multimedia; Students; anterior cingulate; Article; behavioral synchrony; dorsomedial prefrontal cortex; e-learning; eye movement; functional magnetic resonance imaging; fusiform gyrus; human; human experiment; middle temporal gyrus; multimedia learning; neural synchronization; neural synchrony; posterior parietal cortex; superior temporal gyrus; video lecture; visual attention; cognition; learning; physiology; short term memory; student",Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85187803214,Movies / Media
Loizou P.; Panagiotou G.; Zanos P.; Paraskevopoulos E.,"Loizou, Panagiotis (58961006800); Panagiotou, Georgia (58960585800); Zanos, Panos (55628073600); Paraskevopoulos, Evangelos (36008936800)",58961006800; 58960585800; 55628073600; 36008936800,Exploring the neurofunctional impairments and cognitive biases concerning food and body related stimuli in anorexia nervosa: An integrated EEG and eye-tracking study protocol,2024,PLoS ONE,19,3-Mar,e0299529,,,,1,10.1371/journal.pone.0299529,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188917649&doi=10.1371%2fjournal.pone.0299529&partnerID=40&md5=b6a7996e16c2adf7255d80b1f54cfe18,"Background Patients with Anorexia Nervosa (AN) exhibit significant cognitive and neural disturbances compared to healthy individuals when processing food and body-related stimuli. These disturbances not only contribute to the manifestation and chronification of their pathological eating behaviour but also underscore the complex interplay of cognitive, emotional, and neurobiological factors in AN. However, the precise underlying cognitive and neural mechanisms of these disturbances remain a compelling area of investigation. Methods This study presents a protocol developed for conducting a cross-sectional quasi-experimental study using a mixed model ANOVA approach with a crossover design. Our participants will consist of 20 patients with an active diagnosis of AN, 20 Overweight/obese individuals, and 20 Healthy Controls (HCs) with a normal BMI. An integrated eye-tracking and EEG methodology will be used in conjunction, with the primary aim of assessing participants’ cognitive and neural processing towards high and low-calorie food stimuli. On an exploratory level, by utilizing the same methods, the present study will also investigate AN patients’ responses towards high weight, normal weight, low weight, and self-body pictures, as well as towards images from the International Affective Picture System (IAPS) characterized by elevated valence and arousal levels. Additionally, behavioural methods such as yes or no questions, and self-reported questionnaires will be administered. The EEG and eye-tracking data will be analysed at early (50–300 ms) and late (350–500 ms) time intervals. Discussion The investigation of the underlying cognitive and neural processes employed by patients with AN during the processing of food and body-related stimuli can help us develop a better understanding of the cognitive and neural mechanisms that contribute to the manifestation and maintenance of the disorder and assist in the development of more effective screening methods. © 2024 Public Library of Science. All rights reserved.",,"Anorexia Nervosa; Bias; Cognition; Cross-Sectional Studies; Electroencephalography; Eye-Tracking Technology; Humans; adult; Article; attention; behavior; body mass; body stimuli; body weight; caloric intake; clinical article; cognitive bias; controlled study; convenience sample; cross-sectional study; Depression, Anxiety and Stress Scale; electroencephalography; emotion assessment; emotion regulation; eye-tracking technology; feeding behavior; female; food intake; functional connectivity; functional magnetic resonance imaging; human; information processing; International Affective Picture System; Likert scale; male; methodological innovation; methodology; motivation; neurofunctional impairment; neurologic disease; neurophysiological recruitment; normal human; obese patient; obesity; outcome assessment; physiological process; primary outcome; quasi experimental study; reward; scoring system; secondary outcome; self report; Short Form 36; stimulation; time interval; anorexia nervosa; cognition; electroencephalography; eye-tracking technology; psychology; statistical bias",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85188917649,Movies / Media
Sanclemente D.; Belair J.A.; Talekar K.S.; Roedl J.B.; Stache S.,"Sanclemente, Drew (58937287800); Belair, Jeffrey A. (55651550500); Talekar, Kiran S. (39962510700); Roedl, Johannes B. (15846924600); Stache, Stephen (56398462800)",58937287800; 55651550500; 39962510700; 15846924600; 56398462800,Return to Play Following Concussion: Role for Imaging?,2024,Seminars in Musculoskeletal Radiology,28,2,,193,202,9.0,0,10.1055/s-0043-1778031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187686498&doi=10.1055%2fs-0043-1778031&partnerID=40&md5=619ce4d4cbabad53f2af23efd47047c0,"This review surveys concussion management, focusing on the use of neuroimaging techniques in return to play (RTP) decisions. Clinical assessments traditionally were the foundation of concussion diagnoses. However, their subjective nature prompted an exploration of neuroimaging modalities to enhance diagnosis and management. Magnetic resonance spectroscopy provides information about metabolic changes and alterations in the absence of structural abnormalities. Diffusion tensor imaging uncovers microstructural changes in white matter. Functional magnetic resonance imaging assesses neuronal activity to reveal changes in cognitive and sensorimotor functions. Positron emission tomography can assess metabolic disturbances using radiotracers, offering insight into the long-term effects of concussions. Vestibulo-ocular dysfunction screening and eye tracking assess vestibular and oculomotor function. Although these neuroimaging techniques demonstrate promise, continued research and standardization are needed before they can be integrated into the clinical setting. This review emphasizes the potential for neuroimaging in enhancing the accuracy of concussion diagnosis and guiding RTP decisions. © 2024 Thieme Medical Publishers, Inc.. All rights reserved.",amyloid imaging; diffusion tensor imaging; functional magnetic resonance imaging; magnetic resonance spectroscopy; positron emission tomography,Athletic Injuries; Brain Concussion; Diffusion Tensor Imaging; Humans; Neuroimaging; Return to Sport; tracer; Article; chronic traumatic encephalopathy; clinical assessment; cognition; concussion; diagnostic accuracy; diffusion tensor imaging; eye disease; eye movement control; eye tracking; functional magnetic resonance imaging; nuclear magnetic resonance spectroscopy; positron emission tomography; return to sport; sensorimotor function; standardization; vestibular disorder; vestibuloocular reflex; white matter; brain concussion; diagnostic imaging; diffusion tensor imaging; human; neuroimaging; procedures; return to sport; sport injury,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85187686498,Movies / Media
Masson N.; Dormal V.; Stephany M.; Schiltz C.,"Masson, Nicolas (55750708300); Dormal, Valérie (11239635100); Stephany, Martine (58634891700); Schiltz, Christine (8733651700)",55750708300; 11239635100; 58634891700; 8733651700,Eye movements reveal that young school children shift attention when solving additions and subtractions,2024,Developmental Science,27,2,e13452,,,,3,10.1111/desc.13452,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173514152&doi=10.1111%2fdesc.13452&partnerID=40&md5=1f83cfb67b985fc408a04ebd8aaf03a4,"Adults shift their attention to the right or to the left along a spatial continuum when solving additions and subtractions, respectively. Studies suggest that these shifts not only support the exact computation of the results but also anticipatively narrow down the range of plausible answers when processing the operands. However, little is known on when and how these attentional shifts arise in childhood during the acquisition of arithmetic. Here, an eye-tracker with high spatio-temporal resolution was used to measure spontaneous eye movements, used as a proxy for attentional shifts, while children of 2nd (8 y-o; N = 50) and 4th (10 y-o; N = 48) Grade solved simple additions (e.g., 4+3) and subtractions (e.g., 3-2). Gaze patterns revealed horizontal and vertical attentional shifts in both groups. Critically, horizontal eye movements were observed in 4th Graders as soon as the first operand and the operator were presented and thus before the beginning of the exact computation. In 2nd Graders, attentional shifts were only observed after the presentation of the second operand just before the response was made. This demonstrates that spatial attention is recruited when children solve arithmetic problems, even in the early stages of learning mathematics. The time course of these attentional shifts suggests that with practice in arithmetic children start to use spatial attention to anticipatively guide the search for the answer and facilitate the implementation of solving procedures. Research Highlights: Additions and subtractions are associated to right and left attentional shifts in adults, but it is unknown when these mechanisms arise in childhood. Children of 8–10 years old solved single-digit additions and subtractions while looking at a blank screen. Eye movements showed that children of 8 years old already show spatial biases possibly to represent the response when knowing both operands. Children of 10 years old shift attention before knowing the second operand to anticipatively guide the search for plausible answers. © 2023 The Authors. Developmental Science published by John Wiley & Sons Ltd.",cognitive strategies; development; eye-tracker; mental arithmetic; space-number associations; spatial attention,Adult; Child; Eye Movements; Humans; Learning; Mathematics; Movement; Problem Solving; Reaction Time; adult; child; eye movement; human; learning; mathematics; movement (physiology); physiology; problem solving; reaction time,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85173514152,Movies / Media
Nagatsuka Y.; Nakamura D.; Ota M.; Arai G.; Iwami Y.; Suzuki H.; Tomita A.; Hanawa Y.; Hayashi W.; Iwanami A.,"Nagatsuka, Yuta (58741597200); Nakamura, Dan (57222576329); Ota, Marie (57196097652); Arai, Gosuke (57194658689); Iwami, Yuriko (57226721212); Suzuki, Hirohisa (57212324638); Tomita, Akisa (56727660000); Hanawa, Yoichi (57222317578); Hayashi, Wakaho (57204607595); Iwanami, Akira (7006419212)",58741597200; 57222576329; 57196097652; 57194658689; 57226721212; 57212324638; 56727660000; 57222317578; 57204607595; 7006419212,Gaze measurements during viewing human dialogue scenes in adults with ADHD: Preliminary findings,2024,Neuropsychopharmacology Reports,44,1,,73,79,6.0,1,10.1002/npr2.12383,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178475893&doi=10.1002%2fnpr2.12383&partnerID=40&md5=51a6ca12fd6bfcd6868377b26879e868,"Aim: Eye gaze measurement to human dialogue scenes in adults with attention deficit hyperactivity disorder (ADHD) was investigated. We examined whether eye gaze measurement might be a biological marker of ADHD. Methods: Twenty-two individuals with ADHD (mean age, 34.5 years) attending the outpatient clinic of Showa University Karasuyama Hospital were included in the study, and 26 healthy individuals (mean age, 32.6 years) with no history of mental disorders were used as the control group. For the participants, intellectual functioning was estimated using the Japanese Adult Reading Test, and mental symptoms were assessed using the Autism Spectrum Quotient and Conner's Adult ADHD Rating Scale. We extracted human dialogue scenes from two classic movies as visual stimuli and recorded the participant's gaze while watching these scenes using Tobii's eye tracker. Results: For gazing time, repeated measures analysis of variance showed no significant main effect of “group” and no significant interaction effect between “group” and areas of interest “(AOI).” In the normal group, gazing time at the eyes was significantly longer than those at the mouth, body, and background; in the ADHD group, gazing time at the eyes was significantly longer than only that at the background. Conclusion: Given the different results obtained in the past in ASD, these results suggest that it would be necessary to directly compare the two groups to determine whether the gaze measurement shows significant differences in ASD and ADHD. © 2023 The Authors. Neuropsychopharmacology Reports published by John Wiley & Sons Australia, Ltd on behalf of The Japanese Society of Neuropsychopharmacology.",ADHD; adult; ASD; eye-tracker; gaze,"Adult; Attention Deficit Disorder with Hyperactivity; Autism Spectrum Disorder; Cognition; Fixation, Ocular; Humans; antidepressant agent; anxiolytic agent; atomoxetine; guanfacine; methylphenidate; mood stabilizer; neuroleptic agent; adult; Article; attention deficit hyperactivity disorder; autism-spectrum quotient; clinical article; Conners Rating Scale; controlled study; female; gaze; human; impulsiveness; intelligence quotient; male; mouth; national adult reading test; optometry; outpatient department; self concept; videorecording; visual stimulation; attention deficit hyperactivity disorder; autism; cognition; eye fixation",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85178475893,Movies / Media
Csikós N.; Petro B.; Kojouharova P.; Gaál Z.A.; Czigler I.,"Csikós, Nóra (57890004000); Petro, Bela (57191415647); Kojouharova, Petia (57192424226); Gaál, Zsófia Anna (12779025200); Czigler, István (7003933120)",57890004000; 57191415647; 57192424226; 12779025200; 7003933120,Automatic Change Detection in Interwoven Sequences: A Visual Mismatch Negativity Study,2024,Journal of Cognitive Neuroscience,36,3,,534,550,16.0,4,10.1162/jocn_a_02099,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184522691&doi=10.1162%2fjocn_a_02099&partnerID=40&md5=f02dc044c2423cf6295bd42fe25c82e9,"In this study, we investigated whether the cognitive system, known to be able to register regular visual event sequences and the violation of these sequences automatically, had the capacity of processing two sequences simultaneously. To this end, we measured the visual mismatch negativity (vMMN) component of ERPs as interwoven event sequences simultaneously pre-sented to the left and right side of the screen. One of the sequences consisted of geometric patterns (diamonds); the other, photographs of human faces. In successive cycles, parts of the stimuli vanished and then re-appeared (the OFF/ON method). The vanishing parts served as either standard (frequently vanishing parts) or infrequent (deviant) events, but these events were task-irrelevant. The 20 adult participants (age 21.40 ± 2.72 years) performed a visual tracking task, with the OFF/ON task being a passive oddball paradigm. According to the results, both OFF and ON events, and both diamond and face stimuli elicited the vMMN component, showing that the system underlying this activity is capable of processing two event sequences if the sequences consist of fairly different kind of objects as stimuli. The sLORETA analysis showed that the source of vMMN was more frequent contralaterally to the deviant event, and the sources com-prised loci from ventral and dorsal structures, as well as some anterior loci. © 2023 Massachusetts Institute of Technology.",,"Adolescent; Adult; Electroencephalography; Evoked Potentials; Evoked Potentials, Visual; Humans; Psychomotor Performance; Visual Perception; Young Adult; Automatic change detection; Event sequence; Geometric patterns; Human faces; Mismatch negativity; Oddball paradigms; Visual Tracking; adult; article; cognition; controlled study; diagnosis; evoked response; eye tracking; female; human; low resolution brain electromagnetic tomography; male; mismatch negativity; photography; adolescent; electroencephalography; psychomotor performance; vision; visual evoked potential; young adult; Cognitive systems",Article,Final,,Scopus,2-s2.0-85184522691,Movies / Media
Lee J.H.; Nam H.; Kim D.H.; Koo D.L.; Choi J.W.; Hong S.-N.; Jeon E.-T.; Lim S.; Jang G.S.; Kim B.-H.,"Lee, Ji Hyun (57216432798); Nam, Hyunwoo (56187220700); Kim, Dong Hyun (57205202629); Koo, Dae Lim (37034217300); Choi, Jae Won (57219280363); Hong, Seung-No (56666292900); Jeon, Eun-Tae (57195325591); Lim, Sungmook (57931261300); Jang, Gwang soo (57930681700); Kim, Baek-hyun (57931545900)",57216432798; 56187220700; 57205202629; 37034217300; 57219280363; 56666292900; 57195325591; 57931261300; 57930681700; 57931545900,Developing a deep learning model for sleep stage prediction in obstructive sleep apnea cohort using 60 GHz frequency-modulated continuous-wave radar,2024,Journal of Sleep Research,33,1,e14050,,,,6,10.1111/jsr.14050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172135343&doi=10.1111%2fjsr.14050&partnerID=40&md5=4fbf1c88349ac1abf014928e22c65645,"Given the significant impact of sleep on overall health, radar technology offers a promising, non-invasive, and cost-effective avenue for the early detection of sleep disorders, even prior to relying on polysomnography (PSG)-based classification. In this study, we employed an attention-based bidirectional long short-term memory (Attention Bi-LSTM) model to accurately predict sleep stages using 60 GHz frequency-modulated continuous-wave (FMCW) radar. Our dataset comprised 78 participants from an ongoing obstructive sleep apnea (OSA) cohort, recruited between July 2021 and November 2022, who underwent overnight polysomnography alongside radar sensor monitoring. The dataset encompasses comprehensive polysomnography recordings, spanning both sleep and wakefulness states. The predictions achieved a Cohen's kappa coefficient of 0.746 and an overall accuracy of 85.2% in classifying wakefulness, rapid-eye-movement (REM) sleep, and non-REM (NREM) sleep (N1 + N2 + N3). The results demonstrated that the models incorporating both Radar 1 and Radar 2 data consistently outperformed those using only Radar 1 data, indicating the potential benefits of utilising multiple radars for sleep stage classification. Although the performance of the models tended to decline with increasing OSA severity, the addition of Radar 2 data notably improved the classification accuracy. These findings demonstrate the potential of radar technology as a valuable screening tool for sleep stage classification. © 2023 European Sleep Research Society.",deep learning; long short-term memory attention mechanism; obstructive sleep apnea'; polysomnography; radar; sleep stage,"Deep Learning; Humans; Radar; Sleep; Sleep Apnea, Obstructive; Sleep Stages; adult; apnea hypopnea index; apnea index; arousal; arousal index; Article; body mass; cohort analysis; daytime somnolence; deep learning; Epworth sleepiness scale; feature extraction; female; human; hypopnea index; kappa statistics; long short term memory network; major clinical study; male; nonREM sleep; obstructive sleep apnea; oxygen desaturation; oxygen saturation; periodic limb movement disorder; Pittsburgh Sleep Quality Index; polysomnography; REM sleep; sleep; sleep quality; sleep stage; sleep time; slow wave sleep; stage 2 sleep; wakefulness; sleep apnea syndromes; sleep stage; telecommunication",Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85172135343,Movies / Media
Upadhyayula A.; Henderson J.M.,"Upadhyayula, Aditya (57218601773); Henderson, John M. (57212888993)",57218601773; 57212888993,Spatiotemporal jump detection during continuous film viewing: Insights from a flicker paradigm,2024,"Attention, Perception, and Psychophysics",86,2,,559,566,7.0,2,10.3758/s13414-023-02837-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181254022&doi=10.3758%2fs13414-023-02837-8&partnerID=40&md5=2dc886f336374d778c0e2db5a29782c8,"We investigated how sensitive visual processing is to spatiotemporal disruptions in ongoing visual events. Prior work has demonstrated that participants often miss spatiotemporal disruptions in videos presented in the form of scene edits or disruptions during saccades. Here, we asked whether this phenomenon generalizes to spatiotemporal disruptions that are not tied to saccades. In two flicker paradigm experiments, participants were instructed to identify spatiotemporal disruptions created when videos either jumped forward or backward in time. Participants often missed the jumps, and forward jumps were reported less frequently compared with backward jumps, demonstrating that a flicker paradigm produces effects similar to a saccade contingent disruption paradigm. These results suggest that difficulty detecting spatiotemporal disruptions is a general phenomenon that extends beyond trans-saccadic events. © 2024, The Psychonomic Society, Inc.",Change blindness; Film comprehension; Flicker paradigm; Spatiotemporal disruptions; Visual cognition,Humans; Saccades; Visual Perception; human; saccadic eye movement; vision,Article,Final,,Scopus,2-s2.0-85181254022,Movies / Media
Piras A.; Bertucco M.; Del Santo F.; Meoni A.; Raffi M.,"Piras, Alessandro (36089214500); Bertucco, Matteo (24166160400); Del Santo, Francesco (59244372400); Meoni, Andrea (57221080822); Raffi, Milena (6603459027)",36089214500; 24166160400; 59244372400; 57221080822; 6603459027,Postural stability assessment in expert versus amateur basketball players during optic flow stimulation,2024,Journal of Electromyography and Kinesiology,74,,102855,,,,0,10.1016/j.jelekin.2023.102855,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182874480&doi=10.1016%2fj.jelekin.2023.102855&partnerID=40&md5=b60d3db8467026ac94120417c2305189,"We evaluated the role of visual stimulation on postural muscles and the changes in the center of pressure (CoP) during standing posture in expert and amateur basketball players. Participants were instructed to look at a fixation point presented on a screen during foveal, peripheral, and full field optic flow stimuli. Postural mechanisms and motor strategies were assessed by simultaneous recordings of stabilometric, oculomotor, and electromyographic data during visual stimulation. We found significant differences between experts and amateurs in the orientation of visual attention. Experts oriented attention to the right of their visual field, while amateurs to the bottom-right. The displacement in the CoP mediolateral direction showed that experts had a greater postural sway of the right leg, while amateurs on the left leg. The entropy-based data analysis of the CoP mediolateral direction exhibited a greater value in amateurs than in experts. The root-mean-square and the coactivation index analysis showed that experts activated mainly the right leg while amateurs the left leg. In conclusion, playing sports for years seems to have induced some strong differences in the standing posture between the right and left sides. Even during non-ecological visual stimulation, athletes maintain postural adaptations to counteract the body oscillation. © 2023 Elsevier Ltd",Balance; Center of pressure; EMG; Eye movements; Microsaccades; Postural control,"Basketball; Humans; Leg; Muscle, Skeletal; Optic Flow; Postural Balance; Posture; adaptation; adult; article; athlete; attention; basketball player; body position; electromyogram; electromyography; entropy; eye movement; human; human experiment; normal human; optic flow; oscillation; pressure; standing; stimulation; visual attention; visual field; visual stimulation; basketball; body equilibrium; leg; physiology; skeletal muscle",Article,Final,,Scopus,2-s2.0-85182874480,Movies / Media
Ziv I.; Avni I.; Dinstein I.; Meiri G.; Bonneh Y.S.,"Ziv, Inbal (57222267475); Avni, Inbar (57211622769); Dinstein, Ilan (21742041100); Meiri, Gal (7801433301); Bonneh, Yoram S. (6603614594)",57222267475; 57211622769; 21742041100; 7801433301; 6603614594,Oculomotor randomness is higher in autistic children and increases with the severity of symptoms,2024,Autism Research,17,2,,249,265,16.0,6,10.1002/aur.3083,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181712087&doi=10.1002%2faur.3083&partnerID=40&md5=c01ce0ef321874b1c8a692176d605ba2,"A variety of studies have suggested that at least some children with autism spectrum disorder (ASD) view the world differently. Differences in gaze patterns as measured by eye tracking have been demonstrated during visual exploration of images and natural viewing of movies with social content. Here we analyzed the temporal randomness of saccades and blinks during natural viewing of movies, inspired by a recent measure of “randomness” applied to micro-movements of the hand and head in ASD (Torres et al., 2013; Torres & Denisova, 2016). We analyzed a large eye-tracking dataset of 189 ASD and 41 typically developing (TD) children (1–11 years old) who watched three movie clips with social content, each repeated twice. We found that oculomotor measures of randomness, obtained from gamma parameters of inter-saccade intervals (ISI) and blink duration distributions, were significantly higher in the ASD group compared with the TD group and were correlated with the ADOS comparison score, reflecting increased “randomness” in more severe cases. Moreover, these measures of randomness decreased with age, as well as with higher cognitive scores in both groups and were consistent across repeated viewing of each movie clip. Highly “random” eye movements in ASD children could be associated with high “neural variability” or noise, poor sensory-motor control, or weak engagement with the movies. These findings could contribute to the future development of oculomotor biomarkers as part of an integrative diagnostic tool for ASD. © 2024 The Authors. Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.",eye movements; eye-blink; eye-tracking; movies; randomness; saccade,"Autism Spectrum Disorder; Autistic Disorder; Child; Child, Preschool; Eye Movements; Humans; Infant; Saccades; age; Article; autism; Autism Diagnostic Observation Schedule; child; child development; child health; cognition; controlled study; disease association; disease severity; engagement; eye movement control; eye tracking; eyelid reflex; female; gender; human; male; saccadic eye movement; sensorimotor function; eye movement; infant; preschool child; psychology; saccadic eye movement",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85181712087,Movies / Media
MAES P.; STERCQ F.; KISSINE M.,"MAES, Pauline (57219946834); STERCQ, Fanny (57015470200); KISSINE, Mikhail (24067166300)",57219946834; 57015470200; 24067166300,Brief report: Temporal distribution of visual attention between the eyes and mouth in young autistic children,2024,Research in Autism Spectrum Disorders,110,,102292,,,,1,10.1016/j.rasd.2023.102292,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179085936&doi=10.1016%2fj.rasd.2023.102292&partnerID=40&md5=9fd8e06b4bd5aae4458bdffdcd75677f,"Background: Face scanning studies in autistic children report mixed results as to attention allocated to the eyes and mouth regions. While face scanning is a dynamic process, the way autistic children distribute their attention between the eyes and mouth of their interlocutor is usually analyzed by averaging the proportion of time spent looking either on the eyes or the mouth over the whole duration of stimulus presentation. Method: In this study, instead, we focused on the temporal distribution of visual attention between the eyes and mouth of adult faces in 58 autistic and 61 typically developing (TD) children. Participants’ eye movements were recorded as they were freely watching videos of faces of silent and speaking adults. We explored attention to the eyes and mouth with fine-grained analyses of the temporal trajectory of fixations on the two regions using generalized additive mixed effects models. Results: These analyses revealed that both groups started their observation of speaking faces on the eyes and shifted to the mouth as the actor started speaking. However, TD, but not autistic children then slowly shifted their attention back to the eyes. Conclusions: Rigorous analyses of how autistic children modulate their visual attention between key social features of the face over time may provide more accurate descriptions of their face scanning abilities. © 2023 Elsevier Ltd",Autism; Eye-tracking; Face scanning; Generalized additive mixed effects model,adult; aged; Article; autism; Autism Diagnostic Observation Schedule; detection algorithm; eye; eye movement; eye tracking; female; human; intelligence quotient; major clinical study; male; mouth; noise; visual attention,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85179085936,Movies / Media
de Belen R.A.J.; Eapen V.; Bednarz T.; Sowmya A.,"de Belen, Ryan Anthony J. (57194784108); Eapen, Valsamma (7003613122); Bednarz, Tomasz (23089950100); Sowmya, Arcot (6603623225)",57194784108; 7003613122; 23089950100; 6603623225,Using visual attention estimation on videos for automated prediction of autism spectrum disorder and symptom severity in preschool children,2024,PLoS ONE,19,2-Feb,e0282818,,,,1,10.1371/journal.pone.0282818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184881525&doi=10.1371%2fjournal.pone.0282818&partnerID=40&md5=e89b85f7060049fc2801fd44ff39efd9,"Atypical visual attention in individuals with autism spectrum disorders (ASD) has been utilised as a unique diagnosis criterion in previous research. This paper presents a novel approach to the automatic and quantitative screening of ASD as well as symptom severity prediction in preschool children. We develop a novel computational pipeline that extracts learned features from a dynamic visual stimulus to classify ASD children and predict the level of ASD-related symptoms. Experimental results demonstrate promising performance that is superior to using handcrafted features and machine learning algorithms, in terms of evaluation metrics used in diagnostic tests. Using a leave-one-out cross-validation approach, we obtained an accuracy of 94.59%, a sensitivity of 100%, a specificity of 76.47% and an area under the receiver operating characteristic curve (AUC) of 96% for ASD classification. In addition, we obtained an accuracy of 94.74%, a sensitivity of 87.50%, a specificity of 100% and an AUC of 99% for ASD symptom severity prediction. © 2024 de Belen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Algorithms; Autism Spectrum Disorder; Child, Preschool; Humans; Machine Learning; ROC Curve; Videotape Recording; accuracy; Article; autism; Autism Diagnostic Observation Schedule; child; clinical assessment; computer model; controlled study; convolutional neural network; diagnostic test accuracy study; disease severity; DSM-5; dynamic geometric image; dynamic social image; embedding; eye-tracking technology; feature extraction; female; human; human experiment; image analysis; intelligence quotient; leave one out cross validation; long short term memory network; machine learning; male; prediction; preschool child; receiver operating characteristic; sample size; sensitivity and specificity; support vector machine; videorecording; visual attention; visual stimulation; algorithm; autism; videorecording",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85184881525,Movies / Media
Denis C.; Jaussent I.; Guiraud L.; Mestejanot C.; Arquizan C.; Mourand I.; Chenini S.; Abril B.; Wacongne A.; Tamisier R.; Baillieul S.; Pepin J.-L.; Barateau L.; Dauvilliers Y.,"Denis, Claire (57397687100); Jaussent, Isabelle (6603426927); Guiraud, Lily (57193991684); Mestejanot, Caroline (57215692181); Arquizan, Caroline (6602155217); Mourand, Isabelle (21035324300); Chenini, Sofiène (56487919700); Abril, Beatriz (23033187000); Wacongne, Anne (48361735400); Tamisier, Renaud (6601974715); Baillieul, Sébastien (56114942200); Pepin, Jean-Louis (57203591408); Barateau, Lucie (56444360800); Dauvilliers, Yves (7003647751)",57397687100; 6603426927; 57193991684; 57215692181; 6602155217; 21035324300; 56487919700; 23033187000; 48361735400; 6601974715; 56114942200; 57203591408; 56444360800; 7003647751,Functional recovery after ischemic stroke: Impact of different sleep health parameters,2024,Journal of Sleep Research,33,1,e13964,,,,7,10.1111/jsr.13964,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162209909&doi=10.1111%2fjsr.13964&partnerID=40&md5=128a7a21a890be25b0d0b60b28bd9099,"Sleep disturbances after ischaemic stroke include alterations of sleep architecture, obstructive sleep apnea, restless legs syndrome, daytime sleepiness and insomnia. Our aim was to explore their impacts on functional outcomes at month 3 after stroke, and to assess the benefit of continuous positive airway pressure in patients with severe obstructive sleep apnea. Ninety patients with supra-tentorial ischaemic stroke underwent clinical screening for sleep disorders and polysomnography at day 15 ± 4 after stroke in a multisite study. Patients with severe obstructive apnea (apnea–hypopnea index ≥ 30 per hr) were randomized into two groups: continuous positive airway pressure-treated and sham (1:1 ratio). Functional independence was assessed with the Barthel Index at month 3 after stroke in function of apnea–hypopnea index severity and treatment group. Secondary objectives were disability (modified Rankin score) and National Institute of Health Stroke Scale according to apnea–hypopnea index. Sixty-one patients (71.8 years, 42.6% men) completed the study: 51 (83.6%) had obstructive apnea (21.3% severe apnea), 10 (16.7%) daytime sleepiness, 13 (24.1%) insomnia, 3 (5.7%) depression, and 20 (34.5%) restless legs syndrome. Barthel Index, modified Rankin score and Stroke Scale were similar at baseline and 3 months post-stroke in the different obstructive sleep apnea groups. Changes at 3 months in those three scores were similar in continuous positive airway pressure versus sham-continuous positive airway pressure patients. In patients with worse clinical outcomes at month 3, mean nocturnal oxygen saturation was lower whereas there was no association with apnea–hypopnea index. Poorer outcomes at 3 months were also associated with insomnia, restless legs syndrome, depressive symptoms, and decreased total sleep time and rapid eye movement sleep. © 2023 The Authors. Journal of Sleep Research published by John Wiley & Sons Ltd on behalf of European Sleep Research Society.",rapid eye movement; restless legs syndrome; sleep; sleep apnea; sleep intermittent hypoxia; stroke,"Brain Ischemia; Continuous Positive Airway Pressure; Disorders of Excessive Somnolence; Female; Humans; Ischemic Stroke; Male; Restless Legs Syndrome; Sleep; Sleep Apnea Syndromes; Sleep Apnea, Obstructive; Sleep Initiation and Maintenance Disorders; Stroke; anticoagulant agent; antifibrinolytic agent; antithrombocytic agent; aged; apnea hypopnea index; arousal; Article; Barthel index; Beck Depression Inventory; berlin questionnaire; cardiovascular mortality; Chalder Fatigue Scale; clinical evaluation; clinical outcome; computer assisted tomography; consultation; continuous positive airway pressure; controlled study; daytime somnolence; depression; disability; disease severity; electroencephalogram; Epworth sleepiness scale; female; follow up; functional status; hospital admission; hospitalization; human; independence; insomnia; Insomnia Severity Index; International Restless Legs Syndrome Study Group Rating Scale; ischemic stroke; length of stay; major clinical study; male; mechanical thrombectomy; multicenter study; National Institutes of Health Stroke Scale; nuclear magnetic resonance imaging; observational study; obstructive sleep apnea; oxygen desaturation index; percentage of REM sleep; polysomnography; prospective study; randomized controlled trial; Rankin scale; REM sleep; restless legs syndrome; self report; sleep disorder assessment; sleep efficiency; sleep latency; sleep time; slow wave sleep; stage 1 sleep; stage 2 sleep; stroke unit; thrombectomy; brain ischemia; cerebrovascular accident; complication; insomnia; ischemic stroke; restless legs syndrome; sleep; sleep apnea syndromes; somnolence",Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85162209909,Movies / Media
Xie H.; Zhou Z.,"Xie, Heping (57192430939); Zhou, Zongkui (35294601700)",57192430939; 35294601700,Finger versus pencil: An eye tracking study of learning by drawing on touchscreens,2024,Journal of Computer Assisted Learning,40,1,,49,64,15.0,5,10.1111/jcal.12863,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168685239&doi=10.1111%2fjcal.12863&partnerID=40&md5=f3a15ee98d792ba301060af046fe4f5e,"Background: Drawing is generally regarded as a promising learning strategy and has been explored in the touchscreen setting with different drawing modes. Although both a finger and a digital pencil can help individuals complete drawing activities effortlessly on touchscreen devices, there is no guarantee that they show the same effect on learning, which should be further tested. Objectives: This study paid attention to the influence of drawing mode on learning processes and outcomes. Methods: By means of the eye tracking technique, this study recruited college students as participants who were required to learn instructional materials consisting of actual (Experiment 1) or fictitious (Experiment 2) terms and definitions to test the effects of touchscreen-based finger drawing versus pencil drawing on visual attention, learning performance as well as motivation. Results and Conclusions: Across both experiments, learners showed more fixation count in areas of interest, and also more transition count between these areas for the finger drawing condition as compared to the pencil drawing condition. Recall performance on the studied definitions in the finger drawing condition was better than that in the pencil drawing condition. However, learners were subjectively less motivated to use a finger to draw than a digital pencil. Implications: These findings show contributions to the emphasis of importance of drawing mode when the generative drawing activity is applied to touchscreens. © 2023 John Wiley & Sons Ltd.",attention guidance; eye tracking; learning by drawing; learning outcome; touchscreens,,Article,Final,,Scopus,2-s2.0-85168685239,Movies / Media
Biradarpatil R.S.; Chinmayee B.L.; Hegde S.; Mallibhat K.; Mudenagudi U.,"Biradarpatil, Rohit S. (59255955100); Chinmayee, B.L. (59256267200); Hegde, Shreesha (59256581400); Mallibhat, Kaushik (59255952100); Mudenagudi, Uma (6508142222)",59255955100; 59256267200; 59256581400; 59255952100; 6508142222,Eye Gaze Tracking Towards User Attention Analysis,2024,"2024 5th International Conference for Emerging Technology, INCET 2024",,,,,,,1,10.1109/INCET61516.2024.10593440,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200969159&doi=10.1109%2fINCET61516.2024.10593440&partnerID=40&md5=eb50e970d8f57cd32b257814418d4612,"Eye-tracking is a method that involves monitoring the position and movement of eyes that can help towards wide variety of applications including gaming, augmented reality, virtual reality, assistive technologies, human computer interface, marketing and medical diagnostic applications. The authors in this paper uses L2CS-Net, a novel gaze estimation architecture built on ResNet-50. The model, was validated on the MPII Gaze dataset through 5-fold cross-validation and exhibited consistent reduction in combined loss during training, showcasing its promising performance in accurate gaze estimation. The performance of the model was demonstrated for an application of profiling the attention of the user and monitoring the off-screen glances of the user while watching a video. Thus, demonstrating potential applications towards user attention detection in educational and marketing applications. © 2024 IEEE.",Cross-Entropy Loss; L2CS-Net; Mean Angular Error; MPII Gaze dataset; Pitch; Yaw,Augmented reality; Diagnosis; Eye movements; Marketing; Angular errors; Cross entropy; Cross-entropy loss; Entropy loss; L2CS-net; Mean angular error; MPII gaze dataset; Pitch; User attention; Yaw; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85200969159,Movies / Media
"da Silva Soares R., Jr.; Ramirez-Chavez K.L.; Tufanoglu A.; Barreto C.; Sato J.R.; Ayaz H.","da Silva Soares, Raimundo (58876419100); Ramirez-Chavez, Kevin L. (58876416200); Tufanoglu, Altona (58876468400); Barreto, Candida (57223823764); Sato, João Ricardo (56668321500); Ayaz, Hasan (6507639765)",58876419100; 58876416200; 58876468400; 57223823764; 56668321500; 6507639765,"Cognitive Effort during Visuospatial Problem Solving in Physical Real World, on Computer Screen, and in Virtual Reality",2024,Sensors,24,3,977,,,,5,10.3390/s24030977,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184657294&doi=10.3390%2fs24030977&partnerID=40&md5=f7c23b2733d375559fc98cd458b397bb,"Spatial cognition plays a crucial role in academic achievement, particularly in science, technology, engineering, and mathematics (STEM) domains. Immersive virtual environments (VRs) have the growing potential to reduce cognitive load and improve spatial reasoning. However, traditional methods struggle to assess the mental effort required for visuospatial processes due to the difficulty in verbalizing actions and other limitations in self-reported evaluations. In this neuroergonomics study, we aimed to capture the neural activity associated with cognitive workload during visuospatial tasks and evaluate the impact of the visualization medium on visuospatial task performance. We utilized functional near-infrared spectroscopy (fNIRS) wearable neuroimaging to assess cognitive effort during spatial-reasoning-based problem-solving and compared a VR, a computer screen, and a physical real-world task presentation. Our results reveal a higher neural efficiency in the prefrontal cortex (PFC) during 3D geometry puzzles in VR settings compared to the settings in the physical world and on the computer screen. VR appears to reduce the visuospatial task load by facilitating spatial visualization and providing visual cues. This makes it a valuable tool for spatial cognition training, especially for beginners. Additionally, our multimodal approach allows for progressively increasing task complexity, maintaining a challenge throughout training. This study underscores the potential of VR in developing spatial skills and highlights the value of comparing brain data and human interaction across different training settings. © 2024 by the authors.",cognitive workload; fNIRS; geometry puzzle; neuroergonomics; spatial cognition; tangram; virtual reality,Functional neuroimaging; Infrared devices; Near infrared spectroscopy; Neurons; Visualization; Cognitive efforts; Cognitive workloads; Computer screens; Functional near infrared spectroscopy; Geometry puzzle; Neuroergonomic; Problem-solving; Spatial cognition; Spatial reasoning; Tangram; Virtual reality,Article,Final,,Scopus,2-s2.0-85184657294,Movies / Media
Sarimski R.; Schwartze M.M.; Müller C.; Zentel P.,"Sarimski, Ruth (59307875300); Schwartze, Manuel M (57219849876); Müller, Christian (59307720200); Zentel, Peter (55217633800)",59307875300; 57219849876; 59307720200; 55217633800,Image perception and reception in wordless picture books: Eye movements of children with intellectual disabilities,2024,Journal of Intellectual Disabilities,,,,,,,0,10.1177/17446295241276030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202767055&doi=10.1177%2f17446295241276030&partnerID=40&md5=0556d159e3b5b966cc30e97b0ba89165,"Wordless picture books enhance comprehension and vocabulary growth and motivate children with intellectual disabilities (ID) to participate in literary activities. However, the reception of picture books can be challenging because deliberate selective attention processes and recognition of the image's meaning are often delayed. Examining eye movements may help explore these cognitive processes. Therefore, we examined eye movements in 29 children with mild and moderate ID as they explored a wordless picture book, presented on a screen and compared them to 14 typically developing children using a Tobii Pro X3-120 eye tracker. The findings showed that children with moderate ID had shorter fixation duration, fixated less often, and revisited regions of interest less frequently. Our results suggest that children with moderate ID have greater difficulties in selectively directing their attention toward regions of visual input with a high level of informativeness and expend less cognitive effort to understand their meaning. © The Author(s) 2024.",eye-tracking; image reception; intellectual disabilities; picture books; selective attention,,Article,Article in press,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85202767055,Movies / Media
Williot A.; Lafond D.; Tremblay S.; Marois A.,"Williot, Alexandre (36106559100); Lafond, Daniel (24178697000); Tremblay, Sébastien (35238788400); Marois, Alexandre (57196002470)",36106559100; 24178697000; 35238788400; 57196002470,Surveillance-Behavior Support by a Real-Time Gaze-Based Tool Integrated with Augmented Reality,2024,"2024 IEEE Conference on Cognitive and Computational Aspects of Situation Management, CogSIMA 2024",,,,1,7,6.0,1,10.1109/CogSIMA61085.2024.10553855,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196749281&doi=10.1109%2fCogSIMA61085.2024.10553855&partnerID=40&md5=8db847f4ac7c1d540f3d2ee9805bdf2b,"Video surveillance can be cognitively very demanding as it imposes operators to stay focus for a long time and to provide the right response for relevant stimuli among a lot of information. In this challenging activity, it is relevant to consider the use of decision-aid techniques to improve operators’ alertness. The purpose of this study was to examine the impact of a real-time gaze-based tool named Scantracker—which can identify instances of neglect, over-focus and vigilance decrement using eye tracking and display visual notifications to mitigate such situations—on surveillance performance measures during a surveillance simulation. Augmented reality glasses were used to monitor eye movements in real time for all non-expert participants, but notifications presentation to support attention was visually active for only half of them (Scantracker group), as opposed to the control group without support from the Scantracker. No significant differences were observed across those two groups. However, a within-group comparison contrasting trials with active notifications vs. a silent condition showed a reliable improvement in task accuracy and a reduction in screen neglect duration. Results are discussed in light of potential applications of Scantracker with augmented reality. © 2024 IEEE.",Augmented reality; Eye movements; Human-automation teaming; Real-time measures; Video surveillance,Augmented reality; Decision support systems; Eye tracking; Security systems; Condition; Control groups; Decision aids; Eye-tracking; Human-automation teaming; Performance measure; Real time measure; Real- time; Video surveillance; Vigilance decrement; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85196749281,Movies / Media
Surendran A.; Beccaria L.; Rees S.; Mcilveen P.,"Surendran, Anu (58894647100); Beccaria, Lisa (55363452600); Rees, Sharon (15725914500); Mcilveen, Peter (12808257400)",58894647100; 55363452600; 15725914500; 12808257400,Cognitive mental workload of emergency nursing: A scoping review,2024,Nursing Open,11,2,e2111,,,,4,10.1002/nop2.2111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185390924&doi=10.1002%2fnop2.2111&partnerID=40&md5=b92fe460dc82d0890ffeff5de646d63e,"Aim: Emergency nurses work in an environment of high cognitive mental workload. Excessive cognitive mental workload may result in patient harm and nurses' burnout. Therefore, it is necessary to understand nurses' subjective experience of cognitive workload. This scoping review aimed to curate literature about the subjective experience of cognitive mental workload reported by nurses and psychometric measures of the phenomenon. Design: The scoping review was conducted in accordance with JBI methodology and reported using PRISMA extension for scoping review checklist. Methods: A priori protocol was created with Peer Review of Electronic Search Strategies checklist and registered in the OSF registry. Databases including PubMed, CINAHL, ProQuest, Scopus, Science Direct, Web of Science and Google Scholar were searched. Published reports were reviewed against the eligibility criteria by performing Title and Abstract screening, followed by Full-text screening. The initial search yielded 1373 studies. Of these, 57 studies met the criteria for inclusion in this study. Results: The search revealed five general measures of cognitive mental workload and their variations. Only one customised measure specifically for medical–surgical nurses was found in the study. Identified measures were collated and categorised into a framework for conceptual clarity. NASA Task Load Index and its variations were the most popular subjective measure of cognitive mental workload in nursing. However, no measure or self-report scale customised for emergency nurses was identified. Patient or Public Contribution: The findings of this scoping review can inform future research into the cognitive mental workload of nurses. The findings have implications for workplace health and safety for nurses and patients. © 2024 The Authors. Nursing Open published by John Wiley & Sons Ltd.",cognitive load; cognitive workload; emergency nurse; measure; mental workload; nurse; scale; self-report; subjective scale; workload,"Burnout, Professional; Cognition; Emergency Nursing; Humans; Workload; cognition; emergency nursing; human; professional burnout; workload",Review,Final,,Scopus,2-s2.0-85185390924,Movies / Media
Han C.; Zheng B.; Xie M.; Chen S.,"Han, Chao (56609599600); Zheng, Binghan (55512006100); Xie, Mingqing (57226301865); Chen, Shirong (58945553800)",56609599600; 55512006100; 57226301865; 58945553800,Raters’ scoring process in assessment of interpreting: an empirical study based on eye tracking and retrospective verbalisation,2024,Interpreter and Translator Trainer,18,3,,400,422,22.0,5,10.1080/1750399X.2024.2326400,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188058684&doi=10.1080%2f1750399X.2024.2326400&partnerID=40&md5=e16afd8d758aee0c955650032083685b,"Human raters’ assessment of interpreting is a complex process. Previous researchers have mainly relied on verbal reports to examine this process. To advance our understanding, we conducted an empirical study, collecting raters’ eye-movement and retrospection data in a computerised interpreting assessment in which three groups of raters (n = 35) used an analytic rubric to assess 12 English-to-Chinese consecutive interpretations. We examined how the raters interacted with the source text, the rating scale, and the audio player displayed on the computer screen when they were assessing. We found that a) the source text and the rating scale were competing for the raters’ visual attention, with the former attracting more attention than the latter across the rater groups; b) when the raters were consulting the rating scale, they fixated less frequently on the sub-scale of target language quality than the other two sub-scales; c) the rater groups did not seem to exhibit substantially discrepant gazing behaviours overall, although there emerged different eye-movement patterns concerning certain sub-scales; and d) the raters utilised an array of strategies and shortcuts to facilitate their assessment. We discuss these findings in relation to rater training and validation of score meaning for interpreting assessment. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",eye tracking; Interpreting assessment; rater cognition; retrospective verbalisation; scoring process,,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85188058684,Movies / Media
Li X.; Chang Q.; Hu M.; Xu F.; Liang H.; Ding X.,"Li, Xin (57196399539); Chang, Qinyuan (59520435300); Hu, Mingming (59667594400); Xu, Feiyang (57203167888); Liang, Huadong (57679142500); Ding, Xinyun (58002247700)",57196399539; 59520435300; 59667594400; 57203167888; 57679142500; 58002247700,"A Multimodal Framework for Automated Childhood Reading Disability Screening Integrating Speech, Language, and Eye Tracking",2024,"Proceedings of the 2024 11th IEEE International Conference on Behavioural and Social Computing, BESC 2024",,,,,,,0,10.1109/BESC64747.2024.10780681,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215506187&doi=10.1109%2fBESC64747.2024.10780681&partnerID=40&md5=5e231b961d1f95356271af8dc09916a5,"Screening for reading disabilities in childhood is a critical yet challenging task that conventional methods often fail to address with efficiency and accuracy due to a lack of standardization. This study introduces an innovative multimodal framework that synergistically integrates speech, language, and eye-tracking modalities to automate the screening of reading disabilities in children. The groundwork was laid by developing a comprehensive developmental model of Chinese reading abilities through meta-analysis and expert consensus. This model underpinned the creation of a multimodal database comprising speech recordings, eye-tracking trajectories, and behavioral data collected from school-aged children. Employing self-attention mechanisms, our novel end-to-end technique, specifically designed for Chinese reading tasks, exhibited exceptional performance, achieving an F1 score of 93.21% for character recognition and 90.98% for rapid automatized naming in speech assessments. Notably, we devised an embedding representation approach that incorporates domain knowledge to capture intricate multimodal patterns. In conjunction, a cross-modal attention mechanism facilitated effective feature fusion across modalities. Further, ensemble learning strategies combining deep learning with traditional machine learning classifiers yielded an accurate risk prediction rate of 84.21%. A comprehensive evaluation system, quantifying reading abilities through multidimensional eye movement indicators, discerned statistically significant differences between typical readers and those with impairments. Collectively, this framework offers a standardized, efficient, and precise solution for the identification of reading disabilities in children, thereby paving the way for timely interventions and tailored educational strategies.  © 2024 IEEE.",Automated Screening; Childhood Reading Disabilities; Cross-Modal Attention; Ensemble Learning; Eye-Tracking; Multimodal Fusion; Self-Attention Mechanisms,Adversarial machine learning; Contrastive Learning; Deep learning; Diagnosis; Federated learning; Risk assessment; Risk perception; Speech analysis; Attention mechanisms; Automated screening; Childhood reading disability; Cross-modal; Cross-modal attention; Ensemble learning; Eye-tracking; Multi-modal fusion; Multimodal frameworks; Self-attention mechanism; Eye movements,Conference paper,Final,,Scopus,2-s2.0-85215506187,Movies / Media
Park H.; Lee Y.,"Park, Hwidong (59321255000); Lee, Younjoon (57199710783)",59321255000; 57199710783,The Effect of Text Movement on Eye Movements in Generative AI Chatbots; [생성형 인공지능 챗봇(Generative AI Chatbot)의 텍스트 움직임이 안구운동에 미치는 영향 연구],2024,Archives of Design Research,37,4,,181,197,16.0,0,10.15187/adr.2024.08.37.4.181,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203554622&doi=10.15187%2fadr.2024.08.37.4.181&partnerID=40&md5=64cabac755a7350e13b13947148ec17a,"Background Text generating artificial intelligence(AI) chatbots are gaining attention as a new information exploration service. The way participants receive information has expanded through interaction and communication with these chatbots. This study aims to investigate the influence of the nonverbal element of text movement on informative conversations between text generating AI chatbots and conversation participants through eye-tracking. Methods The key attributes were derived through a theoretical review of movement, and these were applied to the conversational interface of the text-generating AI chatbot, classifying them into four types. Eye movement data was collected through eye-tracking while 36 experimental participants read the conversational text generated by the chatbot. In the analysis, differences were identified through repeated measures analysis of variance (ANOVA), Bonferroni post-hoc analysis, and independent samples t-test. Results The direction and focus, the elements of text movement occurring from the bottom, were relatively high in terms first fixation duration, number of whole fixations, and saccade amplitude. This appeared in consecutive conversations with ChatGPT and Bing AI, affecting higher cognitive activities. Additionally, an increase in generating speed of conversational text influenced the differences between text movement types. Therefore, the movement elements must be combined on the top of the screen to reduce excessive cognitive activities. Conclusions In order to achieve effective visual communication with the use of text-generating AI chatbots, design should consider how the text movement impacts the user’s eye movement and cognition, which aims to enhance the comprehension of information while also limiting cognitive overload. Copyright: This is an Open Access article distributed under the terms of the Creative Commons Attribution NonCommercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits unrestricted educational and non-commercial use, provided the original work is properly cited.",Conversational User Interface; Eye Tracking; Text Generation AI Chatbot; Text Movement; 대화형 인터페이스; 아이트래킹; 주제어 텍스트 생성 인공지능 챗봇; 텍스트 움직임,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85203554622,Movies / Media
Sun W.; Wang Y.; Hu B.; Wang Q.,"Sun, Weifeng (58494815900); Wang, Yuqi (56819153500); Hu, Bingliang (26660863200); Wang, Quan (56145277600)",58494815900; 56819153500; 26660863200; 56145277600,Exploring the Connection between Eye Movement Parameters and Eye Fatigue,2024,Journal of Physics: Conference Series,2722,1,12013,,,,2,10.1088/1742-6596/2722/1/012013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191957977&doi=10.1088%2f1742-6596%2f2722%2f1%2f012013&partnerID=40&md5=d75b8f518b0d0126653fc7bf467a4f47,"Eye fatigue, a prominent symptom of computer vision syndrome (CVS), has gained significant attention in various domains due to the increasing diversification of electronic display devices and their widespread usage scenarios. The COVID-19 pandemic has further intensified the reliance on these devices, leading to prolonged screen time. This study aimed to investigate the effectiveness of utilizing eye movement patterns in discriminating fatigue during the usage of electronic display devices. Eye movement data was collected from subjects experiencing different levels of fatigue, and their fatigue levels were recorded using the T/CVIA-73-2019 scale. The analysis revealed that features related to the pupils demonstrated a high level of confidence and reliability in distinguishing fatigue, especially related to pupil size. However, features associated with fixations, such as fixation duration and frequency, did not significantly contribute to fatigue discrimination. Furthermore, the study explored the influence of subjective awareness on fatigue discrimination. By modifying the experimental settings and considering the subjects' subjective perception, it was observed that individual consciousness and self-awareness played a crucial role in fatigue discrimination. The implications of these findings extend beyond the field of computer vision syndrome, offering potential applications in developing interventions and strategies to alleviate eye fatigue and promote eye health among individuals who extensively use electronic display devices. © Published under licence by IOP Publishing Ltd.",,Computer vision; Display devices; Eye movements; Computer vision syndromes; Electronic display devices; Eye fatigue; Eye movement datum; Eye movement patterns; Fatigue level; Fixation duration; Pupil size; Screen time; Usage scenarios; Reliability analysis,Conference paper,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85191957977,Movies / Media
Yang Q.; Fu Y.; Yang Q.; Yin D.; Zhao Y.; Wang H.; Zhang H.; Sun Y.; Xie X.; Du J.,"Yang, Qian (59455655700); Fu, Yanyan (59456378600); Yang, Qiuli (57195962322); Yin, Dongqing (57204562309); Zhao, Yanan (57213968756); Wang, Hao (57213065228); Zhang, Han (59455655800); Sun, Yanran (59456882200); Xie, Xinyi (59456134500); Du, Jian (57212564180)",59455655700; 59456378600; 57195962322; 57204562309; 57213968756; 57213065228; 59455655800; 59456882200; 59456134500; 57212564180,Eye movement characteristics of emotional face recognizing task in patients with mild to moderate depression,2024,Frontiers in Neuroscience,18,,1482849,,,,1,10.3389/fnins.2024.1482849,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210918273&doi=10.3389%2ffnins.2024.1482849&partnerID=40&md5=1d6ba6dbed2dc8f7eaa4a3b6908e8bb6,"Objective: Depression is a complex affective disorder characterized by high prevalence and severe impact, commonly presenting with cognitive impairment. The objective diagnosis of depression lacks precise standards. This study investigates eye movement characteristics during emotional face recognition task (EFRT) in depressive patients to provide empirical support for objective diagnosis. Methods: We recruited 43 patients with depression (Depressive patients, DP) from a psychiatric hospital and 44 healthy participants (Healthy Control, HC) online. All participants completed an EFRT comprising 120 trials. Each trial presented a gray screen for 800 ms followed by a stimulus image for judgment. Emotions were categorized as positive, neutral, or negative. Eye movement trajectories were recorded throughout the task. Latency of First Fixation (LFF), Latency of First Fixation for Eye AOI, and Latency of First Fixation for Mouth AOI were used as representative indicators of early attention, Proportion of Eye AOI, and Proportion of Mouth AOI as measures of intermediate attention, Accuracy (ACC) and Reaction Time (RT) as behavioral indicators of late-stage attention. In this study, these metrics were employed to explore the differences between patients with depression and healthy individuals. Results: Compared to healthy participants, individuals with depression exhibit longer first fixation latencies on the eyes and mouth during the early attention stage of emotional face recognition, indicating an avoidance tendency toward key facial recognition cues. In the mid-to-late attention stages, depressive individuals show an increased fixation ratio on the eyes and a decreased fixation ratio on the mouth, along with lower accuracy and longer response times. These findings suggest that, relative to healthy individuals, individuals with depression have deficits in facial recognition. Conclusion: This study identified distinct attention patterns and cognitive deficits in emotional face recognition among individuals with depression compared to healthy individuals, providing an attention-based approach for exploring potential clinical diagnostic markers for depression. Copyright © 2024 Yang, Fu, Yang, Yin, Zhao, Wang, Zhang, Sun, Xie and Du.",AOI; cognitive deficit; depression; emotional facial expression recognition; eye movement,adult; aged; Article; attention; avoidance behavior; clinical article; cognitive defect; controlled study; decision making; depression; emotion; emotional face recognition task; experimental design; eye movement; eye tracking; facial expression; facial recognition; facies; female; Hamilton Depression Rating Scale; Hamilton Depression Rating Scale 17; human; image analysis; latency of first fixation; latent period; learning and memory test; look proportion; male; measurement accuracy; middle aged; reaction time; social media; Symptom Checklist 90; visual attention,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85210918273,Movies / Media
Barbosa Â.P.; Oliveira T.M.; Trindade P.H.E.; Seidel S.R.T.; Tokawa P.K.A.; Jaramilo F.M.; Roncati N.V.; Baccarin R.Y.A.,"Barbosa, Ângela P. (57225194943); Oliveira, Tiago M. (54980281100); Trindade, Pedro Henrique E. (57200448132); Seidel, Sarah R. T. (57204672416); Tokawa, Paula K. A. (57504907300); Jaramilo, Fernando M. (58843733100); Roncati, Neimar V. (54279343000); Baccarin, Raquel Y. A. (9043086800)",57225194943; 54980281100; 57200448132; 57204672416; 57504907300; 58843733100; 54279343000; 9043086800,Sleep Pattern Interference in the Cognitive Performance of Lusitano Horses,2024,Animals,14,2,334,,,,3,10.3390/ani14020334,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183106805&doi=10.3390%2fani14020334&partnerID=40&md5=4aac07bfc48121889ec786ed8f276d7b,"Like most mammalian, polyphasic sleep, equine sleep can be divided into two phases: the REM (rapid eye movement) phase and the NREM (non-rapid eye movement) phase. For this study, a randomized crossover experiment was conducted using ten purebred Lusitano horses, all dressage athletes aged from three to seven years old. The horses were filmed before the intervention to characterize their sleep patterns. REM sleep deprivation was achieved by not letting the horses attain sternal or lateral recumbency for three consecutive days, totaling 72 h. A spatial memory task and a visual attention test were performed. A recording time of 48 h appeared to be long enough to characterize the sleep patterns of the stalled horses. The total recumbency time of the studied population was lower than that previously reported in horses. Although the recumbency times before and after the intervention were similar, there was a tendency shown by the delta (p = 0.0839) towards an increased time needed to resolve spatial memory tasks in the sleep-deprived group. Future studies may deepen the understanding of horse sleep requirements and patterns, and the effects of environmental changes on horse sleep. © 2024 by the authors.",learning; REM sleep; sleep–wake cycle; welfare,aged; animal experiment; article; athlete; attention test; crossover procedure; drug therapy; environmental change; Equus; female; horse; learning; male; mental performance; nonhuman; percentage of REM sleep; randomized controlled trial; recumbency; REM sleep; REM sleep deprivation; sleep; sleep pattern; sleep waking cycle; spatial memory test; visual attention,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85183106805,Movies / Media
Takase M.; Shimizu S.; Morimoto T.; Okuno S.,"Takase, Miwa (58911445600); Shimizu, Sota (55448783400); Morimoto, Takumi (58911713600); Okuno, Satoshi (57804199700)",58911445600; 55448783400; 58911713600; 57804199700,Discriminant Method between Consciously Paying Attention and Unconsciously Seeing using Gaze Rate Distribution,2024,"2024 IEEE/SICE International Symposium on System Integration, SII 2024",,,,834,839,5.0,1,10.1109/SII58957.2024.10417547,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186269138&doi=10.1109%2fSII58957.2024.10417547&partnerID=40&md5=9d2df68f38f9987d0b8d23e328baf618,"This paper proposes a discriminant method whether a person pays attention to something consciously (intentionally) or sees it unconsciously by using a time-series of gaze rate distributions. The gaze rate is defined as a statistical possibility of when and where many people look, e.g. in some target movie. In this paper, first, eye movement data from multiple participants wearing a head mount display (HMD) are measured when some movie is displayed. Second, the gaze rate is calculated as a distribution of statistical probabilities at each frame (time). Lastly, verification experiments of our proposed gaze rate-based conscious/unconscious discrimination have been conducted compared to results from saliency-map-based prior method, and have got better results numerically. The author think it is quite important and meaningful to distinguish whether a person look at something consciously or just sees unconsciously, because it is not difficult to understand such discrimination improves analysis of persons' potential consciousness more precisely and more in detail.  © 2024 IEEE.",,Eye movements; Eye movement datum; Frame time; Head-mount displays; Rate distributions; Saliency map; Statistical probability; Times series; Probability distributions,Conference paper,Final,,Scopus,2-s2.0-85186269138,Movies / Media
Küchelmann T.; Velentzas K.; Essig K.; Schack T.,"Küchelmann, Thomas (37461511700); Velentzas, Konstantinos (26667342200); Essig, Kai (6701685019); Schack, Thomas (22635455800)",37461511700; 26667342200; 6701685019; 22635455800,Expertise-dependent visuocognitive performance of chess players in mating tasks: evidence from eye movements during task processing,2024,Frontiers in Psychology,15,,1294424,,,,1,10.3389/fpsyg.2024.1294424,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208637441&doi=10.3389%2ffpsyg.2024.1294424&partnerID=40&md5=5c212a253744785bab0bdee2b1dd8fb5,"Introduction: Visuocognitive performance is closely related to expertise in chess and has been scrutinized by several investigations in the last decades. The results indicate that experts’ decision-making benefits from the chunking process, perception and visual strategies. Despite numerous studies which link these concepts, most of these investigations have employed common research designs that do not use real chess play, but create artificial laboratory conditions via screen-based chess stimuli and obtrusive stationary eye tracking with or without capturing of decision-making or virtual reality settings. Methods: The present study assessed the visuocognitive performance of chess novices, intermediates and experts in a real chess setting. Instead of check detection, find-the-best-move tasks or to distinguish between regions of a chessboard that were relevant or irrelevant to the best move in previous studies, we introduced n-mate tasks and sequentially manipulated their difficulty. Due to the complexity of the tasks, we monitored players’ visual strategies in a fine-graded initial phase (different time intervals instead of analysing a fixed number of first fixations) of task-solving and for complete trials, employing non-obtrusive mobile eye tracking, multi-sensor observation and full-automatic annotation of decision-making. Results: The results revealed significant expertise-dependent differences in visuocognitive performance based on a circumstantial spatial and temporal analysis. In order to provide more detailed results, for the first time the analyses were performed under the special consideration of different time intervals and spatial scalings. In summary, experts showed a significantly higher number of fixations on areas of interest and empty squares between pieces in the task processing than less-skilled players. However, they had a strikingly low total number of fixations on the whole board and in complete trials. Discussion: As a conclusion, experts apply different visual search strategies in problem-solving. Moreover, experts’ visuocognitive processing benefits from stored chunks of mating constellations. Copyright © 2024 Küchelmann, Velentzas, Essig and Schack.",chess expertise; eye tracking; multi-sensor observation; perceptual processing; visual attention,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85208637441,Movies / Media
Zhang J.; Feng Y.,"Zhang, Jicheng (58919527000); Feng, Yi (58684699800)",58919527000; 58684699800,Research on the Creative Performance of Digital Film and Television Works Based on Virtual Reality Technology,2024,Applied Mathematics and Nonlinear Sciences,9,1,,,,,2,10.2478/amns-2024-0633,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186712406&doi=10.2478%2famns-2024-0633&partnerID=40&md5=c1ab95aac8e3eb6ad8505412f22837ed,"This study investigates the application of virtual reality technology in the creative expression of digital film and television productions, especially the role of EEG signal denoising and feature recognition methods in enhancing the audience experience. The study uses wavelet threshold denoising and parallel RLS adaptive filtering algorithms to process EEG signals to improve the accuracy and reliability of the data. Then, the EEG signals were feature extracted using a bi-hemispheric domain adversarial neural network (BiDANN) to more accurately recognize the user’s emotional responses. The experimental results show that in the virtual reality environment, the users’ concentration and emotional reactions are significantly improved, with the average concentration reaching 74.21 and the average value of the electrodermal test data being 6.19. In addition, the eye-movement interaction experiments show that different types of digital movie and television works can cause additional attention allocation of users in the VR environment, leading other creative performance effects. The study’s results prove that virtual reality technology can significantly enhance the innovative performance of digital movie and television works and improve the audience’s viewing experience. © 2023 Jicheng Zhang and Yi Feng, published by Sciendo.",Creative performance; Digital film and television works; EEG denoising; Feature recognition; Virtual reality technology,Adaptive filters; Biomedical signal processing; Electroencephalography; Eye movements; Virtual reality; Creative performance; Creatives; De-noising; Digital film and television work; Digital films; Digital movies; EEG denoising; EEG signals; Features recognition; Virtual reality technology; Adaptive filtering,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85186712406,Movies / Media
Fang Y.; Pérez-Molerón J.M.; Merino L.; Gomez R.,"Fang, Yu (57261733400); Pérez-Molerón, José Manuel (59302708500); Merino, Luis (7003946345); Gomez, Randy (12806763700)",57261733400; 59302708500; 7003946345; 12806763700,Enhancing Human Perception of Direct Gaze from a Social Robot through Eye-Head Coordination,2024,"IEEE International Workshop on Robot and Human Communication, RO-MAN",,,,2037,2043,6.0,0,10.1109/RO-MAN60168.2024.10731195,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209823545&doi=10.1109%2fRO-MAN60168.2024.10731195&partnerID=40&md5=4a1e87c17fea193e4e6422fccfde7b52,"The development and integration of robots capable of expressing gaze directionality through eye-head movements are crucial for effective human-robot interaction, especially for those with eye designs on 2D screens. Our proposed mutual eye-head gaze model aligns eye movements with head/body rotation, incorporating an attention engine for estimating the most saliency location, and a retina-fovea engine for precise gaze alignment. Additionally, the eye-head engine controls head movements, enhancing the robot's ability to perform responsive coordinated eye-head gaze behaviors. This improvement leads to enhanced human subjective perception of direct gaze from the robot, ultimately holding potential for advancing human-robot interaction in social dynamics and human-centered robot development research.  © 2024 IEEE.",,Anthropomorphic robots; Behavioral research; Eye movements; Eye protection; Industrial robots; Intelligent robots; Machine design; Man machine systems; Microrobots; Nanorobots; Engine control; Eye-head coordination; Gaze behaviours; Head movements; Human perception; Humans-robot interactions; Robot development; Social dynamics; Social robots; Subjective perceptions; Social robots,Conference paper,Final,,Scopus,2-s2.0-85209823545,Movies / Media
Alexander R.G.; Venkatakrishnan A.; Chanovas J.; Ferguson S.; Macknik S.L.; Martinez-Conde S.,"Alexander, Robert G. (53986130600); Venkatakrishnan, Ashwin (57222048174); Chanovas, Jordi (57210588516); Ferguson, Sophie (58976617900); Macknik, Stephen L. (6603312653); Martinez-Conde, Susana (6603412728)",53986130600; 57222048174; 57210588516; 58976617900; 6603312653; 6603412728,Why did Rubens add a parrot to Titian’s The Fall of Man? A pictorial manipulation of joint attention,2024,Journal of Vision,24,4,1,,,,0,10.1167/JOV.24.4.1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189790370&doi=10.1167%2fJOV.24.4.1&partnerID=40&md5=c500ac330f8a3e8058375a57bfae21b1,"Almost 400 years ago, Rubens copied Titian’s The Fall of Man, albeit with important changes. Rubens altered Titian’s original composition in numerous ways, including by changing the gaze directions of the depicted characters and adding a striking red parrot to the painting. Here, we quantify the impact of Rubens’s choices on the viewer’s gaze behavior. We displayed digital copies of Rubens’s and Titian’s artworks—as well as a version of Rubens’s painting with the parrot digitally removed—on a computer screen while recording the eye movements produced by observers during free visual exploration of each image. To assess the effects of Rubens’s changes to Titian’s composition, we directly compared multiple gaze parameters across the different images. We found that participants gazed at Eve’s face more frequently in Rubens’s painting than in Titian’s. In addition, gaze positions were more tightly focused for the former than for the latter, consistent with different allocations of viewer interest. We also investigated how gaze fixation on Eve’s face affected the perceptual visibility of the parrot in Rubens’s composition and how the parrot’s presence versus its absence impacted gaze dynamics. Taken together, our results demonstrate that Rubens’s critical deviations from Titian’s painting have powerful effects on viewers’ oculomotor behavior. Copyright 2024 The Authors This work is onlicensed 05/14/2024 under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",artwork analysis; eye movement patterns; fixational eye movements; gaze behavior; joint attention; microsaccades; oculomotor dynamics; renaissance art; shared gaze; troxler fading; viewer interest,"Animals; Attention; Eye Movements; Fixation, Ocular; Humans; Male; Paintings; Parrots; animal; attention; eye fixation; eye movement; human; male; painting; parrot",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85189790370,Movies / Media
Zhang K.; Chen Y.; Luo J.-F.; Hu M.; An X.; Zhai G.; Zhang X.-P.,"Zhang, Kaixun (58917345300); Chen, Yuzhen (57215427495); Luo, Ji-Feng (59194528900); Hu, Menghan (55818700700); An, Xudong (59440779900); Zhai, Guangtao (15847120000); Zhang, Xiao-Ping (35214025100)",58917345300; 57215427495; 59194528900; 55818700700; 59440779900; 15847120000; 35214025100,Human-Centered Financial Signal Processing: A Case Study on Stock Chart Analysis,2024,Communications in Computer and Information Science,2067 CCIS,,,187,198,11.0,0,10.1007/978-981-97-3626-3_14,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200440427&doi=10.1007%2f978-981-97-3626-3_14&partnerID=40&md5=0a0ae07fa00afdb4b6fc99fdc7e55378,"In this paper, we explore the “human-centered” financial model. To illustrate this idea, we conducted a case study on the stock chart, referring to stock price chart plus stock volume chart. We first construct the stock chart with professional stock traders’ visual attention (SPSTV) dataset, which contains 150 stock charts images associated with eye-movement data from 10 professional stock traders. Based on the SPSTV dataset, the transfer learning and human attention inspired morphological operation are leveraged to develop the stock chart attention model. In validation experiments, compared to other models, SamVgg optimized by transfer learning and human visual attention function performs best with the AUC_Judd, CC, SIM, and NSS of 96.11%, 82.74%, 69.84%, and 2.84, respectively. Through visual comparative analysis, we can find that the visual attention map area after the double optimization strategy is more focused overall and has less excess attention at the edges. This visual optimization will enhance people’s observation experience. The proposed model has great potential for two application scenarios: (1) instruct amateur traders how to observe stock charts; and (2) evaluate stock analysis ability of investors. In the future, we will continue to iterate the model and try to apply it in real economic activities to generate benefits.  © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.",Financial Computer Vision; Financial Signal Processing; Human Attention; Saliency Prediction; Stock Analysis,Behavioral research; Commerce; Electronic trading; Eye movements; Financial markets; Investments; Learning systems; Mathematical morphology; Case-studies; Financial computer vision; Financial signal; Financial signal processing; Human attention; Saliency prediction; Signal-processing; Stock analysis; Stock charts; Visual Attention; Computer vision,Conference paper,Final,,Scopus,2-s2.0-85200440427,Movies / Media
,,,"Proceedings - 2024 2nd International Conference on Pattern Recognition, Machine Vision and Intelligent Algorithms, PRMVIA 2024",2024,"Proceedings - 2024 2nd International Conference on Pattern Recognition, Machine Vision and Intelligent Algorithms, PRMVIA 2024",,,,,,156.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205324840&partnerID=40&md5=1faecdb599e626d488bf0d9c42b6e6c7,The proceedings contain 29 papers. The topics discussed include: a flexible and comprehensive approach for assessing cooperative intelligence levels of unmanned swarms; research on bolt loosening fault detection method in random vibration test based on acoustic event detection; a semantic-based framework for multi-label text classification; multi-view graph attention complementary based brain networks analysis for brain diseases diagnosis; eye movement classification and prediction via attention-based distribution distance; text region detection algorithm for medical instruments screen based on improved DBNet; infrared ship object detection utilizing deformable large kernel convolution and a highly sensitive intersection over union loss; research on bad data detection in power grid based on improved algorithm; an efficient multimodal imaging device for acquiring high quality dorsal hand vein and finger vein images based on adaptive dimming; and residual dual attention generative adversarial networks for tissue segmentation on histopathological image.,,,Conference review,Final,,Scopus,2-s2.0-85205324840,Movies / Media
Wang Y.; Maeda Y.; Nomura T.; Ishii M.,"Wang, Yuxuan (58097978000); Maeda, Yoshinobu (55687025600); Nomura, Taishin (7403421729); Ishii, Masako (58883827500)",58097978000; 55687025600; 7403421729; 58883827500,Temporal Changes in Convergence Distance and Level of Eye Fatigue during Video Viewing on a Smartphone,2024,Advanced Biomedical Engineering,13,,,52,57,5.0,2,10.14326/abe.13.52,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181771843&doi=10.14326%2fabe.13.52&partnerID=40&md5=6569618a76a5a7c4bb2011526321d640,"In recent years, ophthalmic problems such as asthenopia and strabismus due to watching videos on smartphones have increased, particularly among the younger generation. A smartphone can be operated with one hand regardless of posture. Consequently it is possible to use a smartphone at a closer distance than the usual near-sighted working distance (40-30 cm) for long periods. This may be the cause of the problems de-scribed above. In this study we aim to investigate the control of eye movements during viewing of a video on a smartphone. The video features intense two-dimensional images with depth information. The gaze of both eyes was measured, and the convergence distance was examined. Six university students participated in the study. They were asked to watch a 15-minute video on a smartphone, during which their eye movements were measured. During the experiment, the participants watched a self-made “video moving through a 3-D maze.” For each viewing distance, the convergence distance was calculated based on the intersection of the eyes’ gaze. In some instances, the viewing distance and the convergence distance did not match when watching the video, suggesting that the mismatch could lead to eye strain and strabismus. © 2024 The Author(s).",convergence distance; fatigue level; gaze point; strabismus,Eye movements; Fatigue of materials; Closest distance; Convergence distance; Eye fatigue; Fatigue level; Gaze point; Smart phones; Strabismus; Temporal change; Viewing distance; Younger generations; Smartphones,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85181771843,Movies / Media
Azizinezhad P.; Chowdhury A.,"Azizinezhad, Parastoo (57202728148); Chowdhury, Anirban (58520811600)",57202728148; 58520811600,Exploring Pupil Dilation as an Indicator of Performance in Gaze-Based Robot Navigation for Assistive Technology,2024,"IEEE International Conference on Modeling, Simulation and Intelligent Computing, MoSICom 2024 - Proceedings",,,,513,518,5.0,0,10.1109/MoSICom63082.2024.10881597,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219616010&doi=10.1109%2fMoSICom63082.2024.10881597&partnerID=40&md5=bc10c09050a2bd867375f97da08bcbb1,"Human-robot interaction (HRI) based assistive devices play a crucial role for individuals with severe disability, significantly impacting their quality of life. A pivotal step towards creating a more human-centric HRI involves gaining a thorough understanding of the user's mental load such as cognitive load, stress, and fatigue, which can influence the performance of the system. Previous studies have found pupil dilation as a potential candidate for exploring mental workload. This paper explores the impact of pupil diameter variation on performance during an eye-tracking-based robot navigation task. Nineteen healthy individuals participated in the experiment where they used eye-gaze to activate different navigational buttons on a computer screen to control the movement of a mobile robot on a predefined trajectory for two rounds. The variation of pupil diameter is correlated to various performance parameters such as lap completion time and number of commands. Results show that the difference between the Gaussian means of the pupil diameter distribution during round1 and round2 is significantly correlated (rho =0.5, p-value =0.03) with the lap completion time while the correlation with the number of commands is also found to be strong (r h o=0.45, p-value =0.05). These quantifications of pupil diameter variations with performance measures have the potential to play a vital role in advancing the HRI systems as they can be used to predict the performance variation in real-time so that the HRI can be more responsive to the user's changing mental states, a key requirement for the practical usability and acceptability of such systems as assistive technologies.  © 2024 IEEE.",Assistive device; Eye-tracking; Pupil diameter,Disabled persons; Eye controlled devices; Eye movements; Gaussian distribution; Human robot interaction; Mobile robots; Assistive devices; Assistive technology; Completion time; Diameter variation; Eye-tracking; Humans-robot interactions; Performance; Pupil diameter; Pupil dilation; Robot navigation; Assistive technology,Conference paper,Final,,Scopus,2-s2.0-85219616010,Movies / Media
Yoo J.H.; Kang C.; Lim J.S.; Wang B.; Choi C.-H.; Hwang H.; Han D.H.; Kim H.; Cheon H.; Kim J.-W.,"Yoo, Jae Hyun (58912095700); Kang, ChangSu (58910630100); Lim, Joon Shik (7403454472); Wang, Bohyun (56142751600); Choi, Chi-Hyun (57204419869); Hwang, Hyunchan (57202022375); Han, Doug Hyun (58736569000); Kim, Hyungjun (58312624100); Cheon, Hosang (58910233500); Kim, Jae-Won (56423490100)",58912095700; 58910630100; 7403454472; 56142751600; 57204419869; 57202022375; 58736569000; 58312624100; 58910233500; 56423490100,Development of an innovative approach using portable eye tracking to assist ADHD screening: a machine learning study,2024,Frontiers in Psychiatry,15,,1337595,,,,16,10.3389/fpsyt.2024.1337595,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186240538&doi=10.3389%2ffpsyt.2024.1337595&partnerID=40&md5=373e66b9c950e1ecc1930b507b5251ed,"Introduction: Attention-deficit/hyperactivity disorder (ADHD) affects a significant proportion of the pediatric population, making early detection crucial for effective intervention. Eye movements are controlled by brain regions associated with neuropsychological functions, such as selective attention, response inhibition, and working memory, and their deficits are related to the core characteristics of ADHD. Herein, we aimed to develop a screening model for ADHD using machine learning (ML) and eye-tracking features from tasks that reflect neuropsychological deficits in ADHD. Methods: Fifty-six children (mean age 8.38 ± 1.58, 45 males) diagnosed with ADHD based on the Diagnostic and Statistical Manual of Mental Disorders, fifth edition were recruited along with seventy-nine typically developing children (TDC) (mean age 8.80 ± 1.82, 33 males). Eye-tracking data were collected using a digital device during the performance of five behavioral tasks measuring selective attention, working memory, and response inhibition (pro-saccade task, anti-saccade task, memory-guided saccade task, change detection task, and Stroop task). ML was employed to select relevant eye-tracking features for ADHD, and to subsequently construct an optimal model classifying ADHD from TDC. Results: We identified 33 eye-tracking features in the five tasks with the potential to distinguish children with ADHD from TDC. Participants with ADHD showed increased saccade latency and degree, and shorter fixation time in eye-tracking tasks. A soft voting model integrating extra tree and random forest classifiers demonstrated high accuracy (76.3%) at identifying ADHD using eye-tracking features alone. A comparison of the model using only eye-tracking features with models using the Advanced Test of Attention or Stroop test showed no significant difference in the area under the curve (AUC) (p = 0.419 and p=0.235, respectively). Combining demographic, behavioral, and clinical data with eye-tracking features improved accuracy, but did not significantly alter the AUC (p=0.208). Discussion: Our study suggests that eye-tracking features hold promise as ADHD screening tools, even when obtained using a simple digital device. The current findings emphasize that eye-tracking features could be reliable indicators of impaired neurobiological functioning in individuals with ADHD. To enhance utility as a screening tool, future research should be conducted with a larger sample of participants with a more balanced gender ratio. Copyright © 2024 Yoo, Kang, Lim, Wang, Choi, Hwang, Han, Kim, Cheon and Kim.",attention-deficit/hyperactivity disorder; biomarkers; eye-tracking technology; fixation; machine learning; saccades,ADHD Rating Scale; anti saccade task; Article; assessment of humans; attention deficit hyperactivity disorder; Beck Depression Inventory; caregiver; change detection task; child; Child Behavior Checklist; Child Depression Inventory; clinical feature; controlled study; diagnostic test accuracy study; disease severity; Disruptive Behavior Disorders Rating Scale; experimental behavioral test; eye tracking; Family Adaptability and Cohesion Evaluation Scale IV; female; human; intelligence quotient; interview; machine learning; major clinical study; male; memory guided saccade task; multicenter study; neuropsychological assessment; pro saccade task; receiver operating characteristic; Schedule for Affective Disorders and Schizophrenia; scoring system; Stroop test; task performance; working memory,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85186240538,Movies / Media
Chhimpa G.R.; Kumar A.; Garhwal S.; Dhiraj; Khan F.; Moon Y.-K.,"Chhimpa, Govind Ram (58475342700); Kumar, Ajay (58494401200); Garhwal, Sunita (56082381600); Dhiraj (56499157300); Khan, Faheem (57353121900); Moon, Yeon-Kug (36762882400)",58475342700; 58494401200; 56082381600; 56499157300; 57353121900; 36762882400,"Revolutionizing Gaze-Based Human-Computer Interaction Using Iris Tracking: A Webcam-Based Low-Cost Approach with Calibration, Regression and Real-Time Re-Calibration",2024,IEEE Access,12,,,168256,168269,13.0,3,10.1109/ACCESS.2024.3498441,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209722064&doi=10.1109%2fACCESS.2024.3498441&partnerID=40&md5=a2b9c9d3c7248863fbb29fe278242145,"Eye movements are essential in human-computer interaction (HCI) because they offer insights into individuals' cognitive states and visual attention. Techniques for adequately assessing gaze have increased in the last two decades. Notably, video-based tracking methods have gained considerable interest within the research community due to their nonintrusive nature, enabling precise and convenient gaze estimation without physical contact or invasive measures. This paper introduces a video-based gaze-tracking method that presents an affordable, user-friendly, and dependable human-computer interaction (HCI) system based on iris movement. By utilizing the MediaPipe face mesh model, facial features are extracted from real-time video sequences. A 5-point user-specific calibration and multiple regression techniques are employed to predict the gaze point on the screen accurately. The proposed system effectively handles changes in body position and user posture through real-time re-calibration using z-index tracking. Furthermore, it compensates for minor head movements that may introduce inaccuracies. The proposed system is cost-effective, with a general cost below $25, which may vary based on camera usage. Thirteen participants were involved in the system testing. The system demonstrates a high level of sensitivity to low light conditions, a strong response to changes in distance, and a moderate reaction to glasses, with an average frame processing time of 0.047 seconds. On average, it achieves a visual angle accuracy of 1.12 degrees with head movement and 1.3 degrees without head movement. © 2013 IEEE.",calibration; eye-gaze tracking; Human-computer interaction; iris-tracking; low-cost; real-time re-calibration; regression,Eye protection; Face recognition; Video analysis; Computer interaction; Eye gaze tracking; Head movements; Iris tracking; Low-costs; Real- time; Real-time re-calibration; Recalibrations; Regression; Tracking method; Video recording,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85209722064,Movies / Media
Büter R.; Soberanis-Mukul R.D.; Ruiz Puentes P.; Ghazi A.; Wu J.Y.; Unberath M.,"Büter, Regine (58676728100); Soberanis-Mukul, Roger D. (55845113600); Ruiz Puentes, Paola (59774565200); Ghazi, Ahmed (26658992700); Wu, Jie Ying (57207823155); Unberath, Mathias (56893868600)",58676728100; 55845113600; 59774565200; 26658992700; 57207823155; 56893868600,Eye tracking for tele-robotic surgery: A comparative evaluation of head-worn solutions,2024,Progress in Biomedical Optics and Imaging - Proceedings of SPIE,12928,,129281Y,,,,0,10.1117/12.3006476,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192266262&doi=10.1117%2f12.3006476&partnerID=40&md5=4324c730a7476d05d5dd6f8ec9b14f8a,"Purpose: Metrics derived from eye-gaze-Tracking and pupillometry show promise for cognitive load assessment, potentially enhancing training and patient safety through user-specific feedback in tele-robotic surgery. However, current eye-Tracking solutions' effectiveness in tele-robotic surgery is uncertain compared to everyday situations due to close-range interactions causing extreme pupil angles and occlusions. To assess the effectiveness of modern eye-gaze-Tracking solutions in tele-robotic surgery, we compare the Tobii Pro 3 Glasses and Pupil Labs Core, evaluating their pupil diameter and gaze stability when integrated with the da Vinci Research Kit (dVRK). Methods: The study protocol includes a nine-point gaze calibration followed by pick-And-place task using the dVRK and is repeated three times. After a final calibration, users view a 3x3 grid of AprilTags, focusing on each marker for 10 seconds, to evaluate gaze stability across dVRK-screen positions with the L2-norm. Different gaze calibrations assess calibration's temporal deterioration due to head movements. Pupil diameter stability is evaluated using the FFT from the pupil diameter during the pick-And-place tasks. Users perform this routine with both head-worn eye-Tracking systems. Results: Data collected from ten users indicate comparable pupil diameter stability. FFTs of pupil diameters show similar amplitudes in high-frequency components. Tobii Glasses show more temporal gaze stability compared to Pupil Labs, though both eye trackers yield a similar 4cm error in gaze estimation without an outdated calibration. Conclusion: Both eye trackers demonstrate similar stability of the pupil diameter and gaze, when the calibration is not outdated, indicating comparable eye-Tracking and pupillometry performance in tele-robotic surgery settings. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",Eye-Tracking; Gaze Estimation; Head-worn eye trackers; Pupillometry; Tele-Robotic surgery,Deterioration; Eye tracking; Glass; Robotic surgery; Stability; Eye trackers; Eye-tracking; Gaze estimation; Gaze stabilities; Head-worn eye tracker; Pupil diameter; Pupillometry; Robotics surgery; Tele-robotic surgery; Tele-robotics; Calibration,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85192266262,Movies / Media
Albert J.; Schneider W.X.; Poth C.H.,"Albert, Josefine (57236032200); Schneider, Werner X. (12645050300); Poth, Christian H. (8533567200)",57236032200; 12645050300; 8533567200,Can natural scenes cue attention to multiple locations? Evidence from eye-movements in contextual cueing,2024,Frontiers in Cognition,3,,1352656,,,,1,10.3389/fcogn.2024.1352656,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006936484&doi=10.3389%2ffcogn.2024.1352656&partnerID=40&md5=b3eda76a2280444e26b07a05ec332201,"Humans find visual targets more quickly when the target appears at the same location in a repeated configuration of other stimuli. However, when the target alternates between two locations in the repeated configuration, the benefit for visual search is smaller. This reduction of benefits has been explained as the result of an averaging of a benefit for one location and a cost for the other location. In two experiments, we investigated this two-target-locations effect in real-world scenes using high-resolution eye-tracking. Experiment 1 adapted a study in which subjects searched for a small “T” or “L” superimposed on real-world photographs. Half of the trials showed repeated scenes with one possible target location each; half showed novel scenes. We replicated the pronounced contextual cueing effect in real-world scenes. In Experiment 2, two conditions were added. In one of them, targets appeared in repeated scenes alternating between two possible locations per scene. In the other condition, targets appeared in repeated scenes but at new locations, constrained to one side of the screen. Subjects were faster to search for and identify a target in repeated scenes than in novel scenes, including when the scene was paired with two alternating target locations and (after extensive training) even when the scene only predicted the hemifield. Separate analyses on the two possible target locations resulted in rejection of the suggestion of costs for the additional target location, since the contextual cueing effect was present in the second half of the experiment for both the favored and the less favored target location. The eye-tracking data demonstrated that contextual cueing influences searching fixations, characteristic of attentional guidance, rather than responding fixations, characteristic of facilitation of response processes. Further, these data revealed that adding another possible target location leads to less guidance, rather than impeding response processes. Thus, this study delivers evidence for a flexible and attentional guidance mechanism that is able to prioritize more than one location in natural contexts. Copyright © 2024 Albert, Schneider and Poth.",attention; contextual cueing; learning; multiple target locations; natural scenes; reaction time; visual search,,Article,Final,,Scopus,2-s2.0-105006936484,Movies / Media
Al-Mazidi S.,"Al-Mazidi, Sarah (57200084190)",57200084190,Molecular physiology unlocks the mystery that relates cognitive impairment with the retina in schizophrenia and autism spectrum disorders: a perspective review,2024,Frontiers in Psychiatry,15,,1495017,,,,0,10.3389/fpsyt.2024.1495017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210559267&doi=10.3389%2ffpsyt.2024.1495017&partnerID=40&md5=d33af5ef521356154ee149825ec1d414,"Schizophrenia and Autism spectrum disorders (SSD and ASD) are neurodevelopmental disorders involving cognitive impairment. Timely diagnosis is important for early intervention; currently, no tools are available to help with early diagnosis. Molecular biomarkers of cognitive impairment have been extensively studied, but clinical correlation is crucial in screening for cognitive impairment in SSD and ASD. There has been growing interest in examining the retina to scan for neurological disorders since the retina is the only part of the central nervous system that can be directly imaged non-invasively and in a timely manner. This review discusses biomarkers of cognitive impairment and their correlation to the retina in SSD and ASD. It also discusses the possible involvement of the retina and molecular biomarkers, specifically Disintegrin and metalloproteinase domain-containing protein 10 (ADAM10) and ciliary neurotrophic factor (CNTF) in the pathophysiology of SSD and ASD. A protocol for early diagnosing cognitive impairment and its severity in SSD and ASD is also suggested. This review also mentions insights into the potential use of molecular biomarkers of cognitive impairment to enhance cognitive performance in ASD and SSD and areas where more research is needed to solve the mystery of the relationship between the retina and cognitive impairment in neurodevelopmental psychiatric disorders. Copyright © 2024 Al-Mazidi.",autism; biomarkers; cognition; OCT; retina; schizophrenia,ADAM10 endopeptidase; alpha secretase; amyloid beta protein; amyloid precursor protein; amyloid protein; biological marker; calcium calmodulin dependent protein kinase II; ciliary neurotrophic factor; cyclic AMP dependent protein kinase anchoring protein; disintegrin; mitogen activated protein kinase; n methyl dextro aspartic acid receptor; retinoic acid; retinol; tau protein; vasculotropin; Alzheimer disease; amnesia; Article; artificial intelligence; autism; brain-gut axis; cognitive defect; dementia; depression; disease severity; down regulation; electroretinography; environmental factor; eye-tracking technology; facial expression; functional neuroimaging; health care system; human; macular thickness; mental disease; nerve cell plasticity; neurotoxicity; ophthalmoscopy; optical coherence tomography; oxidative stress; phenotype; protein misfolding; psychosis; quality of life; retina blood vessel; retina degeneration; retina image; retinal nerve fiber layer; retinol deficiency; saccadic eye movement; schizophrenia; sensory dysfunction; social interaction; upregulation; vision; visual impairment; vitamin deficiency,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85210559267,Movies / Media
Chen S.; Jiang M.; Zhao Q.,"Chen, Shi (57206653462); Jiang, Ming (56027704500); Zhao, Qi (55743334300)",57206653462; 56027704500; 55743334300,Deep Learning to Interpret Autism Spectrum Disorder behind the Camera,2024,IEEE Transactions on Cognitive and Developmental Systems,16,5,,1803,1813,10.0,3,10.1109/TCDS.2024.3386656,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190170781&doi=10.1109%2fTCDS.2024.3386656&partnerID=40&md5=1ab17c2020aa50ed09275df57aec6be0,"There is growing interest in understanding the visual behavioral patterns of individuals with autism spectrum disorder (ASD) based on their attentional preferences. Attention reveals the cognitive or perceptual variation in ASD and can serve as a biomarker to assist diagnosis and intervention. The development of machine learning methods for attention-based ASD screening shows promises, yet it has been limited by the need for high-precision eye trackers, the scope of stimuli, and black-box neural networks, making it impractical for real-life clinical scenarios. This study proposes an interpretable and generalizable framework for quantifying atypical attention in people with ASD. Our framework utilizes photos taken by participants with standard cameras to enable practical and flexible deployment in resource-constrained regions. With an emphasis on interpretability and trustworthiness, our method automates human-like diagnostic reasoning, associates photos with semantically plausible attention patterns, and provides clinical evidence to support ASD experts. We further evaluate models on both in-domain and out-of-domain data and demonstrate that our approach accurately classifies individuals with ASD and generalizes across different domains. The proposed method offers an innovative, reliable, and cost-effective tool to assist the diagnostic procedure, which can be an important effort toward transforming clinical research in ASD screening with artificial intelligence systems. Our code is publicly available at https://github.com/szzexpoi/proto-asd.  © 2016 IEEE.",Autism spectrum disorder (ASD); deep neural networks (DNNs); interpretable model; visual attention,Behavioral research; Cameras; Clinical research; Cost effectiveness; Deep neural networks; Diseases; Semantics; Autism; Autism spectrum disorders; Behavioral patterns; Face; Gaze-tracking; High-precision; Interpretable model; Machine learning methods; Prototype; Visual Attention; Eye tracking,Article,Final,,Scopus,2-s2.0-85190170781,Movies / Media
Liu Y.; Gu J.; San Y.; Zhang B.; Ma Y.; Xiang J.; Gong Z.; Zhang J.; Miao X.; Zhou T.,"Liu, Yali (59116290400); Gu, Jiexin (55255529900); San, Ying (58910867400); Zhang, Bing (58910867500); Ma, Yong (59611376500); Xiang, Jie (57203733721); Gong, Zunke (58453241900); Zhang, Jing (58909876000); Miao, Xun (58910472200); Zhou, Tongquan (57226630826)",59116290400; 55255529900; 58910867400; 58910867500; 59611376500; 57203733721; 58453241900; 58909876000; 58910472200; 57226630826,The left posterior sMMN: a marker of syntactic processing compensation in agrammatic aphasia,2024,Aphasiology,38,9,,1527,1549,22.0,1,10.1080/02687038.2024.2318828,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186186770&doi=10.1080%2f02687038.2024.2318828&partnerID=40&md5=de1fe04e36572d7c10b37e04babac554,"Background: Agrammatic aphasia poses challenges in assessing grammatical abilities due to language comprehension difficulties. The suitability of sMMN as an indicator of syntactic processing abilities in these individuals remains uncertain. Aims: Two ERP experiments were conducted to investigate whether early syntactic mismatch negativity (sMMN) could assess the syntactic processing ability of Chinese-speaking individuals with agrammatic aphasia. Methods & Procedures: Prior to the ERP experiments, the Western Aphasia Battery (WAB) and the Northwestern Assessment of Verbs and Sentences-Chinese (NAVS-C) were used to screen people with agrammatism. ERP data were collected for both the agrammatic group (AG) (n = 12) and the control group (CG) (n = 12). The first experiment (Experiment 1) involved a passive tone oddball task to control for the influence of primary sound perception. The second experiment (Experiment 2: experiment 2a and experiment 2b) investigated syntactic processing through a passive speech oddball task. Experiment 2a examined the processing of correct sentences and syntactic violation sentences in context. In contrast, Experiment 2b assessed well-formed sequences and ill-formed sequences out of context. Outcomes & Results: The results revealed that frontocentral distributed acoustic MMNs were recorded for the CG between 176 - 196ms in Experiment 1, but not for the AG. In Experiment 2, during the 143 - 173ms window, the left anterior sMMN was exclusively observed for the CG, while the left posterior sMMN was specific to the AG. Furthermore, the amplitudes of the left posterior sMMN (143-173ms) were found to have a negative correlation with scores on sentence comprehension tests: the more negative the sMMN, the lower the scores of people with agrammatic aphasia. Notably, this left posterior MMN was absent in Experiment 1. Conclusions: The early posterior sMMN, discovered for the first time in our study, appears to be more sensitive in detecting syntactic processing impairments in agrammatics compared to the early anterior sMMN. This finding has the potential to enhance the precision of aphasia assessment. © 2024 Informa UK Limited, trading as Taylor & Francis Group.",Agrammatic aphasia; Chinese; event related potential (ERP); syntactic mismatch negativity (sMMN); syntactic processing,adult; aphasia; Article; auditory attention; auditory stimulation; cognitive development; controlled study; data processing; electroencephalogram; electrooculogram; eye movement; human; language disability; structure analysis; syntactic mismatch negativity; Western aphasia battery,Article,Final,,Scopus,2-s2.0-85186186770,Movies / Media
Mahanama B.; Ashok V.; Jayarathna S.,"Mahanama, Bhanuka (57206891362); Ashok, Vikas (55633359800); Jayarathna, Sampath (36052654200)",57206891362; 55633359800; 36052654200,Multi-Eyes: A Framework for Multi-User Eye-Tracking using Webcameras,2024,"Proceedings - 2024 IEEE International Conference on Information Reuse and Integration for Data Science, IRI 2024",,,,308,313,5.0,1,10.1109/IRI62200.2024.00069,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207856613&doi=10.1109%2fIRI62200.2024.00069&partnerID=40&md5=c60cae8aca6c4b73400b5a4a70b82bcb,"The human gaze provides informative cues on human behavior during interactions in multi-user environments. However, capturing this gaze information using traditional eye trackers often requires complex and costly experimental setups. Furthermore, conventional eye-tracking algorithms are catered for single-user scenarios and cannot be used for multi-user environments. We propose Multi-Eyes, a commodity webcam-based solution offering scalability and cost-efficiency while leveraging the advancements in deep learning for capturing multi-user gaze. Multi-Eyes propose a three-step multi-user eye tracking framework that (1) detects gaze subjects, (2) estimates gaze, and (3) maps gaze-to-screen with a scalable, memory, and parameterefficient disentangled gaze estimation model. We evaluate the gaze estimation model using two publicly available datasets and the framework's utility through a joint-attention case study. Our proposed architecture achieves the lowest gaze error of 4.33, while the case study demonstrates the feasibility of the Multi-Eyes for multi-user interactions and joint attention with comparable results to the state-of-the-art. © 2024 IEEE.",Deep Learning; Eye Tracking; Joint Attention; Multi-user,Adversarial machine learning; Contrastive Learning; Scalability; Case-studies; Deep learning; Estimation models; Eye trackers; Eye-tracking; Gaze estimation; Human behaviors; Joint attention; Multiuser environments; Multiusers; Deep learning,Conference paper,Final,,Scopus,2-s2.0-85207856613,Movies / Media
Raptis I.; Tsourma M.; Drosou A.; Tzovaras D.,"Raptis, Iakovos (58876001800); Tsourma, Maria (57160088000); Drosou, Anastasios (6506058246); Tzovaras, Dimitrios (13105681700)",58876001800; 57160088000; 6506058246; 13105681700,Optimizing Advertisement Placement Using Saliency Estimation in Filmmaking,2024,"Proceedings - 2024 19th International Workshop on Semantic and Social Media Adaptation and Personalization, SMAP 2024",,,,63,67,4.0,0,10.1109/SMAP63474.2024.00021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218410729&doi=10.1109%2fSMAP63474.2024.00021&partnerID=40&md5=b8910c238242ef3ccefaed2cfc95975f,"As audiences spend an increasing amount of time consuming video content through online platforms, effective advertisement placement has become crucial for both engagement and revenue generation. While recommendation systems help match relevant advertisements to users, the optimal placement of film-related advertisements within visual content, remains underexplored. Traditionally, eye-tracking has been considered the most reliable method for gauging user attention, but it is both expensive and impractical in large-scale applications. This paper proposes a saliency-driven optimization approach for advertisement placement, leveraging saliency map estimations to predict areas of high visual attention. An automated solution that identifies optimal advertisement locations by focusing on the visual center of saliency maps is presented, eliminating the need for intrusive methods like eye-tracking. Additionally, a comparative analysis of two popular saliency estimation techniques is conducted, with both methods fine-tuned to enhance advertisement placement specifically in the context of film production. This approach aims to integrate advertisements seamlessly into visual media without disrupting viewer immersion. This approach will be used to insert film-related adverts in an audience engagement application.  © 2024 IEEE.",ad placement; comparative study; saliency,Video analysis; Ad placement; Comparatives studies; Eye-tracking; Online platforms; Optimal placements; Revenue generation; Saliency; Saliency map; Video contents; Visual content; Marketing,Conference paper,Final,,Scopus,2-s2.0-85218410729,Movies / Media
Gershov S.; Mahameed F.; Raz A.; Laufer S.,"Gershov, Sapir (57219314064); Mahameed, Fadi (57214807588); Raz, Aeyal (7101745542); Laufer, Shlomi (26432021800)",57219314064; 57214807588; 7101745542; 26432021800,More Than Meets the Eye: Physicians’ Visual Attention in the Operating Room,2024,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14313 LNCS,,,11,20,9.0,0,10.1007/978-3-031-47076-9_2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177213193&doi=10.1007%2f978-3-031-47076-9_2&partnerID=40&md5=bb13369286a3af73ca53e396de0172ea,"During surgery, the patient’s vital signs and the field of endoscopic view are displayed on multiple screens. As a result, both surgeons’ and anesthesiologists’ visual attention (VA) is crucial. Moreover, the distribution of said VA and the acquisition of specific cues might directly impact patient outcomes. Recent research utilizes portable, head-mounted eye-tracking devices to gather precise and comprehensive information. Nevertheless, these technologies are not feasible for enduring data acquisition in an operating room (OR) environment. This is particularly the case during medical emergencies. This study presents an alternative methodology: a webcam-based gaze target prediction model. Such an approach may provide continuous visual behavioral data with minimal interference to the physicians’ workflow in the OR. The proposed end-to-end framework is suitable for both standard and emergency surgeries. In the future, such a platform may serve as a crucial component of context-aware assistive technologies in the OR. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Anesthesia; Deep Learning; Eye-tracking; Operation Room; Surgery; Visual Attention; Webcams,Anesthesiology; Behavioral research; Data acquisition; Deep learning; Operating rooms; Surgery; Anesthesia; Deep learning; Eye tracking devices; Eye-tracking; Head-mounted eye tracking; Operation room; Recent researches; Visual Attention; Vital sign; WebCams; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85177213193,Movies / Media
Huang H.; Zhao L.; Dai H.; Zhang L.; Hu X.; Zhu D.; Liu T.,"Huang, Heng (57221180537); Zhao, Lin (57748941700); Dai, Haixing (57211428065); Zhang, Lu (57215062392); Hu, Xintao (56177187200); Zhu, Dajiang (36162659100); Liu, Tianming (58741130700)",57221180537; 57748941700; 57211428065; 57215062392; 56177187200; 36162659100; 58741130700,BI-AVAN: A Brain-Inspired Adversarial Visual Attention Network for Characterizing Human Visual Attention From Neural Activity,2024,IEEE Transactions on Multimedia,26,,,11191,11203,12.0,0,10.1109/TMM.2024.3443623,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201270100&doi=10.1109%2fTMM.2024.3443623&partnerID=40&md5=fba0585c05c43f74ca40f76d05df05e9,"Visual attention is a fundamental mechanism in the human brain, and it inspires the design of attention mechanisms in deep neural networks. However, most of the visual attention studies adopted eye-tracking data rather than the direct measurement of brain activity to characterize human visual attention. In addition, the adversarial relationship between the attention-related objects and attention-neglected background in the human visual system was not fully exploited. To bridge these gaps, we propose a novel brain-inspired adversarial visual attention network (BI-AVAN) to characterize human visual attention directly from functional brain activity. Our BI-AVAN model imitates the biased competition process between attention-related/neglected objects to identify and locate the visual objects in a movie frame the human brain focuses on in an unsupervised manner. We use independent eye-tracking data as ground truth for validation and experimental results show that our model achieves robust and promising results when inferring meaningful human visual attention and mapping the relationship between brain activities and visual stimuli. Our BI-AVAN model contributes to the emerging field of leveraging the brain's functional architecture to inspire and guide the model design in artificial intelligence (AI), e.g., deep neural networks.  © 1999-2012 IEEE.",brain; brain-inspired AI; fMRI; visual attention,Brain mapping; Deep neural networks; Vision; Brain modeling; Brain-inspired; Brain-inspired artificial intelligence; Features extraction; FMRI; Functional magnetic resonance imaging; Gaze-tracking; Human visual attention; Predictive models; Visual Attention; Magnetic resonance imaging,Article,Final,,Scopus,2-s2.0-85201270100,Movies / Media
Hao C.; Zhang X.; An J.; Bao W.; Yang F.; Chen J.; Hou S.; Wang Z.; Du S.; Zhao Y.; Wang Q.; Min G.; Li Y.,"Hao, Chenxi (58819568900); Zhang, Xiaonan (57260437000); An, Junpin (59363162200); Bao, Wenjing (59363162300); Yang, Fan (58657185100); Chen, Jinyu (58138867000); Hou, Sijia (58543079100); Wang, Zhigang (59363026800); Du, Shuning (59363290300); Zhao, Yarong (57209397091); Wang, Qiuyan (57260873500); Min, Guowen (57201566716); Li, Yang (57203118159)",58819568900; 57260437000; 59363162200; 59363162300; 58657185100; 58138867000; 58543079100; 59363026800; 59363290300; 57209397091; 57260873500; 57201566716; 57203118159,An effective screening model for subjective cognitive decline in community-dwelling older adults based on gait analysis and eye tracking,2024,Frontiers in Aging Neuroscience,16,,1444375,,,,2,10.3389/fnagi.2024.1444375,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206075500&doi=10.3389%2ffnagi.2024.1444375&partnerID=40&md5=1ad2ed2e6e0ac1f29a9d082a46ee6fd0,"Objective: To evaluate the effectiveness of multimodal features based on gait analysis and eye tracking for elderly people screening with subjective cognitive decline in the community. Methods: In the study, 412 cognitively normal older adults aged over 65 years were included. Among them, 230 individuals were diagnosed with non-subjective cognitive decline and 182 with subjective cognitive decline. All participants underwent assessments using three screening tools: the traditional SCD9 scale, gait analysis, and eye tracking. The gait analysis involved three tasks: the single task, the counting backwards dual task, and the naming animals dual task. Eye tracking included six paradigms: smooth pursuit, median fixation, lateral fixation, overlap saccade, gap saccade, and anti-saccade tasks. Using the XGBoost machine learning algorithm, several models were developed based on gait analysis and eye tracking to classify subjective cognitive decline. Results: A total of 161 gait and eye-tracking features were measured. 22 parameters, including 9 gait and 13 eye-tracking features, showed significant differences between the two groups (p < 0.05). The top three eye-tracking paradigms were anti-saccade, gap saccade, and median fixation, with AUCs of 0.911, 0.904, and 0.891, respectively. The gait analysis features had an AUC of 0.862, indicating better discriminatory efficacy compared to the SCD9 scale, which had an AUC of 0.762. The model based on single and dual task gait, anti-saccade, gap saccade, and median fixation achieved the best efficacy in SCD screening (AUC = 0.969). Conclusion: The gait analysis, eye-tracking multimodal assessment tool is an objective and accurate screening method that showed better detection of subjective cognitive decline. This finding provides another option for early identification of subjective cognitive decline in the community. Copyright © 2024 Hao, Zhang, An, Bao, Yang, Chen, Hou, Wang, Du, Zhao, Wang, Min and Li.",eye tracking; gait analysis; in the community; machine learning; screening model; subjective cognitive decline,accuracy; aged; anthropometric parameters; antisaccade; area under the curve; arm swinging; Article; Ascertain Dementia 8 item Informant Questionnaire; brain function; calibration; clinical dementia rating scale; clinical effectiveness; clinical evaluation; cognition assessment; cognitive defect; community assessment; community care; community dwelling person; controlled study; coordination; counting backwards dual task; daily life activity; deep learning; dual task gait; dual task gait analysis; dual task test; error correction rate; error correction time; eye tracking; eye tracking parameters; female; foot lifting; gait; gait parameters; gap saccade; health practitioner; human; lateral fixation task; machine learning; major clinical study; male; median fixation; memory; mild cognitive impairment; Mini Cog scale; Mini Mental State Examination; multimodal feature; multimodal parameters; naming animal dual task; neurologist; neuropsychological assessment; overlap saccade; performance; SCD9 scale; screening model; sensitivity and specificity; shapley additive explanation method; single task gait; stance phase; step frequency; step height; step time variation; step width; step width variation; swing phase; walking speed,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85206075500,Movies / Media
Kiss M.; Hayes D.; Rooney B.,"Kiss, Miklós (57189692709); Hayes, David (57192703821); Rooney, Brendan (55007994600)",57189692709; 57192703821; 55007994600,"Attention, memory, and narrative interpretation of Michel Gondry’s The Green Hornet: Comparing 2D and 3D film viewing using eye-tracking and self-report",2024,Convergence,,,,,,,0,10.1177/13548565241267720,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200335855&doi=10.1177%2f13548565241267720&partnerID=40&md5=c965275eeb8d5b5d72a81ec415fa590d,"Historically 3D effect in film has been used as a relatively superficial aesthetic attraction. Here we consider and test the idea that 3D can be used to guide viewer attention and narrative interpretation in film. The current study used self-report measures in conjunction with eye-tracking technology to record attention, memory and narrative interpretation of 32 participants (25 female). Eye-gaze behaviour was recorded while half of the participants were randomly assigned to watch Michel Gondry’s The Green Hornet (2011) in 3D and the other half watched the same film in 2D. We concentrated on a particular moment where the use of 3D technology brings some aspects of the image to the forefront, such as a prop that might have narrative significance for the story as it unfolds. We were unable to confirm that 3D effect in Gondry’s film is effectively used to direct viewers’ visual attention towards narratively relevant information. Also, we found no evidence that the 3D version of Gondry’s film contributes to better memory or narrative interpretation of this particular scene. In discussing our findings, beyond the technical conditions of our eye-tracking research, we consider the role of film genre, narrative mode, viewers’ expectations and media literacy in shaping such visual attention and narrative interpretation. © The Author(s) 2024.",3D; attention; eye-tracking; film; narrative interpretation; Psychology,,Article,Article in press,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85200335855,Movies / Media
Szita K.; Rooney B.,"Szita, Kata (57222100780); Rooney, Brendan (55007994600)",57222100780; 55007994600,Smartphone spectatorship in unenclosed environments: The physiological impacts of visual and sonic distraction during movie watching on mobile devices,2024,Entertainment Computing,48,,100598,,,,2,10.1016/j.entcom.2023.100598,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168555886&doi=10.1016%2fj.entcom.2023.100598&partnerID=40&md5=d409e36eedd2e48889e67712161b3ce6,"Smartphones’ popularity is largely based on their pervasiveness, portability, and the wide range of functions they encompass: they can play high-definition moving-image content without spatial and temporal constraints. However, the lack of spatial and temporal frameworks can account for distractions. Distractions (generally sonic or visual information) can originate from the surrounding environment or from the device itself and they may or may not hold semantic links to the content being watched. In this paper, we argue that the distraction effect in movie watching is based on a distractor's modality, neutrality, and ecological relevance to the movie. To test the effects of these properties, we recorded viewers’ gaze and electrodermal activity while they watched a narrative film sequence on smartphone and projector screens in the presence of sonic and visual distractors. We found that screen type can affect attention and arousal: in comparison to projector viewers, smartphone viewers experienced lower arousal and were more likely to shift their attention from the movie even when a distractor closely related to the movie was played. It was also observed that distractors that require urgent attention and are unrelated to the movie redirect the viewer's attention and increases electrodermal activity values. In contrast, distractors with ecological relevance to the movie are less likely to induce changes in attention and arousal. © 2023 The Authors",Arousal; Attention; Distraction; Electrodermal activity; Eye tracking; Smartphone; Spectatorship,Ecology; Electrodes; Semantics; Smartphones; Arousal; Attention; Distraction; Ecological relevance; Electrodermal activity; Eye-tracking; High definition; Moving image; Smart phones; Spectatorship; Eye tracking,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85168555886,Movies / Media
Takács K.; Haidegger T.,"Takács, Kristóf (57217308699); Haidegger, Tamás (16315516400)",57217308699; 16315516400,Eye Gaze Tracking in Robot-Assisted Minimally Invasive Surgery: A Systematic Review of Recent Advances and Applications,2024,Acta Polytechnica Hungarica,21,10,,393,411,18.0,5,10.12700/aph.21.10.2024.10.25,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192720449&doi=10.12700%2faph.21.10.2024.10.25&partnerID=40&md5=a2f575c83e110e6a24e9bc567935fb0d,"This article provides insights into the utilization of eye gaze tracking technologies in robot-assisted minimally invasive surgery. Ranging from enhancing surgical precision to non-technical skill assessment, workload analysis and extended reality-based applications, all recent research fields are covered. Utilizing the PRISMA methodology, relevant studies were identified, screened and analyzed from the past 5 years from PubMed and IEEE Xplore databases. This review reveals that eye gaze tracking technology can significantly improve surgical efficiency, reduce cognitive load reliably, assess skill and stress levels, and foster better coordination. In conclusion, eye gaze tracking is still a widely researched and evolving field in RAMIS, potentially revolutionizing surgical practices and patient outcomes. © 2024, Budapest Tech Polytechnical Institution. All rights reserved.",Attention Computing; Eye Gaze Tracking; RAMIS; Situation Awareness; Skill Assessment; Stress Measurement; Surgical Robotics,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85192720449,Movies / Media
Kong Y.; Wang S.; Cai J.; Zhao Z.; Shen Z.; Li Y.; Fei M.; Wang Q.,"Kong, Yan (59156070200); Wang, Sheng (59291654600); Cai, Jiangdong (58630491000); Zhao, Zihao (58119576400); Shen, Zhenrong (57316512500); Li, Yonghao (58022716400); Fei, Manman (58660476500); Wang, Qian (57192157811)",59156070200; 59291654600; 58630491000; 58119576400; 57316512500; 58022716400; 58660476500; 57192157811,Gaze-DETR: Using Expert Gaze to Reduce False Positives in Vulvovaginal Candidiasis Screening,2024,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) ,15004 LNCS,,,133,143,10.0,0,10.1007/978-3-031-72083-3_13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207641386&doi=10.1007%2f978-3-031-72083-3_13&partnerID=40&md5=0858bcaca2bbd762371a7bb4ee50f336,"Accurate detection of vulvovaginal candidiasis is critical for women’s health, yet its sparse distribution and visually ambiguous characteristics pose significant challenges for accurate identification by pathologists and neural networks alike. Our eye-tracking data reveals that areas garnering sustained attention - yet not marked by experts after deliberation - are often aligned with false positives of neural networks. Leveraging this finding, we introduce Gaze-DETR, a pioneering method that integrates gaze data to enhance neural network precision by diminishing false positives. Gaze-DETR incorporates a universal gaze-guided warm-up protocol applicable across various detection methods and a gaze-guided rectification strategy specifically designed for DETR-based models. Our comprehensive tests confirm that Gaze-DETR surpasses existing leading methods, showcasing remarkable improvements in detection accuracy and generalizability. Our code is available at https://github.com/YanKong0408/Gaze-DETR. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",Candida detection; DETR; Eye-tracking,Candida detection; DETR; Eye-tracking; False positive; Neural-networks; Sparse distribution; Sustained attention; Tracking data; Vulvovaginal candidiasis; Warm up; HTTP,Conference paper,Final,,Scopus,2-s2.0-85207641386,Movies / Media
Goto K.; Chen L.; Minematsu T.; Shimada A.,"Goto, Ken (59498925900); Chen, Li (57206892326); Minematsu, Tsubasa (56723724700); Shimada, Atsushi (57222646656)",59498925900; 57206892326; 56723724700; 57222646656,INTEGRATING GAZE DATA AND DIGITAL TEXTBOOK READING LOGS FOR ENHANCED ANALYSIS OF LEARNING ACTIVITIES,2024,"Proceedings of the 21st International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2024",,,,27,34,7.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213982105&partnerID=40&md5=682cd87e9290b757559e382403afaf74,"Learning logs collected by digital educational systems, increasingly deployed in educational settings, include clickstream logs recorded through page transitions in teaching materials and digital marker logs recorded by drawing a marker. A challenge with these learning logs is their low temporal and spatial resolutions. This paper proposes a system that generates a high-resolution learning log (HLL) by utilizing learners' gaze information obtained through webcam-based eye tracking. We also propose methods for analyzing learners' learning-theme browsing patterns using HLL. The HLL retains the attention time of the learning-themes on the learning material and viewing time in and out of the screen. Utilizing the HLL allows learners' attention transitions to be captured over time. Compared with traditional topic-based learning log analysis methods, HLL offers a more granular analysis of detailed learning theme browsing patterns. © 2024 Proceedings of the 21st International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2024. All rights reserved.",Eye Tracking; Learning Log; Non-negative Matrix Factorization,Adversarial machine learning; Contrastive Learning; Federated learning; Browsing patterns; Clickstreams; Digital textbooks; Educational settings; Educational systems; Eye-tracking; High resolution; Learning Activity; Learning log; Nonnegative matrix factorization; Non-negative matrix factorization,Conference paper,Final,,Scopus,2-s2.0-85213982105,Movies / Media
Zhao Q.; Guo F.; Chen X.; Chen Y.; Liang Z.; Yu Q.; Zhou Z.,"Zhao, Qingbai (15761273200); Guo, Fang (57206197388); Chen, Xuemei (58993952800); Chen, Yan (58433683000); Liang, Zheng (57221124250); Yu, Quanlei (56890162000); Zhou, Zhijin (55623383700)",15761273200; 57206197388; 58993952800; 58433683000; 57221124250; 56890162000; 55623383700,The Advantage of Novel Solutions on Subsequent Memory in Insight Problems,2024,"Psychology of Aesthetics, Creativity, and the Arts",,,,,,,3,10.1037/aca0000662,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190855823&doi=10.1037%2faca0000662&partnerID=40&md5=525acdbc467b864cf7177bba876ab3cf,"Insight during problem solving is beneficial to long-term memory formation. It has been shown to promote later memory for the solution; however, the reason for this memory effect is unclear.We used eye tracking to test the memory effect of insight on delayed recall (Experiment 1) and immediate recall (Experiment 2) when participants selected novel or normal answers to riddles. Both experiments adopted the learning-test paradigm of answer selection. In the learning phase, four alternative answers to a riddlewere presented on screen. Eye tracking recorded the fixation duration time on each alternative answer to evaluate the competition of thoughts in the process of problem solving. Delayed and immediate recall were assessed by asking the participants to provide the same answers to the riddles as they had in the learning phase. The results showed that (a) Whether in immediate or delayed recall tasks, the accuracy was higher after selecting novel answers than normal answers, confirming the memory advantage of insight. This effect was more obvious in the delayed recall task. (b) There was a longer total fixation duration time when selecting a novel answer than a normal answer. This suggests that novel answers have an advantage in the competition of thoughts. (c) Compared with selecting normal answers, selecting novel answers involved significantly longer fixation on the target region of interest, and significantly less attention on the main interference region. The results of this research suggest that the competitive advantage of novel thinking in problem solving may be an important reason why insight promotes memory. © 2024 American Psychological Association",eye tracking; insight; memory; thinking competition,,Article,Article in press,,Scopus,2-s2.0-85190855823,Movies / Media
Wu H.D.,"Wu, H. Denis (22952324700)",22952324700,Enjoyment and Appreciation of Political Advertisements: How voters’ Issue Involvement and Congruence with the Sponsor Influence Their Responses and Decisions,2024,Journal of Political Marketing,,,,,,,1,10.1080/15377857.2024.2374234,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197782489&doi=10.1080%2f15377857.2024.2374234&partnerID=40&md5=1185c473c6328a6b9512a9f5b060a96e,"This study investigates how voters derive pleasure and meaning from political advertisements by conducting a 3 (sponsorship) × 2 (issue) factorial experiment. It examines the impact of the interaction of issue involvement and congruence between sponsorship and voters’ party affiliation on enjoyment and appreciation of the advertisement. Voters’ real-time emotions (determined by their facial expression) and their attention to the screen (captured via eye-tracking sensor) were measured. Voters’ responses to advertisement were examined in association with their subsequent candidate preference. Advertisements by congruent sponsors are enjoyed and appreciated more than those by incongruent sponsors. Negative and mixed emotions and time spent on the screen are more pronounced among those with higher issue involvement when viewing congruent advertisements. Only enjoyment, appreciation, and expression of positive emotions during advertisement exposure are positively associated with voting decision. © 2024 Taylor & Francis Group, LLC.",appreciation; emotion; enjoyment; eye-tracking; political advertisement; sponsorship,,Article,Article in press,,Scopus,2-s2.0-85197782489,Movies / Media
Tural A.; Tural E.,"Tural, Alp (59466629200); Tural, Elif (56237387000)",59466629200; 56237387000,"Exploring sense of spaciousness in interior settings: Screen-based assessments with eye tracking, and virtual reality evaluations",2024,Frontiers in Psychology,15,,1473520,,,,0,10.3389/fpsyg.2024.1473520,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211602072&doi=10.3389%2ffpsyg.2024.1473520&partnerID=40&md5=77a831405b044932e1e9424eca29259a,"This study investigates the perception of spaciousness in interior environments using screen-based assessments with eye tracking, and virtual reality (VR) technologies. The research explores how four key design elements -view access, view content, materiality, and ceiling geometry- influence perceived spaciousness. Thirty-five college students participated in screen-based and VR-based evaluations of 16 photorealistic interior settings. Eye tracking data were collected during screen-based assessments to analyze visual attention patterns. Statistical analyses included repeated measures ANOVAs, pairwise comparisons, and correlations between screen and VR assessments. Results showed that view access significantly affected perceived spaciousness in both screen and VR conditions, with larger windows correlating to higher spaciousness ratings. Materiality also demonstrated significant effects, with natural and textured materials perceived as more spacious than concrete surfaces. View content and ceiling geometry showed trends towards influencing spaciousness perception but did not reach statistical significance. VR presentations generally yielded higher spaciousness ratings compared to screen-based presentations, suggesting that immersive technologies may enhance spatial perception. Eye tracking analyses revealed common gaze patterns and variations in visual attention across different design conditions. This study contributes to the understanding of how design elements influence spatial perception and demonstrates the potential of integrating eye tracking and VR technologies in environmental psychology research. The findings have implications for evidence-based design practices aimed at enhancing perceived spaciousness in interior environments. Copyright © 2024 Tural and Tural.",eye tracking; interiors; sense of spaciousness; spatial perception; virtual reality,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85211602072,Movies / Media
Li Y.; Huang S.; Zang W.; Gao Z.,"Li, Yi (55983807900); Huang, Shifeng (55684961700); Zang, Wenbin (55461441200); Gao, Zhiguo (58955274000)",55983807900; 55684961700; 55461441200; 58955274000,Discussion on flood control application technology of digital twin basin based on virtual geographic environment; [基于虚拟地理环境的数字孪生流域防洪应用技术探讨],2024,National Remote Sensing Bulletin,28,5,,1330,1339,9.0,1,10.11834/jrs.20233022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196779696&doi=10.11834%2fjrs.20233022&partnerID=40&md5=401b79d45617b4eb745f97e24d7bedd4,"Flood control is the main application field of the digital twin basin. The application of flood control in the digital twin basin not only needs to express the natural elements in the basin scientifically but also must describe the characteristics of human activities. Virtual geographic environment integrates natural elements and human elements, focuses on building an immersive experimental and cognitive environment, and provides a new perspective and method for the modeling of man-land relationship, flood scene expression, and risk cognition in the digital twin basin flood control. This article takes the application of digital twin watershed flood control as research field and proposes a four-layer technical framework for digital twin watershed flood control based on virtual geographic environment. The resource layer covers the hardware resources involved in data acquisition, storage, and calculation in the digital twin watershed flood control application, and realizes unified storage from global watershed feature awareness to data baseboard framework. The data layer provides the relevant data foundation for digital twin flood control applications, including four categories of data: basic data, business data, monitoring data, and geographic data. It also provides the twin layer with the necessary data service support through the steps of data resource extraction, aggregation, cleaning, conversion, and governance. The twin layer is the core of the technical framework, reflecting the interactive mapping between the model watershed and the real watershed. Model watersheds focus on building water models and human-land relationship models. Based on the natural laws of the water cycle, mathematical language and methods are used to describe the changes in the elements of a real watershed, reflecting the laws of human activity and the correlation between human activities and the natural elements of the watershed. Real watersheds lead the construction of digital twin watersheds, upgrade traditional monitoring systems, enhance automatic monitoring and computational feedback control of digital twin watersheds, and support flood control construction and management of watersheds. The application layer is based on the main idea of virtual geographic environment, relying on wearable technology, eye movements, gestures, brain wave, large screens, digital sand tables, and other devices to provide a multiuser, touchable, interactive, and scene-responsive digital twin watershed environment. On this basis, the“four pre”application of digital twin watershed flood control is conducted. Subsequently, the paper elaborates on key technologies such as digital watershed scene construction, digital watershed state synchronization, flood spatiotemporal process modeling and experiment, human-land relationship modeling, and flood scene expression and risk perception, and looks forward to the future development of VR/AR applications in digital twin watersheds and public participation in flood control. The research trend of virtual geographic environment in digital twin river basin flood control can be summarized as follows: further developing relevant disciplines such as geographic human-land relationship, geographic spatial cognition, and behavioral geography; constructing an immersive flood evacuation spatial cognitive environment that allows participants to obtain real-time, authentic, and rich environmental information for interdisciplinary research; and conducting cognitive experiment activities with public participation. © 2024 Science Press. All rights reserved.",augmented reality; digital twin basin; flood disaster; metauniverse; remote sensing; virtual geographic environment,Augmented reality; Data acquisition; Digital devices; Digital storage; Environmental regulations; Flood control; Floods; Information management; Watersheds; Wearable technology; Control applications; Digital twin basin; Flood disaster; Flood scenes; Human activities; Immersive; Metauniverse; Natural elements; Remote-sensing; Virtual geographic environments; Remote sensing,Article,Final,,Scopus,2-s2.0-85196779696,Movies / Media
Troncoso-Seguel M.; Urrutia M.; Bustos C.; Guevara P.; Pino E.J.,"Troncoso-Seguel, Maria (59048466600); Urrutia, Mabel (22954966200); Bustos, Claudio (58111457700); Guevara, Pamela (24766261300); Pino, Esteban J. (23028926500)",59048466600; 22954966200; 58111457700; 24766261300; 23028926500,How Does Your Brain Process Words? EEG and ET Co-Registration in a Reading Task Among Chilean University Students,2024,"Proceedings of the 20th International Symposium on Medical Information Processing and Analysis, SIPAIM 2024",,,,,,,0,10.1109/SIPAIM62974.2024.10783604,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215533593&doi=10.1109%2fSIPAIM62974.2024.10783604&partnerID=40&md5=59d4780f301d5f3bfba2bef0b514576a,"Signals were acquired, processed, and analyzed using the co-registration technique of electroencephalography (EEG) and eye tracking (ET) in a reading comprehension study applied to a population of university students. EEG and ET data were synchronized, obtaining potential related to the first fixation (FRP) in search of the underlying processes of reading in this population. The study was conducted in two periods: before and after training applied to the population, which was divided into two groups: control and experimental, receiving different training. The main stimuli is presented as a lexicality challenge: word or pseudoword in three different contexts: familiar, less familiar and neutral. This word is presented in the center of the screen and the EEG is segmented in epochs using the first fixation mark. Preliminary FRP results show significant differences in N400 component related to the triple interactions: period-group-context and group-context-lexicality. These findings lay the groundwork for future research and methodological improvements, making it possible to measure reading ability through the co-registration technique. © 2024 IEEE.",Co-registration; Cognition; EEG; ET; FRP; Reading Comprehension,Biomedical signal processing; Brain mapping; Engineering education; Brain process; Cognition; Coregistration; Eye-tracking; FRP; Group control; Reading comprehension; Registration techniques; Tracking data; University students; Students,Conference paper,Final,,Scopus,2-s2.0-85215533593,Movies / Media
Liu L.; Duffy V.G.,"Liu, Li (57208129208); Duffy, Vincent G. (7007049892)",57208129208; 7007049892,Investigating cognitive workload in irrelevant speech-based information communication with visual distractions: Pleasant or distracted?,2024,International Journal of Industrial Ergonomics,99,,103539,,,,2,10.1016/j.ergon.2023.103539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180368134&doi=10.1016%2fj.ergon.2023.103539&partnerID=40&md5=37d8f13bab9f83043ac7faf97bf7402b,"Irrelevant background sounds have been proven to decrease efficiency while working, while the perception may be different when people actively listen to pleasant background sounds at work. This study aims to investigate the cognitive workload in irrelevant speech-based information communication (live streaming, white noise, movie, songs, and quiet environment) with visual distractions under different reading tasks (familiar and unfamiliar reading material) using NASA-TLX and eye-tracking metrics. The results showed the main effect of irrelevant speech-based information type on NASA-TLX was not significant. Participants tended to show a higher preference for quiet-based information and the live-based information was the opposite. Revisits and fixation duration had a similar trend for a small window and movie-based information had the most revisits and fixation duration and white noise was the opposite. The results of this experiment will contribute to helping improve the pleasure perception while working and make communication information more efficient. © 2023 Elsevier B.V.",Cognitive workload; Concurrent speech; Visual distractions; Voice-based interaction,Behavioral research; NASA; Speech communication; White noise; Cognitive workloads; Concurrent speech; Eye-tracking; Fixation duration; Information communication; Live streaming; Main effect; NASA-TLX; Visual distractions; Voice-based interaction; adult; Article; cognitive effort; cognitive workload; environment; eye tracking; female; human; human experiment; interpersonal communication; irrelevant speech based information communication; live streaming; male; music; normal human; questionnaire; reading; task performance; visual stimulation; white noise; wireless communication; workload; Eye tracking,Article,Final,,Scopus,2-s2.0-85180368134,Movies / Media
Bağçı E.,"Bağçı, Ebru (59256375900)",59256375900,Neurotourism and national tourism promotion: a thematic analysis of the Turkish tourism market based on neuroscience,2024,International Journal of Tourism Anthropology,9,4,,281,299,18.0,0,10.1504/IJTA.2024.143396,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212841466&doi=10.1504%2fIJTA.2024.143396&partnerID=40&md5=e0f3b939de4c9251e402f38d51f76e37,"Given the complex biological structure, people act with their emotions and minds. Understanding emotions, neuromarketing focuses on the problem of capturing rationality. This study aims at determining the symbols and music enabling creation of the ‘Turkey’ brand in tourism, revealing these symbols effects and music in tourists’ mind within this rationality framework. Accordingly, electroencephalography (EEG) and eye tracking devices from neuroscience tools and 21 themed tourism promotion films prepared by Turkish Republic Ministry of Culture and Tourism were analysed considering view number on different dates. Results revealed that music, human figures, and symbols used in promotional films affect people’s attention. The limited number of experimental studies on the subject in Turkey and high cost of experimental studies concerning the neuroscience tools are the main constraints for the researchers in the field. In this respect, the related study is of high importance. © 2024 Inderscience Enterprises Ltd.",EEG; electroencephalography; eye tracking; neuromarketing; neurotourism; tourism promotion,,Article,Final,,Scopus,2-s2.0-85212841466,Movies / Media
Hu T.; Hou W.,"Hu, Tianrui (59567460500); Hou, Wenjun (14627737100)",59567460500; 14627737100,Gaze-Adaptive Subtitles for 360° Videos in Virtual Reality,2024,"2024 10th International Conference on Virtual Reality, ICVR 2024",,,,68,77,9.0,0,10.1109/ICVR62393.2024.10868250,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218412310&doi=10.1109%2fICVR62393.2024.10868250&partnerID=40&md5=60c83088966c81e77ca024ddec3c1e63,"Subtitles (captions displayed on the screen) play a crucial role in cross-lingual multimedia content, serving as valuable aids for individuals who are deaf or hearing-impaired, as well as in situations involving unknown languages or loud environments. Subtitles are equally indispensable when viewing 360° immersive videos in virtual reality (VR). However, the experience of watching 360° videos in VR differs significantly from that on desktop screens. Hence, we propose a method for presenting VR 360° video subtitles that leverages users' gaze data as indirect input to dynamically adjust subtitle positions in real-time. Our research investigates the impact of adaptive subtitles compared to traditional subtitles on users' experiences when viewing 360° videos in VR environments.Research findings suggest that the proposed adaptive subtitle placement method is more effective than traditional subtitles located below the field of view in reducing visual fatigue and enhancing the watching experience for users. Furthermore, in comparison to conversational 360° videos featuring speaking subjects, adaptive subtitles offer greater optimization and improvement in scene-oriented videos with voice-overs. © 2024 IEEE.",eye tracking; gaze-responsive display; subtitles; Virtual reality,Audition; Hearing aids; Multimedia systems; Speech enhancement; Virtual reality; Cross-lingual; Eye-tracking; Gaze-responsive display; Hearing impaired; Immersive; Multimedia contents; Real- time; Subtitle; Users' experiences; Virtual-reality environment; Virtual environments,Conference paper,Final,,Scopus,2-s2.0-85218412310,Movies / Media
Cheekaty S.; Muneeswari G.,"Cheekaty, Suresh (58812159900); Muneeswari, G. (37102404900)",58812159900; 37102404900,Enhanced multilevel autism classification for children using eye-tracking and hybrid CNN-RNN deep learning models,2024,Neural Computing and Applications,,,103107,,,,1,10.1007/s00521-024-10633-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211785341&doi=10.1007%2fs00521-024-10633-0&partnerID=40&md5=412eb0a4e40ad26747a7deff86b8bf3e,"This article aims to improve the detection of ASD in children using ET data and advanced ML techniques. ASD, a neurodevelopmental disorder characterized by impairments in social communication, interaction, and repetitive behaviors, typically manifests before the age of three. Early diagnosis is crucial for timely and effective interventions. ET data have revealed distinct gaze patterns in children with ASD, such as diminished attention to social cues and increased fixation on repetitive stimuli. However, current methods of ET data analysis are largely manual and lack scalability for widespread clinical screening. To address these limitations, we propose a novel, scanpath-based ASD detection method that identifies atypical gaze behaviors through dynamic changes in visual attention. We extract four sequential features from scanpaths and analyze variations in feature space across different ASD severity levels low, mild, moderate, and severe using the MultiMatch and DTW similarity metrics. Our analysis reveals that children with ASD exhibit unique and highly individualized gaze patterns when compared to TD children. Notable differences are observed in attention duration and vertical gaze distribution, providing key insights into ASD-related visual behaviors. For classification, we employ a hybrid CNN-RNN model, which significantly outperforms traditional ML methods. The CNN-RNN model achieves an accuracy of 97%, recall of 98.24%, and an F1-score of 97.04% using the feature set (x, d, y). In comparison, models based on GRU and 2-LSTM networks show competitive accuracies of 92% and 90%, respectively. However, RFC and XGBoost models underperform, with accuracies ranging between 70.25 and 80.80%. These findings demonstrate the efficacy of DL approaches, particularly the CNN-RNN hybrid model, in accurately classifying ASD based on ET data, emphasizing their potential to enhance diagnostic accuracy. The proposed scalable method for ASD detection holds promise for improving early diagnosis and intervention, which is critical for better long-term outcomes in children with ASD. Further evaluation on an independent dataset will assess the generalizability and precision of the model. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.",Autism spectrum disorder; CNN-RNN hybrid network; Early diagnosis; Eye-tracking data; Machine learning; Scanpath analysis,Deep learning; Diagnosis; Fracture fixation; Pediatrics; Autism spectrum disorders; CNN-RNN hybrid network; Early diagnosis; Eye-tracking; Eye-tracking data; Hybrid network; Machine-learning; Scan path; Scanpath analysis; Tracking data; Diseases,Article,Article in press,,Scopus,2-s2.0-85211785341,Movies / Media
Schroer S.E.; Yu C.,"Schroer, Sara E (57213736944); Yu, Chen (16032623800)",57213736944; 16032623800,Word learning is hands-on: Insights from studying natural behavior,2024,Advances in Child Development and Behavior,66,,,55,79,24.0,0,10.1016/bs.acdb.2024.04.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194921909&doi=10.1016%2fbs.acdb.2024.04.002&partnerID=40&md5=19fb471ea0991cc8f0e2abcab598068a,"Infants’ interactions with social partners are richly multimodal. Dyads respond to and coordinate their visual attention, gestures, vocalizations, speech, manual actions, and manipulations of objects. Although infants are typically described as active learners, previous experimental research has often focused on how infants learn from stimuli that is well-crafted by researchers. Recent research studying naturalistic, free-flowing interactions has explored the meaningful patterns in dyadic behavior that relate to language learning. Infants’ manual engagement and exploration of objects supports their visual attention, creates salient and diverse views of objects, and elicits labeling utterances from parents. In this chapter, we discuss how the cascade of behaviors created by infant multimodal attention plays a fundamental role in shaping their learning environment, supporting real-time word learning and predicting later vocabulary size. We draw from recent at-home and cross-cultural research to test the validity of our mechanistic pathway and discuss why hands matter so much for learning. Our goal is to convey the critical need for developmental scientists to study natural behavior and move beyond our “tried-and-true” paradigms, like screen-based tasks. By studying natural behavior, the role of infants’ hands in early language learning was revealed—though it was a behavior that was often uncoded, undiscussed, or not even allowed in decades of previous research. When we study infants in their natural environment, they can show us how they learn about and explore their world. Word learning is hands-on. © 2024",Dyadic interactions; Eye tracking; Multimodal attention; Natural behavior; Sensorimotor development; Word learning,Attention; Gestures; Hand; Humans; Infant; Infant Behavior; Language Development; Verbal Learning; Vocabulary; attention; behavior; chapter; eye tracking; eye-tracking technology; female; gesture; human; human experiment; infant; language development; learning; learning environment; male; signal transduction; speech; validity; visual attention; vocabulary; vocalization; child behavior; hand; language development; physiology; verbal learning,Book chapter,Final,,Scopus,2-s2.0-85194921909,Movies / Media
Wang J.,"Wang, Jiahui (57191491117)",57191491117,Mind wandering in videos that integrate instructor’s visuals: An eye tracking study,2024,Innovations in Education and Teaching International,61,5,,972,987,15.0,0,10.1080/14703297.2023.2251955,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168652431&doi=10.1080%2f14703297.2023.2251955&partnerID=40&md5=0e0d382280ce247da2779f9190c94723,"With an increasing number of videos integrating instructor’s visuals on screen, we know little about the impacts of this design on mind wandering. The study aims to investigate a) how instructor visibility impacts mind wandering; b) the relationship between mind wandering and retention performance; c) how visual behaviour during video-watching influences mind wandering. Each participant watched a video with or without instructor visibility, while their visual behaviour was recorded by an eye tracker. Retention performance was measured at the completion of the video. Mind wandering was inferred via global self-report measure and objective eye tracking measure. Both measures of mind wandering indicated the instructor visible video resulted in less mind wandering. Findings suggested mind wandering impaired retention performance. Additionally, visual attention to the instructor was associated with less mind wandering. © 2023 Informa UK Limited, trading as Taylor & Francis Group.",instructor visibility; mind wandering; retention; Video; visual attention,,Article,Final,,Scopus,2-s2.0-85168652431,Movies / Media
Liu L.; Zou Z.; Greene R.L.,"Liu, Li (57208129208); Zou, Zishuai (57658838800); Greene, Runyu L. (57193531982)",57208129208; 57658838800; 57193531982,"The Effects of Type and Form of Collaborative Robots in Manufacturing on Trustworthiness, Risk Perceived, and Acceptance",2024,International Journal of Human-Computer Interaction,40,10,,2697,2710,13.0,16,10.1080/10447318.2023.2169527,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147492983&doi=10.1080%2f10447318.2023.2169527&partnerID=40&md5=988be5948ef2cc7041df7c6b4158cf59,"As one of the latest applications in the field of artificial intelligence, collaborative robots (cobots) are playing an increasingly important role in manufacturing. This study is aimed to ascertain the effects of the type and form of a collaborative robot in manufacturing on trustworthiness, risk perceived, and acceptance. A 2 (single-arm cobot/dual-arm cobot) * 2 (cobot with a screen/cobot without a screen) full factorial within-subject experiment was conducted by using eye-tracking metrics and subjective questionnaires. A total of 40 participants were recruited and all stimuli were played randomly. Results suggest both features are essential attributes with interactive effects in the process of viewing tasks. For single-arm cobots, cobots without a screen showed higher trustworthiness than those with a screen. Dual-arm cobots with a screen showed higher perceived risk than those without a screen. Furthermore, compared to the cobots without a screen, cobots with a screen evidenced more fixation counts and longer fixation duration, which means more attention resources and greater cognitive effort were required. The same results were also found in dual-arm cobots. This study contributes to the extant literature on cobot design and training by emphasizing the effect of cobot form and type in particular. © 2023 Taylor & Francis Group, LLC.",,Collaborative robots; Intelligent robots; Cognitive efforts; Collaborative robots; Dual arm; Eye-tracking; Fixation duration; Full factorial; Interactive effect; Perceived risk; Robot training; Subject experiment; Eye tracking,Article,Final,,Scopus,2-s2.0-85147492983,Movies / Media
Özdemir S.; Bülbül I.A.; Suna H.E.; Akkuş Ş.K.,"Özdemir, Selda (23985940600); Bülbül, Işık Akın (57421376900); Suna, Hayri Eren (57223020059); Akkuş, Şemsi Kübra (58898083200)",23985940600; 57421376900; 57223020059; 58898083200,An Examination of Eye Tracking in Videos and 3D Animations in Children with ASD and TD Children,2024,Egitim ve Bilim,49,217,,21,43,22.0,0,10.15390/EB.2023.11750,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185595043&doi=10.15390%2fEB.2023.11750&partnerID=40&md5=c97af7c241ba010c12be05b406877afc,"Visual attention impairments of children with autism spectrum disorder (ASD) have been investigated in many studies over the past two decades. The purpose of this study was to examine the visual attention of children with ASD and typically developing (TD) children in different social interaction contexts. Videos and 3D animations with three different levels of social interaction content (low, medium, and high) were created for the current study. The participants included 21 children with ASD (̅ = 7.6, SD = 1.7) and 22 TD children (̅ = 8.5, SD = 1.0), all aged between 5 and 12 years. The participants observed the video and 3D animation presentations on a computer screen as a passive viewing task. While the children watched the social interaction scenarios, eye-tracking data was collected to analyze their total fixation duration. The findings indicated that both children with ASD and TD children exhibited the longest total fixation duration on the Eyes and Mouth regions, particularly during the Chocolate Bread scenario, which featured low-level social interaction. When we examined visual attention during the presentation of videos and 3D animations, we found that both groups of children displayed significantly more fixation duration on the face region, especially the Eyes region during the 3D animation presentation compared to the video presentation. The research findings were discussed, and recommendations for future studies were provided. © 2024 Turkish Education Association. All rights reserved.",Animation Video; Autism spectrum disorder; Eye tracking; Face processing; Visual attention,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85185595043,Movies / Media
Du M.; Zhang Y.; Zhang J.; Liu H.,"Du, Mengqi (57202005795); Zhang, Yue (57302647600); Zhang, Jianhua (58685090700); Liu, Honghai (57218402201)",57202005795; 57302647600; 58685090700; 57218402201,CRED: A Corneal Reflection and Environment Dataset,2024,"Proceedings of the 2024 27th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2024",,,,2246,2251,5.0,0,10.1109/CSCWD61410.2024.10580597,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199116564&doi=10.1109%2fCSCWD61410.2024.10580597&partnerID=40&md5=c873102d1abac983501678b3b4e57712,"Existing studies have proved that corneal reflection images can not only visualize the human surroundings, but also accurately reflect the attention information of the eyes to the environment, which promotes the research and application of visual tracking and human posture localization in the field of human-computer interaction. The cornea is a small and transparent reflective surface with weak reflective ability, and its reflected images always have dull colors and low resolution. Some researches try to obtain clearer and brighter corneal reflection images when a person is facing a screen or outdoors, but the reflected images are highly susceptible to the interference of iris color and texture. However, strong corneal reflections are highly susceptible to obscuring the iris and pupil regions, affecting the accuracy of gaze tracking. In addition, a large number of reflected images interfered by the iris must rely on iris features for image enhancement. These two limitations make it difficult to directly apply eye images taken outdoors. We try to propose a corneal reflection and human eye surroundings dataset, CRED, which contains not only segmented images of human eye images and ocular structures (e.g., iris, pupil, and eyelid margins) with significant corneal reflections, but also corneal reflections and ground truth of the human eye surroundings scene separated from the ocular images. We believe that with the help of the CRED dataset, a large number of deep learning-based end-to-end works can be performed for iris and pupil position estimation and localization in the presence of strong corneal reflection interference. Similarly, the clarity and usability of corneal reflection images will be significantly improved.  © 2024 IEEE.",Environmental reconstruction; Ocular dataset; Pupil and iris localization; The Corneal imaging system,Deep learning; Eye tracking; Human computer interaction; Large datasets; Textures; Corneal reflection; Environmental reconstruction; Eye images; Human eye; Iris localization; Localisation; Ocular dataset; Pupil localization; The corneal imaging system; Image enhancement,Conference paper,Final,,Scopus,2-s2.0-85199116564,Movies / Media
Sugimoto T.; Nakamura J.; Ishiwata Y.,"Sugimoto, Taiki (58131043300); Nakamura, Jun (56109407400); Ishiwata, Yoshinobu (57193727492)",58131043300; 56109407400; 57193727492,Visualization of the Skilled Physician’s Gaze characteristic during Diagnosis,2024,Proceedings of International Conference on Artificial Life and Robotics,,,,907,910,3.0,0,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190282448&partnerID=40&md5=1f9918ded2c953dd9641225ba56bca22,"This study examines gaze movement differences in diagnosis between skilled and beginner physicians, aiming to identify factors influencing diagnostic speed and developing human resource and enhance artificial intelligence's diagnostic capabilities. Results reveal that experienced physicians, on average, spent 61% less diagnostic time than beginners, covering 49% of the gaze distance on the X and Y-axes. (comparison of the cumulative distance of gaze on the screen). Despite increased movement on the Z-axis (comparison of the scrolling speed of the CT scan results),skilled physicians moved 2-3 times faster, effectively narrowing attention and identifying specific areas. © The 2024 International Conference on Artificial Life and Robotics.",Artificial Intelligence (AI); Cognitive Science; Experimental Economics; Eye-tracking,,Conference paper,Final,,Scopus,2-s2.0-85190282448,Movies / Media
Supritha R.; Bharathi Mohan G.,"Supritha, R. (59265995800); Bharathi Mohan, G. (56026524900)",59265995800; 56026524900,Deep Learning for Autism Detection Using Eye Tracking Scanpaths,2024,"2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation, IATMSI 2024",,,,,,,8,10.1109/IATMSI60426.2024.10502546,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192252816&doi=10.1109%2fIATMSI60426.2024.10502546&partnerID=40&md5=22b401acac16c1291bb9110de7d2223e,"Autism spectrum disorder (ASD) is a neurodevelopmental condition marked by difficulties in social interaction, communication, and limited repetitive behaviors, with symptoms varying significantly among individuals. Eye tracking holds promise in autism detection due to its unique ability to capture and analyze visual attention patterns, providing insights into the cognitive processes and atypical visual behaviors associated with ASD. Eye-tracking technology offers a unique perspective, allowing the observation and quantification of visual attention patterns, which may reveal distinctive features associated with ASD. These visualizations represent how individuals, particularly those with ASD, explore and engage with stimuli. In this research, we propose a novel approach using deep learning models, specifically DenseNet-201, EfficientNet B7, ResNet-50, and MobileNetV2, to analyze eye-tracking scan paths for ASD detection. The dataset focuses on visualizations of eye-tracking scan paths, primarily involving individuals with ASD. The study yielded promising results, with the deep learning models achieving accuracies of 94.97%, 94.74%, 84.21%, and 92.45%, respectively. DenseNet-201 demonstrated the highest accuracy at 94.97%. The research contributes to advancing early diagnosis and intervention strategies for individuals with ASD.  © 2024 IEEE.",Autism spectrum disorder; Deep learning; eye tracking; Typical Control,Behavioral research; Computer vision; Deep learning; Diagnosis; Diseases; Visualization; Autism spectrum disorders; Cognitive process; Condition; Deep learning; Eye-tracking; Learning models; Scan path; Social interactions; Typical control; Visual Attention; Eye tracking,Conference paper,Final,,Scopus,2-s2.0-85192252816,Movies / Media
Hennessey E.-M.P.; Swales D.A.; Markant J.; Hoffman M.C.; Hankin B.L.; Davis E.P.,"Hennessey, Ella-Marie P. (57219235699); Swales, Danielle A. (57202209036); Markant, Julie (55804173600); Hoffman, M. Camille (59157707200); Hankin, Benjamin L. (6603938682); Davis, Elysia Poggi (7402374201)",57219235699; 57202209036; 55804173600; 59157707200; 6603938682; 7402374201,Maternal anxiety during pregnancy predicts infant attention to affective faces,2024,Journal of Affective Disorders,344,,,104,114,10.0,6,10.1016/j.jad.2023.09.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173694882&doi=10.1016%2fj.jad.2023.09.031&partnerID=40&md5=04dcb22e73bfe2bd01498c242326a739,"Background: Prenatal maternal anxiety is a known influence on offspring development. General anxiety and pregnancy-related anxiety (a distinct type of anxiety encompassing fears associated with pregnancy) are associated with offspring socioemotional development, with potential consequences for later emotional and behavioral problems. This study examines whether maternal pregnancy-related and general anxiety relate to infant attention to affective faces, a process which plays an integral role in early socioemotional development. Methods: Participants included 86 mothers and their 6-month-old infants (56.3 % female). Mothers completed measures of pregnancy-related and general anxiety three times through gestation. Infants' attention to affective faces was assessed with an eye-tracking task during which a series of face pairs were presented (happy, angry, or sad face paired with a neutral face). Overall attention measures included attention-holding (total looking time) and attention-orienting (latency to faces); affect-biased attention measures included proportion of total looking time to emotional faces and latency difference score. Results: Higher maternal pregnancy-related anxiety across gestation predicted decreased infant attention-holding to affective faces [F(1,80) = 7.232, p =.009, partial η2 = 0.083]. No differences were found in infant attention-orienting or affect-biased attention. Limitations: Reliance on a correlational study design precludes the ability to make causal inferences. Conclusions: Maternal pregnancy-related anxiety is an important predictor of child outcomes. We provide novel evidence that pregnancy-related anxiety predicts infant attention to emotional faces, behaviors which have important implications for socioemotional development. Providers may consider pregnancy-related anxiety as a target for screening and treatment that may benefit both pregnant individual and offspring. © 2023 Elsevier B.V.",Anxiety; Attention; Eye-tracking; Fetal programming; Infancy; Pregnancy,Anger; Anxiety; Child; Emotions; Facial Expression; Female; Happiness; Humans; Infant; Male; Mothers; Pregnancy; adult; animal experiment; anxiety; article; attention; controlled study; correlational study; eye tracking; female; human; infancy; male; mother; nonhuman; pregnancy; progeny; anger; child; emotion; facial expression; happiness; infant; pregnancy; psychology,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85173694882,Movies / Media
Schlezingerová N.; Málková P.; Kocourek M.; Telenský P.,"Schlezingerová, Nicol (59341103600); Málková, Petra (59340683800); Kocourek, Martin (57190026281); Telenský, Petr (57217117178)",59341103600; 59340683800; 57190026281; 57217117178,"Mild hunger elicits attentional desensitization to visual food cues in healthy, non-obese individuals",2024,Frontiers in Psychology,15,,1441184,,,,0,10.3389/fpsyg.2024.1441184,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204782125&doi=10.3389%2ffpsyg.2024.1441184&partnerID=40&md5=93941b7bcb78c5309c86d65e75d91533,"Introduction: Food is a vital human need, and the human visual system is finely tuned to detect and respond to food cues in the environment. The omnipresence of food cues across various settings has been linked to the prevalence of obesity in susceptible populations. However, the influence of the post-prandial state on visual attention to food stimuli remains poorly understood. This study aimed to elucidate how a 12 hour fast affects visual attention to food and non-food stimuli in healthy, non-obese individuals. Methods: Visual attention was assessed by measuring the total duration of visual fixations on stimuli presented on a computer screen, using a screen-based eye tracker (Tobii X2-60). Participants were divided into two groups: those who had fasted for 12 hours and those tested within two hours after consuming breakfast (satiated state). Additionally, performance on the Food Stroop task and electrodermal activity (EDA) responses were measured to evaluate attentional interference and physiological arousal, respectively. Salivary samples were also collected to assess levels of alpha-amylase and cortisol. Results: Fasted participants exhibited a progressive decline in visual attention toward food stimuli compared to satiated individuals, reflecting a satiated state. This effect was independent of the palatability of the depicted food items and was not observed with stimuli representing non-food items. The Food Stroop task revealed no differences between fasting and satiated participants, indicating that the presence of food-related stimuli does not differentially impact attentional interference under varying hunger states. Moreover, no significant variations were observed in EDA responses across participant groups and stimulus types, suggesting that the modulation of visual attention to food cues by hunger is independent of physiological arousal. Interestingly, satiated subjects exhibited higher levels of salivary alpha-amylase, which was inversely related to their subjective hunger ratings. No differences in salivary cortisol levels were found between groups. Discussion: The findings indicate a novel influence of mild hunger on the processing of visual food cues, independent of physiological arousal. The decline in visual attention to food stimuli in fasted individuals suggests that satiety modulates visual processing. The lack of differences in attentional interference and physiological arousal between fasting and satiated states further supports the notion that visual attention to food cues is primarily driven by hunger-related mechanisms rather than stress. Additionally, the inverse relationship between salivary alpha-amylase levels and hunger ratings implies that alpha-amylase may serve as a marker of satiety rather than stress. Copyright © 2024 Schlezingerová, Málková, Kocourek and Telenský.",EDA; eye-tracking; Food Stroop test; hunger; salivary cortisol and alpha-amylase; satiety; Visual Analog Scale; visual food cues,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85204782125,Movies / Media
Zaharia A.; Kojovic N.; Rojanawisut T.; Sander D.; Schaer M.; Samson A.C.,"Zaharia, Alexandra (57193111532); Kojovic, Nada (57201132662); Rojanawisut, Tara (59294558500); Sander, David (7101673174); Schaer, Marie (57205783996); Samson, Andrea C. (7005553546)",57193111532; 57201132662; 59294558500; 7101673174; 57205783996; 7005553546,Examining the Link Between Social Affect and Visual Exploration of Cute Stimuli in Autistic Children,2024,Journal of Autism and Developmental Disorders,,,,,,,0,10.1007/s10803-024-06504-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201818095&doi=10.1007%2fs10803-024-06504-1&partnerID=40&md5=bece3d9a7469558aaf298e36c3ca77b3,"Baby schema refers to physical features perceived as cute, known to trigger attention, induce positive emotions, and prompt social interactions. Given the reduced visual attention to social stimuli observed in individuals on the autism spectrum, the current study examines whether the sensitivity to baby schema is also affected. We expected that the looking time towards cute-featured stimuli would vary with symptom severity levels and would be associated with social affect. Ninety-four children (31 typically developing; 63 diagnosed with autism spectrum disorder - ASD) aged 20–83 months (M = 49.63, SD = 13.59) completed an eye-tracking visual exploration task. Autistic participants were separated into two groups based on symptom severity: children with high autism severity symptoms (HS ASD; N = 23) and low-moderate autism symptoms (LMS ASD; N = 40). Animals and neutral objects were simultaneously presented on the screen along with either human babies (condition 1) or adults (condition 2). The results indicated that visual attention oriented to cute-featured stimuli varied with autism symptom severity: only LMS and TD groups spend more time looking at cute-featured stimuli (babies; animals) than neutral objects. Moreover, children with higher severity in the social affect domain spent less time on the stimuli depicting cute than non-cute stimuli. These findings suggest that autism symptom severity and social skills are linked to variations in visual attention to cute stimuli. Implications of baby schema sensitivity are discussed in relation to the development of social competencies and play, responsiveness to robot-based interventions, as well as appraised relevance in autistic children. © The Author(s) 2024.",Autism spectrum disorder; Baby schema; Cuteness; Eye-tracking; Social affect,,Article,Article in press,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85201818095,Movies / Media
Thiele L.; Schmidt-Borcherding F.; Bateman J.A.,"Thiele, Leandra (57221809707); Schmidt-Borcherding, Florian (55581455600); Bateman, John A. (7202065408)",57221809707; 55581455600; 7202065408,All eyes on the signal? - Mapping cohesive discourse structures with eye-tracking data of explanation videos,2024,Frontiers in Communication,9,,1356495,,,,0,10.3389/fcomm.2024.1356495,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191183190&doi=10.3389%2ffcomm.2024.1356495&partnerID=40&md5=bb8607229ee1f79ecb6f328e6eeec17f,"In this paper, we consider the issue of how the fine-grained multimodal design of educational explanation videos, such as those widely available on YouTube and other platforms, may be made accessible to empirical studies of reception and effectiveness. This is necessary because previous research has often led to conflicting conclusions concerning the roles of particular design elements. We argue that this may largely be due to insufficient characterizations of multimodal design itself. To achieve tighter control of this potential source of variation, we present a multimodal descriptive annotation framework drawing on multimodal (cohesive) film discourse analysis. This framework is seen as a critical first step toward being able to highlight just those differences in design that have functional consequences. For such consequences to accrue, however, viewers need to attend differently to corresponding design differences. The goal of the current paper, therefore, is to use eye-tracking techniques to explore the extent to which discourse structures revealed by our analytic framework relate to recipients' attention allocation. We hypothesize that any potentially emerging anomalies in regards to discourse organization, such as instances of unsuccessful cohesion signaling, may have correlations in the behavioral data. We report our current state of development for performing this kind of multimodal cohesion analysis and some of the unresolved challenges raised when considering how such analyses may be related to performance data. Copyright © 2024 Thiele, Schmidt-Borcherding and Bateman.",cohesion; discourse analysis; education videos; explanation videos; eye-tracking; multimodal cohesion; multimodality,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85191183190,Movies / Media
Calignano G.; Lorenzoni A.; Semeraro G.; Navarrete E.,"Calignano, Giulia (57208666204); Lorenzoni, Anna (57031683700); Semeraro, Giulia (59495212100); Navarrete, Eduardo (8725200900)",57208666204; 57031683700; 59495212100; 8725200900,Words before pictures: the role of language in biasing visual attention,2024,Frontiers in Psychology,15,,1439397,,,,0,10.3389/fpsyg.2024.1439397,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213687302&doi=10.3389%2ffpsyg.2024.1439397&partnerID=40&md5=9bf0d5deb0ce663a2c94b1d647f08235,"Background: The present study investigated whether semantic processing of word and object primes can bias visual attention using top-down influences, even within an exogenous cueing framework. We hypothesized that real words and familiar objects would more effectively bias attentional engagement and target detection than pseudowords or pseudo-objects, as they can trigger prior knowledge to influence attention orienting and target detection. Methods: To examine this, we conducted two web-based eye-tracking experiments that ensured participants maintained central fixation on the screen during remote data collection. In Experiment 1, participants viewed a central prime—either a real word or pseudo-word—followed by a spatial cue directing them to a target on the left or right, which they located by pressing a key. Experiment 2 presented participants with real objects or pseudo-objects as primes, with primes and targets that either matched or did not match in identity. Importantly, primes in both experiments conveyed no information about target location. Results: Results from Experiment 1 indicated that real word primes were associated with faster target detection than pseudo-words. In Experiment 2, participants detected targets more quickly when primed with real objects and when prime-target identity matched. Comparisons across both experiments suggest an automatic influence of semantic knowledge on target detection and spatial attention. Discussion: These findings indicate that words can contribute to attentional capture, potentially through top-down processes, even within an exogenous cueing paradigm in which semantic processing is task-irrelevant. Copyright © 2024 Calignano, Lorenzoni, Semeraro and Navarrete.",eye-tracking online; generalized additive mixed model; linguistic labels; novel objects; Posner cueing paradigm; pseudoword; spatial cueing; target detection,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85213687302,Movies / Media
Jurič I.; Tomić I.; Pál M.,"Jurič, Ivana (55836317200); Tomić, Ivana (55834483000); Pál, Magdolna (57189265701)",55836317200; 55834483000; 57189265701,VISUAL DYNAMICS IN DIGITAL CATALOGUES: A COMPREHENSIVE ANALYSIS OF CINEMAGRAPH INTEGRATION THROUGH EYE-TRACKING TECHNOLOGY,2024,International Symposium on Graphic Engineering and Design,,,,,,7.0,0,10.24867/GRID-2024-p28,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209672730&doi=10.24867%2fGRID-2024-p28&partnerID=40&md5=03fd8c933e6e6cb0569bfd15b4816f20,"This paper investigates the transformative influence of cinemagraphs, a captivating hybrid of static images and subtle motion, on the overall quality and user experience of digital catalogues. As e-commerce and online browsing continue to shape consumer behaviour, the need for dynamic and visually appealing content is crucial. We delve into the aesthetic and functional enhancements brought about by cinemagraphs, analyzing their ability to capture attention, convey product features, and elevate the overall engagement levels within digital catalogues. Through a comprehensive analysis of user gaze patterns, fixations, and engagement metrics, we explore how cinemagraphs influence attention distribution, enhance product perception, and contribute to the overall quality of the digital shopping experience. Our findings not only underscore the significance of cinemagraphs but also provide valuable insights into designing visually compelling and user-centric digital catalogues. © 2024 Authors. Published by the University of Novi Sad, Faculty of Technical Sciences, Department of Graphic Engineering and Design.",cinemagraph; digital catalogues; eye-tracking; user experience,,Conference paper,Final,,Scopus,2-s2.0-85209672730,Movies / Media
Lee M.; Lee Y.; Kim J.,"Lee, Minhwa (57479406500); Lee, Younjoon (57199710783); Kim, Jeeyoun (57217138202)",57479406500; 57199710783; 57217138202,The Product Listing Page UI Structure in Mobile Commerce: An AHP and Visual Attention Analysis of Key Information for Sales Enhancement; [모바일 커머스의 상품리스트 페이지 UI 구조 제안: 판매 활성화 관점의 주요 정보에 대한 AHP 분석과 시각적 주의 분석을 기반 으로],2024,Archives of Design Research,37,5,,335,351,16.0,0,10.15187/adr.2024.11.37.5.335,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211503512&doi=10.15187%2fadr.2024.11.37.5.335&partnerID=40&md5=67312d5e92e10b8356e4baf01358a57e,"Background Considering the business aspects of mobile commerce, this study aims to explore how to improve the user interface(UI) to enhance e-commerce sales by focusing on the ‘Product Listing Page (PLP)’. PLP can influence sales by simplifying consumers’ shopping experiences and promoting informed purchasing decisions. Therefore, we aim to propose a UI structure that enhances the information-providing environment to increase sales. Methods The study used the analytic hierarchy process(AHP) and eye tracking methods to identify key information that enhances sales and analyzes customer responses. Initially, the information provided on the PLP was categorized, followed by a survey targeting e-commerce experts to prioritize the information for enhancing sales using AHP. Subsequently, eye tracking was used to examine which information users looked at for longer periods and more frequently across different interface types. Finally, the two sets of results were integrated. Results Through the AHP analysis for e-commerce experts, the key information to enhance sales on the PLP is ‘price information (1st)’, ‘review information (2nd)’ and ‘visual information (3rd)’. Additionally, through the eye-tracking analysis for consumers, when exploring the PLP with a list layout, users gaze more frequently at the important information to enhance sales, namely ‘price information’ and ‘review information’ and to navigate more smoothly using scrolling when compared to PLP with a grid layout. Furthermore, when viewing the PLP with a grid layout, users gaze longer and more frequently at the ‘visual information’, and there is a tendency for their gaze to be more dispersed across the entire screen rather than using scrolling for navigation. Conclusions Based on the results, this study proposes the UI structure of the PLP according to e-commerce strategies. By enhancing the information-providing environment, it is suggested to use a list layout for platforms requiring efficient provision of key information to increase sales from a strategic perspective. Additionally, for platforms where visual images are prioritized, the use of a grid layout is proposed. This is an Open Access article distributed under the terms of the Creative Commons Attribution NonCommercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits unrestricted educational and non-commercial use, provided the original work is properly cited.",AHP; AHP; Eye Tracking; Mobile Commerce; UI; UI; UX; UX; 모바일 커머스; 아이트래킹,,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85211503512,Movies / Media
Cvetojević S.; Dedijer S.,"Cvetojević, Sanja (59417113100); Dedijer, Sandra (36991967500)",59417113100; 36991967500,THE INFLUENCE OF COLOR ON CAPTURING CUSTOMER ATTENTION IN ONLINE PURCHASES OF ORGANIC COSMETICS CASE,2024,International Symposium on Graphic Engineering and Design,,,,,,9.0,0,10.24867/GRID-2024-p55,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209690453&doi=10.24867%2fGRID-2024-p55&partnerID=40&md5=b8c2b201053f091eac8a919d1817c64e,"This study examines the effect of colour on users in the context of online sales of organic cosmetics. The primary goal is to identify which colours most effectively capture attention and drive engagement, ultimately influencing purchasing behaviours for organic cosmetic products. Through the use of eye-tracking technology, participants' attention and focus were monitored as they observed products displayed in various colours on screens. Key metrics such as Time to First View and Time Viewed were analyzed to gain a comprehensive understanding of how participants' attention and engagement were impacted by the recommended colour tones, particularly concerning their perception of organic cosmetics. The analysis revealed that lighter tones are detected more rapidly than darker tones, with statistical analysis supporting the finding that lighter colours more effectively attract immediate attention. Additionally, stimuli in lighter tones were viewed for longer periods compared to those in darker tones. This study provides a preliminary exploration of how colour tones influence the attention and engagement of e-commerce users. The findings offer valuable insights into the emotional and cognitive dimensions of consumer engagement, enhancing our understanding of how colour affects purchasing behaviour. © 2024 Authors. Published by the University of Novi Sad, Faculty of Technical Sciences, Department of Graphic Engineering and Design.",Impact of colour; Online sales; Organic cosmetics,,Conference paper,Final,,Scopus,2-s2.0-85209690453,Movies / Media
Rosenthal E.; O’neil J.; Hoyt B.; Howard M.,"Rosenthal, Elyssa (58867099500); O’neil, James (57204894802); Hoyt, Briggs (57215894878); Howard, Matthew (58866211400)",58867099500; 57204894802; 57215894878; 58866211400,Inter-Rater Reliability of EyeSpy Mobile for Pediatric Visual Acuity Assessments by Parent Volunteers,2024,Clinical Ophthalmology,18,,,235,245,10.0,0,10.2147/OPTH.S440439,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184209059&doi=10.2147%2fOPTH.S440439&partnerID=40&md5=596481491b2dcb6318d7636d4e640e0d,"Purpose: To assess the inter-rater test reliability of the EyeSpy Mobile visual acuity smartphone algorithm when administered to children by eye professionals and parent volunteers. Patients and Methods: Visual acuity test-retest results were analyzed for 106 children assigned to one of three different screenings: (1) An eye technician and pediatric ophthalmologist using their typical visual acuity testing method on a M&S computer; (2) An eye technician and pediatric ophthalmologist using EyeSpy Mobile; (3) An eye technician and parent volunteer using EyeSpy Mobile. Results: All three phases demonstrated a strong agreement between the two testers, with mean test-retest equivalency results within 0.05 logMAR (2.5 letters, 90% CI). Whether testing using their typical technique on an M&S computer or using EyeSpy Mobile, eye professionals obtained statistically closer mean test-retest results than parent volunteers by 1 letter, with equivalency results within 0.03 logMAR (1.5 letters, 90% CI). Conversely, the number of retests within 2 vision lines was statistically greater when EyeSpy mobile was used by parents as compared to eye professional’s customary technique on the M&S computer. Conclusion: EyeSpy Mobile provides clinically useful visual acuity test-retest results even when used by first-time parent volunteers. Adaptive visual acuity algorithms have the potential to improve reliability, lessen training requirements, and expand the number of vision screening volunteers in community settings. © 2024 Rosenthal et al.",adaptive algorithm; EyeSpy Mobile; M&S computer; vision screening; visual acuity,adolescent; algorithm; Article; child; contrast sensitivity; electronic health record; eye tracking; fatigue; female; health care personnel; human; human experiment; interrater reliability; intraocular pressure; male; ophthalmologist; preschool child; rating scale; reliability; school child; vision; vision test; visual acuity; volunteer,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85184209059,Movies / Media
Cirelli L.K.; Talukder L.S.; Kragness H.E.,"Cirelli, Laura K. (55556339700); Talukder, Labeeb S. (59224110800); Kragness, Haley E. (57190062721)",55556339700; 59224110800; 57190062721,Infant attention to rhythmic audiovisual synchrony is modulated by stimulus properties,2024,Frontiers in Psychology,15,,1393295,,,,0,10.3389/fpsyg.2024.1393295,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198969063&doi=10.3389%2ffpsyg.2024.1393295&partnerID=40&md5=4dc7ab9aa3188c3f60604566f90af70f,"Musical interactions are a common and multimodal part of an infant’s daily experiences. Infants hear their parents sing while watching their lips move and see their older siblings dance along to music playing over the radio. Here, we explore whether 8- to 12-month-old infants associate musical rhythms they hear with synchronous visual displays by tracking their dynamic visual attention to matched and mismatched displays. Visual attention was measured using eye-tracking while they attended to a screen displaying two videos of a finger tapping at different speeds. These videos were presented side by side while infants listened to an auditory rhythm (high or low pitch) synchronized with one of the two videos. Infants attended more to the low-pitch trials than to the high-pitch trials but did not display a preference for attending to the synchronous hand over the asynchronous hand within trials. Exploratory evidence, however, suggests that tempo, pitch, and rhythmic complexity interactively engage infants’ visual attention to a tapping hand, especially when that hand is aligned with the auditory stimulus. For example, when the rhythm was complex and the auditory stimulus was low in pitch, infants attended to the fast hand more when it aligned with the auditory stream than to misaligned trials. These results suggest that the audiovisual integration in rhythmic non-speech contexts is influenced by stimulus properties. Copyright © 2024 Cirelli, Talukder and Kragness.",audiovisual synchrony; eye-tracking; infant perception; music development; rhythm,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85198969063,Movies / Media
Yin Z.; Wan Z.; Yang M.; Xiong Y.; Wang W.; Wu S.,"Yin, Zihang (58131847400); Wan, ZhongHua (57195490237); Yang, Mingxuan (59206437300); Xiong, Yi (59481087500); Wang, Wei (59662795900); Wu, Shiqian (55913991500)",58131847400; 57195490237; 59206437300; 59481087500; 59662795900; 55913991500,Robust Gaze-based Intention Prediction for Real-world Scenarios,2024,IEEE Transactions on Cognitive and Developmental Systems,,,,,,,0,10.1109/TCDS.2024.3519904,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212614119&doi=10.1109%2fTCDS.2024.3519904&partnerID=40&md5=617c56b03b206879b33f88261299691a,"Existing intention prediction scenarios in daily life primarily focus on 2-D screens, while the process of intention expression in 3-D scenarios remains largely unexplored. We first analyze eye-tracking data from both 2-D and 3-D scenarios to reveal differences in cognitive load. To address the increased error and redundant gaze points in 3-D scenarios, we propose a gaze region model combined with a clustering method based on density and ordering principles, providing a robust representation of visual attention. Additionally, we integrate this visual attention representation with advanced classifiers for intention prediction. The results indicate that when intentions are expressed in a 3-D scenario, subjects' cognitive load is reduced, facilitating their understanding and expression of intentions, ultimately improving the accuracy of intention prediction. Simultaneously, an evaluation of existing visual attention representation models related to intention prediction is conducted. Our proposed 3-D visual attention model, as part of the intention prediction framework, improves accuracy to 94.50%. To validate the theory and model, we introduce the ADLIP Gaze dataset, which consists of data from 102 individuals. These findings are expected to provide theoretical explanations and methods for intention prediction and efficient human-robot interaction in 3-D scenarios. © 2024 IEEE.",Cognitive load analysis; Gaze; Intention prediction; Real-world scenarios; Visual attention representation,Human robot interaction; Cognitive load analyze; Cognitive loads; Daily lives; Gaze; Intention expressions; Intention predictions; Load analysis; Real-world scenario; Visual Attention; Visual attention representation; Prediction models,Article,Article in press,,Scopus,2-s2.0-85212614119,Movies / Media
Sánchez-Torres J.A.; Palacio-López S.-M.; Hernández-Fernández Y.-L.; Arroyo-Cañada F.-J.; Argila-Irurita A.,"Sánchez-Torres, Javier A. (57193553562); Palacio-López, Sandra-Milena (57215305624); Hernández-Fernández, Yuri-Lorene (57211391655); Arroyo-Cañada, Francisco-Javier (55337071600); Argila-Irurita, Ana (57219609774)",57193553562; 57215305624; 57211391655; 55337071600; 57219609774,Visual photography’s influences on hotel selection: an analysis using e-booking as a comparative platform,2024,International Journal of Electronic Customer Relationship Management,14,2,,128,142,14.0,0,10.1504/IJECRM.2024.138643,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194953616&doi=10.1504%2fIJECRM.2024.138643&partnerID=40&md5=4edb88bf4bf5a5b912dc4a62505de217,"In the digital era, the reservation and purchase of tourist services online have increased, with factors such as images playing a crucial role in consumers’ decision-making when choosing a hotel on comparison sites like Booking.com. The aim of this study was to analyse the importance of appropriately using photographs, specifically of hotels, according to the tourist destination to be visited. This study employs a quasi-experimental design with four groups to investigate the impact of specific images on hotel selection according to the tourist destination. Conducted in a Gesell chamber using eye-tracking technology, two experimental and two control groups were formed with 11 individuals each, randomly assigned. The results show that image characteristics significantly influence reservation decisions. Specifically, in groups where images aligned with a beach, urban, or rural destination were presented, participants consistently chose the hotel that displayed related images. Additionally, it was found that the first image located on the right side of the screen received more visual attention. These findings underscore the importance of using appropriate images to influence customer choices and enhance online marketing of tourist destinations and their hotels. Copyright © 2024 Inderscience Enterprises Ltd.",decisions; e-booking; electronic purchase; emotions; post-pandemic; tourism; tourist destination image,,Article,Final,,Scopus,2-s2.0-85194953616,Movies / Media
Hatzithomas L.; Theodorakioglou F.; Margariti K.; Boutsouki C.,"Hatzithomas, Leonidas (18634315300); Theodorakioglou, Fotini (57240020400); Margariti, Kostoula (57204764092); Boutsouki, Christina (23666481500)",18634315300; 57240020400; 57204764092; 23666481500,Cross-media advertising strategies and brand attitude: the role of cognitive load,2024,International Journal of Advertising,43,4,,603,636,33.0,8,10.1080/02650487.2023.2249342,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169680286&doi=10.1080%2f02650487.2023.2249342&partnerID=40&md5=91c87a56db8d30e12f6bb806c8c760dc,"In recent years, cross-media advertising has received widespread attention from researchers and practitioners seeking effective ways to communicate with their audience. Building on Kahneman’s dual-system theory, the present article proposes a model of the impact of cross-media advertising on brand attitude (Abr). An eye-tracking experiment with 60 participants indicates that simultaneous (vs. sequential) exposure to ads for the same brand on TV and the Internet increases cognitive load and, through subjective comprehension, decreases brand attitude. Two online experiments with 395 and 198 participants in a low- and high-involvement product category, respectively, validate the proposed model. Experiment 2 reveals that in sequential exposure to TV and the internet, the fit between campaign ads further decreases the cognitive load leading to improved brand attitude. Experiment 3 strongly suggests that in simultaneous exposure, synchronous (vs. asynchronous) ads reduce cognitive demands and, through subjective comprehension and TV ad engagement, improve brand attitude. © 2023 Advertising Association.",brand attitude; cognitive load; Cross-media advertising; fit between campaign ads; subjective comprehension; synced advertising; TV advertising engagement,,Article,Final,,Scopus,2-s2.0-85169680286,Movies / Media
Mallibhat K.,"Mallibhat, Kaushik (59255952100)",59255952100,Student Attention Detection Using Multimodal Data Fusion,2024,"Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024",,,,295,297,2.0,1,10.1109/ICALT61570.2024.00092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203811946&doi=10.1109%2fICALT61570.2024.00092&partnerID=40&md5=4f4aa2566563b81db34c93c24cd09de9,"In this work, we propose a framework for integrating the information from behavioral and cognitive spaces to perform attention profiling of a learner while engaging with digital content. Attention profiling helps examine and comprehend students' concentration, attention, and cognitive engagement patterns. Attention profiling of learners enables educators to discern the digital content types that effectively engage students, identify potential distractors, empower educators to customize learning resources and enhance students' overall learning experience. Attention profiling integrated into the Learning Management System (LMS) environment helps students by providing feedback on the content or resources that require more focus. Several studies focus on student engagement through behavioral cues, including click stream data, time spent watching the videos, number of GIT commits, and participation in discussion forums; however, limited research is available in measuring student attention using both behavior cues and cognitive measurements. We address the problem of attention profiling of a learner using the data from behavioral and cognitive spaces. Integrating the data from both spaces necessitates a fusion technique to enhance the performance of the attention profiling of a learner. We propose to use EEG and eye gaze information from cognitive and behavioral space, respectively. We used 'Stroop test,' 'Sustained Attention to Response Task' (SART), and 'Continuous Performance Task' (CPT) to invoke selective attention and sustained attention states among learners. The data collected during the mentioned tests served as ground truth. Further students watched three different types of videos and we collected the data from cognitive space using Emotiv+, a 14-channel head mount EEG device, and the data from the behavioral space through eye gaze information using a web camera-based solution. The advantage of the Emotiv+ device is the comprehensive coverage of sensors across both brain hemispheres, and the device's real-time data stream includes raw EEG and FFT/band power. On the other hand, to capture the on-screen and offscreen behavior of the learners, we used the L2CS-Net gaze estimation architecture built on ResNet-50. We aim to develop a coordinated multimodal data representation framework by employing co-learning methods. © 2024 IEEE.",Attention; Co-learning; Electroencephalogram; Eye gaze; Machine Learning; Multimodal fusion,Adversarial machine learning; Contrastive Learning; Information fusion; Information management; Machine learning; Network security; Sensor data fusion; Teaching; Attention; Attention detection; Co-learning; Digital contents; Eye-gaze; Learning resource; Machine-learning; Multi-modal fusion; Multimodal data fusion; Sustained attention; Students,Conference paper,Final,,Scopus,2-s2.0-85203811946,Movies / Media
Jost L.; Siebertz M.; Hofmann P.; Jansen P.,"Jost, Leonardo (56123091900); Siebertz, Markus (57212132749); Hofmann, Philipp (57222508682); Jansen, Petra (24437966900)",56123091900; 57212132749; 57222508682; 24437966900,The effect of internal and external visualization of rotation on postural stability,2024,Frontiers in Cognition,3,,1356441,,,,0,10.3389/fcogn.2024.1356441,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006908230&doi=10.3389%2ffcogn.2024.1356441&partnerID=40&md5=63126cd001c8311800b81076349f7198,"Introduction: During mental rotation tasks, it is assumed that participants visualize a rotation of objects in their minds (internal visualization), but mental rotation has also been linked to the visible rotation of objects on a screen (external visualization). The angular disparity in mental rotation also influences postural sway, the movements of the body center. Postural sway is thus suspected as one type of indirect measurement of the rotation process. We compare the external visualization of rotation with the suspected internal visualization during mental rotation tasks. We suspect both are similar and thus produce a comparable effect on postural sway. Methods: One hundred and fifty participants completed three rotation tasks with cube figures, two of which were aided by external visualization. Their center of pressure was measured throughout. The effects of external visualization, angular disparity, and their interaction on postural sway were compared using Bayesian statistics and a decision boundary of 3 or 1/3. Results and discussion: The results indicate no differences between conditions for all postural sway parameters. We observe differences between conditions in cognitive load and reaction time. However, as these partially also differ between the two external visualization conditions and do not transfer to differences between the postural sway parameters, the underlying processes in the three conditions are likely similar. Our results support the notion that the visualization of rotation is central to postural sway during mental rotation. This further supports that the rotation process of the external visualization and mental rotation are similar and thus that stimuli are indeed rotated mentally during mental rotation tasks. Our results further support that the common process between mental and manual rotation lies in the visualization instead of mental rotation being an imagined motor action. Because visual control and feedback play an essential role in many motor tasks, the results could also be of further interest for a more general link between motor and cognitive tasks and bidirectional benefits through the construction of visual similarities. Copyright © 2024 Jost, Siebertz, Hofmann and Jansen.",dual-task; eye-tracking; mental rotation; postural stability; spatial cognition; trial design; visualization,,Article,Final,,Scopus,2-s2.0-105006908230,Movies / Media
Arpaia P.; De Luca M.; Calce A.D.; Carone G.; Castelli N.; Duran D.; Gargiulo L.; Moccaldi N.; Nalin M.; Perin A.; Piccolo S.; Puttilli C.; Visani E.,"Arpaia, Pasquale (7006199525); De Luca, Matteo (59258907700); Calce, Anna Della (58028587700); Carone, Giovanni (57214107841); Castelli, Nicolò (57189762264); Duran, Dunja (55806625600); Gargiulo, Ludovica (57408729800); Moccaldi, Nicola (57190984642); Nalin, Marco (24822481300); Perin, Alessandro (14060833100); Piccolo, Salvatore (37091312800); Puttilli, Cosimo (56367779300); Visani, Elisa (14619842400)",7006199525; 59258907700; 58028587700; 57214107841; 57189762264; 55806625600; 57408729800; 57190984642; 24822481300; 14060833100; 37091312800; 56367779300; 14619842400,EXplainable Artificial Intelligence Improves EEG-Based Cognitive Workload Assessment Induced by Fine Motor Activity in Neurosurgeons,2024,"2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering, MetroXRAINE 2024 - Proceedings",,,,588,593,5.0,0,10.1109/MetroXRAINE62247.2024.10796852,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216120011&doi=10.1109%2fMetroXRAINE62247.2024.10796852&partnerID=40&md5=3cbf055dea336bf66c477759bb852f08,"Cognitve workload associated with fine motor activity in neurosurgeons was monitored by using a wearable electroen-cephalographic (EEG) device. The most informative EEG features were selected by means of an explainable Artificial Intelligence (XAI) algorithm. XAI represents a promising novel approach in this application field and offers new opportunities for extracting information from EEG data beyond traditional statistical and Machine Learning-based methods. Six neurosurgeons performed the Purdue Pegboard Test (PPT) at two difficulty levels related to low or high cognitive load. EEG signals were acquired with an eight dry electrode device. Absolute powers in six different frequency bands of interest were explored. Three most involved EEG features resulted from SHapley Additive exPlanations (SHAP) methods, namely absolute power in delta band on C3 and Fz channels and the absolute power in theta band on Fz. Summary plots showed a decrease of the three identified EEG features in the high cognitive load task. These findings demonstrate the potential of Artificial Intelligence-supported wearable EEG solutions to monitor cognitive load over time, to track the cognitive load of trainee neurosurgeons and to design adaptive training courses.  © 2024 IEEE.",Cognitive load; EEG; Explainable AI; fine motor skill; Real-time monitoring in surgery,Behavioral research; Biomedical engineering; Biomedical signal processing; Brain mapping; Breath controlled devices; Electroencephalography; Electrotherapeutics; Machine learning; Neurosurgery; Wearable technology; Absolute power; Cognitive loads; Electroen-cephalographic; Explainable AI; Fine motor skill; Fine motors; Motor activity; Motor skills; Real time monitoring; Real-time monitoring in surgery; Personnel training,Conference paper,Final,,Scopus,2-s2.0-85216120011,Movies / Media
Seymour K.; Mcnicoll J.; Koenig-Robert R.,"Seymour, Kiley (25824022600); Mcnicoll, Jarrod (59512332800); Koenig-Robert, Roger (16679191300)",25824022600; 59512332800; 16679191300,Big brother: the effects of surveillance on fundamental aspects of social vision,2024,Neuroscience of Consciousness,2024,1,niae039,,,,2,10.1093/nc/niae039,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214923312&doi=10.1093%2fnc%2fniae039&partnerID=40&md5=9fb09922d9f77529a1b94c6d894e8756,"Despite the dramatic rise of surveillance in our societies, only limited research has examined its effects on humans. While most research has focused on voluntary behaviour, no study has examined the effects of surveillance on more fundamental and automatic aspects of human perceptual awareness and cognition. Here, we show that being watched on CCTV markedly impacts a hardwired and involuntary function of human sensory perception - the ability to consciously detect faces. Using the method of continuous flash suppression (CFS), we show that when people are surveilled (N = 24), they are quicker than controls (N = 30) to detect faces. An independent control experiment (N = 42) ruled out an explanation based on demand characteristics and social desirability biases. These findings show that being watched impacts not only consciously controlled behaviours but also unconscious, involuntary visual processing. Our results have implications concerning the impacts of surveillance on basic human cognition as well as public mental health.  © 2024 The Author(s).",being watched; consciousness; eye gaze; privacy; social cognition; surveillance; technology,adult; Article; cognition; female; human; male; mental health; social desirability bias; undergraduate student; vision,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85214923312,Movies / Media
Mora J.C.; Fouz-González J.,"Mora, Joan C. (55505235100); Fouz-González, Jonás (57096118300)",55505235100; 57096118300,Contrastive input enhancement in captioned video for L2 pronunciation learning,2024,Language Learning and Language Teaching,61,,,150,175,25.0,3,10.1075/lllt.61.07mor,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205512067&doi=10.1075%2flllt.61.07mor&partnerID=40&md5=be927748b9dbe102543269a99c653983,"This study investigated the potential of input enhancement in captioned video to facilitate learners’ perceptual sensitivity to a difficult L2 vowel contrast (/æ/-//). Participants were randomly assigned to two control and four experimental viewing conditions to explore the effects of audiovisual input (a 30-minute TV episode) on perceptual learning. Textual enhancement on captions highlighted target sounds contrastively (two colors) or non-contrastively (one color) in words transcribed orthographically or in IPA phonetic symbols. Learners’ /æ/-// perception gains were assessed through lexical and phonetic identification and discrimination tasks. Eye-gaze measures were used to determine the effectiveness of enhancement in drawing learners’ attention to the target contrast across viewing conditions. Perceptual learning was observed, although not always consistently across tasks and conditions. © 2024 John Benjamins Publishing Company.",,,Book chapter,Final,,Scopus,2-s2.0-85205512067,Movies / Media
Ramzani Shahrestani M.; Motamed S.; Yamaghani M.,"Ramzani Shahrestani, Matin (59149909500); Motamed, Sara (24824978600); Yamaghani, Mohammadreza (57191887554)",59149909500; 24824978600; 57191887554,Recognition of facial emotion based on SOAR model,2024,Frontiers in Neuroscience,18,,1374112,,,,1,10.3389/fnins.2024.1374112,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194536881&doi=10.3389%2ffnins.2024.1374112&partnerID=40&md5=bd5f78994e3bcd6ea0954f337b4335b8,"Introduction: Expressing emotions play a special role in daily communication, and one of the most essential methods in detecting emotions is to detect facial emotional states. Therefore, one of the crucial aspects of the natural human–machine interaction is the recognition of facial expressions and the creation of feedback, according to the perceived emotion. Methods: To implement each part of this model, two main steps have been introduced. The first step is reading the video and converting it to images and preprocessing on them. The next step is to use the combination of 3D convolutional neural network (3DCNN) and learning automata (LA) to classify and detect the rate of facial emotional recognition. The reason for choosing 3DCNN in our model is that no dimension is removed from the images, and considering the temporal information in dynamic images leads to more efficient and better classification. In addition, the training of the 3DCNN network in calculating the backpropagation error is adjusted by LA so that both the efficiency of the proposed model is increased, and the working memory part of the SOAR model can be implemented. Results and discussion: Due to the importance of the topic, this article presents an efficient method for recognizing emotional states from facial images based on a mixed deep learning and cognitive model called SOAR. Among the objectives of the proposed model, it is possible to mention providing a model for learning the time order of frames in the movie and providing a model for better display of visual features, increasing the recognition rate. The accuracy of recognition rate of facial emotional states in the proposed model is 85.3%. To compare the effectiveness of the proposed model with other models, this model has been compared with competing models. By examining the results, we found that the proposed model has a better performance than other models. Copyright © 2024 Ramzani Shahrestani, Motamed and Yamaghani.",3D convolutional neural network (3DCNN); deep learning; facial emotional recognition; learning automata (LA); SOAR model,accuracy; Article; artificial intelligence; artificial neural network; attention; cognitive model; computer simulation; conceptual framework; convolutional neural network; decision making; deep learning; emotion; eye tracking; facial emotion; facial expression; feature extraction; feature selection; human; learning algorithm; machine learning; nerve cell network; soar model; training; validation process; visual information; working memory,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85194536881,Movies / Media
Maehigashi A.; Fukuchi Y.; Yamada S.,"Maehigashi, Akihiro (42961984300); Fukuchi, Yosuke (57197799609); Yamada, Seiji (35418721700)",42961984300; 57197799609; 35418721700,Empirical investigation of how robot head motion influences acceptance of heatmap-based XAI: Designing XAI with social robot,2024,"IEEE International Workshop on Robot and Human Communication, RO-MAN",,,,344,350,6.0,1,10.1109/RO-MAN60168.2024.10731272,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209802100&doi=10.1109%2fRO-MAN60168.2024.10731272&partnerID=40&md5=c4d6489478869d80bd68ff71c55c8436,"This study investigated how a robot head motion towards an AI attention heatmap during a visual identification task influences a human user's trust in eXplainable AI (XAI). The findings revealed that the robot head motion presented in a video increased the user's acceptance of AI-generated results compared to the robot eye gaze displayed in a static image with or without the AI attention heatmap. However, displaying the heatmap improved task performance more than displaying no heatmap with or without the robot. Overall, these results suggest a possibility that showing a robot head motion towards an AI attention heatmap in a movie can serve as an interpretable XAI for visual tasks.  © 2024 IEEE.",,Industrial robots; Machine vision; Robot vision; Empirical investigation; Eye-gaze; Head motion; Heatmaps; Human users; Robot head; Social robots; Static images; Users' acceptance; Visual identification; Social robots,Conference paper,Final,,Scopus,2-s2.0-85209802100,Movies / Media
Bise K.; Saitoh T.; Tsuchiya K.; Sato H.; Nakamura K.; Abe T.; Coffey F.,"Bise, Kazuya (59155723400); Saitoh, Takeshi (13006364300); Tsuchiya, Keiko (56074166000); Sato, Hitoshi (59155909700); Nakamura, Kyota (8561675300); Abe, Takeru (23466146400); Coffey, Frank (36961914100)",59155723400; 13006364300; 56074166000; 59155909700; 8561675300; 23466146400; 36961914100,Joint Attention Detection Using First-Person Points-of-View Video,2024,"Proceedings - 2024 2nd International Conference on Computer Graphics and Image Processing, CGIP 2024",,,,118,123,5.0,1,10.1109/CGIP62525.2024.00029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195118963&doi=10.1109%2fCGIP62525.2024.00029&partnerID=40&md5=45a1294b2499b4423becaa4514236424,"Both verbal and nonverbal communication is important to facilitate collaborative activities by multiple people. This study focused on eye gaze as a form of nonverbal communication. The proposed method consists of a local feature-matching method, an object detection method, and a combination of the two. A simulated scene was designed and filmed to evaluate the proposed method quantitatively. Experimental results show that the proposed method can achieve high accuracy when applied to local feature-matching. Furthermore, the effectiveness of the proposed method was confirmed by shooting a real scene of a medical procedure in a hospital.  © 2024 IEEE.",communication; first-person points-of-view video; image matching; Joint attention; local feature matching; object detection,Feature extraction; Object recognition; Attention detection; Features matching; First person; First-person point-of-view video; Joint attention; Local feature; Local feature matching; Non-verbal communications; Objects detection; Verbal communications; Object detection,Conference paper,Final,,Scopus,2-s2.0-85195118963,Movies / Media
